{"title": "How to See the 'Ring of Fire' Annular Solar Eclipse of October 14", "date": "2023-09-29 10:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nThis annular solar eclipse will only reveal its full glory to a select few, but onlookers across much of the Western Hemisphere can catch a partial glimpse of the dazzling phenomenon\nPeople in parts of the U.S., Mexico, and Central and South America are in for a rare celestial treat in October: an annular eclipse of the sun.\nAn annular eclipse is similar to a total solar eclipse, in which the moon completely covers the sun’s face, except at the former’s peak, the moon is too small in the sky to fully blot out our home star. This creates a bright ring of sunlight around a dark lunar silhouette—thus the name “annular,” which means “ring-shaped.” (Some people prefer to simply call an annular eclipse a “ring of fire” instead.)\nSolar eclipses happen when the moon passes directly in front of the sun—essentially, our natural satellite’s shadow sweeps across the surface of Earth. If the moon orbited in the same plane as Earth orbits the sun, we’d get a solar eclipse every 29 days—the length of time it takes the moon to move around our planet, relative to the sun. But the moon’s orbit is actually tipped, inclined by about five degrees to that of Earth.\nLike two Hula-Hoops, one inside the other and tipped, the path the sun appears to take around the sky once per year and the moon’s monthly orbit intersect at two points, called nodes. We only get a solar eclipse when both the sun and moon are at a node at the same time; otherwise the moon “misses” the sun in the sky, passing it above or below. Most of the time the two don’t line up perfectly, resulting in a partial solar eclipse, in which the moon blocks only a fraction of the sun’s face.\nIf they line up just right, the entirety of the sun’s Earth-facing hemisphere is blocked, and we get the glory of a total solar eclipse. The sky gets dark, and the sun’s ethereal outer atmosphere, called its corona, pops into prominence. I was in Wyoming for the 2017 total solar eclipse, and it was, without exaggeration, one of the most beautiful and moving events I have ever witnessed. The U.S. will be treated to another one of these incredible phenomena on April 8, 2024.\nBut sooner than that—on October 14, to be specific—yet another factor will come into play: the moon’s distance from Earth.\nBy an amazing coincidence, on average, the sun is 400 times farther away from Earth and 400 times physically bigger than the moon. These two effects cancel out, so the sun and moon are the same apparent size in the sky: about half a degree, or half the width of your extended pinky seen at arm’s length.\nThe moon doesn’t orbit Earth in a circle, however, but in an ellipse. At its closest, the point in its orbit called perigee, the moon is roughly 355,000 kilometers from the surface of Earth. At its farthest—apogee—it’s about 397,000 km. That change of about 10 percent in distance means that the moon’s apparent size in the sky changes by 10 percent over the course of half an orbit. So at its apogee, the moon can appear to be smaller than the sun.\nThe moon reaches apogee on October 9, just five days before this upcoming eclipse. It will be about 391,000 km from Earth—more or less. The exact figure depends on other factors, such as the latitude and longitude of the observer, the time of day, and so on. At that distance, it will appear to be 0.51 degree across. At the same time, Earth and the sun will be at almost exactly their average separation, 149 million km, so the sun will appear as a disk about 0.54 degree in size.\nAnd that makes all the difference in the worlds. The moon will be too small to completely cover the sun. Instead it will leave a ring—an annulus—around it as it passes, creating this annular eclipse. At most, 91 percent of the sun’s surface will be covered by the moon, so technically this will be a partial eclipse—but a very special, perfectly centered one.\nThe eclipse will have three main stages: first contact, annularity and last contact. First contact will be when the moon’s edge first appear to touch the edge of the sun. Over time, as the moon moves, it will appear to eat more and more of our star’s disk. About 70 to 90 minutes after first contact, depending on your location, the annularity will occur. It will last from one to five minutes, also depending on location. Then the moon will start to leave the sun’s face. Our natural satellite will take another 70 to 90 minutes to completely move off the star (last contact).\nThat’s how the eclipse will work. So how can you see it?\nFirst, there is no safe time to watch this with your naked eye! Throughout the eclipse’s duration, the sun will be visible, so you will need adequate eye protection. (Do not just use sunglasses, exposed film or welder’s glasses.) A lot of companies sell “eclipse glasses”—usually a paper frame with heavily filtered plastic film to look through—but not all of these are safe. The American Astronomical Society has a list of trusted vendors that have glasses that are compliant with the ISO 12312-2, the International Organization for Standardization’s (ISO’s) safety standard for directly viewing the sun. I’ll add that Astronomy for Equity sells them in bulk, and the money they organization makes from those sales goes toward excellent causes.\nA fun way to observe this event is with a pinhole projector. A small hole poked into a piece of cardboard will allow sunlight through as parallel rays—that is, as focused light suitable for imaging. You can then hold it up and project the resulting rays onto a sheet of white paper, a sidewalk or even the bare ground. You’ll see a lovely perfect little image of the sun as the moon eats away at it. Foliage can produce a similar effect as well (overlapping leaves make lots of little holes), so you can see dozens or even hundreds of images of the sun on the ground below most trees.\nOn the morning of October 14, the path of the moon’s shadow will start over the Pacific Ocean. The exact time it will reach any given spot will depend on the location and the time zone. For example, Eugene, Ore., the first big city to see annularity, will get the first contact at 8:06 A.M. PDT, the annularity for four minutes starting at 9:16 A.M. and then the last contact at 10:39 A.M. The moon’s shadow will move southeast, passing over extremely northeastern California, Nevada, Utah, extremely northeastern Arizona, New Mexico and then Texas. After that it will pass over the Yucatán peninsula in Mexico, followed by southern Central America and then northern South America before moving off onto the Atlantic Ocean.\nAstronomer and long-time umbraphile (literally, “shadow lover”) Fred Espenak has created an interactive map for the eclipse path. Just zoom in and click anywhere to get detailed information on timing.\nI’ll add that the entire continental U.S. will see at least a partial eclipse, but only those along the narrow shadow path will be able to view the ring of fire. NASA has an excellent website with loads of information about the eclipse. SciStarter, a terrific program that promotes “citizen science” projects, has a list of scientific projects you can participate in as well—excellent prep for next year’s total solar eclipse. The American Astronomical Society also has an app (available for iOS and Android devices) called Totality 3.0, which has a ton of information about this eclipse and next year’s total one, too.\nI’ve never seen an annular eclipse, and from my location in Virginia, only be about one third of the sun will be covered. But if you’re in the path of annularity, and you’re able to do so, go out and take a look (safely, please)! Although it’s perhaps not as grand as a total solar eclipse, it’s still a fascinating and rare astronomical phenomenon and one well worth your time to observe.\nPhil Plait is a professional astronomer and science communicator in Colorado. He writes the Bad Astronomy Newsletter. Credit: Nick Higgins\nEdwin L. Turner\nSusana Martinez-Conde and Stephen L. Macknik\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Song of the Stars, Part 3: The Universe in all Senses", "date": "2023-09-29 11:00:00", "text": "An astronomy festival in Italy opted to make all of its events and workshops multisensory. They wanted to see whether sound, touch and smell can, like sight, transmit the wonders of the cosmos.\n[CLIP: Music]\nTimmy Broderick: So I’m sitting inside this stone clock tower in the small town of Castellaro Lagusello in Italy. It’s pretty old, like 800 years old. I had found a nook in this tower where I could sit and record this ethereal music coming from the speaker in front of me. And through the slit of a window behind me, I could watch Italians mill about below.\nJason Drakeford: So Timmy, why are you being a recluse in this tower instead of talking with people on the ground?\nBroderick: [Laughs.] Well, it’s a fair question. I was gathering tape to be played on this podcast, but it was also my last day at the Universe in All Senses, it’s an astronomy festival. And I was pooped. For three days, I ran around this tiny, picturesque town capturing what was likely the first multisensory astronomy festival ever.\n[CLIP: Music]\nBroderick: Oh, does this sound familiar?\nDrakeford: Yes! That’s Matt Russo’s TRAPPIST-1 sonification that we listened to in the first episode!\nBroderick: Yeah! The festival organizers rigged up the clock tower to play a bunch of sonifications on a loop, and then at night, they’d project visualizations of these compositions onto the face of the clock tower.\n[CLIP: Show theme music]\nDrakeford: You are listening to Scientific American’s Science, Quickly. I’m Jason Drakeford.\nBroderick: And I’m Timmy Broderick. In the prior episode of this three-part Fascination, we dove into the origins of turning space data into sound. In this final episode, we’re traveling to Italy to see whether astronomical sonifications can help people with disabilities better understand the awe and wonder of the cosmos.\nBroderick [on tape]: Okay, so I’m walking around. Four thousand people at once is a lot…\nDrakeford: Okay so how did you even hear about this festival?\nBroderick: In January I wrote a story about this burgeoning movement in astronomy. One of my sources for that story was Anita Zanella. She’s an Italian astronomer who grew up playing with her relatives on the stone streets of Castellaro Lagusello. She told me about the festival.\nAnita Zanella: Castellaro has a lot of historical buildings. The villa and the lake are typical ones. The other important point for this little village is the tower, which is really the key part, the heart, of the village.\nBroderick: Castellaro has been holding an astronomy festival for a couple years now. But this is the first time it has really been multisensory. Every workshop, every talk, every event—all of them were available in at least two senses.\nZanella: Inclusion is the main focus this year. So being able to share the knowledge and the beauty of astronomy and the beauty of the universe with whoever, irrespective of disability and sensory limitations.\nBroderick: They also had these giant QR code-like signs set up around the festival to help blind people navigate and understand a workshop or exhibit.\nDrakeford: Uhuh.\nBroderick: It was pretty wild. My phone picked up the code from like 10 feet away!\nDrakeford: Woah, this is so cool!\n[CLIP: Festival sound]\nBroderick: Yeah. The highlight of the first evening was the keynote panel with Anita and two visually impaired astronomers, Nic Bonne and Enrique Pérez-Montero. You might remember Enrique from our last episode. The three of them discussed how to build a “multi-sensory discovery of the sky above us.”\n[CLIP: Festival sound]\nBroderick: After the discussion, I talked with Claudia Beschi. She’s 25, hails from nearby Mantova, wants to be a translator and just completed graduate school. She found the discussion fascinating. She’s also been blind since birth.\n[CLIP: “The Bullet Cluster” by Matt Russo] \nClaudia Beschi: I didn’t think it was possible to translate galaxies into sounds.... I felt like nature was talking to me.\nI believe that nature has its own sounds. And listening to that sound, it was as if that galaxy was telling something to me. Like this galaxy was describing itself to me.\nDrakeford: Woah. The galaxy was speaking to her. This is wild!\nBroderick: Yeah, I was actually really moved by that conversation. It stuck with me throughout the festival.\nAnd so the next day was the first, like, full day. There was a lot going on. We had a bunch of workshops happening. We had a radio wave scavenger hunt, we had comet smelling, there was crafting galaxies out of felt and other fabrics, and also last but definitely not least, banging pots and pans to represent stellar energies.\n[CLIP: Pots and pans banging]\nAll of the workshops were staffed by local kids who could teach the attendees and especially the young kids. Elisa Zaltieri goes to high school in Mantova, and she ran the pots and pans station.\nZaltieri: It's an activity about how stars are actually different. We make child play pots actually.\nBroderick (tape): So what are you gonna have these kids do?\nZaltieri: We have to make them recognize how stars are different and then we have to make them play, like, if they were stars.\nWe were trying to explain to them that [for] the biggest star, play the hardest. And the smallest, play lower, actually, because they have less energy.\nBroderick (tape): So if you play really loudly, you'll have more energy; if you play really softly, you’ll have less energy?\nZaltieri: Yep!\n[CLIP: Pots and pans banging]\nBroderick: While the festival was ostensibly for kids, there were many workshops and events for adults.\nMattia Grella: I’m Mattia, 33, and I’m from Verona, quite close by.\nBroderick: Mattia came to the festival for a couple of reasons. He knows one of the organizers, but he is also passionate about astronomy. He’s a hardcore Trekkie, as well. I met him at one of the workshops. He was creating a kind of patch made from different fabric textures. It was supposed to represent the different parts of a galaxy.\nGrella: It’s smooth and kind of wavy, soft but not really smooth, kind of like the music we listened to before. It was a piece played on the piano. It was a soft piece, but played with the piano, it also had kind of a certain rhythm to it. So these little waves, at least to me, they represent this softness but also this movement.\nBroderick: Mattia has been visually impaired since birth. His version of space is definitely not the inky, black expanse that you or I perceive it as.\nGrella: I know the stars are classified like yellow dwarfs, red giants. And in my head, I imagined them quite with vivid colors, but I have no idea if they’re like basically white with a slight shade of yellow, red, or if they’re as vivid as I imagine them.\n[CLIP: “SgrA Chandra” by Matt Russo] \nDrakeford: So what did you think? Was the festival successful?\nBroderick: To be honest, I’m not sure. It was definitely fun! Like, everyone I saw was having a great time and really engaged with astronomy. But I didn’t really see many people using those giant QR codes. I know that there was bus trouble that kept many local blind and partially sighted people from coming to Castellaro.\nDrakeford: Were there a lot of visually impaired people there?\n[CLIP: “The Galactic Center” by Matt Russo] \nBroderick: I don’t know how many of the 4,000 attendees were blind or visually impaired. Neither do the festival organizers. That’s just unknowable. What I do know is that for the blind people I talked with — for Claudia, for Mattia — the festival and sonifications were really helpful. Claudia was there for one night, but she was thrilled by what she heard.\nBeschi: I don’t know if I will see the world in a different way in the future, but I’m sure that this experience, in a way, taught something positive to me. Because I love nature. I think that nature speaks to us in every way possible. And these translations into sound and into tactile modes is a really good way to get in touch with nature, especially for us because we can’t, we can’t see how nature is really made of.\n[CLIP: Outro music]\nBroderick: Science, Quickly is produced by Jeff DelViscio, Tulika Bose, Kelso Harper and Carin Leong. Our theme music was composed by Dominic Smith. Matt Russo provided the sonifications you heard in this episode.\nDrakeford: Don’t forget to subscribe to Science, Quickly wherever you get your podcasts. For more in-depth science news and features, go to ScientificAmerican.com. And if you liked the show, give us a rating or review.\nBroderick: For Scientific American’s Science, Quickly, I’m Timmy Broderick.\nDrakeford: And I’m Jason Drakeford. See you next time!\nTimmy Broderick is a news intern covering energy, disability and disaster at Scientific American. Follow them on Twitter @broderick_timmy\nDocumentary filmmaker, video journalist and educator telling true, impactful stories with motion graphics and cinematic visuals. Follow Jason Drakeford on Twitter\nCarin Leong is a multimedia intern producing podcasts and videos at Scientific American. Follow Carin Leong on Twitter\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "EPA's Critics Recycle Nonsense about Cost to Cut Pollution", "date": "2023-09-29 11:30:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nFor decades industry has claimed that curbing pollution costs too much, but the reality has proven otherwise. Here we go again, this time on power plant carbon emissions\nAs young lawyers, working out of the dusty attic in an aging townhouse, a few of us were given a simple but monumental task: figure out how to make a new law—the Clean Air Act—work.\nThe struggle for clean air we engaged in five decades ago is, sadly, relevant once again as the Environmental Protection Agency moves to create the first carbon standards for power plants.\nIn 1971 the EPA was less than a year old, and Congress had given it just a few months to set limits to pollutants, such as sulfur dioxide, that harm our lungs and can cause asthma. The EPA moved quickly, issuing rules that year mandating that new coal-fired power plants either install scrubbers or burn low-sulfur coal.\nScrubbers act like chemical cleaners of smokestack exhaust. While ubiquitous now, only a few were then in operation. Still, the EPA determined the equipment would perform well once the standards were in place. What happened next would not surprise anyone who has followed the Clean Air Act for the past five decades: the electric companies howled.\nIn a full-page New York Times advertisement, American Electric Power claimed that scrubbers have been “time and time again proven too unreliable, too impractical for electric utility use.” It concluded: “If the system doesn’t clog and shut down, it creates massive amounts of sludge.”\nUnder pressure from coal-heavy utilities and their congressional allies, the EPA undertook nationwide listening sessions where the agency’s new bureaucrats were bombarded with criticism: the new rules relied on unproven technology; the compliance deadline was too tight; jobs would be lost; the electricity grid would falter; prices would skyrocket, and the American economy would suffer a monumental toll.\nI watched all this blowback with alarm, wondering if the EPA and Congress would back down. In the end, the utilities and coal companies managed to secure a few short delays and technical tweaks, but the EPA—with support and legal pressure from the Natural Resources Defense Council (where I still work today)—stuck by its crucial pollution control requirements for those new plants.\nWhen the companies’ lawyers failed to block the rules, the companies’ engineers took over. And they delivered.\nSulfur dioxide pollution has fallen by more than 90 percent in the U.S., thanks to EPA rules—one of the great environmental protection achievements in the history of the U.S. The EPA found that without the clean air standards put in place after 1970, 205,000 more Americans would have died prematurely over the subsequent two decades, and millions more would have suffered illnesses ranging from asthma to high blood pressure. The economic benefits in just those two decades are stunning, with estimates ranging from $6 trillion to $50 trillion.\nOver the past five decades, however, the electricity industry has kept crying wolf whenever the EPA proposes new pollution limits.\nWhether it was the acid rain programs in the 1990s or the EPA rules to cut mercury and other toxic air pollutants in 2012, the industry’s playbook remains the same: Sure, we want to protect public health and the environment, they will say, but your rules—now the power plant carbon standards— are too much, too fast, too expensive. We won’t be able to keep delivering reliable electricity.\nAnd, just as with sulfur dioxide, once the rules are in place and the company engineers get to work, deadlines are met, pollution is cut—and the American economy keeps humming along. In fact, in nearly every case the power sector has cut pollution faster and for less money than the EPA forecast.\nAnd so, here we are today.\nIn May, the EPA proposed critical standards to cut carbon pollution from power plants. Long overdue, they come 14 years after EPA determined that carbon dioxide endangers our health and well-being by driving destructive climate change. The standards, which would phase in requirements on coal and gas plants over a decade or more, are an important piece of the puzzle to address the climate crisis.\nGiven market trends toward cheaper wind and solar energy and the billions of dollars of clean energy incentives in last year’s Inflation Reduction Act, the electricity sector is changing. Clean energy is on the rise. These rules will ensure those economic and carbon reduction benefits are fully delivered.\nMany utilities have publicly committed to cut their carbon emissions, some laying out plans to get to net zero by 2050, and mostly there by the mid-2030s. But now that the EPA is actually setting rules to make sure they follow that path, the familiar arguments are back: This is too much and too fast. The EPA rules will endanger grid reliability. And the costs—oh my!\nNonsense. Fifty years of experience tell us that when companies stop relying on their lawyers, their engineers and grid experts know how to keep the lights on. And the EPA’s proposed rules allow for exceptions, extensions and waivers if real reliability problems should crop up, so that power companies can keep their plants operating when needed.   \nAnd, in fact, we’ve been here before.\nBack in 2015, the Obama administration adopted the first carbon pollution standards for power plants with rules aimed at delivering a 32-percent reduction in power plant emissions by 2030. Big industry dusted off the old playbook. The U.S. Chamber of Commerce argued: “It will drive up electricity costs for businesses, consumers and families, [and] impose tens of billions in annual compliance costs.” The North American Electric Reliability Corporation, NERC, a nonprofit that oversees the system, said the “proposed timeline does not provide enough time to develop sufficient resources to ensure continued reliable operation of the electric grid.” And coal industry interests went to court to block the rule. In a rare move, the Supreme Court stepped in to stay the EPA standards.\nThe Clean Power Plan never went into effect.\nBut then something remarkable happened: While the rules were on hold, the U.S. hit the Clean Power Plan targets of a 32-percent reduction in carbon emissions—11 years early! Again, even with no rules in place, the power sector achieved what industry claimed would lead to steep costs and reliability problems.\nCheaper, cleaner options have replaced many old fossil-fuel plants. With the historic support from tax incentives passed by Congress, new technologies are coming online quickly. And the grid continues to deliver cleaner, affordable, reliable electricity. But, given the climate crisis, we need new standards now to cut carbon pollution faster.\nIt’s time for industry to throw away its old playbook and put its engineers to work.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.\nDavid Hawkins is a senior attorney with the Natural Resources Defense Council. He served as the EPA assistant administrator for Air, Noise and Radiation in the Carter administration.\nTyler Carroll\nDaniel Garisto\nShannon Hall and Nature magazine\nAvery Ellfeldt and E&E News\nTanya Lewis\nSophie Bushwick and Lauren Leffer\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "What Humans Lose When AI Writes for Us", "date": "2023-09-29 12:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nIn Who Wrote This? linguist Naomi S. Baron discusses how artificial intelligence threatens our ability to express ourselves\nArtificial intelligence has pervaded much of our daily life, whether it’s in the form of scarily believable deepfakes, online news containing “written by AI” taglines or novel tools that could diagnose health conditions. It can feel like everything we do is run through some sort of software, interpreted by some mysterious program and kept on a server who knows where. When will the robots take over already? Have they already taken over?\nThe recent developments in AI offer existential questions we’ve been wrestling with since we put pen to proverbial paper: Who wrote this, and can I trust it? Fake news is old news, but some still argue over whether Shakespeare existed or represented multiple authors. Large language models (LLMs) are combinations of authors, each with their own style, voice and expertise. If the generative AI program ChatGPT keeps trying—and we keep feeding it Shakespeare—will it write our next great tragedy?\nLinguist Naomi S. Baron of American University has been wading in the AI waters for years. In her latest book, Who Wrote This? How AI and the Lure of Efficiency Threaten Human Writing, she dives into the crux of the matter: If we hand over the written word to AI, what will we lose? Scientific American spoke with Baron on the issue of the ownership and trustworthiness of written communication now that AI is on the scene.\n[An edited transcript of the interview follows.]\nDid you use ChatGPT to write any of this book?\nSort of but just a smidge. I completed Who Wrote This? in mid-November 2022, two weeks before ChatGPT burst on the scene. It was a no-brainer that I needed to incorporate something about the new wonder bot.\nMy solution was to query ChatGPT about the intersection of this cutting-edge form of AI with issues such as creativity, education and copyright. In the book, I quote some of ChatGPT’s responses.\nWhen I asked ChatGPT if it could hold copyright on short stories that it authored, the answer was “no” the first time I asked and “yes” the second. The discrepancy reflected the particular part of the dataset that the program dipped into. For the “no” answer, ChatGPT informed me that as an LLM, it was “not capable of holding copyrights or owning any form of intellectual property.”\nBy U.S. copyright law, that’s true. But for the “yes” response, the bot invoked other aspects of U.S. copyright: “In order for a work to be protected by copyright, it must be original and fixed in a tangible form, such as being written down or recorded. If a short story written by GPT meets these criteria, [ChatGPT said], then it would be eligible for copyright protection.\nConsistency is the hobgoblin of large language models.\nWhen thinking about AI-written news, is it all just a snake eating its own tail? Is AI writing just fodder to train other AIs on?\nYou’re right. The only thing relevant to a large language dataset is having text to consume. AI isn’t sentient, and it’s incapable of caring about the source.\nBut what happens to human communication when it’s my bot talking to your bot? Microsoft, Google and others are building out AI-infused e-mail functions that increasingly “read” what’s in our inbox and then draft replies for us. Today’s AI tools can learn your writing style and produce a reasonable facsimile of what you might have written yourself.\nMy concern is that it’s all too tempting to yield to such wiles in the name of saving time and minimizing effort. Whatever else makes us human, the ability to use words and grammar for expressing our thoughts and feelings is a critical chunk of that essence.\nIn your book, you write, “We domesticate technology.” But what does that “domestication” look like for AI?\nThink about our canine companions. They descended from wolves, and it took many years, plus evolution, for some of their species to evolve into dogs, to be domesticated.\nSocial scientists talk about “domestication” of technology. Forty years ago personal computers were novelties. Now they’re ubiquitous, as are software programs running on them. Even Wikipedia—once seen as a dubious information source—has become domesticated.\nWe take editing tools such as spell-check and autocomplete and predictive texting for granted. The same goes for translation programs. What remains to be seen is how domesticated we will make text-generation programs, such as ChatGPT, that create documents out of whole virtual cloth.\nHow has your understanding of AI and LLMs changed how you read and approach writing?\nWhat a difference three years makes! For my own writing, I remain old-fashioned. I sometimes still draft by hand. By contrast, in my role as a university professor, I’ve changed how I approach students’ written work. In years past I assumed the text was their own—not so today. With AI-infused editing and style programs such as Microsoft Editor or Grammarly, not to mention full-blown text-generation tools, at students’ beck and call, I no longer know who wrote what.\nWhat are the AI programs that you feel are the least threatening, or that you think should be embraced?\nAI’s writing ability is an incredible tour de force. But like the discovery of fire, we must figure out how best to harness it. Given the novelty of current programs, it will take at least several years to feel our way.\nToday’s translation programs, while not perfect, are remarkably good, and the benefit is that everyday users who don’t know a language can get immediate access to documents they would have no other way of reading. Of course, a potential drawback is losing motivation for learning foreign languages.\nAnother promising use of generative AI is for editing human-generated text. I’m enthusiastic when AI becomes a pedagogical tool but less so when it simply mops up after the writer, with no lessons learned. It’s on users to be active participants in the composition process.\nAs you say in your book, there is a risk of valuing the speed and potential efficiency of ChatGPT over the development of human skills. With the benefit of spell-check, we can lose our own spelling proficiency. What do you think we’ll similarly lose first from ChatGPT’s ability to write legal documents, e-mails or even news articles?\nAs I argue in my book, the journalism business will likely feel the effects on employment numbers, though I’m not so much worried about the writing skills of the journalists who remain.\nE-mails are a more nuanced story. On the one hand, if you use Microsoft Outlook or Gmail, you’ve already been seeing a lot of autocomplete when you write e-mails. On the other hand, the new versions of AI (think of GPT-4) are writing entire e-mails on their own. It can now literally be my bot writing to your bot. I worry that the likes of ChatGPT will lull us into not caring about crafting our own messages, in our own voice, with our own sentiments, when writing to people who are personally important to us.\nWhat do you think of the recent and potential copyright infringement cases involving authors or publishers and ChatGPT?\nThe copyright infringement cases are interesting because we really are in uncharted territory. You’ll remember the case of the The Authors Guild v. Google, where the guild claimed Google Books enabled copyright infringement when it digitized books without permission and then displayed snippets. After many years of litigation, Google won ... under the ruling of fair use.\nFrom what I’ve been reading from lawyers who are copyright experts, I suspect that OpenAI [the company that developed ChatGPT] will end up winning as well. But here’s the difference from the Authors Guild case: With Google Books, authors stood to lose royalties because users of Google Books were presumably less likely to purchase copies of the books themselves. With ChatGPT, however, if a user invokes the bot to generate a text, and then said user looks to sell that text for a profit, it could be a different ball game. This is the basis of cases in the world of generative art. It’s a brave new legal world.\nBrianne Kane is senior editorial coordinator at Scientific American.\nTamlyn Hunt | Opinion\nTim Hornyak and Nature magazine\nSophie Bushwick, Kelso Harper and Jeffery DelViscio\nAnanya\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Stop Trying to 'Find' Your Passion--There's a Better Way to Love What You Do", "date": "2023-09-29 13:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nRecognizing that interests are malleable and can be developed can make us more resilient, open and creative\n“Find your passion!” Whether we hear it from our parents, teachers, bosses or college commencement speakers, this injunction is woven into the fabric of American culture. It is well-intended and meant to inspire. But is it good advice?\n“Finding” a passion implies that it already exists fully formed and is simply waiting to be discovered. Unfortunately, this idea doesn’t square with what science tells us. Instead passions, like interests, are developed. They often begin with a spark of curiosity caused by something in one’s environment, such as a fascinating physics lecture or a moving piece of art. Through a process involving repeated engagement, positive experiences and accrued knowledge, people can come to personally value that content or activity and internalize it. What was at first interesting becomes an interest. If these qualities continue to intensify, a passion can emerge.\nIn several studies, we and our colleagues have found that misunderstanding this idea can hold people back. Assuming passions are immutable and essential—rather than something to cultivate and build—can cause people to be less open to different topics, less resilient to challenges in pursuit of new interests and less creative when problem-solving. Fortunately, our latest research reveals that there are ways to correct course and cultivate a more open, accurate perspective about interest.\nTo study these ideas, we use a framework of “fixed” and “growth” mindsets, which may be familiar from educational research. In school, conceiving of one’s intellectual abilities as fixed can be detrimental, whereas believing one can develop and grow skills supports greater learning. We argue that encouraging people to “find” their passion may cause them to eventually believe that interests and passions are inherent and relatively unchangeable. People who think this have a fixed mindset of interest. By contrast, some people, whom we refer to as having a growth mindset of interest, view their interests and passions as developed.\nOur work has revealed that fixed and growth mindsets about interest are distinct from fixed and growth mindsets surrounding intellectual abilities. We have also repeatedly found that a growth mindset of interest comes with many advantages. People with a fixed mindset of interest, for example, may fall into the trap of thinking, “If I have already found my passion, why keep exploring?” In our studies, after engaging in a new science task, arts students with a fixed mindset expressed less interest in that scientific topic than arts students with a growth mindset. Meanwhile science students with a fixed mindset responded similarly to an art-related task. For those with a growth mindset, having a strong pre-existing interest in the arts or sciences did not preclude them from viewing a new area as interesting.\nIn addition, people with a fixed mindset of interest tend to expect their passions to provide limitless motivation, such that their favorite topics should never feel too difficult or demanding. In one study we tested this idea by sparking people’s interest in a topic that was new for them—the science of black holes—with a fun, easy-to-understand animated video about Stephen Hawking’s theories. But when we next asked our participants to read a dense and complex article on black holes from a scientific journal, people with a fixed mindset were frustrated by the technical reading and came to dislike the topic. Meanwhile those with a growth mindset maintained their newfound interest despite the difficulty.\nA fixed mindset of interest can also inhibit creativity and innovation. If people believe they are limited to only a few inherent interests and, in consequence, do not explore other areas, they may miss seeing important connections across different domains. When we recruited undergraduates who identified as either an “arts person” or a “sciences person,” we found that those with a fixed mindset were less likely than those with a growth mindset to generate novel solutions—for example, ideas for new university programs—that integrated the arts and sciences. In other words, seeing interests as fixed stymied their creative potential. That loss is especially unfortunate when we consider how leaders at innovative companies have long prized problem-solving that melds ideas from diverse disciplines and brings together science, technology, art and the humanities.\nSo can a growth mindset of interest be taught? In June we published findings from an intervention that succeeded in that aim. In two studies involving more than 700 first-year liberal arts undergraduates in total, we began by assessing how our participants saw themselves. The majority held strong interests in the arts, humanities and social sciences. Moreover, most reported that they were not a “math-and-science person.” We then randomly assigned students to either our intervention or a study skills module. Both programs were online and took most students less than half an hour to complete during their university orientation week.\nOur intervention included reading and reflective writing activities that helped students think about interests and passions as cultivated rather than as simply found and fixed. For example, the students read a short article that presented research on the benefits of viewing interests as developable. They also wrote a paragraph about an occasion when they developed interest in a new activity. We were careful to present this material in a neutral way—not as a corrective of their current behavior but rather as part of an exercise by their college to better support students’ transition to college. The study skills module had a similar set of exercises but with an emphasis on building classic skills, such as time management and active learning.\nImportantly, these students were required to take at least one math and science course during their first year. That meant we could check how the intervention may have influenced their perspectives on math and science. By the end of the year, students who had received the intervention were more interested in their required math and science courses than those who received the study skills module—and this boost was particularly apparent among students who initially reported that they were not a “math-and-science person.” They also earned better grades in those courses than their counterparts who had received the study skills module. These students, who might have otherwise eschewed these disciplines, became more skilled in math and science and grew into interdisciplinary scholars.\nAlthough our intervention offers a way for schools to support students in cultivating a growth mindset, we believe people can do a lot independently to embrace this way of thinking. First, realize that your interests and passions aren’t pre-existing and waiting to be “found.” Take an active role in developing your passions. Indulge your curiosities, get involved, and don’t expect that pursuing new interests will always be easy or exciting. If you’re a parent, teacher or boss, consider how you might foster a growth mindset of interest in others. Create opportunities for them to pursue their curiosities and interests and engender a culture that rewards exploration; the seeds of passion cannot grow in infertile soil. Of course, exploration can at times lead to failure or disappointment, so communicating that such negative experiences are normal will help others stay motivated through challenges. Finally, consider how you phrase feedback. When someone expresses waning interest in a novel task, signal that interests can develop with time and engagement.\nOf course, not every activity will become a burning passion. But a growth mindset of interest will help you remain open and curious. The old saying “find something you love to do, and you’ll never have to work a day in your life” needs to be updated. The science tells us we should instead work toward loving what we do. We might expand our horizons and become more creative and resilient as a result.\nAre you a scientist who specializes in neuroscience, cognitive science or psychology? And have you read a recent peer-reviewed paper that you would like to write about for Mind Matters? Please send suggestions to Scientific American’s Mind Matters editor Daisy Yuhas at pitchmindmatters@gmail.com.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.\nPaul A. O'Keefe, Ph.D., is an associate professor of organizational behavior at the University of Exeter Business School in England. He studies the roles of mindsets in the pursuit of challenging goals and designs interventions to remove psychological barriers that can impede success and flourishing.\nE. J. Horberg, Ph.D., is a senior research fellow at Yale-NUS College in Singapore. She studies motivation, emotion, the self, socioeconomic status, culture and moral judgment.\nTyler Carroll\nDaniel Garisto\nShannon Hall and Nature magazine\nAvery Ellfeldt and E&E News\nTanya Lewis\nSophie Bushwick and Lauren Leffer\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Eaten, Crushed or Starved; Male Tarantulas Trade Their Life to Impregnate a Mate", "date": "2023-09-29 15:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nAfter eight years maturing in a burrow, male tarantulas venture out to mate, then die a cruel death\nOn an early evening in September, 16 dark, hairy legs were kicking up dust on the prairie floor in La Junta, Colo. A male Oklahoma brown tarantula was locked in a heated mating match with a female twice his age. Although weary, he plunged a set of hooks that had recently grown on his front legs into his mate’s mouth, just below her glossy fangs, to prevent her from chewing him up.\nThe intense ritual was taking place across the arid grasslands of southeastern Colorado, where the tarantula mating season spans September. Female tarantulas can live multiple decades and never travel more than a few inches from their burrows. Males mature in seven to 10 years, and when they finally venture beyond their burrows, they have only one goal—mate—and then their life’s job is done.\n“They weren’t evolved to survive,” says entomologist Maia Holmes, education and outreach coordinator at the department of agricultural biology at Colorado State University. “They are at the end of their life cycles, and this is their last hurrah.” Similar fates await male tarantulas in other western U.S. states, in Central and South America, and around the world.\nUsing a specialized appendage near his mouth called a pedipalp, the male spider reached forward and carefully slid a packet of sperm into the female’s abdominal cavity. The package contained enough sperm to fertilize upward of 1,500 eggs. Typically only a few spiders from a clutch of hundreds survive into adulthood; offspring only need to replace their parents to sustain a population.\nOnce our male—let’s call him Spiderman—carefully extracted his hooks from his mate’s fangs, he dropped to the ground and scurried backward while the female was still reared up like a horse on her hind legs. All tarantulas are nearly blind their whole life, so he was fleeing by feel.\nSpiderman might have tried to mate again, if he could summon the energy. But in the following weeks only one thing was certain: he would perish. Spiderman didn’t die like his father may have: eaten head-first by his female mate. Both ravenous and bold, the mother would strike the father’s head with her venom as soon as he finished gifting his sperm and immediately take a bite from his left “temple.” Spiderman had picked a mate who, luckily for him, had recently eaten.\nOur protagonist didn’t die like his brother may have either. The sibling, let’s call him Brother, was taken captive by a tarantula hawk, a massive spider wasp that grows to two inches long. Tarantula hawks are pollinators, sampling nectar from flowering plants, but when it’s time to raise their young, the females of the species take on a different demeanor.\nBrother had just stopped to rest on a quiet patch of dirt when he was attacked. For several minutes the wasp circled him, flitting in and out with the agile prodding of a fencer. Brother did what most tarantulas do when they feel threatened: he froze. The wasp turned upside down and maneuvered under Brother’s abdomen to search for a soft spot, like a mechanic sliding under the chassis of a car, and injected his paralyzing venom there.\nThe tarantula hawk dragged his paralyzed but living prey into Brother’s own den and laid a single egg on his abdomen. Over the next couple of weeks, the egg hatched, and the developing insect that emerged ate its way through Brother’s tissues, saving vital organs for last so that he stayed alive and fresh, though starved, for as long as possible.\nFortunately, Spiderman also didn’t die like any number of his cousins—crushed by a semitruck while scrambling across a street in search of a mate. Moments before they die this way, the poor-sighted tarantulas can sense a vehicle’s vibrations through their highly sensitive paws on the pavement, but by then it’s too late. And as habitat fragmentation continues, and humans’ footprint on the landscape widens, this fate will become increasingly common.\nOur Spiderman died a slower death. After mating, he lost interest in food. He became weak because the majority of his energy reserves went to sperm production. He managed to avoid tarantula hawks and roads. But as he continued to lose energy, his body became slower, more rigid. The blood pressure generated from his heartbeat slowed, causing his legs to curl inward—what’s known in the spider world as the “death curl.” It was also time for him to molt his exoskeleton, an impossible feat that sealed his fate. “Molting is like pulling yourself from a suit of armor without using your hands,” Holmes says. “And for a male spider who has mated, his hooks and reproductive parts prevent his molt from sliding off. They get stuck.”\nAs the hours went on, Spiderman twitched less. He stopped fighting. And as he lay there, curled up beside a halo of small yellow flowers—perhaps the very flowers pollinated by the wasp that killed his brother—he had no idea of the impact he had on the world. He had no idea that his position as a key predator in his ecosystem helped manage its insect population, no idea that his eight-legged form inspired robotic technology and innovations in artificial webbing and no idea of the future that a changing planet might have in store for his descendants.\nResearchers are trying to understand what climate change might do to tarantula populations. As temperatures warm, and flowers’ growing season extends later into the year, the pollinating tarantula hawks might be out later. Male tarantulas might be mating at a time when more wasps—more threats—are around, explains Richard Reading, vice president of science and conservation at an invertebrate zoo called the Butterfly Pavilion in Denver and an adjunct professor at the University of Denver. “Tarantulas also have a mechanical system to their movement; heat impacts that, too,” Reading says.\nBack in La Junta, Spiderman’s own mechanics were failing. In these final moments, his partially shed exoskeleton blocked his book lungs—delicate, platelike structures that allowed air to enter his body passively. He was running out of energy and now oxygen. But just moments before he faded away, a bushy-tailed Swift Fox no bigger than a house cat swiped him up and gobbled him.\nIn these grasslands, tarantulas are both prey for numerous species and top predators, crucial to keeping the insect populations at bay and the ecology in balance. “All creatures serve a purpose in the web of life. Every species contributes to the stability of an ecosystem,” Reading says.\nThe fox wandered into the night as the sun set over the dusty hills of La Junta, perhaps trotting over the very burrow that housed the female who now held the future of Spiderman’s bloodline. As humans, we often anthropomorphize the animal kingdom, and some of us may feel pity for our central character. But “there are no good guys or bad guys in nature–it’s all interconnected,” Holmes says. “Everything needs to exist for everything else to exist.”\nKatie Weeman is a science writer based in Denver, Colo., and communications director at the Colorado Water Conservation Board. Follow her on Twitter @katie_weeman\nMindy Weisberger and LiveScience\nJack Tamisiea\nFelicity Muth\nJohn R. Platt\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Controversy Surrounds Blockbuster Superconductivity Claim", "date": "2023-09-29 15:20:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nWill a possible breakthrough for room-temperature superconducting materials hold up to scrutiny?\nEditor’s Note (9/29/23): This article from March 10 reported on a study claiming the discovery of room-temperature superconducting material that was published in Nature. Earlier this week the Wall Street Journal reported that nearly three quarters of that paper’s co-authors had contacted the publisher to ask that the study be retracted because it had flaws. Nature confirmed that it is in contact with this group and plans to take action.\nThis week researchers claimed to have discovered a superconducting material that can shuttle electricity with no loss of energy under near-real-world conditions. But drama and controversy behind the scenes have many worried that the breakthrough may not hold up to scientific scrutiny.\n“If you were to find a room-temperature, room-pressure superconductor, you’d have a completely new host of technologies that would occur—that we haven’t even begun to dream about,” says Eva Zurek, a computational chemist at the University at Buffalo, who was not involved in the new study. “This could be a real game changer if it turns out to be correct.”\nScientists have been studying superconductors for more than a century. By carrying electricity without shedding energy in the form of heat, these materials could make it possible to create incredibly efficient power lines and electronics that never overheat. Superconductors also repel magnetic fields. This property lets researchers levitate magnets over a superconducting material as a fun experiment—and it could also lead to more efficient high-speed maglev trains. Additionally, these materials could produce super strong magnets for use in wind turbines, portable magnetic resonance imaging machines or even nuclear fusion power plants.\nThe only superconducting materials previously discovered require extreme conditions to function, which makes them impractical for many real-world applications. The first known superconductors had to be cooled with liquid helium to temperatures only a few degrees above absolute zero. In the 1980s researchers found superconductivity in a category of materials called cuprates, which work at higher temperatures yet still require cooling with liquid nitrogen. Since 2015 scientists have measured room-temperature superconductive behavior in hydrogen-rich materials called hydrides. but they have to be pressed in a sophisticated viselike instrument called a diamond anvil cell until they reach a pressure of about a quarter to half of that found near the center of Earth.\nThe new material, called nitrogen-doped lutetium hydride, is a blend of hydrogen, the rare-earth metal lutetium and nitrogen. Although this material also relies on a diamond anvil cell, the study found that it begins exhibiting superconductive behavior at a pressure of about 10,000 atmospheres—roughly 100 times lower than the pressures that other hydrides require. The new material is “much closer to ambient pressure than previous materials,” says David Ceperley, a condensed matter physicist at University of Illinois at Urbana-Champaign, who was not involved in the new study. He also notes that the material remains stable when stored at a room pressure of one atmosphere. “Previous stuff was only stable at a million atmospheres, so you couldn’t really take it out of the diamond anvil” cell, he says. “The fact that it’s stable at one atmosphere of pressure, that also means that it’d be easier to manufacture.”\nHydrogen is key to the new material’s superconducting ability and to that of any hydride. In the 1960s researchers first calculated that the metallic form of this element might be a superconductor. The idea is that superconductivity occurs when electrons pair up and form a new state of matter and that this could happen in the soup of electrons that surrounds a metal’s nuclei—particularly when those nuclei belong to ultralight hydrogen atoms. Unfortunately, making those atoms shift their phase from gas to metal would require extreme pressure—about one and a half times greater than pressures at the center of this planet. But if a hydrogen atom is combined with one or two other elements in the form of a hydride, researchers think the other atoms would compress the hydrogen, allowing it to attain a metallic state at lower, much more easily obtainable pressures. “We wanted to find the right rare-earth material to mimic these same metallic hydrogen properties as much lower pressures. So that’s where the lutetium metal came into the picture,” says study co-author Ranga Dias, a physicist at the University of Rochester. “And then the use of nitrogen is to stabilize these structures.”\nThe material, described in a Nature paper published this week, could raise hopes for other hydrides that lower the pressure requirements still further. Unfortunately, the work is dogged by controversy over previous papers by Dias and study co-author Ashkan Salamat, a physicist at the University of Nevada, Las Vegas. “There are two approaches possible. One is just ignore the past and look at this paper and just see what it is,” says Dirk van der Marel, a professor emeritus at the University of Geneva, who was not involved in the new study. “And if I do that, then it is a great paper.” The authors, he notes, used multiple tests of superconductivity, which provided an “extraordinary richness of data.” But van der Marel does not automatically trust these data, in part because of his experience analyzing previous work from the same authors.\nIn 2020 Dias, Salamat and their colleagues published a Nature paper describing room-temperature superconductivity in a different material, called carbonaceous sulfur hydride. Jorge Hirsch, a physicist at University of California, San Diego, questioned the appearance of data demonstrating the extent to which the material could become magnetized, referred to as its “magnetic susceptibility,” and called on the authors to release their raw data. This measurement is important because it indicates one sign of a superconductor: the ability to expel a magnetic field, a phenomenon called the Meissner effect. Because this measurement must be made while the superconducting hydride is in a diamond anvil cell, results contain background noise. To remove that noise, researchers take a separate measurement of the background and subtract it from the raw data to give the final magnetic susceptibility value. Dias and Salamat pushed back against Hirsch’s claims and eventually released the requested data. Hirsch and van der Marel worked together to analyze those data and concluded they had been processed in an unconventional way at best or had been manipulated at worst. Dias and Salamat contend that their processing method had been misunderstood.\nThe controversy drove Nature to retract the 2020 paper in 2022, a decision to which all its authors objected. Dias and Salamat say they stand by their results, and two investigations by the University of Rochester, where Dias works, found no wrongdoing. The authors also say they have rerun the original experiments at two different Department of Energy labs with outside observers present and that this effort verified the original results. “Time is a great peer-review process,” Salamat says. Dias says the researchers have updated their original paper as a preprint and resubmitted it to Nature. Other labs, however, have not been able to replicate the original results independently. But it can take a long time for a lab to reproduce and then test a specific material. The drawn out conflict has involved the release of multiple preprints, with neither side accepting the other’s arguments. And it eventually became so acrimonious that administrators of the preprint server arXiv.org removed papers from both parties and put Hirsch under a temporary publishing ban, which he objected to. “My papers analyzed the data and pointed out inconsistencies,” he says.\nHirsch previously earned a reputation as an outspoken critic of superconductivity research, but he and van der Marel were not the only researchers to investigate these authors. In addition to looking at magnetic susceptibility, James Hamlin, a physicist at the University of Florida, examined the electrical resistance data from the 2020 Nature paper. When a material reaches a superconducting state, its electrical resistance drops to zero. The measurement of this phenomenon does not require any processing to remove background noise like the magnetic susceptibility data do. Yet Hamlin notes that even the resistance data appeared to have undergone this processing, which was not disclosed in the paper. He finds Dias’s and Salamat’s responses to be insufficient explanations of these discrepancies. “They’ve kind of muddied the waters by publishing these things that have the appearance of a scientific argument,” Hamlin says. “But if you actually examine their response..., it just holds no water. And it does not address the concerns” raised by other researchers.\nHamlin went on to analyze a paper that Dias and Salamat published in Physical Review Letters (PRL) in 2021 in which they and their colleagues measured another hydride called manganese sulfide. Hamlin noted similarities between the electrical resistance data in the 2021 paper and those in Dias’s 2013 Ph.D. thesis, which had involved a completely different superconducting material. He shared these concerns with the journal and the paper’s authors. Salamat has since responded, suggesting that even though the two data sets may appear similar, the resemblance is not indicative of copied data. “We’ve shown that if you just overlay other people’s data qualitatively, a lot of things look the same,” he says. “This is a very unfair approach.”\nThis did not satisfy at least one of Salamat’s co-authors on the PRL paper: Simon A. J. Kimber, a former researcher, was disturbed to hear about the potential problem with the data and agrees with Hamlin’s conclusions. “I’ve been at this game for a long time, and I couldn’t think of a single reasonable explanation as to why those data sets should overlap like that,” he says. “I replied to everybody, to PRL’s editors, and said, ‘I think this should be retracted. I can’t think of any logical reason why this should be—retract, retract, retract.’” According to Jessica Thomas, executive editor at the journal’s publisher, the American Physical Society, editors are currently investigating these claims. “We take allegations of data fabrication very seriously,” she says. “At the same time, professional reputations are at stake, and we have to gather information thoughtfully and accurately. We also strive to ensure that the exchanges remain professional and respectful.”\nGiven the past controversies, Dias and Salamat took pains to test the new material thoroughly for their new paper, performing three different categories of experiments that suggest superconductivity had occurred. “The key fields that you wanted to provide, in order to prove superconductivity, is electrical resistance goes to zero, magnetic susceptibility—which is a demonstration of this expelling the magnetic fields—and heat capacity measurements. These are three different directions,” Dias says. “In this paper, our group has done all three measurements, including submeasurements,” such as two different measurements of magnetic susceptibility for both continuous and fluctuating fields.\nThe new paper also provides a “recipe” for other researchers who want to synthesize the new hydride and test it themselves, but the authors have not shared existing samples of the material. They are co-founding a start-up called Unearthly Materials to commercialize room-temperature superconductors and say they do not wish to reveal their intellectual property. “We have incredibly clear, detailed instructions on how to make these materials, like all of our studies. We just ask that the groups that are in denial ... go through the protocols themselves,” Salamat says. “We’re excited to see other groups replicate and push forward the field of high-temperature superconductivity.” Some researchers, such as Kimber, have stated they would not devote time and resources to replicating the results because they do not trust the new paper. But other superconducting labs may make the attempt.\nIf they do succeed at replicating these results, they could open up fascinating new lines of research. For instance, the exact structure of the new material is not yet fully understood. Salamat has used imaging methods that reveal where the heavy lutetium atoms are within the compound, but the team isn’t yet certain about the configuration of the lighter hydrogen and nitrogen atoms. The material also contains relatively little hydrogen, even though this is the substance that theoretically gives hydrides their superconducting ability. Multiple researchers, including Zurek and Ceperley, were intrigued by this contradiction. It could point to alternate theories for how superconductivity arises in hydride materials.\nThe big claims made in this paper, as well as past controversies, have raised the bar for proof, says Michael Norman, group leader of the condensed matter theory group at Argonne National Laboratory in Illinois, who was not involved in the new study. But a reluctance to trust results until they are replicated is not unusual in the field of superconductivity. He points to the 1986 discovery of cuprates, which were found to be superconducting at much higher temperatures than previous materials. After it was published, “over the first six months, people pretty much didn’t pay the paper much attention. But then when the result was reproduced by a Japanese group, that’s sort of when everybody jumped into the field,” Norman says. As for the new study, “I’m pretty sure that people will be cautiously optimistic until they see another group reproduce it.”\nSophie Bushwick is an associate editor covering technology at Scientific American. Follow her on Twitter @sophiebushwick Credit: Nick Higgins\nBob Henderson\nNature Video\nJennifer Hackett\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Government Shutdown Could Delay Climate Action", "date": "2023-09-29 16:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nEPA rules on clean cars, power plants and methane could face delays if there is a federal government shutdown because of budget turmoil in Congress\nCLIMATEWIRE | EPA was already facing a mad dash to complete climate rules in the next six months. A government shutdown could make that harder.\nThe agency has run behind schedule to propose and finalize regulations throughout the Biden administration, and the government's looming closure threatens to make it harder for the agency to complete work on key pieces of the president’s climate agenda before they may become vulnerable to Republican-led reversals.\nThe administration’s regulatory agenda in June projected that the Office of Air and Radiation would clear a slate of methane-related actions over the summer, including a final oil and gas rule and a proposed fee on excess emissions envisioned in last year’s climate law. Neither has begun White House review.\nEPA also expected to finish work on rules for passenger vehicle and heavy-duty truck emissions before the end of this year. While the truck rule is expected to hit that mark, EPA has said the clean car rule won't be ready until the spring. And the agency's marquee rule for power plant carbon emissions is projected to be final in April.\nIf EPA sticks to its current schedule, that should prevent Republicans from using the Congressional Review Act to undo those rules in one fell blow if they win control of both congressional chambers and the White House in next year's elections. But experts say a government shutdown could delay the rulemaking process. The CRA sets a strict window based on the congressional calendar allowing lawmakers to pass — and the president to sign — a resolution to veto a newly minted rule. It's not clear when that window will close next year, but the later the rule is final the more it is at risk.\nIf Congress fails to pass a funding bill by Saturday at midnight, EPA has said it has cash on hand to stay open through Oct. 7. Deputy Administrator Janet McCabe said in an email to staff first reported by POLITICO that if Congress still hadn’t passed government funding legislation by next Friday, “most EPA employees” will be furloughed.\nAnd that could cost the agency more productivity than the length of the shutdown would suggest, say former EPA officials.\n“If the shutdown is one week, it's more than one week that they're going to lose on the rulemaking process,” said Bob Perciasepe, a former EPA deputy administrator who has experienced three government shutdowns. “It's already eroding their effectiveness, I'm guessing, right now.\"\nThe looming shutdown also raises the prospects of other interruptions that could grind agency work to a halt. Online portals that are used to submit grant applications and to comment on EPA actions might close, requiring extensions. And outside contractors that EPA relies on for some of its economic modeling and analysis related to rulemakings could take other work.\nExisting laws do allow EPA to carry on with some activities if appropriations lapse. The agency's 2-year-old contingency plan outlines those exceptions — including allowing work to continue if it's related to court-ordered deadlines, securing EPA facilities or protecting “life and property.” The plan points to the example of responding to the release of hazardous substances when it endangers public health.\nCongress enacted climate and infrastructure legislation over the last two years that provides funding outside of the regular appropriations process — and that work can continue during a government shutdown. But money from the Inflation Reduction Act probably can’t be used to continue EPA regulatory work, experts say.\nStan Meiburg, who served at EPA for nearly 40 years including a stint as acting deputy administrator, said rules that are already under review at the White House Office of Management and Budget likely face the thorniest shutdown-related delays.\n“With major rules in particular there'd have been a lot of discussion going on between OMB and EPA before they send the rule over there, and they have it pretty well laid out as to what their schedule is and what they were expecting to do,” he said. “If you can't get it out of OMB, though, you start to get day-to-day extensions of where and when the actual release is going to be.”\nThe EPA air office has a handful of rules currently under White House review, including one that would guide state plans to implement the power plant carbon rule and the oil and gas methane rule. The methane rule is expected to go to OMB any day, observers say.\nEPA released draft methane rules during the last two global climate summits, and the final version might be unveiled at the talks that start in Dubai, United Arab Emirates, in November. But interagency review typically takes at least two months, so a government shutdown of any length would make that timing unlikely.\nMeiburg said a shutdown that causes short-term delays for some rules would be unlikely to create a long-term backup that could affect the clean car and power plant rules expected in the spring.\n\"Usually the agency can do a certain amount of scrambling around to just kind of make up some time,” he said. OMB might also work to complete reviews more quickly.\nReporter Kevin Bogardus contributed.\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nJean Chemnick is a reporter with E&E News.\nThomas Frank and E&E News\nJean Chemnick and E&E News\nLamar Johnson and E&E News\nBenjamin Storrow and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Government Shutdown Looms over Scientists", "date": "2023-09-29 21:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nA government shutdown would disrupt biomedical research and clinical trials as federal experimental facilities shuttered\nFuelled by infighting among Republicans in the House of Representatives over spending cuts, the United States is barreling towards a government shutdown. Lawmakers in the US Congress have until 30 September (the end of the fiscal year) to reach an agreement over how to keep money flowing to federal agencies, or the government will have to close many of its doors and furlough staff — including tens of thousands of scientists — without pay. Depending on how long the shutdown lasts, work at science agencies will stop, interrupting experiments, delaying the approval of research grants and halting travel to scientific conferences.\nThe shutdown drama is unfolding in the House, where the Republican party holds a narrow majority. A handful of extreme right-wing Republicans are refusing to support a ‘continuing resolution’ to fund the government temporarily while negotiations over a 2024 budget continue — that is, unless Congress agrees to drastically cut government spending, among other demands. Democrats are united in opposition to their requests, and most Republicans in both the House and the Democrat-controlled Senate are looking for compromise that would keep the government open. But time is running out.\nHere Nature takes a look at what’s driving this latest budgetary crisis, and what’s in store for scientists if the US government shuts down next week.\nThis is basically a continuation of the US debt-ceiling crisis, which occurred less than four months ago. At that time, some Republicans threatened to block legislation that would make sure the government had enough money to pay its bills, unless Democrats, including President Joe Biden, agreed to future spending cuts. Congress avoided disaster by reaching a bipartisan agreement to limit federal ‘discretionary’ spending — money that goes to US science and other programmes. The legislation, which broadly outlined reductions in spending over the next two years, was signed by Biden on 3 June.\nSince then, lawmakers in both chambers of Congress have gone about their business with unusual efficiency, making progress on a series of annual bills that outline detailed spending levels for federal agencies. The irony is that lawmakers haven’t made this much progress by the fiscal-year deadline in a long time, says Jennifer Zeitzer, who leads the public-affairs office at the Federation of American Societies for Experimental Biology (FASEB), based in Rockville, Maryland. “And yet here we are, staring down the barrel of another shutdown.”\nNormally, Congress would pass a resolution to continue funding agencies for a couple of months while lawmakers finish up budget negotiations, but the situation is different this year. Republicans hold only a narrow majority in the House, occupying 222 seats, compared with the Democrats’ 213. That means that to pass legislation, the Republican party needs to maintain a united front and vote nearly in unison, to overcome Democratic opposition. Several hardline Republicans are holding out, however, using their leverage to force further concessions on spending.\nThe answer differs from agency to agency. Some agencies have residual funds that they can tap to continue operating in the short term. And to varying degrees, all agencies maintain a skeleton staff of ‘essential’ workers to complete duties related to national security and the protection of public property, for instance.\nThe US National Science Foundation (NSF), expects to halt work for 1,487 out of its 1,946 employees, once short-term funding runs out, for example. Scientists can continue to submit applications for funding to the agency, which pays for about one-quarter of the taxpayer-supported basic research in the United States, but no new projects will be approved. The Department of Health and Human Services, which houses the US National Institutes of Health, a significant funder of biomedical research, plans to furlough some 37,325 people — 42% of its staff — by the second day of a shutdown. ‘Essential’ staff working at its clinical centre or on public-safety missions such as monitoring for viral outbreaks will continue to report to work.\nGovernment scientists will have access to laboratories for the maintenance of equipment, cell cultures and animals, but research will mostly grind to a halt, says Joanne Carney, chief government-relations officer for the American Association for the Advancement of Science in Washington DC.\nIf the shutdown drags on, she says, it could have knock-on effects for scientists outside of government, who might lose access to federally funded experimental facilities or be forced to delay hiring for projects while awaiting grant decisions. Scientists witnessed such impacts in late 2018 and early 2019, when the US government partially shut down for 35 days.\n“It does create a ripple effect into the research community outside the federal government,” Carney says.\nMichael Moloney, chief executive officer of the American Institute of Physics in College Park, Maryland, says US shutdowns can also impact international collaborations and the country’s reputation abroad. He is attending the International Astronautical Congress in Baku, Azerbaijan, next week, and fears that scientists from NASA will now have to cancel their attendance. “That may not have any immediate short-term impact, but it does chip away at our reputation as a global player,” he says.\nTo end a shutdown, Congress would need to pass a continuing resolution that enables the government to fund activities for weeks or months while lawmakers finish passing bills locking in the 2024 budget. According to Zeitzer, one natural landing place in terms of budget negotiations is where everything started: with the broad spending limits laid out in the debt-ceiling agreement cemented back in June.\nThe impacts of such a move would vary by agency, but Zeitzer says many agency leaders are probably already preparing for some tough budgetary decisions next year. This is one of those years where no increase — but also no decrease — in funding will be “the good scenario,” she says.\nThis article is reproduced with permission and was first published on September 28, 2023.\nJeff Tollefson works for Nature magazine.\nJean Chemnick and E&E News\nThomas Frank and E&E News\nThomas Frank and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "New York City's Floods and Torrential Rainfall Explained", "date": "2023-09-29 21:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nRecord-breaking rains caused major flash flooding in New York City, reminiscent of Hurricane Ida and a sign of what climate change will increasingly bring\nPhotographs and videos of New York City have shown rainwater spurting from between subway station tiles, cars bobbing in floodwaters that turned Brooklyn intersections into lakes and parts of LaGuardia Airport inundated as the city and surrounding areas have been deluged by heavy downpours on Friday.\nBetween midnight and the afternoon, rainfall rates up to two inches per hour dropped more than five inches of water on Central Park and more than eight inches on John F. Kennedy International Airport—a record for any calendar day in the latter. That precipitation overwhelmed ground that was already well saturated from the previous weekend’s rains (courtesy of the remnants of Tropical Storm Ophelia) and the storm drains and subway pumps used to funnel rainwater away.\nThe rain has been reminiscent of what might happen in a tropical system—and has reminded many New Yorkers of Hurricane Ida’s deadly flooding two years ago—though the exact mechanics were a bit different in this case. Here Scientific American answers some questions readers may have about this and similar events—particularly how climate change comes into play.\nHow does this compare with other major rain events in New York City’s history?\nWe can’t say exactly where this event will rank because the rain is still falling, but comparing it to Ida is not off base. Ida’s peak rainfall rates were higher—about three inches per hour—and it dropped 7.13 inches on September 1, 2021, the worst day of rain during that storm. And though the current storm has caused major flash flooding, “we haven’t seen the catastrophic flash flooding” that happened during Ida and killed 11 people in basement apartments in Queens, says Dominic Ramunni, a meteorologist at the National Weather Service’s office in Upton, N.Y.\nThis event has dropped more rain than Ida did on JFK Airport, though—it is the most rain the airport has recorded since records began in 1948. Every storm is a little different, and where the heaviest bands of rain form can vary, which means some areas experience higher totals in some storms than in others. “That's why we see this variability from event to event,” Ramunni says.\nHow do you get such a deluge without the involvement of a tropical storm?\nThough tropical cyclones (the broad term for tropical storms, hurricanes and typhoons) are notorious for the torrents of rain they can bring, nontropical systems are capable of causing heavy downpours if they have enough moisture available.\nTropical systems are driven by convection that is fueled by warm ocean waters. They often develop a clear “eye” at their center that is completely surrounded by swirling thunderstorms. That setup has not been present with the system over New York City on Friday.\nRather that system has been driven in part by an area of low pressure to the south of the city that is an offshoot of another, more unusual area of low pressure called an “inverted trough.” In meteorological speak, that means it has caused a northward bulge in the atmosphere instead of a more typical southward one. The whole setup has made moisture-laden air converge and rise upward. As it has risen, the air has cooled and formed clouds and rain. That moisture has been funneled onshore like a hose aimed at the city.\nHow does climate change factor into the situation?\nIt would take a specific study—called an attribution study—to give any hard numbers on how much more likely this event would be with climate change than without it. But broadly speaking, scientists know that rising global temperatures are making heavy downpours more likely.\nThe 2018 National Climate Assessment (a new version of which is due sometime this year) found that the amount of rain that fell during the heaviest 1 percent of rain events had increased by 55 percent across the Northeast since 1958, with most of the increase happening since 1996. That trend will only get worse as global temperature rise, causing more evaporation from oceans and lakes and giving storms more water to fuel deluges.\nHow can I stay more aware of pending storms and flooding threats?\nRamunni says that having more than one source for receiving extreme weather alerts is ideal. These resources can include alerts that government agencies send out to your phone, local news and a weather radio.\nWhen forecasters issue a watch for a flood (or other type of weather event such as a tornado), it indicates that people should be prepared for those conditions in their area. If a warning is issued, that means they should take immediate action.\nIn the case of floods, one of the biggest warnings meteorologists give is to never, ever drive into floodwaters, even if they don't seem very deep. Just six inches of water can reach the bottom of the average passenger car and cause loss of control, and only a foot of water can float many vehicles.\nCould this event have been even worse?\nAmazingly, yes. Meteorologist Mark Bove noted on X, formerly known as Twitter, that the highest rains from the storm occurred just offshore and totaled more than 8.5 inches. If that had fallen over the city, it would have been “the worst #flooding disaster the city has ever experienced,” he wrote.\nAndrea Thompson, an associate editor at Scientific American, covers sustainability. Follow Andrea Thompson on Twitter Credit: Nick Higgins\nMeghan Bartels\nThomas Frank and E&E News\nJaney Camp and The Conversation US\nOliver Wing, Carolyn Kousky, Jeremy Porter, Paul Bates and The Conversation US\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "In War-Torn Ukraine, a Doctor Evacuates Children with Cancer", "date": "2023-09-30 01:00:00", "text": "A pediatric oncologist is racing against time to send scores of sick children out of Ukraine for medical aid.\nRoman Kizyma The first months of war, we didn't have the weekdays, so we just worked seven days, 24 hours.\nThere are moments when I can work for three days without sleep. There are moments like when I, I cannot do anything for this day.\nI had a very long period without my very small kids. And so when I met in a couple of months, my younger son, so he didn't recognize me. So compared to the people that suffered the atrocities in Bucha or European or Eastern Ukraine, this is nothing. But this wasn't a good experience. \nThe main factor for myself is this feeling of responsibility.\n[Roman Kizyma, to camera] So when you see a bald guy or girl in the hospital, that’s my patient. \nIf I just stop, I compromise the treatment of hundreds of children. And I think I'm not in the position to to end this.\n[Roman Kizyma, in Ukrainian to patient] Where is the problem? Where does it hurt? Show me. \n[Patient] Here. \nRoman Kizyma Here? Ok. \n[Roman Kizyma in Ukrainian, to patient] Do you want to show me your tongue? Ok.\nMy name is Roman Kizyma. I am pediatric oncologist, a medical doctor treating children with cancer. Now I’m the Acting Director of Western Ukrainian Specialized Children's Medical Center, a huge, specialized hospital for severely ill children with cancer with other catastrophic diseases.\nThe war made the things for children with cancer and other catastrophic disease very difficult. You have to fight two wars, one against cancer, the other against the crazy Russian army shooting at you. It's not only the physical unsafety, it's also the complete disruption at some point of medical logistics. So no drugs coming to the hospital. No doctors or nurses available in the direct hospital. The physical unsafety, the shelling of Ukrainian electricity infrastructure.\nSo sometimes we were black. All the hospital was black. No electricity. \n[Hospital staff, in Ukrainain] And our doctor’s don’t know this but \n[Staff] — Oh everyone’s with flashlights. \n[Hospital Staff singing Ukrainian National Anthem] \nRoman Kizyma This is a vulnerable group of patients. And when there is a kind of crisis, vulnerable group of people suffers the most because no one cares. Everyone trying to save themselves. So that's why a lot of families like asked or decided or went by themselves to Europe with this project that we call Safer Ukraine. \nBefore the war, I was just treating cancer. I transformed into someone coordinating the big groups of very sick children going here and there. So it means like one and a half thousand children out of Ukraine with cancer treated somewhere else. The team is ready to help these children and we have the capacity. So that's why this is a special hospital.\nDuring two years before the start of the war, we were creating the new department, the Clinic of Pediatric oncology and stem cell transplant here in this hospital.We opened this seven days before the start of the war, so we had a huge amount of patients going to be treated there. And we have to transform ourselves from oncologists to emergency doctors and relocate all our patients to to to the other countries.\nSo it was a huge blow for our level of work. And we have to abandon all these new structures that we created because you cannot perform transplants when you are getting shellings and shootings and all these children.\n[Roman Kizyma in Ukrainian] If not urgent then tomorrow, ok? Ok. If urgent I can look now. Ok. \nI feel so stressed. I feel like in a race against time. The relocation of a child with cancer from Ukraine to Western Europe is not something new. We did that even before the war, but was like a couple of children per year. But how do you do that if you have 100 children with cancer coming to your hospital per night.\nThese are severely ill children. And for each of them you should have a lot of medical staff to support each patient.\n[Nurse, in Ukrainian] Alright. \nThere is no hospital that can treat 1,500 children at one time from some country. So this is not possible, \n[Child, in Ukrainian] It’s cold.\nRoman Kizyma That's why we tried to use different criteria. First of all, we organized multistep approach with different hubs.\nWe got the requests from the families or the doctors from different cities of the east of Ukraine or Kyiv, the capital. The first hub is in Lviv. This hospital that can host any child of any severity. And if they cannot go further, we can treat them here for a long time or for a short time and then allocate them.\nWe created with our partners, with charities or the support for housing and the capacity for transportation. So we had a lot of volunteers meeting children in the railway station, carrying them out of there, carrying 20 patients out of a train in a railway station that is packed with people trying to go somewhere. We went only [as] five doctors to meet a huge convoy at the railway station, so we have to carry kids across the railways.\nThe next step was the hub in Poland. The thing was to cross the border was a lot of queues of people trying desperately to move out of Ukraine. So we used the diplomatic power of Polish consulates situated in Lviv. This was saving time for the severely ill kids because if they stayed for ten or 20 hours in the queue, they would not leave it. So it was possible. \nIn the next hub there was a triage of the international team that came here to Poland and they formed a logistics. A huge hotel was transformed into a medical center in the middle of Poland. Children were arriving there and they were triaged to different rooms and taken care by this group of international doctors.\nThen they contacted their dedicated hospital throughout Europe and U.SA and these hospitals and their government, they were transferring these kids to a specific hospital admitted by their team. In the worst phase, we had more than 150 children per week sent by this pathway. This was very hard. \n[Roman Kizyma in Ukrainian, to patient] You can pull it up a bit. Good. \nRoman Kizyma My job was not to step into one into one case.\nSo this was I was oncologist myself. So I tried just to not to step in each case more than like 10 minutes. So I used my previous experience to triage them. \n[Roman Kizyma in Ukrainian, to patient.] Good. Can you smile? Can you smile and show your teeth? Good, well done. \nDuring all these relocations, we lost two children. It's Russians who were attacking them, kids were from Kharkiv.\nSo it's very close to the Russian border. That's why during their very severe treatment phase, they had to be evacuated from their hospital, put into ordinary trains and they came to L’viv. Like we literally had no choice. So we had to explain to the families, you decide what you do. You don't go and we stay and try to do something here in L'viv during these air strikes, or you risk.\nBut at least, you know you did everything to a child. So they risked and we failed. So this both children died. Some of their doctors who helped us here, they came from the regions that were under attack. There is a sad story of our colleagues in Kyiv. One of their doctors, she was driving to her shift for the children with cancer.\nShe was hit directly by a Russian rocket in her car and she was burned alive. Her name is Oksana Leontieva. And I think this event, it was very influential. So we realized how dangerous, dangerous the work is. \n[In Ukrainian, singing] Hands made some porridge and gave to Darynka. Running to get some porridge, Yes. \nBut there were a lot of happy situations. And I visited a lot of these hospitals afterwards, like in fall in the winter, that here. And the people were happy. The children were happy. Who are you treating? Sometimes I felt like I was going through a hospital in Europe and like the first room, my patient, the second room, my patient. The third room, my patient.\nSo I was feeling like I'm the part of the staff of that hospital. You were asking me like, What should we do with your patients? So mostly these are the good stories and the feedbacks where like people are very grateful to all these countries because they felt like they were in home. During last year even as a pediatric oncologist, I helped to build the facilities.\nSo I'll try to do that as a director, but not only for pediatric oncology, for example, this will be the intensive care unit, the huge project within this year. So some people like outside of Ukraine, how can you build during the wartime? You can. Why not? The life still goes on and we have to have these places for this severely ill children that will look better.\nSo that's what I am focused now to to do that. This is a network that try to balance itself. So this is a never ending process. I hope this will work.\n[The above is a transcript of this podcast]\nCarin Leong and Kelso Harper\nJonathan Schienberg and Retro Report\nAaron Martin\nDaniel Garisto, Jason Drakeford, Lee Billings and Jeffery DelViscio\nDuy Linh Tu and Sebastian Tuinder\nKit R. Roane and Retro Report\nTulika Bose\nKaren G. Lloyd, Peter Barry and David Terry Fine\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Why Do We Forget So Many of Our Dreams?", "date": "2023-09-30 12:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nWe only remember a fraction of our dreams, and even those slip away if we don’t try to remember them—here’s why\nIf you’ve ever awoken from a vivid dream only to find that you can’t remember the details by the end of breakfast, you’re not alone. People forget most of the dreams they have—though it is possible to train yourself to remember more of them.\nDreaming happens mostly (though not always exclusively) during rapid eye movement (REM) sleep. During this sleep stage, brain activity looks similar to that in a waking brain, with some very important differences. Key among them: during REM sleep, the areas of the brain that transfer memories into long-term storage—as well as the long-term storage areas themselves—are relatively deactivated, says Deirdre Barrett, a dream researcher at Harvard Medical School and author of the book The Committee of Sleep (Oneiroi Press, 2001). This may be a side effect of REM’s role in memory consolidation, according to a 2019 study on mice in the journal Science.\nShort-term memory areas are active during REM sleep, but those only hang on to memories for about 30 seconds.\n“You have to wake up from REM sleep, generally, to recall a dream,” Barrett says. If, instead, you pass into the next stage of sleep without rousing, that dream will never enter long-term memory.\nREM sleep occurs about every 90 minutes, and it lengthens as the night drags on. The first REM cycle of the night is typically just a few minutes long, but by the end of an eight-hour night of sleep, a person has typically been in the REM stage for a good 20 minutes, Barrett says. That’s why the strongest correlation between any life circumstance and your memory of dreams is the number of hours you’ve slept. If you sleep only six hours, you’re getting less than half of the dream time of an eight-hour night, she says. Those final hours of sleep are the most important for dreaming. And people tend to remember the last dream of the night—the one just before waking.\nOther factors also contribute to whether you’ll remember your fantastic nighttime adventures, Barrett says. Women tend to remember a few more dreams than men, on average, according to a 2008 meta-analysis of multiple dream studies. Young people remember more dreams than older people, multiple studies have shown. Memory of dreams increases in kids from the age at which they can communicate about those dreams, , plateaus from the early teens to the early 20s and then very gradually declines in adults over the rest of their life span, Barrett says.\nThere is a lot of individual difference in dream memory, though. Some people almost never remember a dream, and others regularly recall several each night. People who are more introverted and inward-focused tend to remember more dreams, Barrett says, while those who are more extroverted and action-oriented tend to remember fewer. Imaginativeness and susceptibility to hypnosis are also linked to dream recall, as are some measures of creativity, she says, though creativity is tricky because not all measures of creativity even line up with one another, much less with dream tendencies. Overall, according to one 2017 study, recall of and interest in dreams seems tied to openness to experience, a personality trait characterized by a desire to try new things and explore unusual ideas.\nA few studies that have investigated lucid dreaming –vivid dreams the dreamer remembers very well and feels in control of --  suggest that some areas of the brain linked to attention are more active in people who recall more dreams, indicating that basic neurological differences may play a role.\n“Some people don’t pay as much attention to their dreams while they’re happening as others, just in terms of brain action going on,” Barrett says.\nIt is possible to train your brain to remember more of your dreams, though, says Leslie Ellis, a clinical counselor in British Columbia and author of A Clinician’s Guide to Dream Therapy: Implementing Simple and Effective Dreamwork (Routledge, 2019). She advises clients who want to remember their dreams to take a moment when they wake up, before they even move their body, to think about what they were just dreaming and remember as much as possible. This moves the dream from short-term memory to long-term memory.\n“Write it down right away, and then you’ll have it there,” Ellis says, “because they do slip away unless they’re deliberately recorded, for most people.”\nDreams are often considered nonsensical in Western culture, Ellis says. Though the narratives may not make much sense, they often hint at emotions that people are processing in their waking lives. “We do dream about the things we kind of don’t want to look at,” she says. “During the day, we can repress a lot of that, but the dreams will bring those things to the surface.”\nEven just thinking about dreams more often can bring them more fully into your waking life. Taking a class on dreaming, reading a book about dreaming or even just thinking more about dreaming has a short-term impact on people’s dream recall, Barrett says.\n“Trying to remember your dreams or even just having a lot of context with references to dreams will temporarily increase your dream recall,” she says. “You can do it on purpose.... But it [also] indirectly works if somebody’s been talking to you a ton about dreams or you read an article in a magazine today on dreams.”\nIn other words, if you’ve made it to the end of this article, you may have sweet dreams tonight.\nStephanie Pappas is a freelance science journalist. She is based in Denver, Colo.\nMarie-Neige Cordonnier\nIngrid Wickelgren\nSusana Martinez-Conde\nDaisy Yuhas | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Pipelines Touted as Carbon Capture Solution Spark Uncertainty and Opposition", "date": "2023-10-01 12:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nFederal investment in carbon capture could help fight climate change, but this technology is facing fierce opposition\nOne hot summer day two years ago, Kathy Stockdale checked her mailbox and found a slip of paper that would change her life. The humble notice revealed that two carbon capture companies wanted to seize part of her family’s farmland in Hardin County, Iowa, for a pair of pipelines slated to pass through it. But Stockdale wasn’t going to give up her property without a fight.\nPipelines are hardly new to the Midwest; thousands of miles of natural gas conduits already crisscross the region. But fresh tension surrounds the construction of a relatively new kind of conduit called a carbon capture pipeline, and the Stockdales’ land lies in the potential pathway of two of them. These pipelines are part of an effort to reduce greenhouse gas emissions from ethanol production plants by capturing and storing carbon dioxide that would otherwise be released into the atmosphere. But despite the green intentions behind the technology, environmentalists are actually joining landowners in pushing back against it. Many experts worry the pipelines could spring deadly leaks or contaminate water—and they question how effective such projects will actually be at fighting climate change.\nStockdale and her husband, Raymond, who have lived on their farm for 47 years, were stunned when representatives from a carbon capture company suddenly showed up just three months after the couple received the notice. Without asking permission, the reps began planting stakes where the pipe would go, Stockdale says. “I have never felt more disrespect in my life,” she adds. She decided to fight back against the use of eminent domain—a legal concept that allows companies to seize private property for public use through the local, state or federal government (although the landowner must be fairly compensated). Stockdale has been fervently attending public hearings on permits, researching pipeline safety and talking with legislators. She has had a lot of sleepless nights. And even though she says she isn’t interested in environmental protection, she has partnered with the local Sierra Club chapter for support.\nEnvironmentalists might not seem like a natural ally in a battle against green technology, but they have concerns about the growing U.S. web of carbon capture pipelines—which currently includes more than 5,300 miles of conduit. And carbon capture technology continues to gain traction nationwide; the Biden administration recently announced that it would spend up to $1.2 billion on carbon capture and storage projects, signaling a commitment to this technology as a means to achieve net zero emissions.\nHere’s how the carbon capture process works: It begins at an industrial site, such as an ethanol or power plant, that produces a lot of carbon dioxide emissions. As the plant burns fossil fuels, a liquid solvent absorbs the exhaust and separates its gases. A storage chamber collects separated carbon dioxide (which would otherwise enter the atmosphere and trap heat), and harmless nitrogen and oxygen are released. Next, the system liquifies the CO2, which flows through steel pipelines to a designated storage site. Once it arrives, another pipe injects it deep underground, where it is isolated from the atmosphere and will no longer actively contribute to climate change.\nBut the process comes with risks.\nCO2 remains a liquid in the high-pressure, high-temperature environment inside a pipeline. But if the pipeline ruptures, that liquid escapes as a colorless, odorless gas that is difficult for people to detect without specialized instruments. This CO2 can displace oxygen and potentially cause suffocation, drowsiness and sometimes death; in fact, the gas is sometimes pumped into specialized chambers to euthanize livestock on farms. In 2020 heavy rains triggered a landslide that damaged a carbon capture pipeline in Satartia, Miss. The pipe burst and released CO2, suffocating 45 people so severely that they needed to be hospitalized.\nFortunately, these pipelines have a low probability of failure. Leaks are few and far between. But Bill Caram, executive director of Pipeline Safety Trust, says that any one rupture can have unacceptable consequences. “We have a goal of zero incidents. And I think that’s a shared goal among regulators and the industry,” Caram says. “We’re a long way away from that happening.”\nA study released in May found that carbon capture pipelines are more likely to experience small punctures than large ruptures such as the one in Satartia. Smaller holes release the gas at a slower rate, which makes them harder to locate. And a delayed response to smaller punctures could cause them to be deadly.\nWhen CO2 vaporizes and escapes, it causes the temperature in the pipeline to drop immediately—a process Caram describes as “violent.” The escaped gas doesn’t ignite or dissipate. It moves quickly along the ground and can collect in low-lying areas, including small valleys and basements near the pipeline route. If a person in one of these pockets breathes air with a 10 percent concentration of CO2, they can fall unconscious within one minute.\nAdditionally, impurities in the liquified gas can erode a pipeline and increase the chance of a leak. Potentially dangerous contaminants include water, nitrogen oxides and sulfur oxides—all of which are sometimes found in CO2 captured from power plants. There is only limited research on how these contaminants will affect the gas’s stability in storage. Experts note that relatively large concentrations of oxygen could potentially dissolve caprock, a natural geological formation that traps oil and coal—and injected CO2—and keeps them from escaping to the surface. One of the main problems, Caram says, is that there are no federal regulations from the Pipeline and Hazardous Materials Safety Administration about limiting impurities, even after the 2020 Satartia incident. “Operators can clean it up somewhat. They can dry it out and get the water out of there to a certain extent,” Caram says. “But there’s no regulation saying that the pipeline can’t have these impurities in it. It’s just kind of up to operators to do it.”\nBeyond their safety concerns, experts question whether carbon capture and storage is even an effective strategy for reducing greenhouse gases. Noah Planavsky, an isotope geochemist at Yale University’s Center for Natural Carbon Capture, says the practice would certainly reduce the CO2 in the air—but the overall situation is not that simple. “It’s not whether or not it’ll remove carbon. It will remove carbon,” Planavsky says. “But are we doing things that are actually propagating further use of fossil fuels?”\nInvesting massive amounts of money in carbon capture and storage, and the pipelines that come with it, will lower carbon dioxide levels in the atmosphere. But with limited federal money allocated for long-term climate change mitigation, Planavsky is not sure this technology is the best use of those funds. He says it’s important to consider whether carbon capture will be used as an excuse for not phasing out fossil fuels.\nCarbon dioxide removal, Planavsky explains, is not meant to replace emissions reduction. Instead meeting the goal of producing net-zero CO2 emissions will require a range of solutions, including both industrial and natural carbon capture. The latter could mean preserving natural spaces such as forests, oceans, grasslands and wetlands, which naturally pull carbon dioxide from the air. Natural forms of carbon capture provide cleaner water and air, as well as increased biodiversity—things that might serve the land, rather than put holes in it.\nBut as more federal money goes into carbon capture pipelines and other projects, public permit hearings such as those happening in the Midwest will continue. The situation is keeping landowners, experts and locals on their toes. And until the carbon capture companies are denied building permits in Iowa, Stockdale says she will continue fighting to keep the pipelines off her land.\n“It’s not what I planned on doing at 72 years old. I have five grandkids who I can spend more time with,” Stockdale says. “But I’m fighting for their futures.”\nAnna Mattson is a freelance science journalist based in South Dakota. You can find more of her work at annamattson.com or follow her on Twitter @AnnaMattson9.\nCorbin Hiar, Carlos Anchondo and E&E News\nRichard Conniff\nRichard Middleton | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "History: October 2023", "date": "2023-10-01 13:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nEarth as a zoo; sunburned eyes\nCraters on Venus\n“Venus is pocked with craters. This fact emerges from studies in which short radio waves were reflected from the solid surface and were analyzed by computer at the Jet Propulsion Laboratory. It shows an area 910 miles across near the equator, where there are a dozen large craters ranging from 21 miles in diameter to 100 miles. Smaller craters may well be present but were not resolved. All the craters are shallow—a clue to Venus' history. They could be the result of meteorite impacts before the planet had an atmosphere. Possibly they were subsequently filled with lava from the interior or erosion on the surface.”\nEarth: Alien Zoo or Petri Dish?\n“The probability is high that humans are not one of the most advanced organisms in the universe. There might be civilizations millions of years ahead of our own. If ‘they’ are out there, why have we not heard from them? John A. Ball, in Icarus: International Journal of Solar System Studies, suggests that extraterrestrial civilizations could communicate with us, but they choose not to. ‘Occasionally,’ he observes, ‘we set aside wilderness areas, wildlife sanctuaries, or zoos in which other species are allowed to develop naturally.’ An extraterrestrial species, he speculates, might consider humans an organism to be preserved in isolation and purity, a part of nature to be observed. ‘They have set aside the area in which we live as a zoo.’ F.H.C. Crick and L. E. Orgel, also writing in Icarus, offer an alternative theory: that life on the earth began as a deliberate ‘infection’ of microorganisms placed here by another civilization. Such a civilization would have regarded the earth not as a zoo but as a Petri dish.”\nSunburned Eyes\n“The huge arc lamps used in the moving-picture studio, just like the sun, give out ultra-violet as well as visible light. Hands and face get quickly accustomed to this, and immune to further burning. But the eyeball is very sensitive to burning, and it does not acquire immunity. The burning is a form of conjunctivitis. It is curable, but during the cure the patient must not be further exposed, and the eye is weakened by having been afflicted. This malady appears so freely among motion-picture actors that a name, ‘Kleig eyes,’ has been coined for it [after the Kleig light, a carbon arc-lamp]. It appears that the solution lies in a film that would work as effectively and as fast in a subdued light as the present films work in the glare.”\nCoast to Coast in 27 Hours\n“Lieutenants John A. Macready and Oakley G. Kelly of the Army Air Service, leaving Roosevelt Field on Long Island, reached Rockwell Field in San Diego after a nonstop flight of 26 hours 50 minutes. According to the pilots the average speed was 93.5 miles per hour. In the initial stages the plane was greatly overloaded [with fuel], and an altitude of only 1,500 feet could be maintained. From Indianapolis to Tucumcari in New Mexico they flew [in the dark] by compass alone. One hundred thousand people welcomed the pilots at San Diego. The pilots came down in perfect condition, although neither had slept the entire trip. They state they would have welcomed signs marking towns and other landmarks, particularly by night.”\nOil by Pipeline\n“Transporting oil by pipes has been in practice in the oil districts of Pennsylvania for several years. It remains to be determined whether the project can be carried out on a gigantic scale. With the discoveries in Butler County, Pa., the idea of transporting oil through iron pipes, from Titusville over the Alleghenies to Philadelphia, a distance of 260 miles, is now exciting considerable attention. It is proposed to lay a cast iron six-inch pipe, in a bee line, which at one locality will be 3,000 feet above the sea level. Some 23,000 barrels may be delivered every twenty-four hours, at ten cents per barrel.”\nPerpetual Motion For Sale\n“J.W.S. writes to say that he has a perpetual motion [machine] in running order, and he will dispose of it for $2,000,000, but if he has to carry it to Washington, he will ask $5,000,000. The existing financial crisis will, we fear, prevent our correspondent from receiving either of the sums he mentions.”\nThis article was originally published with the title \"50, 100 & 150 Years\" in Scientific American  329, 3, 68 (October 2023)\ndoi:10.1038/scientificamerican1023-68\nMark Fischetti is a senior editor at Scientific American. He covers all aspects of sustainability. Follow him on Twitter @markfischetti Credit: Nick Higgins\nTyler Carroll\nDaniel Garisto\nShannon Hall and Nature magazine\nAvery Ellfeldt and E&E News\nTanya Lewis\nSophie Bushwick and Lauren Leffer\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "For Health Equity, Location Matters", "date": "2023-10-01 13:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nA special package explores problems and solutions to the geography of injustice\nThe air we breathe, the water we drink, the temperature outside—all are influenced by where we live, and each has a distinct effect on our health. Over the past few decades an abundance of research has shown that the environment can have dramatic impacts on health and that those who have the healthiest environments tend to have the most privilege. Conversely, those who bear the brunt of environmental health threats tend to have limited power to bring about real change.\nRobert D. Bullard, known as the father of environmental justice, was one of the first people to systematically document the connection between race and exposure to pollution. His work showed clearly how U.S. policies such as redlining had burdened majority-Black communities with far more contaminated air and water than their white neighbors were exposed to. Because of those same historical policies, people of color on average live in neighborhoods with higher surface heat than do non-Hispanic white people. One result of these urban heat islands is that people who already have a higher risk of respiratory and heart disease end up living in environments that exacerbate those illnesses.\nAround the world, people breathing the most toxic air are consistently the poorest and most disadvantaged. This pattern is apparent at every level, from the smallest towns to the largest countries. Wealthy nations have shown that reducing air pollution saves lives, and some poorer countries are proving that clean energy can fuel economic development.\nSnakebite envenomation is one of the deadliest tropical diseases. Like so many other conditions, it is most dangerous to the people with the fewest resources because they are least able to protect themselves from being bitten or to access the best care. New treatments could save lives and limbs.\nThe climate crisis is changing the range and prevalence of many diseases. Valley fever has expanded into new locations, and those working outdoors in construction sites and dusty agricultural fields are the most at risk. The illness also disproportionately affects Latino, Asian and Indigenous American people, who are more likely to contract it than white people and who often experience more severe symptoms.\nSolutions exist, and they require better understanding and a fresh approach. Innovative researchers are devising healthier buildings, designing clinical trials with community involvement, and monitoring the air and water to empower people to protect themselves. They are creating a movement toward a more livable and more just world.\nThis article is part of “Innovations In: Environmental Health Equity,” an editorially independent special report that was produced with financial support from Takeda Pharmaceuticals. \nLauren Gravitz is a science journalist in San Diego, Calif., who has contributed to Nature, NPR, the Washington Post, MIT Technology Review and the Economist, among other publications. She is a 2021–2022 Knight Science Journalism Project Fellow at the Massachusetts Institute of Technology.\nYessenia Funes\nKatherine Bourzac\nJyoti Madhusoodanan\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Readers Respond to the May 2023 Issue", "date": "2023-10-01 13:30:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nLetters to the editors for the May 2023 issue of Scientific American\nI teared up after reading “Designing Life,” in which Philip Ball exquisitely describes how the undifferentiated cells of the early embryo create differentiated tissues, organs and a body, using a genome that does not contain design-plan instructions. The interplay of chemical, physical and electrical signals in the cells and their cooperative response are astounding.\r\nWENDY ROSENBLUM STAMFORD, CONN.\nAs I read of the multiplicity of projects experimenting with living tissues in Ball's article, I realized that this is the complementary situation to that of engineers “playing around” with artificial intelligence. Both groups have little idea of what will emerge from their activities and how it will affect the rest of us.\r\nARNOLD BANNER VIA E-MAIL\n“Witch Hunts,” by Silvia Federici and Alice Markham-Cantor, is a brilliant history of this horrifying and continuing assault against mostly women that often accompanies economic upheaval. The Supreme Court's decision to overturn the national right to an abortion has released what amounts to another contemporary “witch hunt” that targets women who seek this procedure and the medical practitioners who perform it. In many states, these women and professionals are subject to arrest and, for the latter, disbarment from their medical profession. Women travel to other states for an abortion, and those who help them are also subject to arrest.\nI wish the authors had included this present outrage in their article. Considering the current amount of gun violence, I suspect this country will soon see more murders of women who want to or do have an abortion and of professionals who perform the procedure.\r\nJIM BOTTA DELMAR, N.Y.\nSome of the causative factors at play in centuries of accusations of female witchcraft include economic hardship and dislocation, the need for an alien scapegoat, or “other,” and a strongly patriarchal social structure. While I was reading Federici and Markham-Cantor's analysis, it occurred to me that these factors may have further contemporary analogues in such accusations as “pizzagate,” the conspiracy theory that falsely claimed Hillary Clinton and other high-ranking Democrats operated a secret child-sex-trafficking ring.\nMost of the triggers for this kind of charge appear to be present in pizzagate: There is widespread conspiratorial rumormongering. There are threatened white males, who are often economically marginalized and facing alleged “replacement” by nonwhite people, as well as demotion from favored patriarchal hegemony by feminism and increased influence of women in politics and business. And there is even a quasireligious element with the false claim that Clinton and her acolytes performed “Satanism.”\nI think that many similar modern indictments of what amounts to female witchcraft could easily be found.\r\nGERALD A. DONALDSON SOUTHPORT, N.C.\n“Social Security and Science,” by Naomi Oreskes [Observatory], asserts that “Social Security isn't a drain on the federal budget; it pays for itself through a dedicated payroll tax.” The article is in error. Social Security tax receipts are already less than payments. The last Social Security Trustees report shows that demographics will cause growing problems. Lower birthrates mean there are fewer and fewer taxpayers for each recipient. There were 4.1 taxpayers per recipient in 1963, but there are only 2.7 now and expectations of just 2.3 by 2035.\r\nROBERT RAY IRVINE, CALIF.\nPoliticians can lie by speaking the truth in a way that misleads. They've told us Social Security (SS) benefits will need to be cut by 2034 because the SS trust funds will reach a dangerous low. They claim it's a difficult problem.\nIf nothing changes in the SS program, its reserves will be depleted by 2034. But raising the annual wage-base increase by a small amount would fix that. Who benefits by not solving this problem? People earning much more than the SS wage cap.\r\nEMANUEL V. POLIZZI MACUNGIE, PA.\nORESKES REPLIES: In my column, I did not say that all was well with the U.S. Social Security system. As several letter writers noted, demographic changes demand adjustments to the system. My point was that the required changes are not dramatic, but some people are exaggerating them because their antigovernment ideology leads them to look for an excuse to dismantle an extremely effective program.\nRay is right that the numbers look large, and when taken out of context, they are frightening. But as any modeler or manager can tell you, in large systems, small changes can have large effects, especially over time. As Polizzi notes, the looming shortfall could be fixed with a small change in the wage base—the level at which workers stop paying Social Security tax on their income.\nThis last point highlights an odd feature of the system. Most of our taxes keep increasing as our income increases. But with Social Security, payments top out at a certain amount. Right now that level is $160,200. According to a 2016 Wall Street Journal analysis, if you earned $161,413 in 2014, that would put you in the top 3 percent that year. Raising the wage base would not only close the shortfall but also make the system more equitable: currently anyone making more than $160,200 a year pays less of their income, as a percentage, in payroll taxes than someone making less than that. Another option would be to raise the retirement age, something that has been done once and could be done again.\nI was delighted to read “Let's Take the Bus,” Kendra Pierre-Louis's article supporting public transport as a way to help solve the climate crisis. I vacation every summer in a remote region of Italy called Val Pusteria. Moving around there used to be a nightmare until I substituted my rental car for the increasingly efficient local transport system that seamlessly coordinates the arrivals and departures of trains and buses down to the smallest of towns. It even connects to skiing venues accessible only through gondolas. Whether the U.S. can similarly deliver the punctuality, efficiency, cleanliness and safety of this region's transport system remains to be seen.\r\nIRA SOHN NEW YORK CITY\n“Parrot Invasions,” by Ryan F. Mandelbaum [July/August], introduced the Carolina Parakeet by saying that “North America once had its own parrot.” This extinct species was specifically native to the eastern U.S.\n“Urine Luck,” by Elise Cutts [Advances; April], misspelled the family name of archaeologist Justin Pargeter.\n“Science in Images,” by Jordan Kinard [Advances; July/August], should have described the FlyLight initiative researchers as at the Howard Hughes Medical Institute's (HHMI's) Janelia Research Campus in Ashburn, Va., not HHMI in New York.\nThis article was originally published with the title \"Letters\" in Scientific American  329, 3, 6-7 (October 2023)\ndoi:10.1038/scientificamerican1023-6\nTyler Carroll\nDaniel Garisto\nShannon Hall and Nature magazine\nAvery Ellfeldt and E&E News\nTanya Lewis\nSophie Bushwick and Lauren Leffer\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Science News Briefs from around the World: October 2023", "date": "2023-10-01 14:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nMammals munching on dinosaurs in China, Greenland’s melted past, coral catastrophe in Florida, and much more in this month’s Quick Hits\nAustralia is the first country to legalize psilocybin and MDMA for the treatment of depression and post-traumatic stress disorder. As clinical trials for these and other psychedelics gain momentum worldwide, Australia could be a model for governments considering regulation of these substances as medications.\nA 125-million-year-old fossil of a badgerlike animal biting a beaked dinosaur was unearthed in northeastern China. Most paleontologists thought mammals only scavenged dinosaur remains, but the find suggests early mammals hunted live dinosaurs several times their size.\nA mile-thick ice sheet in Greenland melted during a period of moderate warming 416,000 years ago, sediments show. This overturns long-held beliefs that the island remained an icy fortress for the past 2.5 million years, revealing its vulnerability to today's human-induced climate change.\nConstruction has begun on a 35-megawatt geothermal power project in Menengai, Kenya, the top geothermal-energy-producing country in Africa. Geothermal plants provide 47 percent of Kenya's energy, and production is expected to grow as droughts reduce hydropower sources.\nHuman skull and shinbone fossils found in a Laos cave suggest modern humans arrived in mainland Southeast Asia up to 36,000 years earlier than thought. This discovery challenges hypotheses that humans rapidly spread from Africa through Asia 80,000 years ago.\nOcean temperatures off Florida spiked to a record 100 degrees Fahrenheit, causing the worst coral-bleaching event in the state's history. Conservationists say some reefs face “100 percent coral mortality,” meaning the reefs won't recover without active, ongoing restoration work.\nThis article was originally published with the title \"Quick Hits\" in Scientific American  329, 3, 17 (October 2023)\ndoi:10.1038/scientificamerican1023-17b\nLucy Tu is a 2023 AAAS Mass Media Fellow at Scientific American. Follow her on Twitter @LucyTTu\nTyler Carroll\nDaniel Garisto\nShannon Hall and Nature magazine\nAvery Ellfeldt and E&E News\nTanya Lewis\nSophie Bushwick and Lauren Leffer\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "'AI Anxiety' Is on the Rise--Here's How to Manage It", "date": "2023-10-02 10:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nRapid advances in generative artificial intelligence have prompted big questions about the future of work and even human creativity. Experts have suggestions for how to manage all these unknowns\nIt’s logical for humans to feel anxious about artificial intelligence. After all, the news is constantly reeling off job after job at which the technology seems to outperform us. But humans aren’t yet headed for all-out replacement. And if you do suffer from so-called AI anxiety, there are ways to alleviate your fears and even reframe them into a motivating force for good.\nIn one recent example of generative AI’s achievements, AI programs outscored the average human in tasks requiring originality, as judged by human reviewers. For a study published this month in Scientific Reports, researchers gave 256 online participants 30 seconds to come up with imaginative uses for four commonplace objects: a box, a rope, a pencil and a candle. For example, a box might serve as a cat playhouse, a miniature theater or a time capsule. The researchers then gave the same task to three different large language models. To assess the creativity of these responses, the team used two methods: an automated program that assessed “semantic distance,” or relatedness between words and concepts, and six human reviewers that were trained to rank responses on their originality.\nIn both assessments, the highest-rated human ideas edged out the best of the AI responses—but the middle ground told a different story. The mean AI scores were significantly higher than the mean human scores. For instance, both the automated and human assessments ranked the response “cat playhouse” as less creative than a similar AI-generated response from GPT-4, “cat amusement park.” And people graded the lowest-scoring human answers as far less creative than the worst of the AI generations.\nHeadlines ensued, proclaiming that “AI chatbots already surpass average human in creativity” and “AI is already more creative than YOU.” The new study is the latest in a growing body of research that seems to portend generative AI outpacing the average human in many artistic and analytical realms—from photography competitions to scientific hypotheses.\nIt’s news such as this that has fed Kat Lyons’s fears about AI. Lyons is a Los Angeles–based background artist who works in animation and creates immersive settings for TV shows including Futurama and Disenchantment. In many ways, it’s their dream job—a paid outlet for their passion and skill in visual art, which they’ve been cultivating since age four. But some aspects of the dream have begun to sour: the rise of visual generative AI tools such as Midjourney and Stable Diffusion (and the entertainment industry’s eagerness to use them) has left Lyons discouraged, frustrated and anxious about their future in animation—and about artistic work in general. For instance, they were disheartened when Marvel and Disney decided to use an AI-generated, animated intro sequence made by the visual effects company Method Studios for the show Secret Invasion, which premiered in June. “It feels really scary,” Lyons says. “I honestly hate it.” Disney, which owns Marvel Studios, and Method Studios did not immediately respond to a request for comment.\nLike many professional creatives, Lyons now worries about AI models—which need to train themselves on vast swaths of Internet content—stealing and rehashing their artistic work for others’ profit. And then there’s the corresponding loss of employment opportunities. More broadly, Lyons fears for the future of art itself in an era when honing a craft and a personal voice are no longer prerequisites for producing seemingly original and appealing projects. “I worked so hard for my artistic dreams. I’ve been drawing since I was in preschool,” they say. “This is always what I’ve wanted to do, but we might be entering a world where I have to give that up as my full-time job—where I have to go back to waiting tables or serving coffee.”\nLyons isn’t alone. Many people have found themselves newly anxious about the rapid rise of generative AI, says Mary Alvord, a practicing psychologist in the Washington, D.C., area. Alvord says her clients of all ages express concerns about artificial intelligence. Specific worries include a lack of protection for online data privacy, the prospect of job loss, the opportunity for students to cheat and even the possibility of overall human obsolescence. AI’s advance has triggered a vague but pervasive sense of general public unease, and for some individuals, it has become a significant source of stress.\nAs with any anxiety, it’s important to manage the emotion and avoid becoming overwhelmed. “A certain amount of anxiety helps motivate, but then too much anxiety paralyzes,” Alvord says. “There’s a balance to strike.” Here’s how some psychologists and other experts suggest tackling our AI fears.\nFirst off, context is key, says Sanae Okamoto, a psychologist and behavioral scientist at the United Nations University–Maastricht Economic and Social Research Institute on Innovation and Technology in the Netherlands. She suggests keeping in mind that the present moment is far from the first time people have feared the rise of an unfamiliar technology. “Computer anxiety” and “technostress” date back decades, Okamoto notes. Before that, there was rampant worry over industrial automation. Past technological advances have led to big societal and economic shifts. Some fears materialized, and some jobs did disappear, but many of the worst sci-fi predictions did not come true.\n“It’s natural and historical that we are afraid of any new technology,” says Jerri Lynn Hogg, a media psychologist and former president of the American Psychological Association’s Society for Media Psychology and Technology. But understanding the benefits of a new tech, learning how it works and getting training in how to use it productively can help—and that means going beyond the headlines.\nSimone Grassini, one of the researchers of the new study and a psychologist at Norway’s University of Bergen, is quick to point out that “performing one specific task that is related to creative behavior doesn’t automatically translate to ‘AI can do creative jobs.’” The current technology is not truly producing new things but rather imitating or simulating what people can do, Grassini says. AI’s “cognitive architecture and our cognitive architecture are substantially different.” In the study, it’s possible the AI won high creativity ratings because its answers simply copied verbatim parts of a human creation contained somewhere in its training set, he explains. The AI was also competing against human volunteers who had no particular motivation to excel at their creative task and had never necessarily completed such an assignment before. Participants were recruited online and paid only about $2.50 for an estimated 13 minutes of work.\nConfronting fears of generative AI by actually trying out the tools, seeing where and how they can be useful, reading up on how they work and understanding their limitations can turn the tech from a boogeyman into a potential asset, Hogg says. A deeper understanding can empower someone to advocate for meaningful job protections or policies that rein in potential downsides.\nAlvord also emphasizes the importance of addressing the problem directly. “We talk about what actions you can take instead of sticking your head in the sand,” she says. Maybe that means gaining new skills to prepare for a career change or learning about ongoing efforts to regulate AI. Or maybe it means building a coalition with colleagues at work. Lyons says being involved with their union, the Animation Guild, has been crucial to helping them feel more secure and hopeful about the future. In this way, remedies for AI anxiety may be akin to ones for another major, burgeoning societal fear: climate anxiety.\n\r\nThough there are obvious differences between the two phenomena (AI clearly offers some significant possible benefits), there are also apparent similarities. In tackling the biggest concerns about AI and in confronting the climate crisis, “we’re all in this challenge together,” Okamoto says. Just as with climate activism, she explains, meaningfully confronting fears over AI might begin with building solidarity, finding community and coming up with collective solutions.\nAnother way to feel better about AI is to avoid overly fixating on it, Okamoto adds. There is more to life than algorithms and screens. Taking breaks from technology to reconnect with nature or loved ones in the physical world is critical for mental health, she notes. Stepping away from tech can also provide a reminder of all the ways that humans are distinct from the chatbots or image generators that might threaten a person’s career or self-image. Humans, unlike AI, can experience the world directly and connect with one another about it.\nWhen people create something, it’s often in response to their environment. Each word or brushstroke can carry meaning. For Lyons, human creativity is a “feral, primitive drive to make something because you can’t not make it.” So far, all AI can do is mimic that ability and creative motivation, says Sean Kelly, a Harvard University philosophy professor who has been examining the relationship between human creativity and AI for years. When an AI model generates something, Kelly says, “it’s not doing what the original artist did, which was trying to say something that they felt needed to be said.”\nTo Kelly, the real societal fear shouldn’t be that AI will get better or produce ever more interesting content. Instead he’s afraid “that we’ll give up on ourselves” and “just become satisfied” with what AI generators can provide.\nPerhaps the better, and more characteristically human, response is to use our AI anxiety to propel us forward. Mastering a craft—be it drawing, writing, programming, translating, playing an instrument or composing mathematical proofs—and using that skill to create something new is “the most rewarding thing that we can possibly do,” Kelly says. So why not let AI motivate more creation instead of replace it? If the technology spits out something compelling, we can build on it. And if it doesn’t, then why worry about it at all?\nLauren Leffer is a tech reporting fellow at Scientific American. Previously, she has covered environmental issues, science and health. Follow her on Twitter @lauren_leffer\nAnanya\nSophie Bushwick and Elah Feder\nLauren Leffer\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Scientists behind mRNA COVID Vaccines Win 2023 Nobel Prize in Physiology or Medicine", "date": "2023-10-02 10:52:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nKatalin Karikó and Drew Weissman were awarded this year’s Nobel Prize in Physiology or Medicine for mRNA vaccine discoveries that made highly effective COVID vaccines possible\nThis year’s Nobel Prize in Physiology or Medicine goes to a transformative medical technology that significantly altered the path of the pandemic and saved millions: the mRNA vaccines against COVID. Katalin Karikó and Drew Weissman were jointly awarded the prize for advancements that have changed the field of vaccine development and researchers’ understanding of how messenger RNA (mRNA) interacts with the body’s immune system. \nSpeaking to Scientific American, Weissman describes the rollercoaster of emotions he went through after learning of the news this morning. “I’m going through a series of steps, it started off just incredible enjoyment and surprise,” he says. “And right now I’m pretty much numb.”\nKarikó and Weissman began studying in vitro synthetic mRNA technology in the 1990s, when they worked together at the University of Pennsylvania. The pair’s seminal paper in 2005 described how they were able to successfully deliver modified mRNA into the body and trigger an immune response—the kind that trains the immune system for future viral infections. Over the years, their research with mRNA vaccines solved some of the major issues confronting the technique, such as the inflammatory response by the body that involves the production of harmful cytokines. During the pandemic, this mRNA technology led to the production of highly effective vaccines against SARS-CoV-2, the COVID-causing virus, and particularly ones that were adaptable for large-scale rollout. \n“What’s important here I think is that vaccines could be developed so fast,” said Gunilla Karlsson Hedestam, a member of the 2023 Nobel Committee for Physiology or Medicine, at this morning’s announcement. This was “largely due to ... improvements in the technology and this basic discovery.” \nKarikó was born in 1955 in Szolnok, Hungary. In 1989 she became an assistant professor at the University of Pennsylvania, where she remained until 2013. She was a senior vice president at BioNTech RNA Pharmaceuticals—a major manufacturer of an mRNA COVID vaccine—and is now an external consultant for BioNTech. She is also a professor at the University of Szeged in Hungary and an adjunct professor at the Perelman School of Medicine at the University of Pennsylvania.\nWeissman was born in 1959 in Lexington, Mass. In 1997 he established his research group at the Perelman School of Medicine. Weissman is Roberts Family Professor in Vaccine Research at the University of Pennsylvania and director of the Penn Institute for RNA Innovation.\n“The award, to me, is really a victory for vaccines and the potential for vaccines to advance health and improve equity,” says Kathleen Neuzil, a vaccinology professor and director of the Center for Vaccine Development and Global Health at the University of Maryland School of Medicine. \nMany vaccines had been created with weakened or deactivated whole viruses, but in recent decades many researchers have been investigating smaller viral parts, such as viral genetic material: DNA or RNA. When Karikó and Weissman injected the foreign in vitro mRNA into human cells, they found that it created a strong immune reaction that elevated protective antibodies. Subsequent inflammation, as well as enzymes in human blood and cells, would degrade the mRNA, however. Despite these scientific roadblocks, skepticism and difficulties with funding, Karikó and Weissman continued to search for solutions. \n“It was nonstop technical hurdles for 25 years,” Weissman reflects. “We couldn’t get funding, Kati [Karikó] kept getting demoted and pushed out. It was very difficult to do this research, but we saw early on the potential and how important RNA was likely to be. And that kept us going. We never gave up.”\nThe team found a way to modify mRNA to be less inflammatory—replacing uridine, one of its building block molecules, with a similar molecule called pseudouridine. They also developed a more efficient delivery system that used lipid nanoparticles to protect the mRNA and help it to enter cells for protein production.\n“In the early days of vaccinology, we would take a bacteria, we would take a virus, and we would weaken it, or we would combine it with another antigen. But here this was really a targeted immune system approach, both from the use of the mRNA and the use of the lipid nanoparticle,” Neuzil says. “So, to me, that was quite impressive—that they took an entirely different approach to vaccine delivery.”\nStarting in the early 2000s, Karikó and Weissman conducted several animal trials with mRNA vaccines for a variety of different pathogens such as Zika, influenza and HIV. “In every animal model we looked at, HIV was the only one that didn’t work well,” Weissman says. “Just about every single one of them gave us 100 percent protection.” \nThe research unlocked a new path for possible therapy and vaccine development—one that would prove critical during the COVID pandemic. \nAdapting for a Global Public Health Emergency \nWhen SARS-CoV-2 began to spread worldwide, Weissman and Karikó’s mRNA research quickly became a candidate and basis for vaccines against the virus. The mRNA vaccine approach had several advantages, Weissman explains. Only a sequence of the original pathogen was needed rather than an actual piece or full virus. “There’s no growing a virus and inactivating it. It’s a very simple procedure, and that’s because it’s a simple enzymatic reaction,” Weissman says. “It was two months from the sequence being released to the first patients getting the vaccine.” \nClinical trials, production and rollout of the vaccines greatly expanded, with companies creating hundreds of millions of doses within a year. “Switching over to COVID, it was just a technical thing,” Karikó told Scientific American in a 2021 interview. “It was already ready.” \nThe mRNA COVID vaccines work by injecting the genetic material specifically for SARS-CoV-2’s spike proteins—surface proteins on the virus that allow it to bind to healthy cells. Modified mRNA in the vaccine is taken by cells, which then decode it and produce those spike proteins so that the immune system can better identify and neutralize the real virus in the event of a future infection. \n“We’re coming off the worst pandemic in more than a century, and certainly these vaccines contributed to lives saved and to less morbidity,” says Neuzil, who has also been working on mRNA vaccines for malaria. “I think an adaptation of this technology and mRNA vaccines could really be transformative, particularly for low- and middle-income countries, because of the adaptability and flexibility of the platform.”\nFuture Therapies  \nFor future vaccines, the application can be quite broad, Weissman says. When Karikó first became interested in mRNA research, she wasn’t initially seeking to develop vaccines. “I was making this modification in the RNA because I always wanted to develop it for therapies,” she told Scientific American in 2021. \nWhile the mRNA technology has helped to tackle the COVID pandemic, a tremendous number of people will benefit from the technology, says Niek Sanders, a principal investigator at Ghent University’s Laboratory of Gene Therapy in Belgium. “It can also be used to treat any disease that is due to a malfunctioning protein as it allows patients produce their own therapeutic proteins,” Sanders says. “Nobel Prizes with such a high impact on society are rare and occur only once in 25 or 50 years.”\nWeissman, Karikó and other research groups are already trying to apply the technology to autoimmune diseases, cancers, food and environmental allergies, bacterial diseases and insect-borne diseases. In July Weissman and his colleagues published a paper in Science that showed they could deliver RNA gene-editing machinery directly to bone marrow stem cells. This could be key for treating diseases such as sickle cell anemia, in which stem cells are typically taken from an individual, cultured and treated, and then put back into the body. “Now we can give them an off-the-shelf injection of RNA and cure their disease, and that has applicability to thousands of other bone marrow diseases. And then you can expand that to liver, to lung, to brain, to every other organ therapeutics,” Weissman says. “The potential is just enormous.”\nWeissman hopes that the mRNA treatment will be available to sickle cell anemia patients in a year and a half. He also has many mRNA clinical trials underway, including a phase 1 trial for the disease amyloidosis and vaccine trials for HIV, norovirus and malaria. Wiessman’s team is also planning to start clinical trials soon on a pan-coronavirus mRNA vaccine, which could help prevent future coronavirus epidemics. \n“The future is now,” Weissman says. “These therapeutics are in people right now.”\nLauren J. Young is an associate editor for health and medicine at Scientific American. Follow her on Twitter @laurenjyoung617 Credit: Nick Higgins\nNaomi Oreskes\nDaniel Garisto\nLee Billings\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "It's Time to Hear from Social Scientists about UFOs", "date": "2023-10-02 11:30:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nWhether or not UFOs exist, we need to pay attention to how they are influencing our politics and culture\nUFOs, recently renamed unidentified anomalous phenomena (UAP), are attracting public attention in the U.S. in a way we haven’t seen for decades. Ex-government officials, prominent politicians, intelligence agencies, major news outlets and civilian scientists are all looking into the prospect of extraterrestrial visitors, making them no longer seem quite so far-fetched.\nEven NASA, once disinclined to take the subject seriously, convened an independent study team to create a road map for future study of sightings.  The team’s final report, which includes this road map, notes there is no evidence pointing to extraterrestrials. However, the questions asked of NASA officials at their recent press conference showed that aliens and cover-ups remain firmly on the minds of many observers.\nNot everyone has welcomed the UFOs’ newfound measure of legitimacy in the meantime, and critics have questioned both the science and the money behind the resurgence.\nBut for all their wrangling, advocates for and against the serious investigation of UAP share something in common: they all focus on the question of whether the phenomenon is something that exists in nature, whether worldly or other-worldly.\nWe don’t conclusively know if UAP physically exist beyond the mundane, but we do know this: UFOs are social facts. Debate about them is transforming our politics and culture—with effects that are largely overlooked.\nSocial scientists should weigh in on UAP, now. It is a task for which they are well equipped. They not only offer effective techniques for assessing social change, but for decades, social scientists have been conducting research on such relevant topics as human-technological systems, behavioral factors in manned space travel, public attitudes toward UFOs, and the psychophysical and cognitive aspects of sightings.\nTo start, there are three pressing issues surrounding UAP that bear serious study and discussion: intelligence, trust and research ethics.\nThe topic of intelligence turns up in multiple contexts in UAP discussions. For instance, regarding classified military knowledge, much of the current debate and legislation revolves around the reliability of UAP information and how it is handled by government agencies. Given national security needs, what appears to be part of a UFO cover-up may also be explained by mundane organizational failures at the Defense Department, administrations hesitant to poke into those failures, an institutional penchant for secrecy, and finally, plain, old, ignorance. Whatever the case, unidentified flying objects represent a challenge to governmental and military authority. This is because the state is expected to have answers to all possible threats. UAP undermine that guarantee since they are, by definition, unknown.\nIn addition, the subject of UFOs often evokes talk of a separate, mysterious intelligence that must somehow be behind the sightings. This has led philosophers, anthropologists and psychologists to speculate about alien minds, and there is much to be learned from that. We need scholars to figure out how to talk to a being with a nonhuman mind. But we should also examine our assumptions in thinking about and doing research on such intelligence.\nSearch for extraterrestrial intelligence (SETI) projects, for example, often work with culturally limited notions of civilizational evolution rooted in 19th-century ideals of persistent technological and moral progress. As a result, astronomers unknowingly tend to rely on language borrowed from the era of colonial conquest (e.g., space as “frontier”), while also appropriating land formerly belonging to Indigenous populations to set up their installations. Scholars have warned about how easily reason falls into anthropocentrism and cultural bias when dealing with the nonhuman.\nThe UAP debate also has much in common with conversations about the threats of artificial intelligence (AI). Both involve scenarios in which humans may interact with a superior intellect. Aside from the fear of being dominated by an unknown power, the prospect of an alien encounter raises concerns about uncontrollable consequences and crises in our social and political orders.\nIn reality, AI-based methods will allow us to explore such scenarios in detail. In the near future, large language models promise to help generate intellectual positions and communication that are indistinguishable from human ideas. AI could help to simulate how societies and communities might respond to threatening developments such as first contact. And computational methods already offer social scientists ways to explore large language model–based qualitative data; for example, (social) media data and UAP-related government interaction can reveal sentiments and any related patterns that may have eluded us.\nSuch rigor is especially needed because the history of UFOs has been defined by disputes over the trustworthiness of witness testimony and limited forensic data of these unidentified objects. Since the first reports of UFO sightings in 1947, people have continued to debate over the quality of the data, a fact that has been underscored by the most recent report from the Office of the Director of National Intelligence.\nIf in earlier times spiritual authorities have judged the credibility of witnesses reporting anomalous events, today the sciences have increasingly assumed this role—one that is being contested. When it comes to truth and trust, contemporary public communication, especially in the U.S., is characterized by a growing suspicion about established experts. Researchers observe a crisis in confidence in traditional scientific and political institutions.\nThat’s troubling.  Yes, questioning authority is admittedly a vital part of a pluralist society. But the spread of unverified “fake news” and conspiracy theories is shown to have corrosive effects on democracy. The circulation of misinformation and disinformation leads people to rely solely on sources confirming their existing beliefs. In the current environment of uncertainty, polarization and suspicion, tangible evidence often gets replaced by symbolic acts of performance to attest to the credibility of claims. This was apparent at the July 26 congressional hearing on UAP, where elected officials suggested an enormous cover-up.\nHow can we move beyond this? To enhance social trust, experts should lay out responsible standards of research. Deciding how UAP are investigated and by whom raises a variety of research ethics questions warranting reflection.\nSETI researchers have already begun weighing the benefits and harms in probing the universe for signs of intelligent life. They have mapped ways to responsibly search for, communicate with and reveal the existence of extraterrestrial civilizations. But they warn that our cultural biases likely make us ill-equipped to respond to such revelations. Caution about built-in bias and failure to account for complexity also apply to computational methods working with large amounts of text and language data. Here again, social science has a role to play.\nBarriers to learning are often our own doing. Take the defense and intelligence communities. Both have historically concerned themselves solely with whether UFOs pose a threat to safety. Their default is to frame the UAP matter in terms of security—a view the media often reinforces— thus militarizing the issue. In doing so, they literally classify the matter out of the eye of other policy makers and civilian scientists, as well as the skeptical public.\nPutting UAP in the hands of the private sector, however, hardly guarantees greater transparency or conscientiousness. The UFO phenomenon long ago turned into a commercial enterprise, now hyped by streaming services, podcasts, social media and cable television. Its entertainment value has provided the hook for Enigma Labs to promote an app for mobile phone users to report sightings. This raises serious privacy concerns about what this enigmatic company plans to do with the vast amount of users’ personal data it collects. A February RAND report, for example, called for a nationwide way to report sightings. But balancing privacy of both observers and the observed, while making the data transparent to researchers, poses obvious challenges.\nTalk about UFOs has never been just about UFOs. The social sciences likely won’t tell us whether UAP are from another world. They will, however, help us explore the “what ifs” and reveal what our actions today tell us about ourselves.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.\nGreg Eghigian is professor of history and bioethics at Penn State University. His book After the Flying Saucers Came: A Global History of the UFO Phenomenon will be released in 2024. Follow him on X at @GEghigian\nChristian Peters is managing director of the Bremen International Graduate School of Social Sciences. He has published on religion and politics, higher education didactics, and social science epistemology. Follow him on X at @cp_cassius\nKatie Hafner, Claire Trageser and The Lost Women of Science Initiative\nConor Feehly\nLilly Tozer and Nature magazine\nAndrea Thompson\nAshleigh Furlong and E&E News\nDina Genkina\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "The Assumptions You Bring into Conversation with an AI Bot Influence What It Says", "date": "2023-10-02 15:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nA new study reveals an “AI placebo effect”: the same chatbot will respond differently depending on its users’ assumptions about artificial intelligence\nDo you think artificial intelligence will change our lives for the better or threaten the existence of humanity? Consider carefully—your position on this may influence how generative AI programs such as ChatGPT respond to you, prompting them to deliver results that align with your expectations.\n“AI is a mirror,” says Pat Pataranutaporn, a researcher at the M.I.T. Media Lab and co-author of a new study that exposes how user bias drives AI interactions. In it, researchers found that the way a user is “primed” for an AI experience consistently impacts the results. Experiment subjects who expected a “caring” AI reported having a more positive interaction, while those who presumed the bot to have bad intentions recounted experiencing negativity—even though all participants were using the same program.\n“We wanted to quantify the effect of AI placebo, basically,” Pataranutaporn says. “We wanted to see what happened if you have a certain imagination of AI: How would that manifest in your interaction?” He and his colleagues hypothesized that AI reacts with a feedback loop: if you believe an AI will act a certain way, it will.\nTo test this idea, the researchers divided 300 participants into three groups and asked each person to interact with an AI program and assess its ability to deliver mental health support. Before starting, those in the first group were told the AI they would be using had no motives—it was just a run-of-the-mill text completion program. The second set of participants were told their AI was trained to have empathy. The third group was warned that the AI in question was manipulative and that it would act nice merely to sell a service. But in reality, all three groups encountered an identical program. After chatting with the bot for one 10- to 30-minute session, the participants were asked to evaluate whether it was an effective mental health companion.\nThe results suggest that the participants’ preconceived ideas affected the chatbot’s output. In all three groups, the majority of users reported a neutral, positive or negative experience in line with the expectations the researchers had planted. “When people think that the AI is caring, they become more positive toward it,” Pataranutaporn explains. “This creates a positive reinforcement feedback loop where, at the end, the AI becomes much more positive, compared to the control condition. And when people believe that the AI was manipulative, they become more negative toward the AI—and it makes the AI become more negative toward the person as well.”\nThis impact was absent, however, in a simple rule-based chatbot, as opposed to a more complex one that used generative AI. While half the study participants interacted with a chatbot that used GPT-3, the other half used the more primitive chatbot ELIZA, which does not rely on machine learning to generate its responses. The expectation effect was seen with the former bot but not the latter one. This suggests that the more complex the AI, the more reflective the mirror that it holds up to humans.\nThe study intimates that AI aims to give people what they want—whatever that happens to be. As Pataranutaporn puts it, “A lot of this actually happens in our head.” His team’s work was published in Nature on Monday.\nAccording to Nina Beguš, a researcher at the University of California, Berkeley, and author of the upcoming book Artificial Humanities: A Fictional Perspective on Language in AI, who was not involved in the M.I.T. Media Lab paper, it is “a good first step. Having these kinds of studies, and further studies about how people will interact under certain priming, is crucial.”\nBoth Beguš and Pataranutaporn worry about how human presuppositions about AI—derived largely from popular media such as the films Her and Ex Machina, as well as classic stories such as the myth of Pygmalion—will shape our future interactions with it. Beguš’s book examines how literature across history has primed our expectations regarding AI.\n“The way we build them right now is: they are mirroring you,” she says. “They adjust to you.” In order to shift attitudes toward AI, Beguš suggests that art containing more accurate depictions of the technology is necessary. “We should create a culture around it,” she says.\n“What we think about AI came from what we see in Star Wars or Blade Runner or Ex Machina,” Pataranutaporn says. “This ‘collective imagination’ of what AI could be, or should be, has been around. Right now, when we create a new AI system, we’re still drawing from that same source of inspiration.”\nThat collective imagination can change over time, and it can also vary depending on where people grew up. “AI will have different flavors in different cultures,” Beguš says. Pataranutaporn has firsthand experience with that. “I grew up with a cartoon, Doraemon, about a cool robot cat who helped a boy who was a loser in ... school,” he says. Because Pataranutaporn was familiar with a positive example of a robot, as opposed to a portrayal of a killing machine, “my mental model of AI was more positive,” he says. “I think in ... Asia people have more of a positive narrative about AI and robots—you see them as this companion or friend.” Knowing how AI “culture” influences AI users can help ensure that the technology delivers desirable outcomes, Pataranutaporn adds. For instance, developers might design a system to seem more positive in order to bolster positive results. Or they could program it to use more straightforward delivery, providing answers like a search engine does and avoiding talking about itself as “I” or “me” in order to limit people from becoming emotionally attached to or overly reliant on the AI.\nThis same knowledge, however, can also make it easier to manipulate AI users. “Different people will try to put out different narratives for different purposes,” Pataranutaporn says. “People in marketing or people who make the product want to shape it a certain way. They want to make it seem more empathetic or trustworthy, even though the inside engine might be super biased or flawed.” He calls for something analogous to a “nutrition label” for AI, which would allow users to see a variety of information—the data on which a particular model was trained, its coding architecture, the biases that have been tested, its potential misuses and its mitigation options—in order to better understand the AI before deciding to trust its output.\n“It’s very hard to eliminate biases,” Beguš says. “Being very careful in what you put out and thinking about potential challenges as you develop your product is the only way.”\n“A lot of conversation on AI bias is on the responses: Does it give biased answers?” Pataranutaporn says. “But when you think of human-AI interaction, it’s not just a one-way street. You need to think about what kind of biases people bring into the system.”\nNick Hilden writes for the likes of the Washington Post, Esquire, Popular Science, National Geographic, the Daily Beast, and more. You can follow him on Twitter @nickhilden or Instagram @nick.hilden Follow Nick Hilden on Twitter\nJohn Villasenor | Opinion\nTamlyn Hunt | Opinion\nChristof Koch\nGeorge Musser\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "The State of Large Language Models", "date": "2023-10-02 16:00:00", "text": "We present the latest updates on ChatGPT, Bard and other competitors in the artificial intelligence arms race.\nLAUREN LEFFER: At the end of November, it’ll be one year since ChatGPT was first made public, rapidly accelerating the artificial intelligence arms race. And a lot has changed over the course of 10 months.\nSOPHIE BUSHWICK: In just the past few weeks, both OpenAI and Google have introduced big new features to their AI chatbots.\nLEFFER: And Meta, Facebook’s parent company, is jumping in the ring too, with its own public facing chatbots.\nBUSHWICK: I mean, we learned about one of these news updates just minutes before recording this episode of Tech, Quickly, the version of Scientific American’s Science, Quickly podcast that keeps you updated on the lightning-fast advances in AI. I’m Sophie Bushwick, tech editor at Scientific American.\nLEFFER: And I’m Lauren Leffer, tech reporting fellow.\n[Clip: Show theme music]\nBUSHWICK: So what are these new features these AI models are getting?\nLEFFER: Let’s start with multimodality. Public versions of both OpenAI’s ChatGPT and Google’s Bard can now interpret and respond to image and audio prompts, not just text. You can speak to the chatbots, kind of like the Siri feature on an iPhone, and get an AI-generated audio reply back. You can also feed the bots pictures, drawings or diagrams, and ask for information about those visuals, and get a text response. \nBUSHWICK: That is awesome. How can people get access to this?\nLEFFER: Google’s version is free to use, while OpenAI is currently limiting its new feature to premium subscribers who pay $20 per month.\nBUSHWICK: And multimodality is a big change, right? When I say “large language model,” that used to mean text and text only.\nLEFFER: Yeah, it’s a really good point. ChatGPT and Bard were initially built to parse and predict just text. We don’t know exactly what’s happened behind the scenes to get these multimodal models. But the basic idea is that these companies probably added together aspects of different AI models that they’ve built—say existing ones that auto-transcribe spoken language or generate descriptions of images—and then they used those tools to expand their text models into new frontiers. \nBUSHWICK: So it sounds like behind the scenes we’ve got these sort of Frankenstein’s monster of models?\nLEFFER: Sort of. It’s less Frankenstein, more kind of like Mr. Potato Head, in that you have the same basic body just with new bits added on. Same potato, new nose.\nOnce you add in new capacities to a text-based AI, then you can train your expanded model on mixed-media data, like photos paired with captions, and boost its ability to interpret images and spoken words. And the resulting AIs have some really neat applications.  \nBUSHWICK: Yeah, I’ve played around with the updated ChatGPT, and this ability to analyze photos really impressed me.\nLEFFER: Yeah, I had both Bard and ChatGPT try to describe what type of person I am based on a photo of my bookshelf.\nBUSHWICK: Oh my god, it’s the new internet personality test! So what does your AI book horoscope tell you?\nLEFFER: So not to brag, but to be honest, both bots were pretty complimentary. (I have a lot of books.) But beyond my own ego, the book test demonstrates how people could use these tools to produce written interpretations of images, including inferred context. You know, this might be helpful for people with limited vision or other disabilities, and OpenAI actually tested their visual GPT-4 with blind users first. \nBUSHWICK: That’s really cool. What are some other applications here?\nLEFFER: Yeah, I mean, this sort of thing could be helpful for anyone—sighted or not—trying to understand a photo of something they’re unfamiliar with. Think, like, bird identification or repairing a car. In a totally different example, I also got ChatGPT to correctly split up a complicated bar tab from a photo of a receipt. It was way faster than I could’ve done the math, even with a calculator.\nBUSHWICK: And when I was trying out ChatGPT, I took a photo of the view from my office window, asked ChatGPT what it was (which is the Statue of Liberty), and then asked it for directions. And it not only told me how to get the ferry, but gave me advice like “wear comfortable shoes.”\nLEFFER: The directions thing was pretty wild.\nBUSHWICK: It almost seemed like magic, but, of course…\nLEFFER: It’s definitely not. It’s still just the result of lots and lots of training data, fed into a very big and complicated network of computer code. But even though it’s not a magic wand, multimodality is a really significant enough upgrade that might help OpenAI attract and retain users better than it has been. You know, despite all the new stories going around, fewer people have actually been using ChatGPT over the past three months. Usership dropped by about 10 percent for the first time in June, another 10 percent in July, and about 3 percent in August. The prevailing theory is that this has to do with summer break from school—but still losing users is losing users.\nBUSHWICK: That makes sense. And this is also a problem for OpenAI, because it has all this competition. For instance, we have Google, which is keeping its own edge by taking its multimodal AI tool and putting it into a bunch of different products.\nLEFFER: You mean like Gmail? Is Bard going to write all my emails from now on?\nBUSHWICK: I mean, if you want it to. If you have a Gmail account, or even if you use YouTube or Google, if you have files stored in Google Drive, you can opt in and give Bard access to this individual account data. And then you can ask it to do things with that data, like find a specific video, summarize text from your emails, it can even offer specific location-based information. Basically, Google seems to be making Bard into an all-in-one digital assistant.\nLEFFER: Digital assistant? That sounds kind of familiar. Is that at all related to the virtual chatbot pals that Meta is rolling out? \nBUSHWICK: Sort of! Meta just announced it’s not introducing just one AI assistant, it’s introducing all these different AI personalities that you’re supposedly going to be able to interact with in Instagram or WhatsApp or its other products. The idea is it’s got one main AI assistant you can use, but you can also choose to interact with an AI that looks like Snoop Dogg and is supposedly modeled off specific personalities. You can also interact with an AI that has specialized function, like a travel agent.\nLEFFER: When you're listing all of these different versions of an AI avatar you can interact with, the only thing my mind goes to is Clippy from the old school Microsoft Word. Is that basically what this is?\nBUSHWICK: Sort of. You can have, like, a Mr. Beast Clippy, where when you're talking with it, it does—you know how Clippy kind of bounced and changed shape—these images of the avatars will sort of move as if they're actually participating in the conversation with you. I haven't gotten to try this out myself yet, but it does sound pretty freaky.\nLEFFER: Okay, so we’ve got Mr. Beast. We’ve got Snoop Dogg. Anyone else?\nBUSHWICK: Let's see, Paris Hilton comes to mind. And there's a whole slew of these. And I'm kind of interested to see whether people actually choose to interact with their favorite celebrity version or whether they choose the less anthropomorphized versions.\nLEFFER: So these celebrity avatars, or whichever form you're going to be interacting with Meta’s AI in, is it also going to be able to access my Meta account data? I mean, there's like so much concern out there already about privacy and large language models. If there's a risk that these tools could regurgitate sensitive information from their training data or user interactions, why would I let Bard go through my emails or Meta read my Instagram DMs.\nBUSHWICK: Privacy policies depend on the company. According to Google, it’s taken steps to ensure privacy for users who opt into the new integration feature. These steps include not training future versions of Bard on content from user emails or Google Docs, not allowing human reviewers to access users’ personal content, not selling the information to advertisers, and not storing all this data for long periods of time. \nLEFFER: Okay, but what about Meta and its celebrity AI avatars?\nBUSHWICK: Meta has said that, for now, it won’t use user content to train future versions of its AI.... But that might be coming soon. So privacy is still definitely a concern, and it goes beyond these companies. I mean, literal minutes before we started recording, we read the news that Amazon has announced it’s training a large language model on data that’s is going to include conversations recorded by Alexa.\nLEFFER: So conversations that people have in their homes with their Alexa assistant.\nBUSHWICK: Exactly. \nLEFFER: That sounds so scary to me. I mean, in my mind, that's exactly what people have been afraid of with these home assistants for a long time: that they'd be listening, recording, and transmitting that data to somewhere that the person using it no longer has control over.\nBUSHWICK: Yeah, anytime you let another service access information about you, you are opening up a new potential portal for leaks, and also for hacks.\nLEFFER: It’s completely unsettling. I mean, do you think that the benefits of any of these AIs outweigh the risks?\nBUSHWICK: So, it’s really hard to say right now. Google’s AI integration, multimodal chat bots, and, I mean, just these large language models in general, they are all still in such early experimental stages of development. I mean, they still make a lot of mistakes, and they don't quite measure up to more specialized tools that have been around for longer. But they can do a whole lot all in one place, which is super convenient, and that can be a big draw.\nLEFFER: Right, so they’re definitely still not perfect, and one of those imperfections: they’re still prone to hallucinating incorrect information, correct?\nBUSHWICK: Yes, and that brings me to one last question about AI before we wrap up: Do eggs melt?\nLEFFER: Well, according to an AI-generated search result gone viral last week, they do. \nBUSHWICK: Oh, no.\nLEFFER: Yeah, a screenshot posted on social media showed Google displaying a top search snippet that claimed, “an egg can be melted,” and then it went on to give instructions on how you might melt an egg. Turns out, that snippet came from a Quora answer generated by ChatGPT and boosted by Google’s search algorithm. It’s more of that AI inaccuracy in action, exacerbated by search engine optimization—though at least this time around it was pretty funny, and not outright harmful.\nBUSHWICK: But Google and Microsoft—they’re both working to incorporate AI-generated content into their search engines. But this melted egg misinformation struck me because it’s such a perfect example of why people are worried about that happening.\nLEFFER: Mmm ... I think you mean eggs-ample.\nBUSHWICK: Egg-zactly.\n[Clip: Show theme music]\nScience Quickly is produced by Jeff DelViscio, Tulika Bose, Kelso Harper and Carin Leong. Our show is edited by Elah Feder and Alexa Lim. Our theme music was composed by Dominic Smith.\nLEFFER:  Don’t forget to subscribe to Science, Quickly wherever you get your podcasts. For more in-depth science news and features, go to ScientificAmerican.com. And if you like the show, give us a rating or review!\nBUSHWICK:  For Scientific American’s Science, Quickly, I’m Sophie Bushwick. \nLEFFER:  I’m Lauren Leffer. See you next time!\r\n\t \nSophie Bushwick is an associate editor covering technology at Scientific American. Follow her on Twitter @sophiebushwick Credit: Nick Higgins\nLauren Leffer is a tech reporting fellow at Scientific American. Previously, she has covered environmental issues, science and health. Follow her on Twitter @lauren_leffer\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Climate Disasters Threaten to Widen U.S. Wealth Gap", "date": "2023-10-02 17:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nAbout one in five U.S. counties are both socially vulnerable and highly exposed to natural disasters, which could “compound existing inequities,” the Department of the Treasury says in a new report\nCLIMATEWIRE | Climate change is expected to exacerbate social inequality in the United States and put millions of people at risk of severe financial distress, according to a new report from the Treasury Department.\nThe findings, released Friday, focused on two sets of data.\nUsing county-level climate projections through 2045, the Treasury Department determined that about half of all U.S. counties face “elevated exposure” to one or multiple climate hazards including wildfire, extreme heat and flooding.\nTreasury officials then overlaid that information with data about each county’s “social vulnerability,” which takes in account more than a dozen factors including poverty, health conditions, race and ethnicity.\nThe result: About 1 in 5 U.S. counties are both socially vulnerable and highly exposed to natural disasters.\nIt’s a combination that has the potential to “compound existing inequities and cause disproportionate financial strain,” according to the report.\nAs one example, the report looked at the Appalachian region of the eastern United States, which is more likely to flood as the planet warms. In addition to the climate threat, residents in that part of the country often have reduced access to health care services and “more limited employment opportunities,” the report says.\nTaken together, “households in this region may struggle to manage expenses if flooding events result in reduced working hours, or damage or destruction of household property,” wrote Treasury officials.\nAppalachia isn’t the only region at risk. The report highlighted similar problems in the southwestern United States, which is exposed to wildfires, and the Mississippi Delta, which is vulnerable to spells of extreme heat.\nHigh temperatures can be especially dangerous for Americans with less wealth.\n“Lower-income households often lack access to air conditioning, which may make them more susceptible to heat-related illnesses,” the report said. “Additionally, households in the Mississippi Delta are more likely to include older adults and individuals with pre-existing health conditions. These households may experience financial strain from added healthcare and utility costs.”\nThe dual threat of climate impacts and social vulnerability isn’t a new problem. But policymakers say it’s an issue that deserves a robust response.\n“We know managing financial risk is not a new challenge, especially for low income and underserved communities who are often extremely sophisticated budgeters,” Suzanna Fritzberg who serves as a deputy assistant secretary at the Treasury Department, said Friday during an event hosted by the Urban Institute.\n“But it is an emerging risk, it is complex,\" Fritzberg added. \"It has both near-term and long-term challenges.\"\nThe report comes more than two years after President Joe Biden signed an executive order directing federal agencies to consider the financial threats of climate change.\nThat has resulted in a range of actions from the Treasury Department, including working with a council of top financial regulators to examine how natural disasters and the transition away from fossil-based energy could affect the global financial system.\nThe agency also has called on property and casualty insurers to provide ZIP-code-level data about climate-fueled financial risk, and it more recently released principles meant to streamline financial firms’ climate commitments.\nEven so, more work needs to be done.\nThe report outlines several examples of how climate impacts or disasters can affect household finances. That includes an interruption of income, particularly for outdoor workers in industries such as agriculture, tourism and construction. Floods and wildfires can also be devastating for families who do not have the savings required to quickly repair their homes.\nThose scenarios are made worse, Treasury argues, by the fact that many households are both underinsured and face high insurance premiums — further cutting into their savings and leaving their homes unprotected.\nAlso notable is that in the wake of a disaster some households turn to loans or credit cards to cover costs — and struggle to make payments on existing debt. That can increase their likelihood of default, an outcome that can have a long-term impact on credit scores and access to money.\n“That was really our goal with this report, was to try to really put the granular household-level focus on some of these broader events where we see the macro-level impacts and the costs, but understand how it really reflects in people’s day to day lives,” Graham Steele, Treasury’s assistant secretary for financial institutions, said Friday.\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nAvery Ellfeldt is a reporter with E&E News.\nDaniel Cusick and E&E News\nJune Kim\nEmma Seppala\nThomas Frank and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "An mRNA Pioneer Discusses How Her Work Led to the COVID Vaccines", "date": "2023-10-02 17:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nBiochemist Katalin Karikó and her colleague Drew Weissman were recently awarded a $3-million Breakthrough Prize for their work\nEditor’s Note (10/2/23): Katalin Karikó and Drew Weissman were awarded the 2023 Nobel Prize in Physiology or Medicine for their work on mRNA, which led to COVID vaccines that have protected billions of people. Karikó discusses some of the key advances in this interview from 2021.\nResearchers often toil away for years in a lab without any promise that their research will result in anything meaningful for society. But sometimes this work results in a breakthrough with global ramifications. Such was the case for Katalin Karikó, who, along with her colleague Drew Weissman, helped develop the messenger RNA (mRNA) technology that was used to produce the highly effective COVID vaccines made by Pfizer and Moderna.\nKarikó, who is now senior vice president and head of RNA protein replacement therapies at BioNTech (the company that co-developed a COVID vaccine with Pfizer), and Weissman, a professor of vaccine research at the University of Pennsylvania’s Perelman School of Medicine, have just been awarded a $3 million Breakthrough Prize in Life Sciences for their work on modifying the genetic molecule RNA to avoid triggering a harmful immune response. The Breakthrough Prizes, founded by Sergey Brin, Priscilla Chan, Mark Zuckerberg, Yuri and Julia Milner, and Anne Wojcicki, honor groundbreaking discoveries in fundamental physics, life sciences and mathematics. (Earlier this year Karikó received the Vilcek Prize for Excellence in Biotechnology, a $100,000 award that recognizes the extraordinary contributions immigrants make to society and culture.) Karikó spent years on this research despite skepticism and a lack of funding. Ultimately, however, her efforts paid off—laying the groundwork for the overwhelmingly effective vaccines that are likely the world’s surest way out of the COVID pandemic.*\nKarikó was born in Hungary to a family of modest means. She started her work on modifying RNA during her Ph.D. studies and—convinced of the promise of RNA-based therapies—came to the U.S. to pursue postdoctoral research. She later ended up as a professor at the University of Pennsylvania. Interest in mRNA therapies declined, and she was told to pursue other research directions or risk losing her position, but she persisted. Over a conversation at the Xerox machine she got to know Weissman, who was interested in developing vaccines at the time. They started collaborating.\nWhen foreign mRNA is injected into the body, it causes a strong immune response. But Karikó and Weissman figured out a way to how to modify the RNA to make it less inflammatory by substituting one DNA “letter” molecule for another. Next they worked on how to deliver it. After testing many different delivery vehicles, they settled on lipid nanoparticles as the delivery vehicle. These turned out to work incredibly well: the nanoparticles acted as an adjuvant, a substance that enhances the desired immune response to a vaccine.\nWeissman and his colleagues had been working on an mRNA vaccine for influenza when word spread of a mysterious pathogen causing pneumonia in people in Wuhan, China, in late 2019. Weissman quickly realized this virus was a perfect candidate for an mRNA vaccine, and Pfizer-BioNTech and Moderna soon pivoted to work on one. The rest is history.\nScientific American spoke with Karikó about how she came to work on mRNA, why it was well suited for COVID vaccines and what other exciting medical applications it could have.\n[An edited transcript of the interviews follows.]\nWhat was your initial reaction to winning the prize? Were you surprised, or did you expect this?\nKARIKÓ: No, I never expected any kind of prize. For many decades, I never got anything. I was very happy with doing the work. Getting a letter from a New York elderly home where they celebrated that, with the vaccine, nobody died when they got the infection—for me, those are the real prizes. I was aware of this Breakthrough Prize—it’s very famous. But, you know, I never thought about any kind of prize. So it was a very, very pleasant surprise.\nDid you ever expect this technology to have such a global impact, in terms of the COVID vaccines? Or was it just something you were working on at the right place and time for this pandemic?\nKARIKÓ: I never wanted to actually develop a vaccine. I was making this modification in the RNA because I always wanted to develop it for therapies. And when, in 2000, we learned that adding messenger RNA (which I made) to human immune cells, they made inflammatory molecules—cytokines—I thought that I had to do something. I tried to make sure that when we are using it for a therapy—you know, such as treating a patient who has had a stroke—we don’t add some extra inflammatory molecules. At the beginning, it was thought that the immune form of this RNA would be a good vaccine. In 2017 the first paper was published showing that the modification we discovered that makes the mRNA noninflammatory could lead to a good vaccine, and the Moderna and BioNTech-Pfizer vaccines both have this modification.\nHere at BioNTech, I am in charge of the protein replacement program. We use modified mRNA for cancer treatment. And this is not a vaccine. This is mRNA coding for cytokines and injecting them into tumors to make the tumor “hot” so that immune cells will learn what to see and can eliminate metastatic tumors. We did not know that there would be a pandemic, but I was aware that this is a very good way to make a vaccine because, with my colleagues at the University of Pennsylvania, we had already used it not just for Zika virus but for influenza, HIV, herpes simplex—it was already demonstrated in animal studies that it is such an excellent vaccine.\nSo when the pandemic started, was it immediately clear to you that this could be a useful technology to develop COVID vaccines?\nKARIKÓ: From 2018 we had worked with Pfizer to develop a vaccine for influenza. And we were already ready to start a clinical trial for that. But switching over to COVID, it was just a technical thing. And so it was already ready.\nIf the pandemic had happened 20 years ago, you would need to have, physically, in your hands, a piece of the virus. So that would be a big delay. But commercial gene synthesis started about 20 years ago. Now you can just order a gene. You order DNA, and then you insert it into a [typically circular molecule of DNA called a] plasmid, and then you make RNA. But making the nanoparticle to deliver the mRNA is kind of challenging.\nThe lipid nanoparticles were a key part of the technology to make it useful for vaccines, right?\nKARIKÓ: In my view, yes. The lipid nanoparticle protects the mRNA outside the cell because, in the blood and everywhere, there are a lot of human enzymes that can degrade the RNA. Second, it helps it to enter because the cell will pick up the particle. And then it is in the endosome [a membrane-bound compartment] in the immune cells, and then this lipid nanoparticle helps escape from the endosome to the cytoplasm [the solution inside cells] so the protein can be made. It is a very smart particle.\nDo you see this technology being useful for many other types of applications, such as the cancer treatment you mentioned earlier?\nKARIKÓ: It is already. When we started here at BioNTech, injecting messenger RNA coding for cytokines, by that time, the human trial using mRNA for cancer vaccines had already been going on for years. Other program with the nucleoside-modified mRNA was already ongoing at other companies. For example, Moderna is producing antibodies for chikungunya virus. [In a collaboration with AstraZeneca] they already have a phase II trial [led by the latter company] injecting mRNA into the heart [that] codes for [a protein that] generates new blood vessels. And they are also running a clinical trial for wound healing. So the data were out there—you already saw these ongoing trials for mRNA therapy—and it was just people who are not in the field who were not aware. They thought, “Oh, this is the first use.” No, there are many, many other applications.\nHas all this new interest in mRNA changed this field? Do you think it will accelerate the development of mRNA vaccines for other diseases, such as influenza?\nKARIKÓ: Yeah, if you read the Wall Street Journal article [interviewing] Albert Bourla, CEO of Pfizer, you know, he said that Pfizer will pursue mRNA vaccines for other diseases. They will treat autoimmune disease. We published this year, at BioNTech, that we use tolerization [exposing someone to an antigen, or substance that provokes an immune response, until they can tolerate it]. We use an animal model for multiple sclerosis, and we showed that you can use tolerization to treat an autoimmune disease if the mRNA codes for the autoantigen. Before, it was like CureVac, Moderna, BioNTech—these were smaller companies working with RNA. And now, all of the sudden, you can see that Sanofi is buying into other companies, Pfizer is doing it, and so the large companies are realizing that they can get many products in their pipeline very quickly.\nDo you think that this mRNA technology could be a good candidate for a universal coronavirus vaccine?\nKARIKÓ: I think that it could work for all vaccines except those against bacterial infections. [It could work for vaccines against] viruses and parasites, such as [those that cause] malaria and, of course, for cancer—but we have to understand better what to target.\nWhat do you plan to do with the prize money?\nKARIKÓ: Probably, I will use it for research. I will make a company. When I got a smaller award, I gave it back to those who needed it more—for the education of underprivileged children. I am 66 years old and never had a new car, and I don’t think I would have one now.\nEditor’s Note (10/6/21): This article has been edited after posting to correct the description of Katalin Karikó’s work in 2000 involving mRNA in human immune cells and to clarify some of her comments. The text had previously been amended on September 16 to include a reference to the Vilcek Prize for Excellence in Biotechnology.\nTanya Lewis is a senior editor covering health and medicine for Scientific American. Follow her on Twitter @tanyalewis314 Credit: Nick Higgins\nMike May and Nature Medicine\nEmily Willingham\nTanya Lewis\nArthur Allen and Kaiser Health News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Giant Satellite Outshines Most Stars in the Sky", "date": "2023-10-02 19:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nAt times, the enormous BlueWalker 3 telecommunications satellite is brighter than some of the most iconic stars visible from Earth\nOn some nights, one of the brightest objects in the sky is neither a planet nor a star. It is a telecommunications satellite called BlueWalker 3, and at times it outshines 99% of the stars visible from a dark location on Earth, according to observations reported today in Nature.\nBlueWalker 3 is the most brilliant recent addition to a sky that is already swarming with satellites. The spaceflight company SpaceX alone has launched more than 5,000 satellites into orbit, and companies around the globe have collectively proposed launching more than half a million satellites in the coming years — a scenario that astronomers fear could hamper scientific observations of the Universe.\nThe study “shows us that there are no boundaries to satellite brightness,” says Patrick Seitzer, an emeritus astronomer at the University of Michigan, Ann Arbor, who was not involved in the study. “I’m concerned that we’re going to see a very large number of large satellites launched in the next decade, and it will change the appearance of the night sky forever.”\nTelecommunications firm AST SpaceMobile in Midland, Texas, launched BlueWalker 3 on 10 September 2022 as a prototype for a satellite fleet designed to make mobile broadband available almost anywhere. The satellite’s huge array of antennas and white colour mean that it reflects a considerable amount of sunlight back towards Earth, making it shine even at twilight.\nTo quantify its effects, professional and amateur astronomers embarked on an international observation campaign, ultimately spotting the satellite from locations in Chile, the United States, Mexico, New Zealand, the Netherlands and Morocco. The researchers assessed the satellite’s shine using a standard astronomical index called the magnitude scale, on which the brightest objects have the smallest numbers. The brilliant Venus, for example, can reach a magnitude of –4.6, whereas the North Star is much dimmer, at magnitude +2. That is roughly the magnitude limit visible from a city with the naked eye.\nOn 10 November 2022, the satellite unfurled its array of antennas, causing it to brighten to magnitude +0.4. If it were a star, it would have been one of the ten brightest in the sky. But its apparent brightness changes as the satellite rotates, and by late December, it had dimmed to a magnitude of +6. It then brightened again, reaching magnitude +0.4 once more on 3 April 2023.\nThe International Astronomical Union, a group of professional astronomers, recommends that artificial satellites in low-Earth orbit have a maximum brightness of magnitude +7. BlueWalker 3 can be hundreds of times brighter, the authors found. And AST SpaceMobile says it plans to provide broadband coverage with a fleet of 90 similar satellites, including 5 that are scheduled to launch in early 2024.\nMoreover, the team observed a bright object separating from the main satellite during deployment, and later learnt that this was the container that protected the folded antennas during ascent, before being jettisoned into space. It, too, was relatively bright at magnitude +5.5.\nIn a statement to Nature, AST SpaceMobile said that it is currently working with NASA and astronomy groups to address these concerns.\nMany astronomers were caught by surprise in mid-2019, when SpaceX successfully launched 60 satellites, creating a ‘train of stars’ that glided through the night sky. Now, low-Earth orbit is littered with thousands of commercial satellites. If captured by a telescope during a long exposure, such objects can leave a bright streak that renders the data unreadable.\nAstronomers have long steered their telescopes to avoid the brightest of these objects. That workaround will still be possible if AST SpaceMobile launches a fleet of satellites similar to BlueWalker 3, says Jonathan McDowell, an astronomer at the Center for Astrophysics ‌| Harvard & Smithsonian in Cambridge, Massachusetts, who was not involved in the study.\nThe bigger concern, he says, is that other companies might also launch constellations of large satellites. If that happens, Seitzer says, “then the night sky will be irreversibly changed.”\nTo avoid such a scenario, astronomers are working to find mutual solutions. Some of the study’s authors, for example, are a part of a newly formed coalition called CPS that aims to tackle the issue and has been in contact with companies including SpaceX and AST SpaceMobile. SpaceX is already trying methods to make its satellites less visible, and coalition members say that AST SpaceMobile also seems amenable to dimming its satellites. The company says it is planning to use anti-reflective materials on its next-generation satellites, as well as certain flight manoeuvres to reduce the crafts’ apparent magnitude.\n“They left us with a very good impression that they would work more with us,” says coalition member Constance Walker, an astronomer at the National Science Foundation’s NOIRLab in Tucson, Arizona, and also a study author.\nSuch discussions are the way forwards, she says. “No one is going to return to yesterday, when we had darker skies.”\nThis article is reproduced with permission and was first published on October 2, 2023.\nShannon Hall is an award-winning freelance science journalist based in the Rocky Mountains. She specializes in writing about astronomy, geology and the environment. Credit: Nick Higgins\nJonathan O'Callaghan\nRebecca Boyle\nPouria Nazemi | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "New 6G Networks Are in the Works. Can They Destroy Dead Zones for Good?", "date": "2023-10-03 10:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNext-generation 6G technology could “enable applications that we may not even imagine today”\nHigh-speed Internet access has become crucial in a world where school, business, personal life and emergency communications increasingly take place through a handheld device. But surprisingly large swaths of the U.S. still lack a speedy-enough broadband or cellular connection. One potential solution could be a sixth-generation cellular network, which experts say will add a space-based system to ground-based coverage options. This 6G network could eventually connect the entire nation to high-speed data—but its development is still in the early stages.\nActivities such as attending video meetings and streaming high-definition video can require download speeds of 25 megabits per second. But in 2019 those speeds were out of reach for 4.4 percent of Americans, according to the most recent Broadband Progress Report from the Federal Communications Commission. That lack of access to reliable Internet is roughly four to five times higher in rural communities (17 percent) and on tribal land (21 percent), respectively, contributing to a digital divide that disproportionately impacts already underserved communities.\nThis summer the federal government took steps to boost connectivity by expanding existing broadband infrastructure. In late June the Biden administration announced a $42.45 billion commitment to the Broadband Equity, Access, and Deployment (BEAD) program, a federal initiative to provide all U.S. residents with reliable high-speed Internet access. The project emphasizes broadband connectivity, but some researchers suggest a more powerful cellular connection could eventually sidestep the need for wired Internet.\nThe 6G network is so early in its development that it is still not even clear how fast that network will be. Each new generation of wireless technology is defined by the United Nations’ International Telecommunication Union (ITU) as having a specific range of upload and download speeds. These standards have not yet been set for 6G—the ITU will likely do so late next year—but industry experts are expecting it to be anywhere from 10 to 1,000 times faster than current 5G networks. It will achieve this by using higher-frequency radio waves than its predecessors. This will provide a faster connection with fewer network delays.\nNo matter how fast the new network turns out to be, it could enable futuristic technology, according to Lingjia Liu, a leading 6G researcher and a professor of electrical and computer engineering at Virginia Tech. “Wi-Fi provides good service, but 6G is being designed to provide even better service than your home router, especially in the latency department, to address the growing remote workforce,” Liu says. This would likely result in a wave of new applications that have been unfathomable at current network speeds. For example, your phone could serve as a router, self-driving cars may be able to communicate with one another almost instantaneously, and mobile devices might become completely hands-free. “The speed of 6G will enable applications that we may not even imagine today. The goal for the industry is to have the global coverage and support ready for those applications when they come,” Liu says.\nAlthough 6G’s theoretical speeds sound exciting, the 5G network that preceded it also claimed to offer a blazing-fast connection. But people in many parts of the world still lack access to 5G infrastructure; even devices designed to take advantage of 5G must include the ability to fall back on 4G and 3G connections if and when those slower networks are the only available options. “The coverage of the 5G cellular network is only about 10 percent of the Earth’s surface right now,” says Jeffrey Andrews, director of 6G@UT, a research center at the University of Texas at Austin that works on underlying technologies to support 6G cellular networks in the near future. That coverage area could dramatically change in the 6G era, Andrews says, because the new generation will be partially based in space, enabling it to cover much more of the planet than its ground-based predecessors. “I think utilizing space systems to provide global coverage will be a revolutionary aspect of the 6G era,” Andrews says.\nCurrent 6G research-and-development efforts are focused on creating nonterrestrial networks made up of low-Earth orbit (LEO) satellites and uncrewed aerial vehicles. These networks are expected to operate at a fraction of the cost of 5G, which relies mainly on ground-based fiber-optic cables and cellular towers. According to Andrews, piggybacking off the LEO constellations that are already in the works will enable 6G to offer a cheaper connection than 5G, which requires time and money to install fiber all over the country, including in places with relatively few inhabitants.\nThose sparsely populated areas are a major target of the BEAD program—so if BEAD connects the entire country to existing broadband networks, will 6G global coverage even be necessary? Although the BEAD investment is a step toward bridging the digital divide, some experts question its potential. BEAD allocates funds to each U.S. state and territory based on the FCC’s broadband map, which has faced scrutiny from the telecommunications industry because of various inaccuracies. One earlier version of the map was challenged in more than four million locations.\n“I cannot understate that the way that data decisions were made in the creation of this map will have ramifications for generations,” says Alexis Schrubbe, director of the Internet Equity Initiative at the University of Chicago’s Data Science Institute. “This map is probably the highest-stakes data product that the federal government has ever created.” This makes its flaws extremely consequential. According to Schrubbe, the algorithms used to identify broadband serviceable locations for this map often made mistakes when analyzing Native American land and rural areas—prime examples of the very locations where more connectivity is so badly needed.\nEven as the FCC continues to develop its broadband map for a better understanding of where coverage needs lie, the map’s problems mean that 6G may eventually be able to connect every device in the U.S. more quickly and cheaply. Schrubbe views the two types of technology as complementary. “They work in concert with each other,” she says. “It’s not necessarily that one is competing with the other—rather, that if we have a better-distributed transport system across the United States, it will open up avenues for those technologies to blossom even more.”\nAnother way 6G will improve on previous generations is the way it uses artificial intelligence, says Harish Viswanathan, head of radio systems research at Nokia Bell Labs. “I think we will see a lot of applications of AI in 6G, much more than what we are aiming to do in 5G,” Viswanathan predicts. AI will help existing networks conserve energy by analyzing data usage in real time, as well as playing a crucial role in how fast data can be processed and uploaded. “Machine learning, in particular deep learning, which we call artificial intelligence, has made significant advances in other domains,” Viswanathan says. “Those tools are now relevant to us in wireless communications.”\nSixth-generation communication technology may offer revolutionary promises, but it won’t replace existing networks for some time: earlier this year, the ITU estimated that 6G won’t become available to consumers until 2030.\nTyler Carroll is a freelance science and technology journalist based in Boston. You can find him on LinkedIn.\nJacob Templin\nKenneth R. Foster\nMichael Tabb, Jeffery DelViscio and Andrea Gawrylewski\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "This Year's Physics Nobel Awards Scientists for Slicing Reality into Attoseconds", "date": "2023-10-03 10:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nPierre Agostini, Ferenc Krausz, and Anne L’Huillier split the award for their ability to picture nature in a billionth of a billionth of a second\nSome processes in physics happen in the blink of an eye while others happen in the blink of a photon. This year’s Nobel Prize in Physics was awarded to Pierre Agostini of the Ohio State University, Ferenc Krausz of the Max Planck Institute of Quantum Optics in Garching, Germany, and Anne L’Huillier of Lund University in Sweden for developing the field of ultrafast laser pulses. L’Huillier is only the fifth woman to have ever won the Nobel Prize in Physics.\nThese pulses are on the scale of the attosecond—a billionth of a billionth of a second. This duration is so short that there are about as many attoseconds in a single second as there have been seconds in the entire history of the universe. This year’s prize was awarded “for experimental methods that generate attosecond pulses of light for the study of electron dynamics in matter,” according to a press release from the Royal Swedish Academy of Sciences.\n“Attosecond science allows us to address fundamental questions,” said Eva Olsson, chair of the Nobel Committee for Physics at a press conference today. At the atomic level, the motions of electrons and nuclei typically take place over the course of attoseconds. In the late 19th century early photographers made use of cameras to determine whether a horse took all of its hooves off the ground at a gallop—a process too fast for the human eye to discern. (Spoiler: horses do completely leave the ground.) Today’s researchers hope to do the equivalent at attosecond timescales by using ultrafast lasers to get clearer views of otherwise blurry atomic processes.\n“When you look at the impact of ultrafast processes, they are inherent to many important mechanisms in life,” says Ursula Keller, a physicist at the Swiss Federal Institute of Technology Zurich. Processes that involve the conversion of photons into electrons, such as photosynthesis and even basic vision, all happen in attosecond time frames. “The dream is really to see electrons move. And I think this is getting closer and closer to reality,” says Carla Faria, a theoretical physicist at University College London.\nAttosecond scientists were uniformly excited by the award. “I’m really, really excited and really proud of the people who got the Nobel Prize,” says László Veisz, a physicist at Umeå University in Sweden. Keller agrees and points to L’Huillier in particular. “This is really a woman who absolutely deserves it,” she says. “I hope there will be no more discussion about ‘somebody got a Nobel Prize just because they’re a woman’ or something stupid like this.”\nGenerating light in extremely short pulses is not easy. For many years light pulses were stuck in the femtosecond regime (one femtosecond is 1000 attoseconds). That’s good enough to resolve molecules in chemical reactions—a feat that won the 1999 Nobel Prize in Chemistry—but it’s insufficient to spot the zigging and zagging of speedier electrons. The problem was fundamental: even the briefest physically achievable optical laser pulse was a few femtoseconds in length. “You cannot generate a pulse [that] is shorter than one wavelength,” says Mauro Nisoli, a physicist at the Polytechnic University of Milan in Italy. So to get past the femtosecond barrier, physicists needed to produce light with shorter wavelengths. \nOne way to do that is a process called high-harmonic generation (HHG), in which an electron absorbs several low-energy photons and spits out a single high-energy photon. But decades ago HHG seemed to offer diminishing returns, with the number of photons that were emitted decreasing as the energy went up and eventually dwindling away. Then, in 1987, L’Huillier and her colleagues fired an infrared laser through argon and saw something fascinating: instead of decreasing as energy increased, the number of emitted photons remained steady. “What Anne L’Huillier discovered is this plateau,” Keller says. “And it was really a game changer.”\nWithin a few years L’Huillier and others in the field worked out what was happening in such specialized HHG setups. The electrons in argon were performing a complex, three-step dance, first tunneling quantum mechanically away from the atom, then accelerating away from it and finally falling back into its embrace to release their energy as a high-energy photon. This would happen multiple times during an initiating laser pulse and lead to a train of ultrafast, attosecond-scale flashes of light from the gas.\nGoing from L’Huillier’s work on HHG to a working attosecond source required two key innovations. First, researchers had to measure the pulse timings, and second, they had to generate an single isolated pulse. Typically, when lasers need to be timed, they are measured with a shorter laser pulse. “How do you measure the duration of something that’s the shortest time length?” Veisz asks rhetorically. The answer is that you must measure it with itself, he says. One technique that uses this principle is called frequency-resolved optical gating (FROG), which is unusable for attosecond pulses because they’re too low-energy. \nBuilding off of FROG, Agostini created an approach called RABBIT (reconstruction of attosecond beating by interference of two-photon transitions), which works by combining the electric field of an optical laser with the attosecond pulses. (Laser techniques are often named after animals, Veisz says.) Meanwhile Krausz independently developed a similar method for his single pulses called attosecond streaking. Able to characterize the timing of the shortest pulses in the world, researchers now had attosecond sources with which to see the universe on a previously unimaginable timescale.\nWith the newfound probes developed by Agostini, Krausz and L’Huillier, researchers can now generate laser pulses of merely a few dozen attoseconds. Further refinements of these approaches to generate ever shorter pulses promise to deepen scientists’ understanding of electron dynamics and applications. Nisoli points out that while femtosecond lasers can be used to closely monitor chemical reactions, attosecond pulses are so precise that they can be used to nudge the electrons themselves, potentially eliciting a shift from passive observation to active control of chemistry on unprecedented scales. Attosecond pulses can even control the properties of solids, turning an insulator into a conductor and back again in a flash.\nThere are more fundamental possibilities, too, such as more detailed explorations of Einstein’s famed photoelectric effect, in which a photon impinges on metal, causing the metal to emit an electron. “Everybody thought that this is instantaneous, and attosecond physics showed it is not, and this triggered a lot of theoretical studies,” Veisz says. \nAs usual, the award came as a surprise to its recipients. When L’Huillier was notified, she was in the middle of giving a lecture and missed the first few calls from Stockholm. After stepping outside to take the call, she returned to the lecture, where she continued teaching without telling her students anything. “Teaching is very, very important. For me, it’s very important,” she told Hans Ellegren, secretary-general of the Royal Swedish Academy of Sciences, over the phone during the prize’s announcement.\nEditor’s Note (10/3/23): This story has been updated.\nDaniel Garisto is a freelance science journalist covering advances in physics and other natural sciences. He is based in New York. Credit: Nick Higgins\nKatie Hafner, Ashraya Gupta and The Lost Women of Science Initiative\nMichelle Frank\nDavid Labrador\nDina Fine Maron\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Mars Sample-Return Missions Could Reduce Tensions with China on Earth", "date": "2023-10-03 11:30:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nThe U.S. may not beat China at retrieving Martian rocks first, according to an independent review board’s conclusion. But the U.S. can still lead with an exchange of samples here on Earth\nIn September NASA’s Mars Sample Return (MSR) independent review board (IRB), led by the agency’s former “Mars czar” Orlando Figueroa, released findings and recommendations about the MSR project, a collaboration between NASA and the European Space Agency (ESA) that means to return the first samples from the Red Planet. The IRB members did a terrific job analyzing, in their words, the “near zero probability” of its current plans and budget succeeding.\nMars Sample Return matters to our nation and space program and to science, the board emphasized. The return of carefully selected samples, such as ones weathered by geothermal vents, as well as sedimentary and aggregated rocks, will allow scientists on Earth to extensively examine their geochemistry and microscopic composition. It could possibly reveal signs of life, or at least the ingredients of life, on Mars. The mission therefore directly addresses the principal question of space exploration—the nature of life in the universe. But the report’s key finding makes it clear that the mission needs a stretched-out, more robust architecture that would delay its launch into the 2030s and the return of samples to the mid- or even late 2030s. “The current MSR architecture is highly constrained and is not sufficiently robust or resilient,” the panel said in its report. NASA’s current sample-return mission plan relies on the aging Perseverance rover, launched in 2020, to collect its samples. A second rover from Europe was planned, but its development was cancelled. There is a backup plan in case Perseverance is not working, but it relies on brand-new helicopters doing something novel: picking up and carrying the samples. A delay and stretch-out of the schedule will make the rover older when it is needed and move the mission into less favorable trajectory opportunities in the 2030s. That raises the cost and risks of the mission and lowers its chances for success. The report concludes, “Other [return mission] architectures may be more robust and more resilient to schedule risk.”\nIn other words: back to the drawing board. If NASA and ESA continue with MSR (and the report strongly recommends that they should), then a more robust plan involving the collection of more samples and including additional hardware (possibly another rover) must be devised. This plan would stretch well into the 2030s. The panel also noted China’s development of its own, much simpler Mars sample-return mission for 2028 or 2030, which is likely to bring samples back to Earth several years before the NASA-ESA mission returns. (The Chinese mission is more of a “grab sample” mission, in which a lander takes samples from the immediate vicinity of its landing site, and it is much shorter in duration than the NASA-ESA one.) This need not be a negative. We can make the most of our more robust mission by engaging with a putative rival. This will allow us to serve diplomacy while serving science.\nAccording to the report, the NASA-ESA plan is much better scientifically. It will be able to obtain many more extraordinarily well-selected samples, based on both years of in situ experience from previous missions and a careful and extensive sampling campaign by the Perseverance rover. The sampling will be far more wide-ranging than that of the Chinese plan, which is limited to one small region around the mission’s landing spot. Nevertheless, it would be beneficial for American and European scientists to be able to analyze a bit of those first samples—both to uncover the intrinsic science they contain and to exercise the extensive plans of the NASA sampling procedures. Similarly, Chinese scientists would benefit enormously if they had some access to the NASA-ESA samples. A sample exchange would benefit both the U.S. and China. And therein lies the opportunity.\nExamining each other’s samples poses no conceivable strategic threat to either country—the likelihood of a microscopic secret inside a Martian rock helping either nation in their military or economic competition is around zero. But cooperating on this Martian investigation could build up a benign and positive scientific relationship that would serve both countries. It would add to our exploration of Mars, and there are no downsides to advancing China’s exploration of Mars. It plays into American strength—our vigorous and successful science experience on Mars—and mitigates the more trivial worry about who will conduct a Mars sample-return mission first. And it provides resiliency to further delays or mission problems.\nOne obstacle would be reluctance springing from a 2011 law barring even the barest NASA cooperation with China without FBI approval. Exchanging samples involves no dangerous interactions with sensitive hardware or software. But this draconian law has so inhibited agency scientists that one privately told me that they were reluctant to even have a cup of coffee with Chinese researchers at space events. The policy allows the U.S. to cooperate in space with Vladimir Putin while ruling it out with the world’s other leading economy. That might suggest that we need to rethink it.\nChina and the U.S. are at an impasse right now—one filled with hostile, mistrusting, edgy geopolitics. Space cooperation among rivals has a distinguished history. Even now, the U.S. and Russia cooperate on the International Space Station, and in the middle of the cold war, we exchanged lunar samples from the Apollo and Luna missions. Moreover, neither the U.S. nor China want to let current foreign policy tensions move toward confrontation. Presidents Joe Biden and Xi Jinping have expressed interest in developing cooperative initiatives, and in the past three months several U.S. Cabinet officials have gone to China to seek such initiatives. Mars certainly could provide one consistent with the long history of international cooperation in space that would support peace and geopolitical stability.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.\nLouis Friedman holds a Ph.D. in aeronautics and astronautics from Massachusetts Institute of Technology. He has worked on deep-space missions at NASA's Jet Propulsion Laboratory in Pasadena, Calif., and he co-founded the Planetary Society with Carl Sagan and Bruce Murray, serving as the organization's executive director for 30 years. He was co-leader of the Keck Institute for Space Studies Asteroid Retrieval Mission and Interstellar Medium Exploration Studies at the California Institute of Technology.\nConor Feehly\nLilly Tozer and Nature magazine\nAndrea Thompson\nAshleigh Furlong and E&E News\nDina Genkina\nTanya Lewis, Josh Fischman, Carin Leong and Elah Feder\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Climate Disruptions Are Especially Dangerous for the Opioid Epidemic", "date": "2023-10-03 12:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nDrug users must be considered in health and climate preparedness efforts\nAs debates rage over how we can best protect those more directly affected by climate change, one group remains absent from the discussion: people with an opioid addiction.\nAround three million people in the U.S. have an opioid use disorder or are dependent on heroin. More than 100,000 Americans died of drug overdoses from April 2022 to April 2023, most of which were from illicit fentanyl opioids. Cities with high overdose rates, such as New York City, San Francisco, Calif., and Phoenix, Ariz., are also at the highest risk of extreme heat, drought and flooding, and the opioid epidemic is likely to peak just as climate change’s most brutal effects start to take root.\nDuring environmental crises, drug users frequently experience more social and economic hardships than the rest of the population. These hardships often snowball into poor health outcomes, including death. Climate change will likely disrupt the illegal drug supply chain—making dangerous drugs even more variable and deadly. Soaring temperatures will make people more vulnerable to overdose. Despite this, drug users are typically not considered in public health efforts related to climate change preparedness. This urgently needs to change.\nAuthorities must start thinking about the intersection between climate change and drug use. They must design climate literacy programs for drug users, build a housing policy that considers climate change’s impact and make harm reduction programs more widely available.\nAs part of the Helping to End Addiction Long-Term (HEAL) Initiative, I research various aspects of America’s ongoing opioid epidemic. Despite all the useful data the project is producing, climate change’s influence has been of little interest to researchers in the initiative or scholars in the field. It wasn’t until last year that the National Institutes of Health announced the availability of funds to support research that specifically examines the intersection between climate change and substance use. Unsurprisingly, there has been very little published on the topic, significantly limiting the opportunity to study and develop solutions to stem the unique risks that drug users face. This inertia comes as the United Nations has yet again warned of the dire need for implementable, cost-efficient solutions to climate change and after the opioid epidemic’s status as a public health emergency was renewed earlier this year. The staggering economic costs have also been overlooked: climate-fueled disasters cost the U.S. roughly $151 billion per year, while the financial impacts of the opioid epidemic land at roughly $1.5 trillion per year, about seven times the annual cost of addressing heart disease in this country.\nThe link between environmental disaster and drug use became clear in 2017 when Hurricane Maria caused an estimated 5,000 deaths in Puerto Rico. Amid the typical flurry of media images of flooded homes, downed power lines and uprooted trees, drug use and overdose rates dramatically increased, as did needle reuse, a key driver of HIV, which has been soaring in Puerto Rico. While groups such as older and homeless people or those with disabilities often receive special outreach and tailored resources during weather-related disasters, virtually nothing is done to formally forecast and address the needs of illicit drug users during these events. Indeed, the U.S. government’s health authorities currently provide no official guidance or support for preempting this disastrous domino effect.\nClimate change will exacerbate overdose and death risk through the increasingly intricate opioid supply chain. As supplies become harder to transport, drug users, like other consumers, could see steep increases in their product’s costs and decreases in quality. More opioid users will likely switch to cheaper but far more potent and potentially lethal synthetic substances, such as fentanyl. Also, extreme heat can create a deeply sedative effect, making lethargy, muscle breakdown and dehydration worse, all of which significantly increases the risk of fatal overdose.\nTo get ahead of the collision course, it’s essential for public health authorities to first build greater climate change literacy among drug users. This effort must begin by providing them with tailored educational materials that highlight climate change’s core causes and consequences. Most importantly, these materials must identify drug users’ specific vulnerabilities, given their socioeconomic and geographical circumstances.\nNext, we need to build climate-related emergency reserves for home maintenance programs and for rent and mortgage payment deferrals. Housing insecurity is not only intimately connected to drug use onset but also to overdose risk. America’s housing crisis—which intensified during the COVID pandemic—will deepen as property damage from extreme weather accelerates and unemployment rises. More people will be displaced and unhoused. Housing officials have implemented policies to prevent this before. During the more intense waves of the pandemic, officials turned toward eviction moratoriums, which were highly effective before they were rolled back last year.\nFinally, we need deeper support for harm-reduction services and treatment such as naloxone, an emergency opioid-overdose-reversal medication, and highly effective drug treatments such as Suboxone, which are harder to obtain for people in Black and low-income communities. We can anticipate that by the early 2030s there will be an increasing need for these resources and the safety net that propels them. In addition to increasing overdose rates, a lack of investment in harm reduction will spur a rapid increase in HIV/AIDS and sexually transmitted infections.\nThere is no simple solution to address the intersecting crises of climate change and opioid misuse. The best-case scenario is that local governments and industry can collaborate to improve the flow of resources to drug users and those at risk of developing an opioid use disorder. The hyperstigmatization that drug users experience is likely to keep them right in climate change’s crosshairs. This is an altogether different type of pollution that is nonetheless as elusive as the one driving climate change.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.\nJerel Ezell is an assistant professor of community health sciences at the University of California, Berkeley. He is also director of the Berkeley Center for Cultural Humility and a Fulbright Scholar.\nConor Feehly\nLilly Tozer and Nature magazine\nAndrea Thompson\nAshleigh Furlong and E&E News\nDina Genkina\nTanya Lewis, Josh Fischman, Carin Leong and Elah Feder\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "How Can We Trust AI If We Don't Know How It Works", "date": "2023-10-03 14:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nTrust is built on social norms and basic predictability. AI is typically not designed with either\nThe following essay is reprinted with permission from The Conversation, an online publication covering the latest research.\nThere are alien minds among us. Not the little green men of science fiction, but the alien minds that power the facial recognition in your smartphone, determine your creditworthiness and write poetry and computer code. These alien minds are artificial intelligence systems, the ghost in the machine that you encounter daily.\nBut AI systems have a significant limitation: Many of their inner workings are impenetrable, making them fundamentally unexplainable and unpredictable. Furthermore, constructing AI systems that behave in ways that people expect is a significant challenge.\nIf you fundamentally don’t understand something as unpredictable as AI, how can you trust it?\nTrust is grounded in predictability. It depends on your ability to anticipate the behavior of others. If you trust someone and they don’t do what you expect, then your perception of their trustworthiness diminishes.\nMany AI systems are built on deep learning neural networks, which in some ways emulate the human brain. These networks contain interconnected “neurons” with variables or “parameters” that affect the strength of connections between the neurons. As a naïve network is presented with training data, it “learns” how to classify the data by adjusting these parameters. In this way, the AI system learns to classify data it hasn’t seen before. It doesn’t memorize what each data point is, but instead predicts what a data point might be.\nMany of the most powerful AI systems contain trillions of parameters. Because of this, the reasons AI systems make the decisions that they do are often opaque. This is the AI explainability problem – the impenetrable black box of AI decision-making.\nConsider a variation of the “Trolley Problem.” Imagine that you are a passenger in a self-driving vehicle, controlled by an AI. A small child runs into the road, and the AI must now decide: run over the child or swerve and crash, potentially injuring its passengers. This choice would be difficult for a human to make, but a human has the benefit of being able to explain their decision. Their rationalization – shaped by ethical norms, the perceptions of others and expected behavior – supports trust.\nIn contrast, an AI can’t rationalize its decision-making. You can’t look under the hood of the self-driving vehicle at its trillions of parameters to explain why it made the decision that it did. AI fails the predictive requirement for trust.\nTrust relies not only on predictability, but also on normative or ethical motivations. You typically expect people to act not only as you assume they will, but also as they should. Human values are influenced by common experience, and moral reasoning is a dynamic process, shaped by ethical standards and others’ perceptions.\nUnlike humans, AI doesn’t adjust its behavior based on how it is perceived by others or by adhering to ethical norms. AI’s internal representation of the world is largely static, set by its training data. Its decision-making process is grounded in an unchanging model of the world, unfazed by the dynamic, nuanced social interactions constantly influencing human behavior. Researchers are working on programming AI to include ethics, but that’s proving challenging.\nThe self-driving car scenario illustrates this issue. How can you ensure that the car’s AI makes decisions that align with human expectations? For example, the car could decide that hitting the child is the optimal course of action, something most human drivers would instinctively avoid. This issue is the AI alignment problem, and it’s another source of uncertainty that erects barriers to trust.\nOne way to reduce uncertainty and boost trust is to ensure people are in on the decisions AI systems make. This is the approach taken by the U.S. Department of Defense, which requires that for all AI decision-making, a human must be either in the loop or on the loop. In the loop means the AI system makes a recommendation but a human is required to initiate an action. On the loop means that while an AI system can initiate an action on its own, a human monitor can interrupt or alter it.\nWhile keeping humans involved is a great first step, I am not convinced that this will be sustainable long term. As companies and governments continue to adopt AI, the future will likely include nested AI systems, where rapid decision-making limits the opportunities for people to intervene. It is important to resolve the explainability and alignment issues before the critical point is reached where human intervention becomes impossible. At that point, there will be no option other than to trust AI.\nAvoiding that threshold is especially important because AI is increasingly being integrated into critical systems, which include things such as electric grids, the internet and military systems. In critical systems, trust is paramount, and undesirable behavior could have deadly consequences. As AI integration becomes more complex, it becomes even more important to resolve issues that limit trustworthiness.\nAI is alien – an intelligent system into which people have little insight. Humans are largely predictable to other humans because we share the same human experience, but this doesn’t extend to artificial intelligence, even though humans created it.\nIf trustworthiness has inherently predictable and normative elements, AI fundamentally lacks the qualities that would make it worthy of trust. More research in this area will hopefully shed light on this issue, ensuring that AI systems of the future are worthy of our trust.\nThis article was originally published on The Conversation. Read the original article.\nMark Bailey is a faculty member and chair of cyber intelligence and data science at the National Intelligence University.\nKatie Hafner, Claire Trageser and The Lost Women of Science Initiative\nConor Feehly\nLilly Tozer and Nature magazine\nAndrea Thompson\nAshleigh Furlong and E&E News\nDina Genkina\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Beyond Pluto, New Horizons Gets a Reprieve from NASA", "date": "2023-10-03 15:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNASA has reversed course on plans to curtail the New Horizons spacecraft’s planetary science studies following a rebellion among the mission’s leaders\nIt’s lonely out there in the desolation that reigns where NASA’s New Horizons spacecraft now cruises on its one-way trip out of our solar system, with little to pass the time besides sniffing whiffs of plasma and stargazing. After nearly two decades of deep-space operations, the probe is currently more than eight billion kilometers from Earth. And much like our planet itself, the mission’s heyday—a historic encounter with Pluto in 2015 and a 2019 flyby of Arrokoth, the most distant object yet visited by a spacecraft—is receding ever further in the rearview.\nBack on Earth, a battle has raged over the spacecraft’s future. Pluto and Arrokoth alike reside in what’s known as the Kuiper Belt, a remote and mysterious orbital region of icy objects in the outer reaches of our solar system. New Horizons—humanity’s first and so far only robotic emissary to explore the Kuiper Belt—still traverses its depths, dutifully gathering data and somewhat desperately searching for another object to intercept. Yet last year NASA suggested it would end these investigations in an effort to save money, sparking an outcry from astronomers, given that no other spacecraft will explore the Kuiper Belt for decades.\nThat decision, it seems, has been partly reversed. In a statement from NASA posted on September 29, Nicola Fox, associate administrator of the agency’s Science Mission Directorate in Washington, D.C., announced some of New Horizons’ Kuiper Belt science would continue. “The agency decided that it was best to extend operations for New Horizons until the spacecraft exits the Kuiper Belt, which is expected in 2028 through 2029,” Fox said. NASA’s statement noted that the agency would “assess the budget impact of continuing the New Horizons mission so far beyond its original plan of exploration” and that other missions may be affected by the decision. “Future projects may be impacted,” the statement added.\nAlan Stern, a planetary astronomer at the Southwest Research Institute, who leads the New Horizons mission, welcomed the decision. “It is good news for Kuiper Belt exploration and very much welcomed by our team and also by the planetary science community,” he says. Pontus Brandt of the Johns Hopkins University Applied Physics Laboratory (APL) was similarly jubilant. “The community and I are thrilled that this logjam is finally broken,” he says. “This was the right decision for Kuiper Belt science.” Stern notes that some of the finer details are yet to be ironed out, however. It’s not clear, for example, to what extent New Horizons’ studies of the Kuiper Belt will continue, with NASA’s recent statement noting that the agency’s decision “allows for the possibility of using the spacecraft for a future close flyby” of a Kuiper Belt Object (KBO).\nNASA launched the nearly $1-billion New Horizons mission in 2006 on its pioneering voyage to Pluto and the Kuiper Belt. The probe’s arrival at the dwarf planet nine years later was a stunning moment in space exploration, with New Horizons returning breathtaking images of a surprisingly complex world of craggy mountains of ice and seas of frozen nitrogen, as well as snapshots of Pluto’s equally enthralling red-tinted moon Charon. The additional visit to Arrokoth was a lucky bonus, achieved by dint of the KBO’s timely discovery when it was still within reach of the approaching spacecraft’s dwindling propellant reserves. The two flybys produced “spectacular results,” says Jane Luu of the University of Oslo, who co-discovered the Kuiper Belt in 1992.\nAlthough New Horizons’ day-to-day operational needs are modest, they add up to a cost of nearly $10 million per year. Last year NASA approved a mission extension—but only through September 2024 rather than 2025, as requested by Stern and his team. At that point, NASA had planned to end the spacecraft’s planetary science studies in favor of a focus on heliophysics by repurposing New Horizons to exclusively examine how our home star shapes conditions in the outer solar system and toward the hazy boundary with interstellar space. That transition would swap the mission from NASA’s Planetary Science Division to its Heliophysics Division. And given that Stern and his team did not heed the space agency’s request to submit a proposal by November 2022 to dedicate New Horizons solely to heliophysics, the transition would remove them from the mission, too. “We refused to write a proposal that terminated the Kuiper Belt science,” Stern says. “It’s outrageous that you would terminate the only mission purpose-built and sent to the Kuiper Belt while it’s still collecting unique data.”\nSuch a heliocentric shift would have greatly limited the mission’s scientific output, says Jim Green, NASA’s former chief scientist and former head of its planetary science efforts. “It basically pares down the science team to next to nothing and really operates the spacecraft with a minimal cadre,” he says. “From my perspective, if I was the division chief, I would not have made that decision.” He says the reversal was “a good decision” and will “allow the right science for the mission during the right times.”\nThe decision to halt New Horizons’ Kuiper Belt studies originally emerged in 2022 from NASA’s annual review of most of its planetary science missions, a process in which the space agency assesses their current status and future potential. Although this review acknowledged many benefits of New Horizons continuing its current mission, the report also flagged a key weakness. In the absence of a suitable rendezvous target, the spacecraft can only study KBOs from afar—and in far fewer numbers than what various ground-based telescopes can achieve, perhaps less than a dozen. “The proposed studies of [KBOs] are unlikely to markedly improve knowledge,” the review stated, noting the spacecraft’s priorities “should focus on heliophysics and astrophysics.”\nFaith Vilas of the Planetary Science Institute, who led the team that assessed New Horizons for the review, says she and her colleagues did not intend their work to justify ending the mission’s planetary science studies. The team was “being credited, or blamed, for the mission potentially losing the planetary science side of things,” she says. “We didn’t say that. We simply said that all the science together is greater in magnitude than the one portion of science.”\nStern says the mission still has much to offer as it moves through the Kuiper Belt, including feats that cannot be replicated on Earth, such as observing the changing brightness of KBOs as they rotate. “When you do that repeatedly from different angles, you can determine the shape,” he says. “But you can never do that from Earth because you never see the KBOs from significantly different angles.” The spacecraft can also search for binaries—co-orbiting KBOs—in a way Earth-based observers cannot and can collect dust scattered away from distant Kuiper Belt objects. The prospect of visiting a third object remains ever present, too, if a viable target can be found.\nThe spacecraft is projected to exit the known boundaries of the Kuiper Belt in 2028, at which point Stern agrees the Kuiper Belt science could end. “Then I don’t see a reason to continue a planetary science mission,” he says. By some estimates, the spacecraft could continue operating until 2050, when it will be far beyond the generally accepted boundary of interstellar space. At present, no other spacecraft bound for the Kuiper Belt is in development. The next possibility might be Interstellar Probe, a proposal from APL to send a spacecraft to interstellar space. Optimistically assuming Interstellar Probe becomes a reality and launches in 2036, “that would get you out to the same region of space as New Horizons probably within a decade or so,” says Ralph McNutt, who helms the proposal team at APL, “so potentially up to the mid-2040s.”\nIn June Green and other members of the space science community signed a letter to NASA urging the space agency to reconsider its decision and noted “alarm” at the proposed abandonment of Kuiper Belt science. “We ... ask NASA, the Administration, and Congress to reverse course,” they wrote. In September the U.S.-based National Space Society made a similar appeal in its own letter. “Continue New Horizons so we don’t miss out on new discoveries from this rare, perfectly positioned, and fully functional mission,” the letter stated.\nNot all astronomers agree that New Horizons’ remaining Kuiper Belt investigations will be worthwhile, however. Luu says transitioning the mission to a focus on heliophysics and astrophysics would be “a reasonable decision” because ground-based telescopes can surpass the spacecraft’s Kuiper Belt capabilities in many respects, especially by studying many more KBOs at a much faster cadence. “If you just want to use the spacecraft for monitoring KBOs, I would argue it might be better done from the ground,” she says. And the prospects of a third flyby are becoming increasingly remote because no obvious targets have been discovered. “If they find a new candidate, great, but the low-hanging fruits have been picked,” she says.\nMike Brown of the California Institute of Technology, who discovered the object Eris in 2003, which led to Pluto’s demotion from a planet to a dwarf planet, has similar concerns. “These decisions are always tough,” he says. “There is a spacecraft there! It can do unique things! But ultimately it is a zero-sum cost-benefit analysis. Unless there is a new target for a close flyby, it’s hard for me to see why spending a ton of money is justified. If the science can be done on a shoestring, then perhaps that’s fine. But of course, a shoestring in space is probably many full scientific programs on Earth.”\nFor now, New Horizons will continue its studies of the Kuiper Belt—and will remain the only spacecraft likely to do so for many years to come. What knock-on effects its ongoing operations will have on “future projects” alluded to by NASA remains to be seen. Far beyond Pluto, one of our most distant emissaries still speeds on into the unknown.\nJonathan O'Callaghan is an award-winning freelance journalist covering astronomy, astrophysics, commercial spaceflight and space exploration. Follow him on Twitter @Astro_Jonny Credit: Nick Higgins\nJonathan O'Callaghan\nLee Billings\nS. Alan Stern\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Bringing Mars Rocks to Earth Could Cost an Astronomical $11 Billion", "date": "2023-10-03 16:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNASA’s Perseverance rover has collected valuable samples, but a new report says the plan to fetch them is unworkable\nHumanity’s biggest and most ambitious plan to search for extraterrestrial life is about to go back to the drawing board.\nNASA and the European Space Agency (ESA) have been working on a strategy to fly a set of Mars rocks, carefully collected by the Perseverance rover, back to Earth for study. But a new independent assessment of the plan says it can’t be done on current budgets and schedules. The entire project will probably cost between US$8 billion and $11 billion — far more than the roughly $4 billion estimated in a previous independent review report, issued three years ago. And there’s a “near zero probability” of the missions launching in 2027 and 2028, as the space agencies had hoped. Even pushing the launch dates out to 2030 would still cost between US$8 billion and $9.6 billion, the report estimates — comparable with the cost of building the James Webb Space Telescope, the single most expensive astronomy project in history.\nThe report, released on 21 September, stresses that Mars sample return is strategically important to the space agencies, in that it would demonstrate US and European ‘soft power’ at a time when China has also announced plans to bring back rocks from Mars. The mission is also scientifically important: it is the culmination of a decades-long quest to search for life beyond Earth. But the current plan is unworkable, according to the report, which was commissioned by NASA and led by a former NASA manager, Orlando Figueroa.\nNASA says it will put current plans on hold and come up with an alternative strategy by early next year. “It’s going to take a little time for us to assess the path forward,” says Lori Glaze, head of NASA’s planetary-science division in Washington DC. The recommendations from the report are “big”, she says. “They’re not things that can be answered overnight.”\nIn a statement, ESA said it is evaluating how it can adjust its plan while still achieving the overall mission objectives. “We are conducting preliminary studies to assess all options given the various scenarios and will inform member states and coordinate with NASA on the outcome as soon as possible.”\nAs currently envisioned, a Mars sample-return mission would involve NASA building a lander that would fly to the Red Planet to grab up to 30 rock samples, as well as a rocket that would blast off from the Martian surface to carry them into orbit around Mars. ESA would build the spacecraft to retrieve the precious cargo from orbit and fly it back to Earth.\nScientists can analyse the rocks in much greater detail in laboratories on Earth than with the compact instruments available on robotic rovers. The analysis would include hunting for ‘biosignatures’, molecules or other signals of past life in the samples. “These measurements are difficult to do remotely,” says Daniel Glavin, a planetary scientist at NASA’s Goddard Space Flight Center in Greenbelt, Maryland. “You really want the samples back and in the lab.”\nNASA’s Perseverance rover has already collected a bevy of samples from Mars’s Jezero Crater and has even placed ten sealed tubes, containing rock cores, on the ground for possible retrieval. The rover continues to travel around Jezero, gathering more samples that make its collection increasingly valuable as time goes on, the report says. The rocks gathered so far formed in an ancient river delta and lake that were probably once similar to life-friendly environments on Earth.\nMars sample return was one of the highest-ranked priorities recommended for NASA in the last two planetary ‘decadal’ surveys — reports, put together with input from the research community, that aim to guide the direction of US planetary science for the following ten years. But the project has struggled to remain affordable as engineers have refined the designs for the various spacecraft that would be part of the mission. The earlier independent review, which NASA commissioned from experts outside the agency specifically to head off problems with unexpected cost increases, recommended spending $3.8 billion to $4.4 billion on the sample-return project.\nBut that was before engineers had a full sense of what would be involved and hence how much it would cost, Glaze says. And NASA’s Jet Propulsion Laboratory in Pasadena, California, which would lead much of the Mars sample-return project, has struggled with an overstretched work force. This led NASA to delay last year’s planned launch of a separate mission, a spacecraft destined for the asteroid Psyche.\nThere are also questions about how to balance the cost of Mars sample return against other missions in the $3.2-billion budget for NASA’s planetary-science division. The most recent decadal survey, released in 2022, recommended limiting the cost of Mars sample return to no more than 35% of the division’s overall budget. That’s a big challenge as the agency also tries to keep funding going for other priority projects, such as the Dragonfly mission to Saturn’s moon Titan, slated for later this decade, and a mission to Uranus next decade.\nThat means all eyes remain on how to pay for Mars sample return. “The community knew that prioritization of a multi-mission effort and the single most ambitious effort in the history of planetary sciences would have challenges,” says Bethany Ehlmann, a planetary scientist at the California Institute of Technology in Pasadena who helped to lead the most recent decadal survey. “That’s why the [survey] highlights the importance of NASA working with Congress to augment the budget and figure out the appropriate funding profile to get Mars sample return done.”\nThis article is reproduced with permission and was first published on September 27, 2023.\nAlexandra Witze works for Nature magazine.\nShannon Hall\nRobin George Andrews\nLeonard David\nJonathan O'Callaghan\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "FEMA Disaster Money Flowing Again after Budget Standoff", "date": "2023-10-03 16:30:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nThe Federal Emergency Management Agency will resume funding long-term rebuilding projects after withholding funds since August\nCLIMATEWIRE | The Federal Emergency Management Agency lifted temporary spending restrictions Monday that had held up $3 billion for states to rebuild from disasters that occurred in recent years.\nFEMA said it would resume giving states money for rebuilding projects because it received $16 billion in the temporary spending bill that Congress and President Joe Biden signed Saturday.\nThe agency, facing a dwindling budget, had stopped funding long-term projects Aug. 29 to save money for emergency costs such as temporary shelters and road clearing immediately after a disaster.\nThe spending restrictions forced FEMA to withhold funding for 2,400 nonemergency projects that the agency had approved such as rebuilding damaged roads and structures. It was the first time FEMA had imposed “immediate needs funding” restrictions since 2017.\nFEMA said it expects to fund all delayed projects “within the next several weeks.”\nThe $16 billion for FEMA’s Disaster Relief Fund was included in a temporary spending package Congress approved one day before the end of fiscal 2023 when most federal employees were to stop working due to a lack of funding.\nBiden had asked Congress in August to give FEMA $16 billion through a special allocation to enable the agency to continue operating in full.\nFEMA’s disaster fund had dwindled to about $2 billion, which can be spent quickly if a wildfire, storm or flood causes significant damage.\nThe agency’s decision to withhold funds did not automatically block newly approved rebuilding projects. But withholding funds forced states and localities to pay for projects themselves and wait for FEMA reimbursement or to delay the start of the projects.\nFEMA typically pays 75 percent of projects that rebuild public facilities after a major disaster.\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nThomas Frank covers the federal response to climate change for E&E News.\nAndrea Thompson\nAvery Ellfeldt and E&E News\nThomas Frank and E&E News\nThe Editors\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "How AI Could Help China and Russia Meddle in U.S. Elections", "date": "2023-10-03 18:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nChatGPT and similar AI programs give propagandists and intelligence agents a powerful new tool for interfering in politics. The clock is ticking on learning to spot this disinformation before the 2024 election\nThe following essay is reprinted with permission from The Conversation, an online publication covering the latest research.\nElections around the world are facing an evolving threat from foreign actors, one that involves artificial intelligence.\nCountries trying to influence each other’s elections entered a new era in 2016, when the Russians launched a series of social media disinformation campaigns targeting the U.S. presidential election. Over the next seven years, a number of countries – most prominently China and Iran – used social media to influence foreign elections, both in the U.S. and elsewhere in the world. There’s no reason to expect 2023 and 2024 to be any different.\nBut there is a new element: generative AI and large language models. These have the ability to quickly and easily produce endless reams of text on any topic in any tone from any perspective. As a security expert, I believe it’s a tool uniquely suited to internet-era propaganda.\nThis is all very new. ChatGPT was introduced in November 2022. The more powerful GPT-4 was released in March 2023. Other language and image production AIs are around the same age. It’s not clear how these technologies will change disinformation, how effective they will be or what effects they will have. But we are about to find out.\nElection season will soon be in full swing in much of the democratic world. Seventy-one percent of people living in democracies will vote in a national election between now and the end of next year. Among them: Argentina and Poland in October, Taiwan in January, Indonesia in February, India in April, the European Union and Mexico in June and the U.S. in November. Nine African democracies, including South Africa, will have elections in 2024. Australia and the U.K. don’t have fixed dates, but elections are likely to occur in 2024.\nMany of those elections matter a lot to the countries that have run social media influence operations in the past. China cares a great deal about Taiwan, Indonesia, India and many African countries. Russia cares about the U.K., Poland, Germany and the EU in general. Everyone cares about the United States.\nAnd that’s only considering the largest players. Every U.S. national election from 2016 has brought with it an additional country attempting to influence the outcome. First it was just Russia, then Russia and China, and most recently those two plus Iran. As the financial cost of foreign influence decreases, more countries can get in on the action. Tools like ChatGPT significantly reduce the price of producing and distributing propaganda, bringing that capability within the budget of many more countries.\nA couple of months ago, I attended a conference with representatives from all of the cybersecurity agencies in the U.S. They talked about their expectations regarding election interference in 2024. They expected the usual players – Russia, China and Iran – and a significant new one: “domestic actors.” That is a direct result of this reduced cost.\nOf course, there’s a lot more to running a disinformation campaign than generating content. The hard part is distribution. A propagandist needs a series of fake accounts on which to post, and others to boost it into the mainstream where it can go viral. Companies like Meta have gotten much better at identifying these accounts and taking them down. Just last month, Meta announced that it had removed 7,704 Facebook accounts, 954 Facebook pages, 15 Facebook groups and 15 Instagram accounts associated with a Chinese influence campaign, and identified hundreds more accounts on TikTok, X (formerly Twitter), LiveJournal and Blogspot. But that was a campaign that began four years ago, producing pre-AI disinformation.\nDisinformation is an arms race. Both the attackers and defenders have improved, but also the world of social media is different. Four years ago, Twitter was a direct line to the media, and propaganda on that platform was a way to tilt the political narrative. A Columbia Journalism Review study found that most major news outlets used Russian tweets as sources for partisan opinion. That Twitter, with virtually every news editor reading it and everyone who was anyone posting there, is no more.\nMany propaganda outlets moved from Facebook to messaging platforms such as Telegram and WhatsApp, which makes them harder to identify and remove. TikTok is a newer platform that is controlled by China and more suitable for short, provocative videos – ones that AI makes much easier to produce. And the current crop of generative AIs are being connected to tools that will make content distribution easier as well.\nGenerative AI tools also allow for new techniques of production and distribution, such as low-level propaganda at scale. Imagine a new AI-powered personal account on social media. For the most part, it behaves normally. It posts about its fake everyday life, joins interest groups and comments on others’ posts, and generally behaves like a normal user. And once in a while, not very often, it says – or amplifies – something political. These persona bots, as computer scientist Latanya Sweeney calls them, have negligible influence on their own. But replicated by the thousands or millions, they would have a lot more.\nThat’s just one scenario. The military officers in Russia, China and elsewhere in charge of election interference are likely to have their best people thinking of others. And their tactics are likely to be much more sophisticated than they were in 2016.\nCountries like Russia and China have a history of testing both cyberattacks and information operations on smaller countries before rolling them out at scale. When that happens, it’s important to be able to fingerprint these tactics. Countering new disinformation campaigns requires being able to recognize them, and recognizing them requires looking for and cataloging them now.\nIn the computer security world, researchers recognize that sharing methods of attack and their effectiveness is the only way to build strong defensive systems. The same kind of thinking also applies to these information campaigns: The more that researchers study what techniques are being employed in distant countries, the better they can defend their own countries.\nDisinformation campaigns in the AI era are likely to be much more sophisticated than they were in 2016. I believe the U.S. needs to have efforts in place to fingerprint and identify AI-produced propaganda in Taiwan, where a presidential candidate claims a deepfake audio recording has defamed him, and other places. Otherwise, we’re not going to see them when they arrive here. Unfortunately, researchers are instead being targeted and harassed.\nMaybe this will all turn out OK. There have been some important democratic elections in the generative AI era with no significant disinformation issues: primaries in Argentina, first-round elections in Ecuador and national elections in Thailand, Turkey, Spain and Greece. But the sooner we know what to expect, the better we can deal with what comes.\nThis article was originally published on The Conversation. Read the original article.\nBruce Schneier is an adjunct lecturer in public policy at Harvard University's Harvard Kennedy School. Follow Bruce Schneier on Twitter\nGary Marcus\nLauren Leffer\nSiwei Lyu | Opinion\nCharles Seife | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Cats Are Perfect. An Evolutionary Biologist Explains Why", "date": "2023-10-04 10:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nCats have attained evolutionary perfection\nAnjali Goswami thinks cats are perfect—not in the same way that the average cat person might admire their beauty, athleticism and independence of spirit but from a scientific standpoint. Goswami is an evolutionary biologist at the Natural History Museum in London who studies large-scale patterns of evolution in vertebrate animals through time. She contends that cats—from tabbies to tigers—are quintessential products of evolution. I sat down with her to find out why. Her explanation reveals cats, and the meaning of evolutionary success, in a fascinating new light.\n[An edited transcript of the interview follows.]\nWhen I first came across your argument about cats being perfect, my initial thought as a cat fan was “Well, of course they are. Science confirms the obvious.” But then I realized that this was a really interesting idea. How did it come about?\nI was reading a book by Alex Dehgan called The Snow Leopard Project. In it, he mentioned that in this area in Afghanistan where he was setting up a national park, there are several cat species. I thought that was kind of amazing because ecologically, cats all do the same thing. They’re hard-core predators. They’re carnivores. And there are lots of other places around the world where there are multiple species of cats that coexist—not only today but also in deep time. The thing is, although there are lots of species, they all kind of look the same. They’re just big or small. I started thinking about how cats can be so similar.\nTell me more about how they’re similar. I’m thinking of all the breeds of domestic cat, and even within just that species, there seems to be a lot of variation.\nThey have different coat colors, sure. But they all have the same baby heads. They’re round, and they don’t elongate as the animal matures, which is the standard developmental pattern for mammals. Dogs have short, round faces as puppies but long, snouty faces as adults. An adult cat looks pretty much like a baby cat but bigger. With dogs, breeders play off of that developmental variation to create breeds with different face shapes. But because cats don’t have that developmental variation, there isn’t much to play around with other than coat color.\nThis all goes back to the fact that cats are extremely specialized. Every member of the order of mammals known as the carnivorans, including cats and dogs, has an upper fourth premolar and a lower first molar that form what we call the slicing pair, which slices meat. A lot of carnivorans retain molars behind the slicing pair that can grind up stuff such as vegetation. But cats have lost pretty much everything behind their slicing teeth. They might have a little nub, a peg tooth, but it can’t process stuff. This is why foxes are perfectly happy going through garbage, whereas leopards will kill livestock instead.\nIt doesn’t matter if they’re a tiny Bengal cat or a gigantic lion or tiger. They’re still gonna basically look the same. If you handed me a lion or tiger skull, I could not—as a person who’s a pretty solid expert in carnivorans in general—tell you which one it was. Most people would be hard-pressed to tell you. They look nearly identical. That’s how similar cats are. There’s a teeny amount of allometry [disproportionate change in one body part relative to the whole as a consequence of size] if they get really big: a small elongation of the face and an increase in muscle mass. But the variation is nothing compared with what you see in other groups, such as dogs. Ultimately big cats are really similar to small cats, far more so than you would predict.\nWhat does this have to do with being perfect?\nCats have nailed this one thing so well that they all do it and just come up with slightly different sizes. That’s why they’re perfect, evolutionarily. They don’t need variation. They might get bigger or smaller, but they don’t change anything else because they’re doing it just right otherwise. They’re not jacks-of-all-trades; they’re masters of one.\nBears are the anticats. There are only a few species of bear, and they do different things. You’ve got your superspecialized, weird herbivore, the panda [which basically only eats bamboo]. And then you’ve got spectacled bears [which favor fruits and bromeliads]. You’ve got polar bears, which are hypercarnivorous marine mammals, and the omnivorous black bears and grizzlies. And then there are sloth bears, which mostly eat social insects. So almost every single species of bear does something totally different. And they’re just okay at all of it [laughs]. I really do like bears a lot because of that opposite side of things. They’re interesting because they’re so ecologically diverse.\nPeople usually talk about a group’s diversity as a mark of success. But you’re saying it’s the sameness of cat species, their lack of variation, that indicates that they’re evolutionarily successful, or “perfect.”\nCats challenge standard biases in evolutionary biology. People have said to me, “What about bats? What about rodents? These groups have so many species doing all kinds of things.” And I’m like, “Yeah, because they suck.” They haven’t figured out how to do anything well, so they keep trying different things.\nDo any other vertebrate groups measure up to cats in this way?\nMonitor lizards are as awesome as cats. They are the cats of the reptile world. They vary hugely in body size—they have maybe an even bigger body size range than cats do—and they are all utterly identical. They’re also hard-core carnivores.\nYou and your colleagues have been studying skull evolution in a bunch of animals, and you recently published a paper on what you found in mammals. Did you discover anything interesting about cats in the course of that research?\nWe’ve been trying to measure skull shape in a similar way across all tetrapods (vertebrates with four limbs). We’re looking at salamanders and frogs, birds and crocodiles, dinosaurs and mammals and then trying to understand the variation that we see, the speed at which things evolve and the factors that are associated with how fast things evolve. Within mammals, specifically, being social or solitary affects how fast you evolve. Social mammals evolve faster. Cats are notoriously solitary, except for lions. And cats don’t evolve quickly. Compared with other groups, cats are slowly evolving animals.\nThere are lots of things that have tried to be cats—other groups of mammals that have evolutionarily converged on cats. Marsupials have tried to be cats. An extinct group of carnivorans called creodonts have tried to be cats. Weasels have tried to be cats. There’s all kinds of stuff that has tried to be a bit catlike in different ways—mongooses, things like that. But they kind of dip in and dip out of being cats, and they can’t really outcompete cats in their space. They haven’t lasted. All of those things that have tried to be cats, they do other things, too, and those things are fine. But there aren’t a lot of things that are around today that do a very good job of being a cat.\nSo cats are not only perfect but also inimitable.\nYou can’t just casually try to be a cat. You have to commit. Cats have committed to being cats. Everything else is just sort of dabbling, and it doesn’t work.\nKate Wong is a senior editor for evolution and ecology at Scientific American. Follow her on Twitter @katewong Credit: Nick Higgins\nCarlos A. Driscoll, Juliet Clutton-Brock, Andrew C. Kitchener and Stephen J. O'Brien\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "What Colors Do Dogs See?", "date": "2023-10-04 10:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nCanine experts weigh in on a TikTok dog vision filter and the rich sensory world of humanity’s best friends\nHave you ever wondered whether your dog could see (and appreciate) the striking pink or nuanced teal color of a new toy? Humans on TikTok are using a dog vision filter to help answer this question. With the filter on, you’ll see the world in shades of blue, yellow and gray—the only colors your pup can perceive.\nBut is this really how our furry friends see the world? Not exactly, experts say—there’s way more to your pet’s vision than color perception.\nScientists once thought dogs saw only in black and white. The idea took off in the public imagination in the 1940s, when optometrist Gordon Walls published his influential book The Vertebrate Eye and Its Adaptive Radiation, in which he claimed that dogs could only weakly see color, if at all. The myth was finally debunked in 1989 when ophthalmologist Jay Neitz, then at the University of California, Santa Barbara, and his colleagues discovered that canines could see blues and yellows but not reds and greens. Some humans, about 8 percent of men and 0.5 percent of women, are similarly red-green color-blind.\nIt turns out that dogs possess two types of color-sensing receptors, called cones, in their retinas. This makes them similar to most mammals—including cats, cattle and pigs—and unlike humans, who have three cones.\n“Our work has had a big influence, and lots of people now understand what color vision in dogs really is,” says Neitz, who is now an ophthalmology professor at the University of Washington.\nBut to really understand how dogs see the world, we need to move beyond color, says Sarah-Elizabeth Byosiere, an animal behaviorist and former director of the Thinking Dog Center at Hunter College. While a green or red ball lying on grass would not stand out easily to your pet, it might challenge them to identify it by its other features—such as its movement, shape and the way it reflects light, Byosiere says. That challenge could either be enriching or frustrating. “It all depends on an individual dog’s behavior,” she says.\nIf you’re really trying to imagine the world through the eyes of your dog, you should picture everything a lot blurrier. Most dogs have 20/75 vision, meaning that they must be 20 feet away from an object to see it as well as a human with clear vision who is standing 75 feet away.\n“Everything looks clear and detailed in those [TikTok] videos, but it wouldn’t look quite as clear to dogs,” Neitz mentions.\nBut unlike humans, who see very poorly in low light, canines have evolved to see well in both daytime and nighttime conditions, explains Paul Miller, a veterinary ophthalmologist at the University of Wisconsin–Madison. Though dogs have fewer color-sensing cones than humans, they have more rods, the cells that help with night vision. They even have a unique structure in their eyes called the tapetum lucidum, a mirrorlike membrane that allows them to see in six times less light than humans can. The tapetum, which some other animals, such as cats and cattle, also possess, sits behind the retina and reflects light back onto it, giving the receptors a second chance to gather more visual detail. It’s also the reason your pet’s eyes glow in photos and in the dark.\nAlso important for dogs’ perception is their sense of smell, which is 10,000 to 100,000 times more powerful than that of an average human. This is as true for chihuahuas and pugs as it is for bloodhounds. While humans have about five million smell receptors, dogs possess up to a billion and can communicate with one another with chemical signals. They can pick up odors as far as 12 miles away.\nAnd canines’ mighty sense of smell is inextricably linked to how they see the world. A study published last year in the Journal of Neuroscience revealed that canines’ brain has a direct connection between their olfactory bulb, which processes smell, and their occipital lobe, which processes vision. This integration of sight and smell had not been observed before in any animal species, the authors stated.\nThe results raise the question of whether dogs’ sense of smell is orienting their sight, Miller says. “It’s pretty wild,” adds Miller, who was not involved in the study. “They [may be able to] smell in 3-D.”\nSo while humans may be attuned to the aesthetics of color, dogs simply aren’t, Neitz says. “I’ve had dogs all my life. And I never really felt like, ‘Oh, my God, my poor dog’s world is limited from a color vision standpoint,’” he says. They live in a very rich olfactory world that humans can’t appreciate, Neitz adds.\nWhen it comes to buying toys for our canine companions, we don’t always have to select the two colors they can see: yellow and blue. Byosiere recommends getting one red and one blue toy to enrich your pet’s play. You may want to throw the red one on the green grass so that your pup uses its nose and then throw a blue one so that it uses its eyes.\n“These animals are not deprived in any way,” Byosiere says. “It’s just that they just see the world in a different way.”\nNiranjana Rajalakshmi is a freelance journalist and a former veterinarian based in Ohio. She covers health, animals, biodiversity, and the environment.\nStephanie Pappas\nStephanie Pappas\nPat Shipman | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "2023 Nobel Prize in Chemistry Goes to Tiny Quantum Dots with Huge Effects", "date": "2023-10-04 11:21:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nThree scientists won the Nobel Prize in Chemistry for their discovery of quantum dots, an entirely new class of material that is used in large-screen TVs and cancer surgery\nThe 2023 Nobel Prize in Chemistry was awarded today to three scientists for the discovery of quantum dots. These are nanoparticles so small that their size controls their many properties, such as their color. And that in turns makes them invaluable in applications ranging from large color displays to energy production.\nThe winners are Moungi Bawendi of the Massachusetts Institute of Technology, Louis Brus of Columbia University and Alexei Ekimov of the firm Nanocrystals Technology in New York State. The three scientists will share the prize of 11 million Swedish kronor, or nearly $1 million.\nProducing a cornucopia of colors, quantum dots are common materials in big television screens today. Essentially they are tiny crystals, but it’s easier to think of each of them as a compressed ball, just a few nanometers in diameter, that contains electrons. The electrons are key to how the dots work. “If you take an electron and put it into a small space, its wave function gets compressed,” meaning the electron has less freedom to move, said Heiner Linke, a member of the Nobel Committee for  Chemistry, at the announcement. The compression allows the electrons to store more energy.\nThe electrons release that energy as photons—packets of light—and those photons will appear as different colors, depending on how much the electrons are squeezed.\nThat change is a quantum effect, one of the mysterious things that happens in the realm of the incredibly small. So, for example, the smallest dots will emit more shorter-wavelength blue light than longer-wavelength red light. Enlarging the dots slightly will change the color composition.\nThe dots are also used in biomedical imaging—to visualize blood vessels feeding tumors—and in solar cells, where they can amplify the energy generated by the panels. Changing their size can also change other properties, such as their melting point.\nBawendi, when reached by phone by the Royal Swedish Academy of Sciences after the announcement, said he was “very surprised..., sleepy, shocked ... and very honored.” The rest of the world may have been slightly less surprised. Bawendi’s name, along with his two colleagues, was leaked in a document sent out by the academy hours before the official announcement. It was a rare crack in what is ordinarily a highly organized and confidential process. Hans Ellegren, secretary-general of the academy, said the organization did not know what had happened.\nThe news, however it came out, was greeted with applause by other chemists. “These remarkable nanoparticles have huge potential to create smaller, faster, smarter devices, increasing the efficiency of solar panels and the brilliance of your TV screen,” said Gill Reid, president of the Royal Society of Chemistry and an inorganic chemist at the University of Southampton in England, in a recent statement. The Nobel “is really exciting and shows how chemistry can be used to solve a range of challenges,” she said.\nAnd while quantum effects are often considered the province of physics, Judith Giordan, a chemist and president of the American Chemical Society, makes a strong case that dots are chemical products. “We own electrons. They’re on every single atom,” she says. And while the effects of confining electrons in tiny spaces were theorized by physicists, “it was chemists who moved them into novel architectures of atoms, who figured out how to actually produce them in the lab and then in manufacturing settings.”\nThe notion of quantum dots first showed up in theories in the 1930s and then stalled for decades. But in the early 1980s Ekimov put nanoparticles of copper chloride in glass and showed that the particle size changed the color of the glass through quantum effects. Several years later Brus achieved similar color alterations with nanoparticles floating freely in a fluid. \nBawendi, in 1993, developed a way to standardize dot production, which opened the field to many other labs and companies. “He made it easy,” says chemist Rigoberto Advincula, who works on nanoscale technology at the University of Tennessee, Knoxville. Bawendi’s lab created a kind of “soup” of other substances that attached to quantum dot seeds and precisely regulated their growth. This made the seeds very “tunable,” in chemistry lingo, Advincula says. It was a simple way to control their size and thus tune them to produce different levels of energy, he adds.\nIn addition to big screens and solar panels, dots are used to adjust the color of LED lights to make them less harsh. Medical scientists are also exploring their use as sensors and probes for hard-to-find molecules in the body. After the announcement, Bawendi said that “it’s just the beginning.”\nJosh Fischman is a senior editor at Scientific American who covers medicine, biology and science policy. He has written and edited about science and health for Discover, Science, Earth, and U.S. News & World Report. Follow Josh Fischman on Twitter.\nJennifer Ouellette\nDaniel Garisto\nLee Billings\nDaniel Garisto\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "A Popular Decongestant Doesn't Work. What Does?", "date": "2023-10-04 12:00:00", "text": "The popular decongestant phenylephrine is not effective, an FDA panel found. Here’s what to use instead.\nTanya Lewis: Hi, this is Your Health, Quickly, a Scientific American podcast series!\nJosh Fischman: We bring you the latest vital health news: Discoveries that affect your body and your mind.  \nLewis: And we break down the medical research to help you stay healthy. I’m Tanya Lewis.\nFischman: I’m Josh Fischman.\nLewis: We’re Scientific American’s senior health editors. \nFischman: Today, we’re talking about decongestants. Scientists who advise the FDA recently concluded that phenylephrine, a common decongestant in cold medicines, doesn’t work. We’ll talk about what actually does.\n[Clip: Show theme music]\nLewis: I don’t know about you, Josh, but I have bad allergies and my sinuses are blocked pretty often. I’ve tried all sorts of things to help, from nasal sprays and decongestants to to antihistamines to hot showers. Some of these things help, some of them don’t.\nFischman: What helps you the most of all those things, Tanya?\nLewis: I find that the steroid nasal sprays work pretty well, but I don’t like to use them all the time.\nFischman: How come?\nLewis: Um, I just find that sometimes I develop a tolerance to it so it stops having the same effect. Sometimes hot showers do help temporarily, but usually the congestion comes back.\nFischman: Yeah, and there’s only so long you can stand under a hot shower, right? \nLewis: Right.\nFischman: I’ve tried those saline sprays up my nose. They kind of flush things out and I feel more comfortable. But I have to use them for a bunch of days before I feel any difference.\nLewis: Yeah, those saline ones are pretty good. \nFischman: Overall, I tend to go for decongestant tablets, which are supposed to reduce swelling inside my nose, opening up my airways.\nLewis: You’re not alone in preferring tablets. One of the most popular decongestant ingredients is phenylephrine. It’s found in drugs like Sudafed PE, Benadryl Allergy D Plus Sinus, and Vicks Dayquil Cold and Flu Relief.\nBut earlier this month, in a rare move, an FDA advisory panel declared that oral phenylephrine is completely useless at clearing up congestion.\nFischman: That really surprised me. I’ve been buying cold and flu medicines for years. And I always look to see if a decongestant like  phenylephrine is in the capsule.\nLewis: I’d heard for a while that it wasn’t that effective, but it’s in a lot of cold medicines. In fact, it became popular because the standard over-the-counter decongestant, pseudoephedrine —the active ingredient in regular Sudafed—got locked up behind pharmacy counters.  That’s because it can be used as an ingredient in making methamphetamine.\nFischman:  I remember that. In the mid-2000s, all these cold medicines were suddenly put behind plexiglass windows with padlocks on them. I had to ask a pharmacist if I wanted some, and there was a limit to how much I could buy.\nLewis: Exactly. So, more products started using phenylephrine. \nFischman: Basically they were using it as a substitute?\nLewis: Yep. Phenylephrine was actually approved in the 1970s, so it had been around a while. But even back then, the FDA said it wasn’t very effective as a decongestant.\nJennifer Le: There was a cough and cold panel in 1972, in which the panel specifically noted that the data were not strongly indicative of efficacy. So this goes back quite a number of years.\nLewis: That’s Jennifer Le, a professor at the pharmacy school at the University of California San Diego. She was on the recent FDA advisory panel earlier this month that made the decision that phenylephrine wasn’t effective.\nBack in the 1970s, the FDA was more concerned with safety than effectiveness.\nLe: So first and foremost, at the dose that's currently approved, 10 milligram for nasal congestion, it does not appear to provide any safety concerns, except in a very small population who has high blood pressure.\nLewis: Then, in 2007, an FDA advisory panel reviewed the data.\nLe: And in reviewing the data they thought that efficacy was maybe suggestive at higher doses, and so the recommendation at that time was to obtain more clinical data. And the committee who reviewed it withdrew approval for those less than 12 years of age.\nLewis: Fast-forward to today, when another FDA panel—the one Le was one—reviewed the drug’s effectiveness again. They looked at more recent data on both how the drug is metabolized and how well it works in people.\nLe: And the pharmacologic data side indicated that when you take oral phenylephrine, most of it is metabolized to inactive forms, so very little of the active drug—in fact, one percent, based on FDA data—actually gets into the blood.\nFischman: So, most of the drug isn’t even making it to the nose, in other words.\nLewis: Exactly. In addition to that, three trials of oral phenylephrine showed it was no better than a placebo at relieving congestion.\nSo, the committee voted unanimously that oral phenylephrine is basically useless.\nFischman: The FDA panel only reviewed forms of the drug that come in capsules, tablets and syrups, though. So what about things like nasal sprays?\nLewis: They didn’t review phenylephrine nasal sprays. Those might still be effective since they are going right into your nose. But the oral pills won’t do much.\nFischman: But I’ve been taking these cold medications with phenylephrine for years and they do make me feel better. I think. Is that just a placebo effect?\nLewis: Not necessarily. Those meds usually are a combo of several ingredients such as acetaminophen, which helps reduce pain and fever, and antihistamines, which help in the first few days. So the combo may still make you feel better.\nFischman: Overall, though, if oral phenylephrine doesn’t work, what should people use instead of it?\nLewis: I asked Le the same question. She basically said that for short-term congestion with a cold, you should just wait it out.\nLe: The nasal congestion that occurs with the common cold is self-limiting. And so if it's possible, and if it's tolerable—I have a very high tolerance rate when it comes to symptoms— let it resolve, let the symptom resolve. You know, there's nasal saline products that can maybe help with congestion a little bit. A warm, hot, bath, a humidifier can help with some of that too. \nFischman: But Tanya, you said you tried a lot of those things, and often they don’t work. \nLewis: Yeah, I find that most of them only offer temporary relief.\nFischman: So are you just supposed to walk around with your nose blocked or running for a week, and a headache pounding, maybe a box of tissues tucked under your chin? \nLewis: I know, right? It really doesn’t seem great. There are other decongestants, like pseudoephedrine, which you can get by asking a pharmacist, like we mentioned earlier. And that works pretty well. You can also use nasal sprays like Afrin, but be careful—if you use those longer than three days, they can cause your symptoms to rebound.\nFischman: What about other sprays like Flonase or Nasacort?\nLewis: Those steroid nasal sprays work pretty well. But ask a doctor if you’re congested for longer than a few days, because you might have chronic inflammation due to allergies.\nFischman: And allergies are a different story, right? \nLewis: Right. For that kind of congestion, you should consult an allergy specialist. The standard therapy involves some combination of oral and nasal antihistamines and nasal steroids like Flonase. In some cases, you can get allergy shots or even surgery.\nFischman: Okay, but for colds, clearly it’s time to restock my medicine chest. Those saline sprays do help me, so maybe some more of those. And if I have a rougher case, it looks like I’m going to ask the drugstore to take out their keys, and open up their pseudoephedrine stash. \n[CLIP: Show music]\nFischman: Your Health, Quickly is produced by Tulika Bose, Jeff DelViscio, Kelso Harper, Carin Leong, and by us. It’s edited by Elah Feder and Alexa Lim. Our music is composed by Dominic Smith.\nLewis: Our show is a part of Scientific American’s podcast, Science, Quickly. Subscribe wherever you get your podcasts. If you like the show, give us a rating or review!\nAnd if you have ideas for topics we should cover, send us an email at Yourhealthquickly@sciam.com. That’s your health quickly at S-C-I-A-M dot com.\nI’m Tanya Lewis.\nFischman: I’m Josh Fischman.\nLewis: See you next time.\nTanya Lewis is a senior editor covering health and medicine for Scientific American. Follow her on Twitter @tanyalewis314 Credit: Nick Higgins\nJosh Fischman is a senior editor at Scientific American who covers medicine, biology and science policy. He has written and edited about science and health for Discover, Science, Earth, and U.S. News & World Report. Follow Josh Fischman on Twitter.\nCarin Leong is a multimedia intern producing podcasts and videos at Scientific American. Follow Carin Leong on Twitter\nElah Feder is a journalist, audio producer, and editor. Her work has appeared on Science Friday, Undiscovered, Science Diction, Planet Money, and various CBC shows. Follow Elah Feder on Twitter\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Entangled Light from Multitasking Atoms Could Spark Quantum Breakthroughs", "date": "2023-10-04 13:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nA colorful quirk of quantum optics could lead to significant advances in quantum communication and computing\nDriving late at night, you come upon a red light and stop the car. You lift your hand wearily to block the red glow streaming through your windshield. Suddenly, both the green and yellow lights come on, hitting your eyeballs at the same time. Confused, you take your hand away, and again only the red color appears.\nThis surreal scenario is what would actually happen if the traffic light was a single atom illuminated by a laser beam, as recently shown experimentally by researchers in Berlin. They looked at the light scattered by an atom and saw that photons—the tiniest particles of light—arrived at the detector one at a time. The scientists blocked the brightest color they saw, and suddenly pairs of photons of two slightly different colors started arriving at their detector simultaneously. They reported their findings in Nature Photonics in July.\nThe reason for this counterintuitive effect is that single atoms are skilled little multitaskers. Through different underlying processes, they can scatter a variety of colors at the same time like a dangerous traffic light that shines all three colors at once. Yet because of quantum interference between these processes, an observer only sees one of the metaphorical traffic light’s colors at a time, preserving peace on the road.\nThis experiment also paves the way for novel quantum information applications. When the brightest color is blocked, the photons that pop up simultaneously are entangled with each other, behaving in sync even when they are separated over large distances. This provides a new tool for quantum communication and information processing in which entangled photon pairs can serve as distributed keys in quantum cryptography or store information in a quantum memory device.\nAtoms can be surprisingly picky about their couplings with light. Based on the varying arrangements of their constituent electrons, atoms of different elements each display clear preferences for which colors of light they strongly scatter. Proving as much is as simple as shining a laser at an atom, with the laser tuned to a particular color that closely matches that atom’s scattering preference. As expected, your detector will show the atom scattering photons of that predominant color. But strangely, the scattered photons will stream into the detector one at a time, as if in a single-file line. Up through the early 1980s physicists generally accepted a naive explanation for this strange effect: the photons arrive as if in a queue because the atom can only scatter one photon at a time.\nIn 1984, however, two researchers dug into the math governing this phenomenon and found that the reality is much more complicated—and much more inherently quantum. They theorized that the atom is actually doing many things simultaneously: scattering not only single photons but also, through an entirely different process, photonic pairs, triplets and quadruplets. Nevertheless, only one photon at a time arrives at the detector because of quantum interference among these processes.\nRegular interference occurs between two waves like ripples on a pond, overlapping in a pattern of crests and troughs. A distinctive feature of the quantum world is that interference occurs not only between actual waves but also between probabilities: a photon sent through two slits has some probability of going through the left slit and some probability of going through the right one. The two possible paths interfere with each other, forming a pattern of crests and troughs. Block either slit, and the pattern disappears. “I like to tell my students, ‘Imagine that you want to prevent a burglar from entering your house and going into the living room. Just leave two doors open, and then you will have destructive interference, and the thieves cannot go into the living room,’” jokes physicist Jean Dalibard, who co-authored the 1984 paper.\nIn Dalibard’s model, however, this interference is not a joke at all. It actually happens between the two underlying processes, the single-photon and multiphoton scattering. And it happens not in space but in time such that a probability trough appears for two photons arriving at the same time. So the atom multitasks, yet it does so in a way that looks suspiciously like doing just one thing.\nDalibard’s complex description of the multitasking atom languished in relative obscurity until recently. “I was very happy that the group from Berlin found this paper. I don’t know how they did,” he says. From their end, the researchers in Berlin were fascinated by the counterintuitive theory introduced by Dalibard and his co-author, physicist Serge Reynaud. “When we started to dig into the old literature from the 1980s, we really got intrigued,” says Max Schemmer, a former postdoctoral researcher at Humboldt University of Berlin and a co-author of the recent work.\nSchemmer and his colleagues saw the potential of recently developed technology to experimentally test this theory. First, they cooled a cloud of rubidium atoms to just shy of absolute zero. Then they used optical tweezers—a tightly focused laser beam strong enough to grab extremely tiny objects—to isolate and hold one atom. Next they illuminated that atom with another laser tuned to rubidium’s scattering preference and placed a lens off to the side to collect the scattered light and channel it into an optical fiber.\nTo block the brightest color, the researchers guided the light into a finely tuned filter created by a ring of optical fiber. The length of the ring was chosen and adjusted precisely to create destructive interference for only one color of light. When this filter was included in the light’s path, they saw the brightest color disappear. And as Dalibard and Reynaud had predicted, photons of two slightly different colors suddenly started arriving at the detector in simultaneous pairs.\nBy blocking the brightest color, thus taking the atom’s single-photon-generating process offline, Schemmer and his colleagues were able to see the other process in action without the destructive interference created by the dominant single atom—much like a traffic light that shines both green and yellow when red is blocked.\nThe atom’s “second task” of scattering photons in pairs could come in handy for quantum computing and communication. Once the brightest color is blocked, the pairs of photons that arrive simultaneously are entangled with each other—entanglement being the not-so-secret ingredient that gives quantum approaches advantages over classical ones.\nEntangled photon pairs could be used to share quantum information across vast distances or to transmit it between different mediums. Conveniently, the photon pairs produced with this technique come in a very precise color rather than being spread across larger chunks of the rainbow like photon pairs produced by conventional methods. This makes them particularly useful for efficiently storing quantum information in a quantum memory device, Schemmer says, which could in turn lead to more robust quantum communication networks.\nAdditionally, these photon pairs possess a unique kind of entanglement that is not offered by other sources: a syncing in time. “There is one existing technique of producing entangled pairs of photons,” says Magdalena Stobinska, a quantum optics expert, who did not participate in the work. “But this is a different degree of freedom and therefore can be used for different types of applications. So it broadens the palette of efficiently produced entangled pairs of photons. And I think that’s cool.”\nAnd theory predicts that photon pairs are not the end of the story. The atom is also simultaneously scattering entangled photons in threes, fours, and so on. Blocking the red on this “traffic light” makes not only yellow and green shine through but also blue, orange, and much more. Clusters of entangled photons created this way could potentially serve as resources for photon-based quantum computing. “This system is like a treasure trove of quantum correlations,” says Fabrice P. Laussy, a professor of light-matter interactions at the University of Wolverhampton in England, who reviewed the recent study but did not participate in the research. “Everything is in there.”\nDina Genkina is a Brooklyn, N.Y.–based freelance journalist and a science communicator at the Joint Quantum Institute.\nKatherine Wright\nChris Ferrie | Opinion\nAnil Ananthaswamy\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Dengue's Spread in Europe Could Spur Vaccine Development", "date": "2023-10-04 17:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nBut dengue in wealthy countries could divert medication away from poorer nations that may need it more\nCLIMATEWIRE | In the early morning of the last day of August, Parisians experienced for the first time a practice normally confined to tropical regions — authorities fumigating the city against the tiger mosquito. The event was a tangible confirmation of what public health stats already showed: Dengue, the deadly mosquito-borne disease, had well and truly arrived in Europe.\nIn 2022, Europe saw more cases of locally acquired dengue than in the whole of the previous decade. The rise marks both a public health threat and a corresponding market opportunity for dengue vaccines and treatments; news that should spur the pharmaceutical industry to boost investment into the neglected disease.\nOn the face of it, this shift would appear to benefit not only countries like France but also nations like Bangladesh and the Philippines that have long battled dengue.\nBut that assumption could be fatally flawed, experts told POLITICO.\nPeople working in the field say the rise of dengue in the West could, in fact, make it harder to get lifesaving drugs to those who need them most, because pharmaceutical companies develop tools that are less effective in countries where the dengue burden is the highest or because wealthy nations end up hoarding these medicines and vaccines.\n“It might look like a good thing — and it is a good thing — that we're getting more products developed, but does it then create a two-tier system where high-income populations get access to it and then we still have the access gap for low- and middle-income countries?” asked Lindsay Keir, director of the science and policy advisory team at think tank Policy Cures Research.\nClimate change and migration mean the mosquitoes that transmit dengue, as well as other diseases such as chikungunya and Zika, are setting up shop in Europe. The most recent annual data from the European Centre for Disease Prevention and Control shows that, in 2022, Europe saw 71 cases of locally acquired dengue: 65 in France and six in Spain.\nWhile dengue usually results in mild or no symptoms, it can also lead to high fever, severe headache and vomiting. Severe dengue can cause bleeding from the gums, abdominal pain and, in some cases, death.\nSo far, the mosquito has mostly been confined to southern Europe, but it's a worry across the Continent. In Belgium, the national public health research institute Sciensano has even launched an app where members of the public can submit photos of any Asian tiger mosquitos they spot.\nThe diseases spread by these mosquitoes have traditionally fallen under the umbrella of neglected tropical diseases, a group of infections that affect mainly low-income countries and struggle to attract research and development investment. But this is changing.\nPolicy Cures Research, which publishes an annual report on R&D investment into neglected diseases, removed dengue vaccines from their assessment in 2013. Dengue was no longer seen as an area where there was market failure, due to the emergence of a market that the private sector could tap into.\nThe organization is still tracking dengue drugs and biologics and their 2022 analysis showed a 33 percent increase in funding for research into non-vaccine products compared to the previous year, with industry investment reaching a record high of $28 million.\nSibilia Quilici, executive director of the vaccine maker lobby group Vaccines Europe, said the most recent pipeline review of members found that roughly 10 percent were targeting neglected diseases. There is more R&D happening in this area, said Quilici.\nAcross the major drugmakers, J&J is working on a dengue antiviral treatment and MSD has a dengue vaccine in their pipeline, while Sanofi has a second yellow fever jab in development. Two dengue vaccines are already approved in the European Union — one from Sanofi and another from Takeda. Moderna recently told POLITICO that it is looking closely at a dengue vaccine candidate and it already has a Zika candidate in the works.\nBut just because there might soon be larger markets for major pharmaceutical companies doesn’t mean the products will be suitable for the populations that have been waiting years for these tools.\nRachael Crockett, senior policy advocacy manager at the non-profit Drugs for Neglected Diseases initiative (DNDi), said increased pharmaceutical investment in a particular disease won't necessarily lead to products developed that are globally relevant. “Industry will — and governments are also more likely to — focus on prevention,” she said.\nThat means tools such as vaccines will be prioritized; but in countries where dengue is endemic, the rainy season completely overburdens their health systems and what they desperately need are treatments, said Crockett.\nShe also said a massive increase in investment without a structure to ensure access to resulting products means “we have absolutely no guarantee that there isn't going to be hoarding, [that] there isn't going to be high prices.” Case in point: The U.S. national stockpile of Ebola vaccines, which exists despite there never having been an Ebola outbreak in the country.\nUnderlying many of these fears are the mistakes of the Covid-19 pandemic, which saw countries with less cash and political heft at the back of the queue when it came to vaccines.\nLisa Goerlitz, head of German charity Deutsche Stiftung Weltbevölkerung’s Brussels office, warned if drug development picks up because of a growing market in high-income countries, then accessibility, affordability and other criteria that make it suitable for low resource settings might not be prioritized.\nVaccines Europe’s Quilici sought to allay these concerns, pointing to the pharmaceutical industry's Berlin Declaration, a proposal to reserve an allocation of real-time production of vaccines in a health crisis. Quilici said this was a “really strong commitment … which comes right from the lessons learnt from Covid-19 and which could definitely overcome the challenges we had during the pandemic, if it is taken seriously.”\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nAshleigh Furlong is a contributor at E&E News.\nSeema Yasmin and Madhusree Mukerjee\nMeghan Bartels\nHelen Branswell and STAT\nHarini Barath\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "September Was the Most Anomalously Hot Month Ever", "date": "2023-10-04 19:21:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nSeptember shattered a record for the highest temperature anomaly of any month and could help push 2023 to be the first year to exceed 1.5 degrees Celsius above preindustrial temperatures\nIn a year already overloaded with so many climate-related superlatives, it’s time to add another to the list: September was the most anomalously warm month ever recorded.\nAnd the steady heat building this year could make 2023 not only the hottest year on record but the first to exceed 1.5 degrees Celsius (2.7 degrees Fahrenheit) above preindustrial temperatures, or the stable climate that preceded the massive release of greenhouse gases into the atmosphere from burning fossil fuels. Under the landmark Paris climate accord, nations have pledged to try to keep global warming under that threshold. “It’s very worrying,” says Kate Marvel, a senior climate scientist at Project Drawdown, a nonprofit organization that develops roadmaps for climate solutions.\nAccording to data kept by the Japan Meteorological Agency, this September was about 0.5 degree C (0.9 degree F) hotter than the previous hottest September in 2020. It was also about 0.2 degree C (0.4 degree F) warmer than the previous record high temperature anomaly—a measure of how much warmer or colder a given time period is, compared with the average—which had been set in February 2016 during a blockbuster El Niño.\nThe September anomaly “is so far above anything we’ve seen before,” says Zeke Hausfather, a climate scientist who works at the payment processing firm Stripe and wrote about September’s heat in a recent blog post. On X, formerly known as Twitter, he called the feat “absolutely gobsmackingly bananas.”\nThe milestone reached last month comes on the heels of July setting the record for the hottest month overall. (July is always the hottest month of the year globally because it occurs at the peak of the Northern Hemisphere summer. The Northern Hemisphere has much more landmass to soak up the sun’s rays than the Southern Hemisphere, so it has the bigger influence on the global annual temperature cycle.)\nIn a marker of just how much global temperatures have risen in recent decades, Hausfather observes, “this September will be hotter than most Julys before the last decade or two.”\nTwo main factors are at play in driving temperatures to such extremes: their inexorable increase from burning fossil fuels and an El Niño event that is shaping up to be a strong one. El Niño is a part of a natural climate cycle that features a tongue of unusually warm waters across the eastern Pacific Ocean. Those waters release heat into the atmosphere and can cause a cascade of changes to key atmospheric circulation patterns linked to the weather around the world.\nHeat waves have broken records all over the globe during the past few months, including prolonged events called heat domes that plagued the southern stretch of the U.S. and parts of the Mediterranean. Summerlike temperatures were even felt in South America during the Southern Hemisphere’s winter. Two of the heat waves—one in the U.S. Southwest and one in Europe—were found to be virtually impossible without global warming. And summerlike heat has continued in places into October.\nThe most drastic temperature anomalies typically come in the winter months, when El Niño peaks in strength. In fact, the previous most anomalously warm month was February 2016, during one of the strongest El Niños on record. But this year “we’re seeing these [big anomalies] in the Northern Hemisphere summer,” Hausfather says. That leaves open the possibility of even larger anomalies when this event peaks this winter, particularly if it ends up being another strong event.\nIt is possible there is also some influence from the phasing out of sulfur-containing fuels used by ships because the aerosols spewed into the air from burning those fuels tend to have a slight cooling effect. The eruption of the Hunga Tonga–Hunga Haʻapai volcano in the southern Pacific Ocean last year may also be nudging up temperatures because of the huge amounts of water vapor—also a greenhouse gas—it injected into the atmosphere. But both factors have very small influences, compared with climate change and El Niño.\nGiven that this El Niño is expected to persist and likely to strengthen, there’s a good chance that 2023 or 2024—or both—will become the hottest year on record, besting 2016 (and 2020, which some agencies who monitor climate have tied with 2016). That isn’t surprising, given that there has been a tenth of a degree of warming since 2016, though it is “remarkable just how quickly we’ve seen warmth this year,” Hausfather says. Part of the apparent rapid warming is because 2023 began in the tail end of an unusual string of three back-to-back La Niña events. These tend to have a cooling impact on the global climate, though La Niñas today are hotter than even El Niños of several decades ago.\nBeyond potentially becoming the hottest year on record, 2023 could also be the first year to top 1.5 degrees C above preindustrial temperatures (some individual months have already passed that threshold). But even if that happens, all hope is not lost for meeting the Paris accord goals. That threshold is measured as an average of several decades, and climate scientists have long expected that a single year would pass that mark a decade or so before the world could be considered permanently above that limit. “There is still time to limit global warming to 1.5 degrees,” Marvel says. “It is going to be incredibly difficult. The pathways are narrowing.”\nBut this year should be considered a warning of the future we face if we don’t take rapid, ambitious action. “This is what the world looks like when it’s 1.5 degrees hotter in a year, and it’s terrible,” she says. When the world does permanently pass 1.5 degrees C, the climate anomalies for individual years will reach higher than that mark.\nTo stave off that future, every bit of carbon we can keep, or take, out of the atmosphere is crucial. “Every tenth of a degree matters,” Hausfather says.\nAndrea Thompson, an associate editor at Scientific American, covers sustainability. Follow Andrea Thompson on Twitter Credit: Nick Higgins\nMeghan Bartels\nStephanie Pappas\nKatherine Harmon\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Nobel Prizes Are Taking Longer to Award Groundbreaking Research", "date": "2023-10-04 20:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel laureates sometimes wait 20 years or more after making their award-worthy discovery to receive the prize\nThe road to a Nobel Prize, the most prestigious scientific award in the world, is growing ever longer, with almost half of laureates now waiting more than 20 years from making a Nobel-worthy discovery to receiving the prize.\nOne analysis shows that the average time between publishing the work and receiving one of the science prizes has nearly doubled in the past 60 years. Across the three science prizes, chemistry now has the longest ‘Nobel lag’ — an average of 30 years over the past decade — and physiology or medicine has the shortest, at 26 years (see ‘Decades-long delay’).\nAlfred Nobel’s will stated that the prizes should be awarded “to those who, during the preceding year, shall have conferred the greatest benefit to mankind.” In reality this has only happened a few times. But in the first half of the twentieth century, it was common for Nobel prize recipients to be in their 30s — and that is unheard of now, says Santo Fortunato, now a computational social scientist at Indiana University in Bloomington, who published a 2014 analysis on Nobel prizewinners since the award’s conception in 1901. His results showed that the time between laureates’ prize-winning research and their Nobel had slowly increased over the years, with a steeper slope after the 1960s than in the early years of the prize.\nThere are a number of possible reasons for this trend, says Yian Yin, a computational social scientist at Cornell University in Ithaca, New York. It could be that the overall number of breakthroughs is increasing each year, so awards cannot keep up with the number of people who deserve to be recognized, he says. It is also the case that the importance of some works, which Yin describes as ‘sleeping beauties,’ are only realized years or decades later.\nAlternatively, the lengthening gap could be a sign that there has been a decrease in ‘disruptive’ science — important studies or discoveries that change the paradigm of their field. This could be causing the Nobel committees to focus more on the past.\nThe number of ‘big-splash’ discoveries are diminishing, but when they do happen, they tend to get recognized quickly, says Fortunato. For example, biochemists Jennifer Doudna at the University of California, Berkeley and Emmanuelle Charpentier at the Max Planck Unit for the Science of Pathogens in Berlin, won the 2020 Nobel Prize in Chemistry just eight years after their development of the CRISPR–Cas9 system as a genome-editing tool. Some researchers speculate that the inventors of mRNA vaccines, which were rolled out to millions of people worldwide during the COVID-19 pandemic, could receive similar recognition.\nFortunato points out that, if the gap continues to grow, prominent scientists could miss out on the award owing to the Nobel Committee’s rule banning posthumous prizes (with the exception of the 2011 Nobel Prize in Physiology or Medicine, a share of which was awarded to physician Ralph Steinman, who had passed away three days before the announcement, unbeknownst to the committee). “It has to stop at some point,” he says, adding that a rethink of the posthumous-awarding ban would allow more people’s work to get the recognition that it deserves.\nThis article is reproduced with permission and was first published on September 29, 2023.\nLilly Tozer is an intern at Nature News.\nJosh Fischman\nDaniel Garisto\nLauren J. Young\nDina Fine Maron\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Can Lucky Planets Get a Second Chance at Life?", "date": "2023-10-05 12:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nWorlds around red giant stars—and others that don’t orbit any star at all—hint at an unexpected diversity of possibilities for planets and life in the universe\nFor decades, astronomers have endeavored to forecast with confidence the fate of planetary systems, including our own, throughout the cosmos. And these experts’ predictions have one central principle: to confidently guess what will eventually befall a planet, you have to know the size of its star.\nTiny stars don’t really burn out but rather fade away as they shine dimly for hundreds of billions or even trillions of years, likely keeping their planetary companions in tow. Massive stars go out with a bang, expiring as a supernova that leaves behind a neutron star or black hole. Such events tend to be cataclysmic for planetary systems. And stars of middling mass, like our own, expand into a red giant, engulfing or scorching their planets and then dissipating to become a slow-cooling stellar ember called a white dwarf.\nThis dismal fate is expected to befall our sun in some five billion years, setting what has been considered the last-gasp expiration date for life on Earth and perhaps throughout the solar system.\nBut insights from fresh studies of dying stars and doomed worlds elsewhere in the Milky Way challenge this consensus. Increasingly, it seems that the eventual fates of planetary systems, ours included, are not wholly written in the stars.\nSpecifically, two new findings—the discovery of a giant planet closely orbiting around a red giant star and the identification and estimation of the number of so-called rogue planets adrift in our galaxy—have highlighted that there are many more nuanced scenarios to consider. Planets can survive the ruin of their star, and the vast majority of planetary systems shed numerous worlds throughout their history.\nWhen our sun eventually enters its red giant phase, its radius will likely extend well beyond Earth’s present-day orbit. Even if our planet and the solar system’s other inner rocky worlds escape engulfment, the sun’s swelling will probably still spell their end because of the scorching temperatures they will experience. For the former scenario, astronomers have been seeing signs of this demise in the atmospheres of white dwarfs: researchers have found such stars littered with the remnants of dead planets they likely swallowed. \nIn fact, astronomers believed the fate of any planet orbiting a star within its red giant radius was likely sealed. That was until the discovery of the planet 8 Ursae Minoris b (8 UMi b), also known as Halla (after the South Korean mountain Hallasan and in honor of the South Korean astronomers who initially identified it in 2015). \n“We used to think that planets just couldn't survive around stars that become red giants—but this system provides a loophole,” explains Malena Rice, an assistant professor of astrophysics at Yale University, who co-authored new research on Halla postulating how it improbably survived.\nHalla was discovered by the wobbling its orbital tugging induced on its red giant home star, 8 Ursae Minoris (8 UMi). Track the period of that wobble over time, and you can discern the length of a planet’s year and its distance from its star. Such scrutiny showed that Halla orbits a mere 75 million kilometers from 8 UMi—that is, just half the distance between Earth and the sun. But standard modeling of 8 UMi’s red giant phase suggested that the star’s puffy, hot stellar atmosphere should have expanded about 30 million km farther out than that at its swollen peak. That is, Halla appeared to be a planet that shouldn’t exist. It should’ve been consumed and obliterated. Instead it had somehow escaped.\n“This planet was very lucky,” Rice says. “In its past, we think that it may have orbited two stars rather than one, and this helped it to survive what could have been a fiery fate.”\nBinary stars can exchange material back and forth, and they can even merge to become a single star, allowing a rich diversity of novel possibilities for any orbiting worlds. Such major redistributions of mass can alter planetary orbits while also profoundly influencing how a star shines, adding or siphoning away gas to change the nature and timing of its subsequent stellar evolution. According to the careful modeling work of Rice and her colleagues, the most likely explanation for Halla’s survival is that 8 UMi was once accompanied by a smaller close-in companion star, with which it eventually merged. Among other effects, the merger would’ve stifled 8 UMi’s red giant expansion, sparing Halla.\nAlthough this mechanism clarifies how some fortunate worlds might survive their star’s antics, it offers scant hope for our own solar system because our sun lacks a stellar companion to tamp down its eventual evolutionary swelling.\n“It will be tough for our rocky planets to make it through that process if the sun swells beyond their orbits,” Rice says. “But perhaps finding more systems like these might teach us about interesting natural ‘loopholes’ that occur in at least some types of planetary systems.” \nBountiful discoveries of newfound worlds—and with them, perhaps, the revelation of more “loopholes”—could come relatively soon via NASA’s Nancy Grace Roman Space Telescope, which is due to launch by May 2027. Much of Roman’s potential comes from its planned exoplanet survey, which will rely on a relatively underused technique known as microlensing. In this method, Roman will stare at many stars simultaneously, looking for instances where, by chance, a planet-bearing star will be perfectly aligned to cross in front of another “background” star much farther away. In such cases, some of the foreground star’s planets can act as gravitational lenses and magnify the background star’s light in a way that allows astronomers to reconstruct a lensing world’s mass and orbit. The technique is especially sensitive to planets orbiting far from their stars—a circumstellar region that remains scarcely probed by other planet-hunting methods.\nAnd in fact, it’s also capable of finding worlds that have left their stars behind entirely—something Roman could leverage to discover hundreds of rogue planets in interstellar space. Already preexisting microlensing surveys have found a handful of these free-floating worlds, and the statistics of this largely hidden population suggest most planetary systems have a surprisingly turbulent history.\nThe latest example comes from the MOA (Microlensing Observations in Astrophysics) survey, a project conducted at the University of Canterbury Mt. John Observatory on New Zealand’s South Island by an international team, including scientists at NASA and Japan’s Osaka University. Running for almost a decade, MOA has gathered enough data to weigh in on the galactic abundance of rogue planets down to and even below Earth mass.\n“This number turns out to be somewhat larger than we would have guessed,” says David Bennett, a senior research scientist at NASA’s Goddard Space Flight Center and co-author of two new papers reporting on these findings that were posted on the preprint server arXiv.org. These papers are set to be published in a future issue of the Astronomical Journal.\nSo far MOA has only detected six microlensing events that are consistent with magnification by a low-mass rogue planet, says MOA collaborator Takahiro Sumi, a professor at Osaka University, who co-authored both preprint studies. “Taking into account the low detection efficiency and our detections, we estimated that there are many such low-mass objects in the galaxy,” he adds. \n“We found that there are about 20 free-floating planets per star in the galaxy, and the number is dominated by low-mass planets with a mass similar to or smaller than that of Earth,” Bennett says. Those numbers, in turn, suggest an astounding two trillion rogue worlds in the Milky Way alone—six times more than the planets that are estimated to be bound to stars.\nIf this estimate is correct, it means most planetary systems are essentially dissolving across cosmic time, jettisoning many of their members via dynamical interactions between planets or their host stars that can slingshot unlucky worlds out into the interstellar abyss. It’s possible that when we look out into the solar system and other multiplanetary systems, the remaining planets we see are rare vestiges of once-bustling neighborhoods.\nBennett explains that most rogue worlds likely get ejected during the early stages of planetary formation, after which planetary systems settle into more stable configurations. The probability of ejections should generally decrease throughout a sunlike star’s life, he says. But when it swells into a red giant and begins shedding its outer layers of gas, the resulting shifts in planetary orbits can spark new rounds of world-ejecting instabilities.\nStars that are much heavier than the sun and end their life as a supernova, Bennett suggests, could also provide a rich source of rogue worlds and help to explain MOA’s outsize estimates.\nScott Gaudi, an astronomer and microlensing expert at the Ohio State University, thinks MOA’s surprising results are the best currently available but cautions that they remain very uncertain, so they “should be taken with a grain of salt.” Roman, he says, should beef up the statistical certitude, thanks to the unprecedented sensitivity of its prospective microlensing survey.\nIf MOA’s estimates are accurate, however, the sheer number of rogue worlds raises an interesting question: Could any of them provide conditions favorable to life? Ravi Kopparapu, a planetary habitability expert at NASA’s Goddard Space Flight Center, says life on a rogue planet would be problematic—but not impossible.\n“Without a star, life on a cold rogue world would likely need to get its energy from internal sources,” Kopparapu says. “That could be in the form of tidal/frictional heat like in some of Jupiter’s moons where there are subsurface oceans, from residual energy when the planet formed or from the radioactive decay of heavy elements in the planet’s core.” Such worlds might resemble the large moons of our outer solar system and harbor potentially clement conditions beneath an icy crust.\nFor surface habitability, Kopparapu says a thick hydrogen atmosphere could possibly insulate a rogue planet and keep its surface temperature warm enough for living things to endure. Such atmospheres are easily blown away by stellar radiation, but because rogue planets do not orbit stars, they might be able to cling to an insulating atmosphere of hydrogen far longer than any sunbathed world could.\nAmid so much uncertainty, life’s prospects in such alien environments can seem either dizzying or dim. Might biospheres someday be found eking out existence around post-red giant stars or on worlds without a star at all? The thought is staggering, to say the least—and the fact that we could soon have real data to better answer such grand questions is all the more so.\nConor Feehly is a New Zealand based writer who covers topics ranging from astronomy to consciousness studies and the philosophy of science. His work has appeared in New Scientist, Discover, Nautilus, Live Science and many other publications.\nNola Taylor Tillman\nCharles Q. Choi and SPACE.com\nMike Wall and SPACE.com\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "A Chance Discovery Uncovered the Remarkable Life of One of the First Female Oceanographers", "date": "2023-10-05 13:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nEight pages hidden in an archive led to the discovery of the story of Christine Essenberg\nChristine Essenberg had an unusual life and career trajectory. She was married, then divorced and earned her Ph.D. in zoology from the University of California, Berkeley, at age 41. She went on to become one of the early researchers at what is now the Scripps Institution of Oceanography. We know the story of Christine Essenberg only because of a serendipitous find.\nWhile searching in an archive jammed with the papers of male scientists, host Katie Hafner came across a slim folder, called “Folder 29,” in the back of a box at the University of California, San Diego, Library’s Special Collections & Archives. There were just eight pages inside to use as a jumping-off point to flesh out a life, which raises the question: How many other unknown women in science are out there, hidden away in boxes? \nThis is Christine Essenberg’s journey from researcher to teacher. It’s the first discovery of what we’re calling the Folder 29 Project, a research initiative to uncover the work of lost women of science, hidden in the archives of universities across the country.\nLISTEN TO THE PODCAST\n[New to this season of Lost Women of Science? Listen to Episode One here first, then Episode Two, then Episode Three.]\nLost Women of Science is produced for the ear. Where possible, we recommend listening to the audio for the most accurate representation of what was said.\nEPISODE TRANSCRIPT\nLynda Claassen: How much there is to be done, and how little one knows. Yours respectfully, Christine Essenberg.\nKatie Hafner: That's the closing line of a letter that zoologist Christine Essenberg sent to her boss a century ago. \nI'm Katie Hafner, and this is Lost Women of Science.\nA while back, I was poring over papers of a renowned scientist at UC San Diego when suddenly, an accidental discovery. At the very back of a box, there was this. Folder 29. Eight pages of paper. Two letters, written to a Dr. Ritter in 1921 from a Christine Essenberg, and a single letter the following year 1922. There, in fine cursive Essenberg worries about how to help her dying sister back in Switzerland. She considers becoming a school teacher, noting the pay is better. She politely inquires, asking when her research will finally get published. Most intriguing to me: in one letter, she appears to chuck it all and head off to Constantinople. \nWhat? Who? Who was this, and what’s she doing buried in this box? These poignant letters, fragments of a life, survived only because they were part of another scientist's archival collection. Which makes me think, just how many Folder 29s are there out there in archives just like this?\nFolder 29, lost in the back of an archive, haunted me for months. And so I sent producer Claire Trageser back to the UC San Diego archive to dig a little deeper. \nClaire Trageser: Hi. Welcome. Are you Lynda?\nI'm Claire.\nNice to meet you. Nice to meet you. \nClaire Trageser: I made an appointment with Lynda Claassen, the longtime director of Special Collections and Archives. And she has set aside time to delve deeper into Folder 29.\nLynda Claassen: And I only have until 12:25. I'm sorry.\nClaire Trageser: She has set a standard cardboard archive box on the table, labeled box five. It contains the collected papers of Carl Eckart, a geophysicist who Katie was looking into a while back. And Katie's right about this mystery folder. \nLynda Claassen: Eckart. Eckart Ecker. Remind me what we're looking for. What's her last name? \nClaire Trageser: Essenberg.\nLynda Claassen: Oh, of course it's the last folder in this box.\nClaire Trageser: Linda pulls the folder out and the first thing she notices is the swirling cursive on parchment paper. \nLynda Claassen: How wonderful. These wonderfully polite, nice letters that people used to write on paper in, in nice, neat handwriting \nClaire Trageser: It's a letter dated June 18, 1917 to Christine Essenberg. She has just earned her PhD in Zoology, and is working at what is now Scripps Institution of Oceanography on a bluff overlooking the Pacific Ocean in La Jolla, California. She has a passion for research, and is also assisting at the institute’s small library. Lynda Claassen leans in for a closer look.\nLynda Claassen: Let's see. Thank you for your note. And yeah, \nClair Trageser: Can you read it a little bit or just shall I read it? \nLynda Claasen: Yeah, sure. \nClaire Trageser: That'd be great. \nThe letter is from The Academy of Natural Sciences and gives a sense of the kinds of mundane tasks that she did at the library. It seems that she had flagged a missing periodical. And here is the response written to her, all dry and formal.\nLynda Claassen: My Dear Mrs. Essenberg, I thank you for your note regarding the institution’s subscriptions. \nClaire Trageser: And the note goes on to say it was a misunderstanding on the part of the mailing clerk and the error has been corrected. So she was dealing with minutiae, settling up back issues of a journal. It's a far cry from the field research she craved. At least, that's our guess. We only have these eight pages of letters to go on. Just eight pages to try to understand the story of a life.\nAnd that's the point of this project. There are probably so many women like Essenberg, just waiting to be discovered. Each with a unique story, women battling to do their own research in a man's world. \nWe only stumbled on Essenberg because Katie happened to find her letters tucked away in the back of a box.\nSo now our quest is to try to find out as much as we can about Essenberg, with these eight pages as our jumping off point.\nThis much we know. Christine Essenberg came to San Diego after earning her Master's and then in 1917 completing her PhD from U-C Berkeley. Her doctoral thesis was a mouthful, titled “The Factors Controlling the Distribution of the Polynoidae on the Pacific Coast” We’ve since come to learn that Polynoidae are scaly worms that live in the ocean.\nHow did she arrive at this very specific topic? \nWell, for one, many of the early scientists like Christine Essenberg, studying at UC Berkeley, were Zoologists.\nProfessor Joseph LeConte established the department in 1887.\nThen zoology was taken over by William Ritter, who eventually went south to San Diego and established the Marine Biological Association, which became Scripps Institution of Oceanography.\nAnd, more importantly, it appears that both LeConte and Ritter took a special interest in mentoring women, and helping them progress in their scientific careers.\nRitter was married to a physician, who may have influenced his views on women, or perhaps he went into the marriage fully formed as a man ahead of his time. \nWhat we do know is that the newlyweds were an adventurous pair. On their honeymoon, they went to a southern point in San Diego to collect goby fish specimens. We know that their boat capsized, and they had to be rescued.\nWilliam Ritter was Christine Essenberg's boss, and the next letter is written by Essenberg to Ritter in May of 1921, four years after she received her PhD. \nArchivist Lynda Claassen reads from it.\nLynda Claassen: Have you thought about, or have you found out anything about the publication of my appendices or copelata work?\nClaire Trageser: So her research has moved from the scaly worm to the species of plankton . Clearly, the ocean is influencing her. As the letter continues, she's looking ahead, thinking about the next steps in her career \nLynda Claassen: I would like to do some experimental work on the side, so as not to be obliged to sit at the microscope all the time.\nClaire Trageser: Remember, this is 1921. Women had just won the right to vote a year earlier. Very few had careers at all. And so Essenberg was battling not just the idea that she should be working, but that she should be doing the type of work she liked. \nIn this sobering letter, she's surprisingly candid with Ritter. It's clear that she is depending on him both for financial and emotional support. \nLynda Claassen: My sister is sick in Switzerland now. In case she should die, I shall go after her child and raise her. \nKatie Hafner: Amazing. right? Yes. \nClaire Trageser: Katie has been listening in on her cell, following along as we go through the letters. \nWhat we're gleaning from them is that this is a woman determined to make her way in the world as a scientist, but with few prospects despite her PhD. \nNot to mention a very ill sister, with thousands of miles separating them. \nAnd a boss who likely had more pressing concerns than Essenberg's troubles. In her letter, she notes her research would take \"years and years of patient study.\" That would be impossible to set aside once it's started, making it difficult, she writes, to fulfill obligations, both to herself and to her family. Essenberg then makes a not-so-subtle case for better pay. \nLynda Claassen: I may be obliged to go to teaching where I can earn more in nine month’s work. The beginning salary of grammar school teachers is $1,500. It is only fair that I should expect at least similar salary especially when I am under obligations to help my people. It would be selfish of me to follow my dreams and leave them to suffer and die. \nClaire Trageser: It seems Essenberg was treading a thin line with her boss, asserting herself, but not being too assertive. \nLynda Claassen: I am sorry to disturb you with my tales of woe, but you will understand better my attitude and my lack of definitive decision. I hope not to disturb you again in the future. Yours respectfully, Christine Essenberg. \nClaire Trageser: By the end of the year, Essenberg is taking a new tack. In December of 1921 she proposes a one-year leave of absence that will take her to research labs across the globe, and -- likely not incidentally -- within striking distance of her ailing sister in Switzerland. Three months later, in March of 1922, her travel plans are approved. The letter from the President of the University of California is not addressed to her, Dr. Essenberg, but to her boss, Dr. Ritter. It grants \"Mrs\" Christine Essenberg, a one year leave of absence starting that summer, July of 1922 and ending June of 1923.  \nLynda Claassen: Without salary, of course. \nKatie Hafner: What, what did you say, \nLynda Claassen: She's being granted leave, but without salary. \nKatie Hafner: Wow. So how did she support herself during this year, I wonder. \nClaire Trageser: What we do know is that, about two months into her unpaid leave, Essenberg wrote from the most unexpected of places.\nLynda Claassen: A letter in September of 1922 from Christine to Dr. Ritter. \nKatie Hafner: And where's she writing from? \nLynda Claassen: The Constantinople Women's College. In Constantinople, Turkey.  \nKatie Hafner: Wow. How did she get there? How did that happen?\nClaire Trageser: Indeed she was teaching at The Constantinople Women's College. It makes sense. If she stuck with her plan, Dr. Essenberg spent the first two months of her leave traveling to various marine labs. Perhaps she followed through and visited her ailing sister in Switzerland. But remember: It was an unpaid leave. By that fall of 1922 she could very well have exhausted her savings. So teaching, which she earlier noted was more lucrative than her Scripps job, made sense. A teaching position at the Constantinople Women's College would keep her afloat. And it turned her life in an entirely new direction, one she chose for herself. She picked a heady time to be in Constantinople. On the heels of World War One, there was a lot of instability and she walked right into The Turkish War of Independence. But, given what she writes next, she seems undaunted.\nLynda Claassen: I am not the least bit nervous or afraid. Neither does anybody else here at the college pay much attention to the political affairs. . .until the British officers are leaving Constantinople. \nClaire Trageser: Despite the chaos all around her, Essenberg presses on for recognition in her field. \nLynda Claassen: Then she has a paragraph: I hope my paper has gone to print. I sent a brief paper to Mrs. Genter, asking her to hand it over to you. If you find it worthwhile publishing, you will kindly send it to the press. \nClaire Trageser: With a war swirling around her, she updates Ritter in September of 1922, writing about how, despite the chaos, her students are still showing up for her class, and she frets about their future. \nLynda Claassen: I feel sorry for them. After they finish their college, they are discontented with their home life. According to their customs and traditions, there was very little of wholesome pleasures left for the Turkish woman. She's not supposed to do any work either at home nor in public, nor is there any intellectual or social life for her.\nKatie Hafner: Oh, wow. \nLynda Claassen: Right. Some of the women -- and I think she means all of the women in the college, not just the Turkish women -- some of the women are very capable and they are all charming. The education here is making a great influence on the women and will gradually change their position. The change is already noticeable in Constantinople. The girls here suffer a great deal on account of the war rumors and feel as if they had to apologize for some of the actions of their nation. \nClaire Trageser: How would we even know of Essenberg's struggles and triumphs if her letters had not been included in that archival box of papers? Surely there are countless other women like her. To find out about these kinds of lost women, we called MIT where there is another relatively new initiative to recover the lost women. Archivist Thera Webb is working on it. \nThera Webb: I believe it started around 2016 when one of the archivists at that time had been advocating for a focus on collecting the papers of women faculty. \nClaire Trageser: She says one of the big challenges in tracking down women is that they are more likely to change their names when they get married, so she relies heavily on their maiden names.\nThera Webb: There will be like, a folder titled Mr. and Mrs. John C. Smith. And then you're like, oh, okay, well who is Mrs. John C. Smith? And so there's a lot of research being done by archivists and interns, that's sort of tied to genealogy in that we're like tracing back to get to the birth name of these women who are in our collections. There was a folder for Mr. and Mrs. Williams C. Russo. And what I learned was that Mrs. Williams C. Russo was actually Margaret Hutchinson Russo PhD, who was an engineer who designed the first commercial penicillin production plant and was the first woman to become a member of the American Institute of Chemical Engineers. But I never would've known that from the name on the folder.\nClaire Trageser: But more broadly, it's a challenge, Webb says, because artifacts from the lives of women in science are typically not as valued.\nThera Webb: Maybe somebody held onto all of the papers of some woman, but they were never accepted by a repository as a collection that people were interested in. So sometimes it is really the case where you can only sort of piece together bits and pieces in collections that belong to men. \nClaire Trageser: Webb says the movement to find and archive the papers of women scientists is just gaining steam. There's more attention to women's contributions and still a lot out there to be found. \nThera Webb: Whether they're at a repository right now at a university or a historical society or in someone's shoebox under their bed, the letters of their great-grandmother who happened to be a scientist, but at this moment, if you don't know what you're looking for, you won't be able to find it. And we don't know what we're looking for a hundred percent of the time.\nClaire Trageser: MIT is one of several schools plumbing their archives. At UC Berkeley, the search is also on to document the working lives of women who have worked there. \nThere, Sheila Humphreys, an emeritus engineering professor at UC Berkeley, has thrown herself into the research. She's very no-nonsense. She wanted to know right away how I'd become interested in the idea of lost women. \nIt's kind of like the jumping off point is a couple letters from a woman scientist in San Diego at the Scripps Institution of Oceanography.\nSheila Humphreys: But what was her name? \nClaire Trageser: Uh, Christine Essenberg. \nSheila Humphreys: Oh my God, I've, I've researched her for months. I have a whole essay about her. \nClaire Trageser: Oh wow. Okay, great.\nWhat were the odds? What luck! Serendipity had taken me directly to a Christine Essenberg expert! \nAnd she has plenty to say. \nJust ahead…\nDominique Janee: Hi. I’m Dominique Janee, an Associate Producer at Lost Women of Science. We don’t know how many Folder 29’s are out there buried in archives around the world. But we’re guessing there are a lot of them. If you’re interested in helping us with our Folder 29 Project, an ambitious dig through archives, looking for lost scientists like Christine Essenberg, go to lostwomenofscience.org to find out more. \nSheila Humphreys: You, you know, she has the most fascinating, strange story.\nClaire Trageser: That's Professor Emeritus Sheila Humphreys of UC Berkeley, talking about Christine Essenberg. Over a century ago, Essenberg was an early research scientist at what is now the Scripps Institution of Oceanography. Humphreys told me that she had researched Essenberg, along with many other early female scientists. She wrote a 168 page essay about these women, so I asked her to send it over. Then, with essay in hand, Katie and I started scrolling through the details of Essenberg's life. \nKatie Hafner: This is quite a find. \nClaire Trageser: This says she was known for her expertise in plankton, which we kind of…\nKatie Hafner:  … figured out. \nClaire Trageser:. Yes. \nKatie Hafner: Right.\nClaire Trageser: She's, born of Swedish parents, which we had sort of had some inkling of, right? \nKatie Hafner: Uh-huh. \nClaire Trageser: Essenberg had a whole life before coming to the United States. She had been teaching for several years in St. Petersburg in Russia, but once in the U.S. went to Indiana, to Valparaiso University where she studied zoology and botany.\nClaire Trageser: And she got married before she graduated, and then later divorced. Interesting. \nKatie Hafner: Was the husband Essenberg, or was her maiden name Essenberg? \nClaire Trageser: Her maiden name was Adamson, and her husband's name was Essenberg. She got divorced, but I don't know if she, maybe she kept Essenberg or, um mm-hmm. \nor just the, what? The letters from the time that we had, she was still married. It doesn't say when she got divorced.\nClaire Trageser with Katie Hafner: She's, oh my God. There's her picture. Where? She looks so different from what I thought she would look like. Um, and this photo of her is just with the broach and she looks , she looks young, This is amazing.\nClaire Trasgeser: The more we pore over in the essay, the more questions we have. So we go right to the source herself: Sheila Humphreys, who had compiled all of this information. But first we had to ask her: What was it about Essenberg that caught your eye? Humphreys had a quick and simple answer.\nSheila Humphreys: The reason that Christine Essenberg came to my attention was that She was 1, 2, 3, 4, 5. She was the sixth woman to get a PhD in Zoology, so she was very, very early, and that's why she's one of those women that I profiled.\nClaire Trageser: Humphreys explained that, in an effort to rediscover lost women scientists, each department at UC Berkeley was asked to compile a history of women in their disciplines.\nSheila Humphreys: In the case of oceanography in which Christine Essenberg belongs, she was originally a student in the Department of Zoology, which was one of the first departments established at Berkeley. It was taught from the very beginning. \nClaire Trageser: So...you'd think there'd be plenty of documentation, but you'd be wrong. The search for Esssenberg was complicated. Departments had consolidated over the years. Humphreys says 23 departments were merged into three, so Zoology, Essenberg's specialty, essentially disappeared. There was little institutional memory of her. \nSheila Humphreys: And that's how I personally came to know Christine because I decided to fill the gap that I would take this on. \nClaire Trageser: Sheila Humpreys says that, in researching Essenberg, she learned a lot about the early years of Scripps itself. \nBack in Essenberg's day a century ago, the lab was in its infancy and working conditions brought men and women together under very rudimentary conditions. \nSheila Humphreys: They had a temporary lab, they had set up tents and they had one boat and they camped over the summer. And indeed these early women who did their research there, once they went off to teach at various places like Wellesley College, they would come back in the summer to continue their research under Dr. Ritter.\nClaire Trageser: And come back they did. The less-than-optimal conditions required the kind of close cooperation that encourages collegiality.\nSheila Humphreys: And I attribute, and I think others do too, some of their success to the fact that it was a very congenial colony of people. And Ritter's wife Mary Bennett Ritter was the physician to women's students, but she went down with her husband to help establish this marine biology lab, and she was a trusted maternal presence and advisor and friend to some of these women.\nClaire Trageser: Humphreys says the mutual respect that was nurtured helped to break down barriers.\nSheila Humphreys: These women, even though they were probably the single woman in their cohort, they do not talk about feeling discriminated against or that there was any kind of resentment of them at all. It was a very, seems like a pretty happy place where they had Saturday night suppers of clam chowder on the beach and uh, there was even a small school for people who had families, but anyway, that's how I got to Christine Essenberg.\nClaire Trageser: It all sounded pretty idyllic, but Humphreys says it wasn't always that way. From Essenberg's letters to Ritter, while men in her cohort are moving ahead, it seems she has stalled out. It was a constant push to get her research published. \nSo it didn't seem so far-fetched that she would make good on her veiled threat to take a teaching job for better pay, especially when she saw the war-time need for science teachers at that all women's college in Constantinople. Opening up the world to her students only to see the walls close in on them later when they left, was something she struggled with.\nSheila Humphreys: She talks about what a prison these girls would be in, especially the Turkish girls. After they finished their education, they were not supposed to do any work outside the home. In fact, they were barely meant to leave the home. \nClaire Trageser: And she didn't worry only about her students.\nSheila Humphreys:  There's reference to her creating a, a program for their mothers to come and do, I think physical education using the school building. Overall she wanted to, to educate them and to liberate them.\nClaire Trageser: So it's clear that teaching at the school in Constantinople was really eye-opening for Christine Essenberg. Still, we do know that she ultimately left the Women's College there. But Katie, guess where she went next. \nKatie Hafner: Back home to the United States?\nClaire Trageser: No. Or at least not for long. She went to Damascus, Syria. To start a school of her own. The American School for Girls opened in the fall of 1925.\nKatie Hafner: Oh! Damascus! Did she succeed? Did she make a go of it?\nClaire Trageser: Yes! Yes, the school was unique. It admitted not just Muslim students, but there were some Jewish students and Christians too, according to Sheila Humphreys.\nSheila Humphreys:  This school was very well known at the time, and she had very well known scientists on the board, you know, people from Harvard and all over the place. \nClaire Trageser: People like the Harvard Astronomer Harlow Shapley, who served on her board. \nKatie Hafner: Harlow Shapley? Oh my gosh! He was featured prominently in an earlier Lost Women of Science episode, the one about Astronomer Cecilia Payne-Gaposchkin. So Payne-Gaposchkin worked for him at Harvard.\nClaire Trageser: Yeah, that’s right! And we know that, two decades after its founding, during World War Two, the doors of The American School for Girls stayed open. Even during the bombardment of Damascus in 1945, Christine Essenberg did not leave her post. \nSheila Humphreys: And she stayed there and it was bombed. And her school was sort of a center for expatriates who were stuck there.\nClaire Trageser: And not just a center. Humphreys says Christine Essenberg allowed part of her school to be used by the Allied soldiers. \nKatie Hafner: Did her school survive the war?\nClaire Trageser: We know that the year after the war ended, 1946, Shapley from Harvard was chairman of the board of her school. And we know that in subsequent years, Christine Essenberg made multiple trips back to the United States to drum up financial support for her school. \nShe appealed for donors coast-to-coast. There's a local newspaper in New Jersey that talks about one of her fundraising visits, and The San Francisco Examiner noted her stop there to gather support in 1947. By then she was 71 years old. And when questioned about creeping Orientalism, as it was referred to at the time – efforts to teach western values, Christian values – she's quoted as telling a reporter, \"It was never my purpose to endeavor to 'westernize' these girls. My primary objective,\" she said, \"is to educate.\"\nBut Katie. That's pretty much where the trail grows cold. \nWe do know she ultimately did return to California at the end of her life. She spent her final years in San Francisco and died in 1965 when she would have been about 89 years old.\nKatie Hafner: Well, but, do we know whether she ever did get published? I mean, that seemed to have been a recurring sore spot for her in all the letters she wrote back in the 1920s.\nClaire Trageser: Yes, she did. We found at least nine papers from early on. But by the time her last papers were getting published, she was already teaching abroad. Teaching science. To girls and women.\nKatie Hafner: So, this much we do know. Christine Essenberg came to the United States. She ended up in California by way of Indiana as an older student, apparently with a marriage and a divorce thrown in. She got her PhD at 41, becoming one of the early researchers at what is now called The Scripps Institution of Oceanography.\nBut in the end, snippets from her letters tell the story of a female scientist who carved out a niche for herself in the most traditional of all women's professions: teaching school. \nClaire Trageser: So maybe Christine Essenberg became a teacher because she was kept at the microscope and not allowed to do the field research she craved, and so she turned to one of the few occupations open to women back in the day. Or, as Essenberg pointed out to her boss when she was angling for a raise, teachers were simply being paid more than she was being paid, even with her PhD. \nKatie Hafner: Or maybe, finding herself in Constantinople with girls and women who didn’t get the education that she herself got, she then got more satisfaction setting up a school for them. \nClaire Trageser: And who knows. I mean maybe at some point, when she was teaching, she inspired a girl, or two girls, or a dozen, to shine in science.\nKatie Hafner: Yeah. I mean, we'll never really know. All we know is that she was a creature of her time and made her adjustments and appears to have built a satisfying and adventurous life, because really, all we had to go on as a jumping off point were these letters tucked away in Folder 29. \nWell, thank you, Claire.\nClaire Trageser: Katie, you are so welcome.\nKatie Hafner: Claire Trageser produced this episode of Lost Women of Science. Barbara Howard was Managing Senior Producer with help from Associate Producer Dominique Janee. And we'd like to thank Thera Webb at MIT, Lynda Claassen at UC San Diego, and Sheila Humphreys and Jill Finlayson at UC Berkeley. Our audio engineer is Hansdale Hsu and Lizzie Younan composes our music. \nThanks as always to Amy Scharf and Jeff DelViscio. We are funded in part by the Alfred P. Sloan Foundation and Schmidt Futures. Lost Women of Science is distributed by PRX and published in partnership with Scientific American. If you'd like to help us bring lost women to light through our \"Folder 29 Project\", and we hope you will, go to our website, Lost Women of Science dot org. I'm Katie Hafner, thanks for listening.\n---\nFurther reading/listening\nEpisode Guests\nKatie Hafner is host and co-executive producer of Lost Women of Science. She was a longtime reporter for the New York Times,, where she remains a frequent contributor. Hafner is uniquely positioned to tell these stories. Not only does she bring a skilled hand to complex narratives, but she has been writing about women in STEM for more than 30 years. She is also host and executive producer of Our Mothers Ourselves, an interview podcast, and the author of six nonfiction books. Her first novel, The Boys, was published by Spiegel & Grau in July. Follow Hafner on Twitter @katiehafner\nClaire Trageser is a journalist and audio producer. She has produced stories for NPR, The Runner's World Podcast, The New York Times Magazine, National Geographic, Marie Claire, Runner's World, The Denver Post and The San Francisco Chronicle. She lives in San Diego with her family.\nThe Lost Women of Science Initiative is a 501(c)(3) nonprofit with two overarching and interrelated missions: to tell the story of female scientists who made groundbreaking achievements in their fields--yet remain largely unknown to the general public--and to inspire girls and young women to embark on careers in STEM (science, technology, engineering and math). Follow The Lost Women of Science Initiative on Twitter\nTom Metcalfe\nMeghan Bartels\nAndrew Chapman\nThomas Frank and E&E News\nLauren Leffer\nC. Brandon Ogbunu | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Should You Wake Someone from the Throes of a Nightmare?", "date": "2023-10-05 13:40:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNightmares are unpleasant, but waking someone in the midst of one isn’t the best way to handle them—here’s why\nYour bedmate is whimpering in their sleep and perhaps thrashing about. It looks like a nightmare. Should you wake them?\nNope, experts say. As terrible as whatever visions that are running through their head might be, waking someone from a nightmare is more likely to ensure that they’ll remember the bad dream. And if someone appears physically distressed in their sleep like this, it’s more likely that they’re having a night terror than a nightmare; night terrors are different neurological experiences.\nNightmares are a normal part of dreaming, says Deirdre Barrett, a dream researcher at Harvard Medical School and author of The Committee of Sleep (Oneiroi Press, 2001). They almost always happen in rapid eye movement (REM) sleep, the stage of sleep marked by brain activity that looks very similar to that of an awake brain.\n“Except for being scary, they look like every other dream,” Barrett says.\nDuring REM sleep, the brain areas responsible for long-term memory storage show altered activation, so people don’t tend to remember their nightmares unless those sleep tales are scary enough to wake them up. Once a dreamer awakens, their long-term memory regions come back on line. Most of the time, someone having a nightmare will be indistinguishable from a peaceful dreamer. During a nightmare, heart rate increases by seven beats per minute on average, says Michael Schredl, a dream and sleep researcher at the Central Institute of Mental Health in Germany. Otherwise the sleeper typically lies still in bed: during REM sleep, muscles are paralyzed, which keeps people from acting out their dreams.\nIf someone is moving around, talking in their sleep or sleepwalking while appearing distressed, it’s more likely a night terror, which occurs during non-REM sleep, Schredl says.\nNight terrors are particularly common among kids, says Leslie Ellis, a clinical counselor in British Columbia who treats patients with nightmares. “You shouldn’t wake them up because they’ll be disoriented,” Ellis says. “They won’t have any recollection of the episode if you don’t wake them up.”\nNightmares can be echoes of the stressful experiences people are having in their waking hours. During the early days of the COVID pandemic, people reported more nightmares, according to several studies on the topic. New themes also emerged, according to research published in the journal Somnologie in 2022, including those about sickness, confinement and bugs—the latter subject is perhaps a symbol of infection or contamination.\nPeople also sometimes seemed to be working through the new rules of the pandemic, says Anu-Katriina Pesonen, a psychological researcher at the University of Helsinki, who documented dream changes that occurred in early 2020. “The dreams were often reexperiences of new behavioral rules,” Pesonen says. “For example, hand shaking in a dream was vividly experienced as a major mistake. This could assist in learning new norms.”\nThe occasional scary dream is nothing to worry about, but frequent nightmares can sometimes be part of a larger psychological disorder. The good news, Barrett and Ellis say, is that these nightmares are remarkably treatable. The people who have the most trouble with nightmares, Barrett says, have often experienced trauma. They may relive their traumatic experiences, sometimes with the addition of even darker fears. These nightmares are often so alarming that they interrupt the person’s healing.\n“I’ve never heard anyone say they don’t mind having PTSD [post-traumatic stress disorder] nightmares much. They say things like, ‘It’s like having the trauma happen again, night after night,’” Barrett says.\nSome of these trauma-related nightmares can occur outside of REM sleep, Barrett says, suggesting that they’re more like PTSD flashbacks than like regular dreams. Waking someone from these nightmares isn’t a long-term solution, but people having them can be coached to take control of the dreams. There are different ways to do this. Some psychologists and counselors will simply talk a person through possible alternative endings for a nightmare. This can be anything from a magical rescue to the person saving themselves. In her practice, Ellis has patients relax into a sort of daydream where they rewrite the circumstances of the bad dream while making sure they feel safe and comfortable.\nIn a 2020 meta-analysis of studies, researchers found that this treatment, called “imagery rehearsal therapy,” was likely as effective as medications for ending post-traumatic nightmares. Anecdotally, the method can also work for repeated nightmares, or bad dreams that recur, sometimes for years.\n“I’ve worked with people who had the same dream for decades, but now the dream is different, or sometimes it doesn’t come back,” Ellis says.\nIt’s possible to try imagery rehearsal therapy on yourself, Ellis says. But, she adds, if your nightmares are particularly persistent or distressing, or if they’re the result of trauma, it’s best to seek professional help.\nStephanie Pappas is a freelance science journalist. She is based in Denver, Colo.\nStephanie Pappas\nTore Nielsen\nDiana Kwon\nStephanie Pappas\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Vaccine Scientist Warns Antiscience Conspiracies Have Become a Deadly, Organized Movement", "date": "2023-10-05 15:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nVaccinologist Peter Hotez explains how the movement to oppose science and scientists has gained power\nPeter Hotez is no stranger to scientific backlash. The esteemed pediatrician and vaccinologist has been working to develop vaccines for neglected tropical diseases for decades and has encountered fierce opposition to his work. But in recent years the backlash has gained momentum and spread beyond vaccines to science and scientists in general.\nHotez, who is dean of the National School of Tropical Medicine at Baylor College of Medicine, chronicles this movement in his new book The Deadly Rise of Anti-Science. The book traces Hotez’s experiences battling the false belief that vaccines cause autism (a condition that his daughter has), the highly partisan backlash to the COVID vaccines (a low-cost version of which Hotez and his colleagues helped develop) and the authoritarian roots of the antiscience movement.\nScientific American spoke with Hotez about the book, the experiences he’s had as a target of antiscience attacks and the things that should be done to combat such threats.\n[An edited transcript of the interview follows.]\nWhy did you decide to write this book?\nI think one of the things the book does is: it helps connect a few dots. People call [the antiscience movement] “misinformation” or “the infodemic” as though it’s just random junk out there on the Internet or social media, and it’s not—it’s organized, it’s well-financed, and it’s politically motivated. It’s really its own ecosystem that’s doing a lot of damage to the country and to American science and scientists. And now it’s reached a new level. It’s become a lethal force. It’s the fact that [at least] 200,000 Americans needlessly perished [between June 2021 and March 2022] because they refused the COVID vaccine during the [Delta and Omicron COVID waves], and they were victims of this organized campaign.\nYour book discusses how the modern antiscience movement grew out of false claims in the late 1990s that vaccines cause autism, right?\nIn some ways, it’s a sequel to one of my previous books, Vaccines Did Not Cause Rachel’s Autism. So, you know, I have a daughter who has autism. As you point out, the original assertion was that vaccines cause autism. And in the previous book, I detailed the evidence showing that there’s no link. So I’ve been in this for a while, confronting antivaccine groups. But what I saw starting about a decade ago was a shift—maybe because we were taking some of the wind out of their sails around autism, [the people in these groups] needed a new thing. And the new thing was to become part of the American political landscape and link themselves up initially to the Republican Tea Party, even before the pandemic, around this concept of health freedom, medical freedom. And that’s what came off the rails during COVID.\nWhy do you feel compelled to speak out now?\nI’ve been the number one or two target of that movement for years or decades. And now I have an insight into how this is unfolding. It troubles me that it’s not only targeting science but scientists. I think it’s undermining the country because we’re a nation built on science and technology and on the greatness of our research universities and institutions, and they are under threat. I felt compelled to be kind of the tip of the spear, to sound that warning, because we’re seeing mostly silence from our university presidents and from our scientific societies. Even the National Academies [of Sciences, Engineering, and Medicine] weren’t really out there. I think there was a kind of hope that it would just go away on its own. But we’ve seen from past experience that this kind of stuff doesn’t go away on its own. It’s got to be confronted.\nAre you concerned that confronting anti-vaxxers and antiscience people will only give them more attention?\nThat was the response from the [Centers for Disease Control and Prevention] back in 2017 when I wrote about how the anti-vaxxers are winning. We’re not supposed to talk about it, or we’ll give it oxygen. But it’s got all the oxygen it needs. You might say, “Well, why write it now?” For two reasons: one, it’s become a killer movement. Think about the 200,000 Americans who died because of this—that’s a major societal lethal force right up there with anything else we might be concerned about as a society. And the second is the attacks on the individual scientists and the portrayal of scientists as enemies of the state. This is unacceptable. I mean, this is undermining our national security.\nIt's absurd that the people who are trying to protect us all from this deadly disease are the ones who are being attacked for it.\nYeah. I mean, what’s my crime? I helped develop a low-cost COVID vaccine technology that reached 100 million people and provided a proof of concept that was an alternative to the big pharma companies. It’s really unfortunate. And I think it’s going to get worse as we head into the 2024 election.\nDo you think Donald Trump’s presidency influenced the rise of antiscience attitudes?\nWhat’s happening now, I say in the book at the beginning, is actually not about Trump. Most of this got worse after Trump in 2021 to 2022. Now there’s this effort to rewrite history—maybe in part because I’ve called [antiscience politicians and influencers] out by saying 200,000 Americans died because of their disinformation campaign. They’re doubling down and trying to say, “No, it was the COVID vaccine that killed Americans, and the scientists made the COVID virus.” This revisionist history is playing out now with the [U.S. House of Representatives] hearings that we’re seeing in the [Select Subcommittee on the Coronavirus Pandemic], which are trying to parade prominent scientists in front of C-SPAN cameras to try to humiliate them. It’s very Stalin-like, very [similar to the] U.S.S.R. in the 1930s.\nThat’s an interesting analogy because the far right and the anti-vax movement have compared COVID vaccination efforts to the Nazis’ treatment of Jewish people during the Holocaust.\nIt’s totally offensive, right? I mean, trying to draw parallels between vaccinations and the Holocaust, and the heavy use of Nazi imagery—that, too, is a form of antisemitism. So there are a lot of antisemitic undercurrents. And [those making the comparisons] know I’m Jewish, so that’s also a component.\nDo you think that anti-vax and antisemitic groups overlap and strengthen each other?\nIn the Venn diagram, there’s not a complete overlap between the circles, but there’s definitely overlap. There’s a history to that too. People called what Einstein and Freud did “Jewish science,” so there’s that modern history of linking antiscience to antisemitism.\nThe big issue then is: Where do we go from here, now that we’ve got this sort of entire well-oiled, well-financed antiscience ecosystem? How do we begin addressing it and chipping away at it? That was one of the hardest things for me to get my arms around. What do you do? Because it’s a political movement. The scientific societies and national academies don’t want to talk about it because it takes them into an unpleasant place. I don’t like talking about it either. But you have to report it and describe it so you know what you’re dealing with because maybe it'll autocorrect eventually. But right now, it’s not going away.\nIn the book you also talk about how the U.S. is exporting anti-vax and antiscience sentiment around the world.\nThis is coming out of the authoritarian playbook, with devastating consequences. We’re seeing it not only in the U.S. but also in Brazil with [former president Jair Bolsonaro’s] regime or with [Prime Minister] Viktor Orbán in Hungary. This is part of how authoritarian regimes operate: you denigrate science and scientists.\nI think we’re seeing more of the globalization of what’s happening in the U.S. A lot of it’s not in the biomedical literature. It’s in local newspapers and that sort of thing. But there are enough pieces there that make me believe that this is certainly contaminating Canada and also Germany and Austria and France to some extent—and low- and middle-income countries as well. I think this is going to start affecting all immunizations, including childhood immunizations globally. I’m worried about measles and polio coming back.\nWhat’s happening now with the antiscience movement here in the U.S.?\nI worry about what’s going to happen as we head into the 2024 election. I worry about these House hearings—I think they’re going to ratchet up, and they’re going to continue to target scientists. I worry about what’s going on with some members of the Senate and the rhetoric coming out of the [presidential] campaign. I mean, you already have two prominent antivaccine activists running for president—Robert F. Kennedy, Jr., and Ron DeSantis. What’s so chilling is that these are state-sanctioned attacks on science and scientists.\nYou’ve personally experienced some very threatening attacks and even physical confrontations. How do you deal with that?\nThese are multimodality attacks: it’s the threatening e-mails; it’s the stuff on social media. And Twitter’s gotten so awful in the past year that it’s just almost untenable. And then, you know, [people are] stalking me when I speak at scientific conferences or outside my home recently, so it is getting very, very troubling.\nWhat can be done to combat antiscience attitudes and support science and scientists?\nI don’t think the community of scientists by itself can solve this. We’re going to need help, both from the White House and the United Nations because this is now a politically motivated assault. So we need the White House, for instance, to treat this like any politically motivated attack on the country, whether it’s a cyberattack or global terrorism or nuclear proliferation.\nThe first step is bringing in people from the Department of Homeland Security, the Department of Commerce, the Department of Justice and the Department of State because of the role of Russia in amplifying the discord. I think we need an interagency task force [in the U.S.] and the same at the U.N. I don’t think the World Health Organization can solve this problem. I think this needs to go to the attention of the U.N. General Assembly and maybe the Security Council and NATO, perhaps, because it is a security threat, and it undermines democracies and the security of countries.\nTanya Lewis is a senior editor covering health and medicine at Scientific American. She writes and edits stories for the website and print magazine on topics ranging from COVID-19 to organ transplants. She also cohosts the show \"Your Health, Quickly\" on Scientific American's podcast Science Quickly and writes Scientific American's weekly Health & Biology newsletter. She has held a number of positions over her seven years at Scientific American, including health editor, assistant news editor, and associate editor at Scientific American MIND. Previously, she has written for outlets including Insider, Wired, Science News and others. She has a degree in biomedical engineering from Brown University and one in science communication from the University of California, Santa Cruz. Follow Tanya Lewis on Twitter Credit: Nick Higgins\nPeter J. Hotez | Opinion\nDavid Robert Grimes | Opinion\nPeter J. Hotez and Maria Elena Bottazzi | Opinion\nKathleen Hall Jamieson\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Nobel Prize Debate Misses the Mark on the Real Culprits Ignoring Scientific Merit", "date": "2023-10-05 15:30:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nThe furor over a Nobel Prize winner’s derailed career lets scientists off the hook for their own responsibilities to fix a broken academic reward system\nNobel Prize announcements have become our own little nerd Super Bowl, an Academy Awards for the pocket-protector crowd. They are the subject of prediction markets and office pools, debated over teatime and happy hour. We ask, what will win: quantum dots, or protein folding? For one week during the year, we are all experts on what breakthroughs warrant our attention.\nAt best, these conversations are fun, even insightful—teachers often discard their syllabi for a day to discuss the technical advances behind the discoveries, and their wider implications. But less productive exchanges also persist, exemplified by the furor over the 2023 Nobel Prize in Medicine or Physiology, given to Katalin Karikó and Drew Weissman, for their discoveries that enabled the development of effective mRNA vaccines against COVID.\nReactions to the announcement erupted moments after the prize was announced, much of it focusing on the story behind Karikó’s dismissal from the University of Pennsylvania in 2013. This response highlights how criticisms of the Nobel Prize continue to miss the mark, and are often obscured by scapegoating, moral superiority, and public posturing. What we need instead are deeper, more uncomfortable conversations about innovation, inclusion, and merit.\nNobel announcement disagreements often focus on whether the recipients deserved it, or not. But the 2023 Medicine and Physiology prize has received near universal applause: the science that it rewards has already saved the lives of many millions, and (maybe most importantly) has transformed how we think about emerging infectious diseases and other diseases. But the real intrigue surrounds its backstory. Karikó was forced to retire from her position at the University of Pennsylvania in 2013. The much-discussed reasons are familiar villains: the inability to secure major grant funding from the large agencies, and other markers of success in the biomedicine machine.\nThe news has spawned a necessary community reflection. Some suggest that our instruments for evaluating science are hopelessly broken in academia. Relatedly, those in biotech emphasize that the work demonstrates how private industry can deliver important discovery at a speed that academia cannot. Others highlight the role of sexism, where women in science are rarely respected when it comes to intrepid ideas. In the face of this, some suggest specific interventions: that the University of Pennsylvania should apologize, or at least not take credit for the achievement, as “they” (the school or it’s officials) devalued her work. All these arguments are well-intentioned but are festooned with contradictions.\nFirst, there is the notion that the Nobel Prize equals vindication. Consider the contradiction. We are frustrated that Karikó was misjudged by a room full of people at a prestigious institution, the University of Pennsylvania. And yet, we celebrate her receiving a positive judgement from a room full of people at a prestigious institution, the Nobel Committee (notably, few know how either works). This cognitive dissonance tells us to like the subjective processes that give us the outcome that we want, and to dislike the equally subjective ones that don’t. Instead, we could be equally critical of both.  \nThis relates to the second problem: we ignore our collective complicity in a system that offers rewards based on dubious standards. For example, in identifying suitable graduate students or faculty, we have all almost surely missed out on worthy job candidates based on our own (even benign) preferences. One reason that we haven’t been held accountable for our poor decisions is that the people we denied haven’t (yet) won a Nobel Prize. The reality is even worse: our decisions probably prevented deserving scientists from ever having the chance.\nMy personal defense mechanism for overlooking? I conclude that they (the University of Pennsylvania in this case) were wrong for misjudging Karikó, but I’ve been fair and correct in all my own judgments. \nThis sort of hypocrisy is not only prevalent in science but is a near requirement, to make us feel better about the harm we might have caused. The more uncomfortable truth is that academic science has never been a trade that selects for or supports the best scientific minds in the world. Instead, it has been, and will be for the foreseeable future, an enterprise for smart people positioned within the right professional network, armed with vocabulary to make their ideas legible to influential scientists (not the public), who study things that are just interesting enough to not offend academic sensibilities. And many of us suspect that identities like gender and race (and others) can amplify the signals that trip those wires.\nIn my view, academic institutions are fairly transparent (though not enough) about the fact that the primary duty of their scientists is not to make the world better, but to develop a professional profile and raise funds. It is the job I signed up for, and I’ve reconciled this in the same way that I do with many institutions, say the U.S., with baggage: acknowledge the flaws, while leveraging the windows of privilege to do good. Hopefully, I can meaningfully change a thing or two about it in my lifetime. Thankfully, I’ve had dozens of remarkable mentors and friends who are doing just that, better than I ever could. \nBut it is the changing of a “thing or two” part where the do-gooder-rubber meets the selection-committee-road. I am certain about one thing: hurling invective at the University of Pennsylvania won’t fix academia’s flaws. Change only happens with personal reflection: how many students from nontraditional backgrounds have I ever advocated for? How often do I rely on credentials and proximity to power to make professional decisions? Do I rely on silly, hackable citation metrics to evaluate scientific impact? And how often does innovation truly factor into my evaluations of a scientist? \nThe questions make my heart hurt, mostly because I’m just another random scientist swimming against a tide that prefers that we all become fundraising automatons. In the meantime, I can draw inspiration from the lives of Nobel laureates. They contain thrilling tales of discovery, and lessons about creativity and resilience. The winners will be okay. Rather than hunting for villains in their stories, I’m better off using their inspiration and frustration to help find the next Frances Arnold, Carolyn Bertozzi, or Katalin Karikó, many struggling to find a way to participate in science.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.\nC. Brandon Ogbunu is an assistant professor in the Department of Ecology and Evolutionary Biology at Yale University, and an External Professor at the Santa Fe institute.\nTom Metcalfe\nMeghan Bartels\nAndrew Chapman\nThomas Frank and E&E News\nLauren Leffer\nC. Brandon Ogbunu | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "The Latest AI Chatbots Can Handle Text, Images and Sound. Here's How", "date": "2023-10-05 16:30:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNew “multimodal” AI programs can do much more than respond to text—they also analyze images and chat aloud\nSlightly more than 10 months ago OpenAI’s ChatGPT was first released to the public. Its arrival ushered in an era of nonstop headlines about artificial intelligence and accelerated the development of competing large language models (LLMs) from Google, Meta and other tech giants. Since that time, these chatbots have demonstrated an impressive capacity for generating text and code, albeit not always accurately. And now multimodal AIs that are capable of parsing not only text but also images, audio, and more are on the rise.\nOpenAI released a multimodal version of ChatGPT, powered by its LLM GPT-4, to paying subscribers for the first time last week, months after the company first announced these capabilities. Google began incorporating similar image and audio features to those offered by the new GPT-4 into some versions of its LLM-powered chatbot, Bard, back in May. Meta, too, announced big strides in multimodality this past spring. Though it is in its infancy, the burgeoning technology can perform a variety of tasks.\nScientific American tested out two different chatbots that rely on multimodal LLMs: a version of ChatGPT powered by the updated GPT-4 (dubbed GPT-4 with vision, or GPT-4V) and Bard, which is currently powered by Google’s PaLM 2 model. Both can both hold hands-free vocal conversations using only audio, and they can describe scenes within images and decipher lines of text in a picture.\nThese abilities have myriad applications. In our test, using only a photograph of a receipt and a two-line prompt, ChatGPT accurately split a complicated bar tab and calculated the amount owed for each of four different people—including tip and tax. Altogether, the task took less than 30 seconds. Bard did nearly as well, but it interpreted one “9” as a “0,” thus flubbing the final total. In another trial, when given a photograph of a stocked bookshelf, both chatbots offered detailed descriptions of the hypothetical owner’s supposed character and interests that were almost like AI-generated horoscopes. Both identified the Statue of Liberty from a single photograph, deduced that the image was snapped from an office in lower Manhattan and offered spot-on directions from the photographer’s original location to the landmark (though ChatGPT’s guidance was more detailed than Bard’s). And ChatGPT also outperformed Bard in accurately identifying insects from photographs.\nFor disabled communities, the applications of such tech are particularly exciting. In March OpenAI started testing its multimodal version of GPT-4 through the company Be My Eyes, which provides a free description service through an app of the same name for blind and low-sighted people. The early trials went well enough that Be My Eyes is now in the process rolling out the AI-powered version of its app to all its users. “We are getting such exceptional feedback,” says Jesper Hvirring Henriksen, chief technology officer of Be My Eyes. At first there were lots of obvious issues, such as poorly transcribed text or inaccurate descriptions containing AI hallucinations. Henriksen says that OpenAI has improved on those initial shortcomings, however—errors are still present but less common. As a result, “people are talking about regaining their independence,” he says.\nIn this new wave of chatbots, the tools go beyond words. Yet they’re still based around artificial intelligence models that were built on language. How is that possible? Although individual companies are reluctant to share the exact underpinnings of their models, these corporations aren’t the only groups working on multimodal artificial intelligence. Other AI researchers have a pretty good sense of what’s happening behind the scenes.\nThere are two primary ways to get from a text-only LLM to an AI that also responds to visual and audio prompts, says Douwe Kiela, an adjunct professor at Stanford University, where he teaches courses on machine learning, and CEO of the company Contextual AI. In the more basic method, Kiela explains, AI models are essentially stacked on top of one another. A user inputs an image into a chatbot, but the picture is filtered through a separate AI that was built explicitly to spit out detailed image captions. (Google has had algorithms like this for years.) Then that text description is fed back to the chatbot, which responds to the translated prompt.\nIn contrast, “the other way is to have a much tighter coupling,” Kiela says. Computer engineers can insert segments of one AI algorithm into another by combining the computer code infrastructure that underlies each model. According to Kiela, it’s “sort of like grafting one part of a tree onto another trunk.” From there, the grafted model is retrained on a multimedia data set—including pictures, images with captions and text descriptions alone—until the AI has absorbed enough patterns to accurately link visual representations and words together. It’s more resource-intensive than the first strategy, but it can yield an even more capable AI. Kiela theorizes that Google used the first method with Bard, while OpenAI may have relied on the second to create GPT-4. This idea potentially accounts for the differences in functionality between the two models.\nRegardless of how developers fuse their different AI models together, under the hood, the same general process is occurring. LLMs function on the basic principle of predicting the next word or syllable in a phrase. To do that, they rely on a “transformer” architecture (the “T” in GPT). This type of neural network takes something such as a written sentence and turns it into a series of mathematical relationships that are expressed as vectors, says Ruslan Salakhutdinov, a computer scientist at Carnegie Mellon University. To a transformer neural net, a sentence isn’t just a string of words—it’s a web of connections that map out context. This gives rise to much more humanlike bots that can grapple with multiple meanings, follow grammatical rules and imitate style. To combine or stack AI models, the algorithms have to transform different inputs (be they visual, audio or text) into the same type of vector data on the path to an output. In a way, it’s taking two sets of code and “teaching them to talk to each other,” Salakhutdinov says. In turn, human users can talk to these bots in new ways.\nMany researchers view the present moment as the start of what’s possible. Once you begin aligning, integrating and improving different types of AI together, rapid advances are bound to keep coming. Kiela envisions a near future where machine learning models can easily respond to, analyze and generate videos or even smells. Salakhutdinov suspects that “in the next five to 10 years, you’re just going to have your personal AI assistant.” Such a program would be able to navigate everything from full customer service phone calls to complex research tasks after receiving just a short prompt.\nMultimodal AI is not the same as artificial general intelligence, a holy grail goalpost of machine learning wherein computer models surpass human intellect and capacity. Multimodal AI is an “important step” toward it, however, says James Zou, a computer scientist at Stanford University. Humans have an interwoven array of senses through which we understand the world. Presumably, to reach general AI, a computer would need the same.\nAs impressive and exciting as they are, multimodal models have many of the same problems as their singly focused predecessors, Zou says. “The one big challenge is the problem of hallucination,” he notes. How can we trust an AI assistant if it might falsify information at any moment? Then there’s the question of privacy. With information-dense inputs such as voice and visuals, even more sensitive information might inadvertently be fed to bots and then regurgitated in leaks or compromised in hacks.\nZou still advises people to try out these tools—carefully. “It’s probably not a good idea to put your medical records directly into the chatbot,” he says.\nLauren Leffer is a tech reporting fellow at Scientific American. Previously, she has covered environmental issues, science and health. Follow her on Twitter @lauren_leffer\nSophie Bushwick\nGary Marcus\nManon Bischoff\nGary Marcus | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "More States Are Requiring Flood Risk Disclosures. Florida Is Conspicuously Not among Them", "date": "2023-10-05 16:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nMore states are requiring homeowners to disclose a property’s flood risk and history when they sell it. But 18 states, including hurricane-prone Florida, have no flood disclosure requirements\nCLIMATEWIRE | Prospective homebuyers in more states are being told of the flood risk and history of the properties they want to purchase thanks to an uptick in flood disclosure requirements.\nA new analysis by the National Resources Defense Council shows that the number of states with strong flood disclosure policies has jumped to seven from four since 2021. North Carolina soon could become the eighth.\nThe NRDC and others have urged states to require the disclosure during property sales to help buyers decide whether to purchase flood insurance, protect the property or skip the deal. Research has shown disclosure can devalue flood-prone properties and discourage development in risky areas.\n“More states are recognizing that flood disclosure is a crucial tool,” said Joel Scata, an NRDC water and climate attorney who wrote the recent analysis. “States see it as a good way to help protect people.”\nFlood disclosure is increasingly important as climate change causes more frequent and intense flooding, advocates say. They compare flood disclosure to the federal requirement that property owners tell prospective buyers and tenants about any lead-based paint in a home.\nThe three states with new disclosure policies are New York, New Jersey and South Carolina. New York Gov. Kathy Hochul (D) signed the law Sept. 22, calling it a “monumental step” toward protecting New Yorkers from the effects of climate change.\nNew York and New Jersey had received F grades from the NRDC in its previous analysis, released in 2021, because neither state required any disclosure of flood history and risk. New York had a disclosure requirement, but sellers could skip it by giving buyers a $500 credit on a purchase price. The new law removes the option.\nBoth states now have laws requiring disclosure for prospective buyers and renters.\nSouth Carolina previously received a C from the NRDC, indicating its flood disclosure policy was “adequate.”\nThe new policy was implemented in June by the South Carolina Real Estate Commission, a state agency that expanded the information required on its mandatory disclosure statement.\nThe North Carolina Real Estate Commission is considering a similar move after being petitioned by groups including the Southern Environmental Law Center and the North Carolina Justice Center. The commission is reviewing hundreds of public comments on a revised disclosure form.\nFour states — Louisiana, Mississippi, Oklahoma and Texas — retained the top ratings they received in the 2021 NRDC report. Texas expanded its disclosure law in 2022 to apply to rental properties.\nThe top flood disclosure policies require prospective buyers and tenants to receive a form describing whether a home has sustained flood damage, is in a flood zone, is required to be covered by flood insurance or has received any federal money for flood repair.\nDespite the increase in flood disclosure, 18 states remain without any disclosure requirement, including Florida, the nation’s third-largest state and most vulnerable to hurricanes, and Alabama and Georgia, according to the NRDC report.\n\"Florida homebuyers are greatly disadvantaged when it comes to learning of a home's past flood history or potential for future flooding,\" the NRDC report says. The report says a disclosure form created by Florida Realtors is voluntary.\nScata of the NRDC said Florida is showing signs of progress. Four disclosure bills were introduced in the Florida Legislature during its session earlier this year, including one measure that had bipartisan sponsorship. All the bills failed, but Scata said, “You’ll start to see more states push disclosure laws.”\nMany of the states with no disclosure requirement are in New England or the Mountain time zone.\nThe NRDC score card is one of the few analyses of flood disclosure laws in each state.\nIn 2022, the Federal Emergency Management Agency published a reportthat rates each state on a 10-point scale based on the number of required flood disclosures.\nFEMA has been advocating for states to improve flood disclosure and is considering imposing its own requirement, though it is unclear how the agency would do so. Insurance is regulated by state agencies and not the federal government.\nFannie Mae urged FEMA to require flood disclosure, saying that flood awareness \"remains low\" and the government is \"by far the most trusted source\" for flood information.\nFEMA’s report was similar to the NRDC analysis in 2021 and gave Louisiana a perfect score of 10, followed by Texas with a score of 8.\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nThomas Frank covers the federal response to climate change for E&E News.\nMeghan Bartels\nOliver Wing, Carolyn Kousky, Jeremy Porter, Paul Bates and The Conversation US\nThomas Frank and E&E News\nJaney Camp and The Conversation US\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "95 Percent of Penicillin Allergy Diagnoses Are Wrong. A New Test Could Help", "date": "2023-10-05 17:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nA simplified penicillin allergy test could help reduce false positives, but doctors face challenges in using it\nIf you’ve been told your whole life that you have a penicillin allergy, you’d be forgiven for not giving it a second thought. About one in 10 people in the U.S. report having this condition, making it the most common drug allergy in the country—and seemingly ordinary. In reality, 95 percent of those diagnosed with a penicillin allergy aren’t actually allergic. The impact of the sheer number of misdiagnoses is worthy of attention. When treating patients who have an allergy to the antibiotic on their medical record, doctors must turn to other antibiotics that are less effective and more expensive and can lead to serious health complications.\nA small contingent of health care professionals is working to remove the millions of false penicillin allergy diagnoses from individuals’ medical records. Experts say that educating their medical colleagues and the public about the rampant number of falsely diagnosed penicillin allergies and using an easier new test could curb the issue. But removing so many diagnoses from the health record and changing the larger public concern around penicillin allergy may be challenging. Shaking an incorrect penicillin allergy diagnosis has proved difficult among people who have held onto one “longer than a pet, even longer than a student loan,” says Christopher Bland, an associate professor in the College of Pharmacy at the University of Georgia. “It almost becomes a part of them.”\nPenicillin is not just the name of a single antibiotic—it is also a blanket term for the family of drugs containing chemical relatives of penicillin such as amoxicillin or methicillin. Penicillin antibiotics, which kill bacteria by preventing them from building a cell wall, are used to treat various illnesses such as pneumonia, meningitis, skin infections and dental abscesses. They are also the first-choice treatment for common childhood infections.\nWhen doctors ramped up penicillin treatments in the early 1940s, reports of adverse reactions, such as hives, soon emerged. In 1949 doctors reported the first case of penicillin-caused death from anaphylaxis, a severe allergic reaction that lowers blood pressure and impairs breathing. “That was a shock that both the public and health care workers of all types never really forgot,” says Richard Olans, an infectious disease expert at MelroseWakefield Hospital in Massachusetts. Hives and anaphylaxis are true allergic reactions that result from the immune system producing antibodies that target penicillin like it would if it were fighting a pathogen such as a cold or flu virus. These reactions are rare.\nMost people are misdiagnosed with a penicillin allergy in childhood when they take the drug to treat illnesses such as ear infections. Many kids develop a rash, which can appear like an allergic reaction to penicillin but is actually related to viral infections that often occur alongside bacterial ones. “Now we have so many studies that show that these kids are not ever truly allergic when they get these small rashes,” says Ana-Maria Copaescu, an allergy and immunology specialist at McGill University Health Center in Quebec.\nAdditionally, common side effects of penicillin, such as headaches, diarrhea and nausea, are often mistaken as an allergic response, Bland explains. “Most of the time, the patient has the reaction in their mind,” he says. “Then they just report it as an allergy.” People may also falsely get a penicillin allergy diagnosis because a parent or other relative was allergic.\n“There are a lot of myths about drug allergy that stem back to the discovery of penicillin,” says Elizabeth Phillips, an immunology specialist at Vanderbilt University Medical Center.\nPenicillin allergy testing has helped untangle real allergies from misdiagnoses. The current gold standard test—only conducted in specialized allergy clinics—involves pricking the skin and injecting a small amount of penicillin. If the person doesn’t react to the skin prick, they are given a small oral dose of an antibiotic in the penicillin family, usually amoxicillin. Should they tolerate the oral dose, the penicillin allergy can be removed from their medical record.\nTesting has helped doctors realize how few people are truly allergic. Studies have shown that even among individuals who’ve experienced anaphylaxis, 80 percent lose penicillin antibodies after a decade. This is a huge deal for the long-term health and future antibiotic treatment of potentially millions of people who could take the drug safely. “I think one of the worst things to have on your profile as a patient is a penicillin allergy,” Bland says.\nThe alternative medications doctors prescribe to people with a penicillin allergy have more side effects and are less effective. They are usually less targeted, so using them is like casting a net to catch a pathogen rather than shooting an arrow at it. That means they can kill off good bacteria and lead to the overgrowth of potentially dangerous ones such as Clostridium difficile or methicillin-resistant Staphylococcus aureus. Less-targeted antibiotics also give more bacteria the chance to evolve ways to survive, spurring new antibiotic-resistant strains that can have a wider impact on the human population.\nIn addition to the health burdens, there’s also a financial one. A 2018 study found that hospitalized people in several countries, including the U.S., with a documented penicillin allergy paid up to $4,250 more for their visit. Kimberly Blumenthal, an allergist and immunologist at Massachusetts General Hospital, co-authored a 2021 study showing that the cost of having a penicillin allergy overwhelmingly outweighed the cost of running a penicillin allergy test because the alternative antibiotics are more expensive.\nBut even after correcting the penicillin allergy label with the test, it can persist on many people’s health record. Getting rid of an erroneous penicillin allergy diagnosis is a multifaceted issue: “It’s electronic. It’s culture. It’s fear,” says Rita Olans, a nurse practitioner and an associate professor at the Massachusetts General Hospital Institute of Health Professions. Incompletely clearing a penicillin allergy from a person’s electronic health record can cause it to follow them from doctor to doctor. Bland and Copaescu both give people a physical card to show other doctors they tested negative for a penicillin allergy in case it wasn’t completely cleared from the electronic health record. Many people are still afraid to use the drug even after they’ve been cleared, however. One study found that 41 percent of people who had been told they had a penicillin allergy but later tested negative still avoided penicillin.\nMany doctors agree that educating enough people on how to identify potentially incorrect penicillin allergy diagnoses and perform tests is a significant issue. Olans is teaching her nursing students to take more complete allergy histories that could help root out potentially erroneous ones. But even then, allergy tests must be carried out in specialized allergy clinics that are inaccessible to much of the population. “I think the challenges right now are really related to the bottleneck of the process occurring in our specialty clinics,” Phillips says.\nTo try and address the testing bottleneck, Blumenthal developed an algorithm that evaluates patient histories and guides health care workers on the best antibiotics to use so that they can triage the patients that should be sent for allergy testing. The algorithm is now integrated with the electronic health record across all hospital sites in her health system.\nIn people who are unlikely to have a severe penicillin allergy, doctors may streamline the testing process by skipping the skin test and using just the oral dose. People in this low-risk group, which includes approximately 98 percent of penicillin allergies, experienced only mild reactions or unrelated symptoms when given the drug. Oral tests were previously considered riskier because they could cause a severe reaction, but a recent large randomized controlled trial led by Copaescu showed for the first time that oral doses are as effective and safe as skin tests for people who have never had a severe allergic reaction. “More and more, colleagues and allergists that work in a hospital setting are using this direct oral [test] based on studies like ours,” says Copaescu, who published the results of the trial in July.\nCopaescu says that the oral test alone is cheaper and less painful for patients and doesn’t require specialized training. “It expanded who was doing direct [oral tests] in low-risk patients,” says Blumenthal, who wasn’t involved in the trial. With the simplified test, more people could theoretically be freed of their incorrectly diagnosed drug allergy. Blumenthal’s next step is to work with primary care doctors and their patients to use this type of testing in primary care clinics and verify penicillin allergies proactively rather than at the time people need the drugs most.\nBland sees performing proactive testing as a part of routine care, like vaccination, as the ultimate goal. This way, people can have penicillin on standby if they need it. Many people will encounter a bacterial infection in their lives, Bland says. “You’re going to need an antibiotic,” he adds. “It’s very, very likely. And it could be the one that saves your life.”\nAndrew Chapman is a Truckee, Calif.–based freelance science writer who covers life sciences and the environment.\nAmanda Montañez\nKaren Hopkin\nThe Editors\nJaimie Seaton\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "10,000 Pre-Columbian Structures Could Be Hidden beneath Amazon Rain Forest", "date": "2023-10-05 18:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nIf this new estimate holds up, scientists have yet to identify the vast majority of earthworks strewn across the Amazon\nIn the millennia before European colonizers invaded the Amazon rain forest, throngs of Indigenous people moved mountains of dirt to create some 10,000 yet-to-be-identified earthworks across the region.\nThat’s according to new research published on Thursday in Science that identifies two dozen sites where massive amounts of dirt formed circular and rectangular geoglyphs, settlements and religious sites. Based on what the researchers knew about such structures, they estimated the huge number of these mysterious constructions that are likely hidden somewhere beneath still unsearched forest. The model supports theories that hold the Amazon, which covers a huge swath of South America, was densely populated before colonization, and it may strengthen political efforts to uphold the modern sovereignty of the forest’s Indigenous inhabitants.\nTo look for these sites, the researchers found data gathered for other studies of biomass in the northern, central and southern regions of the Amazon rain forest. Those studies relied on a so-called light detection and ranging (lidar) system that bounces an airborne laser off Earth’s surface as it passes overhead, measuring trees’ canopies but also revealing the ground below them. “We thought, ‘Maybe the ground can tell us some stories about the archaeology as well,’” says Vinícius Peripato, a doctoral candidate in remote sensing at Brazil’s National Institute for Space Research and co-lead author of the new study. “At the beginning, it was a complete shot in the dark; we had no idea if we would find anything.”\nBut in that initial data, which represent less than one tenth of 1 percent of the Amazon’s total area, he and his colleagues found 24 novel earthworks to add to the nearly 1,000 previously known examples. The new sites are between 500 and 1,500 years old, and they include a fortified village, other settlement sites and religious structures, Peripato says. The fortified village had a central plaza and would have been part of a local urban network in the southern Amazon, while the geoglyphs included a cluster of ringlike designs. (Geoglyphs are a type of land art in which dirt is shaped into designs that can be viewed from overhead.)\nNext, the researchers used computer modeling to analyze known earthwork sites and predict their spread across the Amazon. That work considered a range of geographical factors such as distance to water, elevation and soil type (sandy soils, for instance, make short-lived earthworks). That work yielded the estimate that there are at least 10,000 earthworks—perhaps even twice that many—hidden across the Amazon. To date, scientists have only found about 1,000 such sites.\nThe sheer magnitude of that estimate supports previous calculations of a pre-Columbian population of eight million to 10 million in the Amazon, says Eduardo Neves, an archaeologist at the University of São Paulo in Brazil, who was not involved in the new research. He’s confident in those population assessments even if the true number of hidden earthworks isn’t quite 10,000. “To be honest, it’s hard to evaluate that number,” he says of the study’s earthwork prediction. “But I think it’s not off the mark; I think it’s a good number.”\nAnd the experience of archaeologists who study the ancient Maya—and have used lidar to uncover entire networks of cities hidden in the jungle in Central America—suggests that as lidar observations of the area develop, their colleagues now beginning such work in Amazonia will indeed find a trove of new sites. “We thought the Maya area was very well studied, but when we started to do lidar work [there], we had lots of surprises,” says Takeshi Inomata, an archaeologist at the University of Arizona, who was not involved in the Science study. “I think there will be more of those surprises in Amazonia.”\nYet all three researchers, however, say that the importance of the study isn’t so much about the precise number of sites. Rather it’s about the scale of human involvement in the Amazon rain forest. Neves argues that the Amazon is not a “natural” region that is purely produced by plants and nonhuman animals and is instead a “biocultural” one that is defined by the interaction of humans with nature. “There’s a still-common popular perception that the Amazon is a vast, wild expanse, but that’s not really true,” Inomata says. “This study really shows well that there was a lot of involvement of humans in this environment.”\nFor instance, the scientists also studied which trees were commonly found near earthworks and noted species that include the Brazil nut (Bertholletia excelsa) and the breadnut (Brosimum alicastrum). That analysis suggests people were cultivating these trees—and their tasty offerings—at sites they frequented. It’s both another clue archaeologists can use to target their search for earthworks and a clear form of people leaving their mark on the forest they lived in.\nThat mark may have real political consequences for their descendants, who are fighting to hold on to the Amazon in the face of agricultural interests and others that could infringe on the forest. Researchers say that the new study supports Indigenous people’s claims of having permeated the Amazon and making it their own, which can strengthen their chances of gaining official stewardship of the forest. “It’s impossible to disentangle the Amazon that we know today from the lives and the history of the Indigenous people who have been living there for millennia,” Neves says. “There’s no future for the forest without a future for the people who have been living there for the last millennia.”\nMeghan Bartels is a science journalist and news reporter for Scientific American who is based in New York City.\nUyunkar Domingo Peas Nampichkai, Juan Manuel Crespo and Jesús Chávez | Opinion\nEmma Bryce\nJennifer Nalewicki and LiveScience\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Ancient Footprints Affirm People Lived in the Americas More Than 20,000 Years Ago", "date": "2023-10-05 18:15:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nA new study suggests humans arrived in the Americas before the height of the last ice age more than 20,000 years ago\nFossilized human footprints found in New Mexico’s White Sands National Park were almost certainly made more than 20,000 years ago, during the height of the last ice age, according to new research. The study, published on Thursday in Science, overthrows decades of thinking about when humans arrived in North America.\nThe researchers determined the ages of pollen grains and tiny quartz crystals in sediments beside the footprints, which are buried a few feet below the surface. The work confirms a 2021 study’s findings, which were based on radiocarbon dates from aquatic plant seeds in the sediments. The new results “are statistically indistinguishable from the seed ages,” says Jeff Pigati, a geologist at the U.S. Geological Survey and co-lead author of the new study. “We’ve now got three different dating techniques—radiocarbon dating of the seeds, radiocarbon dating of the pollens and luminescence dating of the quartz—that all show people were there.”\nThe 2021 announcement of the astonishingly ancient age of the footprints, which were found alongside a dried-up lake in the park, created controversy among archaeologists. Until then, many scientists had thought that the Clovis people became the first known Americans when they arrived from the north about 13,000 years ago, as the ice sheets across North America were retreating. (The Clovis are named after a town in New Mexico where their stone spear points were unearthed in the 1930s, but their artifacts have since been found throughout Central and North America.)\nThe White Sands footprints, however, suggest humans had already lived in New Mexico for thousands of years by the time the Clovis culture began.\nSkeptics questioned the dating method used in the 2021 study, which measured the levels of radioactive carbon 14 in seeds of the freshwater plant Ruppia cirrhosa—also known as spiral ditchgrass—in layers of sediment above and below the footprints. The critics argued water might have flowed through ancient rocks before it was absorbed by the seeds and thereby transmitted carbon that could make them seem older than they really were.\nBut the alternative dating methods refute that idea, says co-lead study author Kathleen Springer, a USGS geologist. “It’s a paradigm-shattering result,” she says. “People were in New Mexico during the Last Glacial Maximum, when the massive ice sheets farther north were [impassable]—that just flies in the face of all ideas about migrations and migratory routes,” she adds, referring to the last ice age’s peak, which occurred between 26,000 and 20,000 years ago.\nIn the new study, the researchers determined the radiocarbon age of microscopic pollen grains in the sediment layers, which hadn’t grown in the lake water. They also found the pollen came from plants that no longer grow in the area. “There’s pollen from pine and spruce and fir, which grow at much higher elevations today,” Springer says. “So the flora indicates that ecosystem extended down to the valley floor 20,000 years ago.”\nThe researchers also dated the sediments with a technique called optically stimulated luminescence, which can determine when minerals were last exposed to daylight. Samples for the technique must be processed in the dark, which the scientists achieved by hammering tubes into the buried sediments and studying them under red light that wouldn’t affect the dating, Pigati says. They then measured the almost imperceptible glow of quartz grains in the samples under specific frequencies of light, and the resulting dates matched those from the radiocarbon method, he says.\nThe new dates confirm the picture of a now vanished landscape at White Sands more than 20,000 years ago, when camels, elephants and giant sloths roamed beside a lake and were probably prey for human hunters. And the human footprints suggest people arrived there up to 30,000 years ago, before the ice sheets made migration from the north impossible.\nSome of the White Sands footprints appear on the surface as “ghost tracks,\" which are only visible when the ground is damp. Scientists think they are caused by water evaporating above fossilized footprints that are buried deeper underground. The team dug a trench in the soil to reveal the buried footprints and take samples for testing. “There are thousands of megafaunal and human footprints at White Sands,” Springer explains. “On some days you can’t see anything, but when the moisture content is just right, they fully pop to your eye.”\nGeologist Cynthia Liutkus-Pierce of Appalachian State University, who has studied ancient human footprints in Tanzania and wasn’t involved in the new White Sands research, says the study further supports the presence of humans in North America during the last ice age. “This is exciting and will certainly have scientists rethinking how humans interacted with the North American environment during the [Last Glacial Maximum],” she says.\nAnthropologist Kimberly Foecke of the Smithsonian Institution, who also wasn’t involved in the study, is now “reasonably convinced” of the antiquity of the footprints.* “These results add to the still scant but growing evidence of human presence in the Americas around the time of the Last Glacial Maximum,” she says.\n*Editor’s Note (10/5/23): This sentence was edited after posting. It originally stated Kimberly Foecke is at George Washington University.\nTom Metcalfe is a freelance journalist who is based in London. Metcalfe writes mainly about science, space, archaeology, Earth and the oceans. He has also written for Live Science, the BBC, NBC News, National Geographic, Air & Space and many others.\nRiley Black\nKate Wong\nAaron Martin\nFreda Kreier\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "The Sky Is Full of Stars--and Exoplanets, Too", "date": "2023-10-06 10:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nOf the thousands of stars visible to the eye, only a few hundred are known to have planets. But that number may be far higher in reality\nI remember quite clearly when we only knew of nine planets in the entire universe.\nThat was the case on the first day of 1992, but scarcely a week later, everything changed. On January 9 of that year astronomers announced the discovery of the very first exoplanets—worlds orbiting stars other than our own. These new planets are so weird that it was difficult to grasp how profoundly they changed our cosmic context: they orbit a pulsar, a rapidly spinning, ultradense, city-sized stellar remnant left behind after a massive star exploded as a supernova. Although that’s extremely interesting, it’s not entirely satisfying. A pulsar is the least sunlike kind of star out there, and we, as irredeemably self-centered human beings, prefer to find places more like home—planets around stars more like our own.\nThen, in 1995, astronomers announced they’d found one: 51 Pegasi b, a Jupiter-class planet circling a star that very much resembled our sun in size, mass and age.\nAnd at just a hair more than 50 light-years away, 51 Pegasi is a naked-eye star.\nIt’s not easy to spot—at a magnitude of 5.5, you need a dark site and a moonless night to see it—but that does raise an interesting question: How many naked-eye stars host planets? It’s surprisingly challenging to definitively answer this question, as we’ll see, so let’s slightly rephrase: How many naked-eye stars host planets that we know about?\nFinding the answer appears to be a snap because you can look it up in databases such as NASA’s Exoplanet Archive, which offers a treasure trove of information on alien worlds. Searching NASA’s database for planets orbiting naked-eye stars (that is, ones with a magnitude of less than 6.0) yields a pretty specific answer: 183.\nBecause nothing in science is ever that cut-and-dried, however, it’s not quite that simple. For example, three of these planets remain officially unconfirmed, bringing the number down to 180. And at least 20 of them are each about 13 times heavier than Jupiter, the largest and most massive planet in our solar system. That means they skirt the border of being objects called brown dwarfs, which are beefier than proper planets but don’t have quite enough oomph to ignite nuclear fusion in their cores to become true stars. With that in mind, the actual number of naked-eye stars hosting known exoplanets is probably around 150 to 160.\nMany of these are easy to see and are among the brightest stars in the sky.\nThe most brilliant in this sample is Aldebaran, a star 66 light-years from Earth that marks the eye of the bull Taurus. It’s a red giant, a star that was once much like the sun but is starting to bloat and die, having run out of hydrogen fuel in its core. Its planet, Aldebaran b, is a gas giant orbiting the star at about the same distance that Mars orbits the sun. Given that the star is more than 400 times more luminous than the sun, Aldebaran b is getting cooked.\nPollux, one of the twin stars at the head of Gemini (the other being the almost equally bright Castor), is another quite bright exoplanetary host. At 34 light-years from us, it’s closer to Earth than Aldebaran is, and it’s also a red giant. Pollux’s planet, Pollux b, is another gas giant that’s also getting blasted by intense stellar light.\nThe closest naked-eye star known to have planets is Tau Ceti, a mere 11.9 light-years from our world. It hosts at least four planets, which range in mass from about two to four times that of Earth. These planets are so-called super-Earths—they are more massive and larger than Earth but are perhaps still-rocky planets that are similar to ours. One of them, Tau Ceti f, even orbits at the right distance from the star to potentially be habitable—under a sufficiently broad definition of “habitable,” that is.\nThe most interesting thing about this list, however, is the stars that aren’t on it. Aldebaran, the brightest, is only about the 13th brightest star in the night sky. Why haven’t we found planets around the dozen brighter ones?\nThere are many reasons, actually. One is that they may simply not have planets. Many of these stars are difficult to observe for planets. Some of them are intrinsically variable, for example, meaning they fluctuate in brightness, which can confound exoplanet surveys. Capella, the fifth brightest star (not including the sun) is at least a quadruple star system, with four stars orbiting one another. Two of them are old, evolved stars, like Aldebaran and Pollux, and orbit so closely together that it’s unlikely there’s a planet around either one of them. Perhaps a planet orbits both farther out, but this has not yet been determined.\nSirius, the brightest star in the night sky, has no confirmed planets. That may be because it’s a binary star, and the two stars move around each other on a mildly elliptical orbit, which could destabilize planetary orbits. One of the stars expired long ago, blowing off its outer layers and becoming a dense and tiny white dwarf. Such an event may not totally disrupt a planetary system but is not exactly great for them, either. Although a search for planets in the Sirius system has ruled out any that would be much more massive than Jupiter, less massive ones may yet await discovery.\nOne oddity on this list of naked-eye exoplanet no-shows involves the famous star Alpha Centauri. It’s actually a triple star system, with two sunlike stars that orbit each other and a third star, called Proxima Centauri, that is much farther out. The aptronymically named Proxima is the closest star to our sun. Despite its proximity, it’s a dim bulb that is so faint that it demands a decent telescope to be seen at all. Neither of the two brighter stars has been confirmed to have planets after intensive searches. Yet Proxima hosts at least two planets, and a third one is strongly suspected. So, in a sense, one of the brightest star systems in the sky, and the closest one to us, hosts planets, but the specific star they orbit is not visible to unaided vision. Although I’m not sure that counts for our list, it’s still a cool situation.\nGiven that there are about 9,000 stars visible to the naked eye, the fraction of them known to host planets is surprisingly small. A lot of this may be because of how we find planets, however. So far most have been found via the transit method, when we happen to see the planet’s orbit edge on so that, once per revolution, it passes directly in front of the star and creates a mini eclipse. The amount of light we see from the star dips a small amount, revealing the planet’s presence.\nBut as this chancy viewing geometry suggests, most planets will never transit as seen from Earth, which renders them effectively invisible to this workhorse detection technique. So from a statistical standpoint, our searches to date have missed a large fraction of existing planets. Present estimates are such that the actual number of planets out there could be at least 10 times higher. The meaningful takeaway of all this is that most stars in the galaxy probably host planets. We just haven’t seen them yet—at least not with the transit method or any of the various other methods that have added smaller numbers of worlds to our galactic tally.\nThink on that the next time you’re outside at night under a clear sky. It may well be that nearly every star you see has planets. The odds are that trillions of them exist in the Milky Way alone. From being able to count all the known planets on two hands to cataloging thousands to positing the existence of trillions, we’ve made incredible progress in our census of worlds in the past 30 years.\nIf there is a single astronomical fact that makes my heart pound a little harder and fills it with wonder and joy, that may very well be it.\nPhil Plait is a professional astronomer and science communicator in Colorado. He writes the Bad Astronomy Newsletter. Follow him on Substack. Credit: Nick Higgins\nElizabeth Howell and SPACE.com\nJoshua N. Winn\nJonathan O'Callaghan\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Millions of Mosquitoes Will Rain Down on Hawaii to Save an Iconic Bird", "date": "2023-10-06 11:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nHawaii’s brightly colored honeycreepers are at imminent risk of extinction, and bacteria could be the key to saving them\nMillions of mosquitoes dropped from helicopters could be the greatest hope for Hawaii’s iconic honeycreepers. At least four species of the brightly colored birds could go extinct within the year if no action is taken to save them. “We’re seriously in a race against time at the moment,” says Hanna Mounce, program manager of the Maui Forest Bird Recovery Project.\nThese small birds evolved on the islands over the course of millions of years and are uniquely adapted to their niche habitat, where they are crucial pollinators for many of Hawaii’s flora. For the people of Hawaii, the honeycreepers are also woven into the cultural fabric, featuring prominently in many legends and providing feathers for traditional garments. More than 50 species of honeycreepers once flitted across the archipelago, but because of introduced predators, habitat destruction and disease, that number has dwindled to only 17. Invasive Culex quinquefasciatus mosquitoes—possibly introduced via water barrels on European ships in the early 19th century—pose a particular threat because they spread the deadly avian malaria parasite.\nThe honeycreepers that still survive today live high in the mountains, where it is too cool for mosquitoes. Rising temperatures are widening the mosquitoes’ habitat, however, and every year they move higher up the mountain slopes—and kill birds as they go. Four species of honeycreeper—the ʻAkekeʻe (Loxops caeruleirostris) and the ʻAkikiki (Oreomsytis bairdi) on the Hawaiian island of Kauai and the Kiwikiu (Pseudonestor xanthophrys) and ʻĀkohekohe (Palmeria dolei) on Maui—are in particularly dire straits. “We have one more warm year, and we're not going to have any birds left,” Mounce says.\nBirds, Not Mosquitoes, a consortium of more than a dozen state, federal, industry and conservation partners, including the Maui Forest Bird Recovery Project, is pinning the birds’ immediate future on the so-called incompatible insect technique (IIT). To date, this mosquito-control method has only been used for mosquito-borne diseases that affect humans, Mounce says. On two islands in China, for example, the technique cut dengue-carrying mosquito populations by 90 percent.\nIIT works like this: C. quinquefasciatus mosquitoes, as well as many other arthropods, naturally contain Wolbachia bacteria in their gut. In order to produce offspring together, mating mosquitoes must be infected with the same strain of the bacteria. Birds, Not Mosquitoes’ plan involves releasing male mosquitoes bred by Verily Life Sciences—the life sciences research arm of Alphabet, which also owns Google. These mosquitos will host a different Wolbachia strain than those on Maui. The idea is that the existing female mosquitoes will mate with the male newcomers, but because of their incompatible Wolbachia bacteria, they will not produce viable offspring. If all goes according to plan, the overall mosquito population will plummet.\nBirds, Not Mosquitoes initially ran trial studies by releasing 5,000 to 30,000 IIT mosquitoes at a time to study their dispersal and longevity in the wild. The team found that although the introduced mosquitoes lived longer than local ones, they did not move far from the release site. This means that future mosquito releases will need to be spaced closer together. For the next phase beginning in November, the consortium will drop 250,000 treated mosquitoes twice a week over about 3,000 acres in east Maui for a year. They will be contained in mango-sized biodegradable capsules that can each hold about 1,000 mosquitoes.\nSuccess, however, hinges not only on reducing mosquito population numbers but also on ensuring that the new Wolbachia strain does not establish itself in the local mosquito population. If the local mosquitoes become infected primarily with the new Wolbachia, then they will be able to produce offspring with the introduced mosquitoes; that would defeat the goal of the technique and project. To prevent that outcome, the team will set egg traps to check for the new Wolbachia strain. If it is found, the project will stop releases “until there is none of that [strain of] Wolbachia detected in the landscape before we’re able to start again,” Mounce says.\nOnly female mosquitoes bite, and the project is not releasing any females. If the intervention works, the number of female mosquitoes in the release area will plummet, and the next step will be a landscape-wide release of these doctored mosquitoes. “If there are no female mosquitoes in those areas, then they can’t bite the birds, and there can’t be any malaria transmission,” Mounce says. Mosquitoes are not endemic to the islands and woven into native ecosystems in the same way that, for example, honeycreepers are. Consequently, scientists do not expect their removal to harm the environment.\nThis approach is not a full solution to the birds' plight. Rather “it’s a Band-Aid to buy time,” says M. Renee Bellinger, a research geneticist at the U.S. Geological Survey, which is one of the consortium’s partners. “We recognize that it’s not a permanent solution. But it is the solution that is available at the moment and has a regulatory pathway that is defined so that we can get the tool on the landscape.” Other concurrent interventions in the U.S. Department of the Interior’s Strategy for Preventing the Extinction of Hawaiian Forest Birds include establishing captive care programs, relocating honeycreepers who belong to the most at-risk species, developing gene drive technology to curb mosquitoes’ ability to transmit the malaria parasite and increasing birds’ malaria resistance.\nThe IIT plan has a lot of potential, especially in settings such as Hawaii’s forests, where insecticide use would be problematic, says Rosemary Lees, a principal research associate at the Liverpool School of Tropical Medicine in England, who is not involved with the project in Hawaii. “As with all new techniques, it will be critical to monitor the effects of the releases, to collect the operational data critical to evaluate impact and maximize cost-effectiveness and coverage,” she says.\nIf the IIT intervention fails, it may be necessary to move the honeycreepers out of mosquito-infested areas. Sam ‘Ohu Gon III, a senior scientist and a cultural adviser at the Nature Conservancy, says other islands with higher elevation could provide a refuge to some birds. “Those birds are doomed unless they can be pulled out of that habitat,” he says.\nBut Gon remains optimistic that the IIT will work, at least as a stopgap. “I’m very hopeful,” he says, “that it can stave off the fact that some of these birds might be extinct in one or two years if we do nothing.”\nSarah Wild is a freelance science journalist, who splits her time between Johannesburg in South Africa and Canterbury in the United Kingdom. She writes about cosmology, particle physics, and everything in between.\nChristopher Intagliata\nRowan Jacobsen\nMeghan Bartels\nChelsea Harvey and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Know Yourself Better by Writing What Pops into Your Head", "date": "2023-10-06 12:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nThe exercise of writing down unfiltered thoughts enhances self-knowledge\nFor decades, physician and author Silke Heimes has been leading groups in therapeutic exercises to put thoughts and feelings down on paper. Heimes, a professor of journalism at Darmstadt University of Applied Sciences,  points to abundant evidence that writing for five to 20 minutes a day can improve health, diminish stress, increase self-confidence and even kindle the imagination. A writing routine, she argues, is a form of mental hygiene that almost anyone can benefit from.\nSo how do you start? What happens if—as every writer fears—the page remains blank? And how do you get rid of an overcritical inner censor? Heimes, director of the Institute for Creative and Therapeutic Writing in Darmstadt, explains how to overcome inhibitions and open up your inner world.\n[An edited transcript of the interview follows.]\nIf you want to write in order to understand yourself better, what's the best way to start?\nThere are writing exercises, for example in so-called fill-in journals, where you directly answer a question. But if I just want to get started without any aids, the best way is to use the method of automatic writing. That means I set myself a short time window, maybe five minutes, in which I write continuously without thinking, without putting down the pen or rereading what I’ve written. The goal is to get thoughts down on paper as unfiltered as possible so that an inner censor can't switch on—or at least doesn't get too loud. It helps not to set the goal too high—not to expect too much—but to understand this writing as a time-out, so to speak, or as a kind of warm-up exercise.\nWouldn’t it be helpful to ask yourself specific questions?\nIf you want to, you can follow programs that, for example, organize specific questions into topics. But that can also be inhibiting at times because such questions primarily get your head working to produce rational answers. Questions often steer thoughts along preconceived paths. Sometimes it is almost easier without them to let the gut lead the way.\nWhat if you just can't think of anything?\nThe half-sentence method can help. With this approach, you complete a given half-sentence such as \"When I woke up this morning” or “What happened to me today.” If you write in the morning, the [first example] is a good choice. Because everyone wakes up in the morning, everyone can think of something to say about it. The same applies to [the second example] if you write in the evening because you inevitably experienced something during the day by then. To start, you can also write down words that begin with the letters of your name and then create a text using those words.\nCan anything go wrong using these methods?\nNot really. Just as with thinking, you can of course get tangled up in your own thoughts or get stuck in brooding loops when writing. But that’s not the fault of the writing itself; it’s just something that becomes obvious on paper. Writing often deals with emotional issues, so you also might temporarily feel bad because something is stirred up or triggered. In that case, you should take a break and do something else or talk to someone about it. If the feeling persists, it is best to seek professional help.\nDoes it make a difference whether you write by hand or on a keyboard?\nWriting by hand is a very complex movement that activates more areas in the brain, which leads to being more creative. It also usually means slowing down, which invites you to pause and take a breath. In addition, there is something sensual and unique about writing by hand. because, for one thing, our handwriting is very individual. And for another thing, it tells us something about our state of mind. In fact, handwriting usually becomes rounder and livelier when we are in a good mood and smaller or tighter when we are not feeling so well. Typing on the keyboard, on the other hand has a soothing quality because it is very rhythmic. Further, it has the advantage of allowing you to share your writing more quickly. I think it’s always good to have both skills and to use them.\nYou have guided many groups in this type of writing. How does that typically work?\nWe first do little writing exercises to warm up. Many people come with the expectation that they’ll sit down, and the writing will flow right away—that they’ll perform brilliantly almost off the cuff. But no athlete, no musician would expect that of themselves. Professional writers know better.\nAnd there are other common misconceptions. The biggest one is “I can't write.” A lot of people come to my seminars with this attitude. But we can all write. Rather the problem is the often exaggerated demands we place on ourselves. I like to quote French writer André Breton, who invented automatic writing. He said, mutatis mutandis, that if you want to write, find a nice place, sit down in peace and quiet and forget about seeking out brilliant thoughts.\nIs there anything else that people particularly struggle with when it comes to writing?\nWe’ve already talked about your own performance expectations. But what can also lead to inhibitions is the fear of emotions or of your personal history—fear of confronting possibly painful topics. And further problems usually arise when people want to put their thoughts into a literary form in order to publish them.\nWhat if someone only produces platitudes? What if they sound banal or superficial?\nWho decides that? That is a judgment that should be unacceptable in creative and therapeutic writing. Everyone expresses what is important, right and possible for them at that moment, and I think that is precisely what deserves appreciation.\nWhat do people in your groups write about most often?\nThey write about the topic of self-worth—that is, the fear of not being good enough—about not being heard or seen and about the topic of freedom versus security, especially at work.\nAnd what insights do they go home with?\nThat varies greatly. But they often take home a lot of pieces of paper, and that’s how they recognize that they can definitely write. They have produced something and are justifiably proud of it. This increases their self-esteem, and they develop more confidence. Writing also sharpens perception and promotes mindfulness. People notice more quickly when something is not good for them and find better ways to deal with those problems. And when thoughts go round in circles, putting them down on paper clears the mind. After that you have more capacity for other things in your life.\nCan these benefits be probed empirically?\nThere are [hundreds] of studies on the effect of expressive or therapeutic writing. Many of them come from the psychologist James Pennebaker, who did research on this primarily with students.\nDo you write a lot yourself?\nYes, every day. I work on a novel or nonfiction book every day, and I also jot down my thoughts for three minutes in the morning. These few minutes of mental hygiene are as important and natural to me as brushing my teeth every day.\nThis article originally appeared in Spektrum der Wissenschaft and was reproduced with permission.\nChristiane Gelitz is a psychologist and an editor at Spektrum der Wissenschaft.\nChristiane Gelitz\nSarah Wild\nPhil Plait\nTom Metcalfe\nMeghan Bartels\nAndrew Chapman\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Journey to the Thawing Edge of Climate Change", "date": "2023-10-06 13:00:00", "text": "What is a permafrost thaw slump? Just imagine a massive hole with an area the size of more than nine football fields—and growing—where ice-cold ground once stood.\nJoc Bentley: Are you okay?\nSteve Kokelj: Yeah. No, I’m just looking around where everyone is. I have to do that once in a while. We had a bear almost walk into us the other day because we were, like, staring at a thaw slump. And we turn around, and we’re like, “Oh, that, that’d be a grizzly bear there.”\nBentley: That’s Steve Kokelj. And the reason he has to be on the lookout for grizzlies has everything to do with where we’re standing right now.\nKokelj: We’re, uh, we’re in the Northwest Territories.\nBentley: That’s the Northwest Territories in the high Canadian Arctic.\nHey, I’m Joc Bentley, and I’m out here just north of the Arctic Circle to take you on a journey to the thawing edge of climate change.\nOver the next three episodes of Science, Quickly, we’ll be mucking around in a part of the world that is warming faster than just about any other.\nJust a few years ago the tundra here was frozen solid, and now there’s a massive hole with an area the size of more than nine football fields—and growing. The ground is disappearing under our feet. I’m trying not to get too close because there’s a 20-meter drop-off.\nAnd I’m gonna say meters because I’m Canadian. Just getting that out of the way.\nThis used to be a landscape shaped by ice. Now it’s being completely transformed.\n[CLIP: Show music]\nBentley: But let’s get back to Steve. He’s here to study that now not-so-perma permafrost.\nKokelj: We’re on the Peel Plateau.\nBentley: Steve works for the Northwest Territories Geological Survey. He has a constant entourage of students, and he’s wearing an amazing Canadian lumberjack uniform.\nKokelj: Behind me is a type of permafrost landslide called a retrogressive thaw slump. That's a type of permafrost landslide that forms in areas where the permafrost contains a lot of ice.\nBentley: That thaw slump he’s talking about? That’s the hole. To picture it, you have to imagine what it would look like if a massive mound of earth just sorta turned into molasses one day and started flowing downhill.\nAnd the land that became molasses is really old.\nKokelj: So the ice that’s melting behind us is a leftover of the, of the glaciation that covered most of Canada, and it’s somewhere around [16,000] to 13,000 years old.\nBentley (tape): Does this mean we’re still in an ice age?\nKokelj: We are. We are still in an ice age. And the process of deglaciation, which is when the ice goes away, in the North, it hasn’t ended yet. So we’re still going through a period of deep glaciation here.\nBentley: This always blows my mind. We’re still in an ice age. And that means Earth has a lot of room to get even hotter. Canada is seeing some of the fastest warming on the planet. And Steve says that has huge implications, especially for our frozen ground.\nKokelj: Most people don’t, may not appreciate this, but half of Canada is affected by permafrost, right? So it’s the northern half. But now that everything’s changing, it’s becoming a really, really important discipline to understand and improve the resilience of the Canadian North but also to understand global change issues related to the carbon being released from permafrost.\nBentley: Half of Canada. That’s almost too large an area to really comprehend. And even when you’re standing next to a thaw slump, it can still be tough to appreciate how big the changes are here.\nSo we got in a chopper for a bird’s-eye view. Keellie Stachniak, our pilot, took us for a tour of nearby slumps. So hold on and listen close because it’s about to get real noisy.\n[CLIP: Helicopter taking off ambience]\nStachniak: Should I take them to a slump?\nKokelj: Yeah, same one as yesterday.\nRight beneath us, this debris tongue, it has infilled the whole valley, and it has accumulated about 35 meters.\nBentley: And just to put that into perspective, that’s as high as a 10-story building.\nKokelj: Yeah, a lot of these streams were clearwater streams before, right? The thaw slumps are releasing all these sediments, and they’re just changed, and they will be from now ...\nKeellie: Forever?\nKokelj: For the foreseeable future, yeah.\nThe materials that are coming out of the permafrost, it’s not so much their makeup, it’s the volume that are being put into the river systems here that are detrimental to the ecosystems.\nBentley: And Steve says this is just the beginning.\nKokelj: As the climate is warming and as summers are getting wetter, these types of disturbances are getting bigger. And in the past, under colder conditions, a thaw slump would grow over a period of a number of years and then stabilize. But as the climate’s warming, they continue to grow and impact larger areas of land.\nBentley: This isn’t just about land. There are Indigenous communities here that have been living off of this land for thousands of years. What’s going to happen to them?\nKokelj: So the people that live here are the Gwich’in people, and they’re very concerned about their landscape. They’re concerned about the water in their lakes and streams. They’re the people that have traditionally lived off of fish and caribou, of course. These types of disturbances, these types of landslides, deliver lots of sediment and other materials that have been locked into the permafrost into the streams, and that can affect the habitat in the streams and, and the health of the stream ecosystems.\nBentley: And the streams don’t only get filled with sediment. Steve and his team have seen entire lakes disappear. Both the Gwich’in and the Inuvialuit populations are facing some massive challenges.\nIn order to better predict what exactly is going to happen to permafrost on a warming planet, Steve’s team is running all kinds of experiments.\nOn the team, permafrost scientist Alice Wilson is trying to figure out if snow cover slows permafrost thaw. In the darkness of the freezing arctic winter, she manipulates the amount of snow on different areas of tundra. Then, when summer arrives, they check how much of the top layer of permafrost has melted.\nWilson: Alright, so what we’re doing right now is active layer, or thaw depth, measurements. So we use this graduated probe, where we have markings every 10 centimeters. So if we push it into the ground where we hit the bottom, you can kind of hear it sometimes. That’s the base of, at this time of year, the active layer and shows you where the frozen front is, or permafrost.\nBentley: And then Alice does these kinds of measurements again but in a different area with the same setup.\nWilson: And so we can measure this to see how deep it is to permafrost in different areas. And then the other thing I can pull out is this. So this is a thermosphere chain, and so it has a logger on top recording all the information. And then each of these has a temperature sensor. So we know the temperatures over time at different depths.\nBentley: Alice drops the line down a PVC tube running deep beneath our feet.\nWilson: So this would be half a meter, one meter, meter and a half, two. And this one goes all the way down to three meters below the ground and into the permafrost.\nBentley: The researchers are hoping all of these data will help to better predict what exactly is going to happen to the North in the decades to come. Steve is a big believer in the importance of the research performed by his entire team.\nKokelj: We just haven’t built our infrastructure, considering all these things, right? So it’s kind of one of the important reasons to just study things, because if you don’t make these observations, you can’t kind of adapt your infrastructure to deal with this kind of stuff. Yeah, a lot of the challenges can’t be overcome unless you do basic science, right?\nBentley: Science, Quickly is produced by Jeffery DelViscio, Tulika Bose and Kelso Harper. Our music was composed by Dominic Smith. Like and subscribe wherever you get your podcasts. And for more science news, please go to ScientificAmerican.com.\nFor Science, Quickly, I’m Joc Bentley.\nFunding for this story was provided in part by Let's Talk Science, a charitable organization that has provided engaging, evidence-based STEM programs for 30 years at no cost for Canadian youth and educators.\nJocelyn Bentley started Science Media Creator in 2015. The science-focused production company has produced over 78 micro-documentaries, podcasts, and 360 videos profiling STEM across Canada. With degrees in film and neuroscience, Bentley has worked on broadcast productions for Smithsonian Channel, TVO, and the CBC. Follow Jocie Bentley on Twitter\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "'Morning After' Antibiotic Could Reduce STIs", "date": "2023-10-06 15:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nDraft CDC guidelines recommend doxycycline for the prevention of sexually transmitted infections in some populations\nA commonly used antibiotic could become a standard way to prevent sexually transmitted infections (STIs) such as chlamydia, syphilis and gonorrhea.\nOn October 2 the U.S. Centers for Disease Control and Prevention issued a draft guidance recommending that physicians prescribe doxycycline as a preventative therapy for certain people at high risk of acquiring STIs. If these guidelines go into effect, in addition to providing general sexual health counseling and STI screening, physicians could advise these individuals to take doxycycline as a postexposure prophylactic (PEP) after having unprotected sex. This strategy, known as doxy-PEP, “represents a new approach to addressing STI prevention,” the CDC wrote in a notice about the draft guidance.\nThe agency hopes that doxy-PEP, which can lower infection risk by half or more, could put a significant dent in the rising STI levels in the U.S. Between 2020 and 2021, the number of syphilis cases rose by 32 percent, while chlamydia and gonorrhea each rose by around 4 percent. “If we’re really honest about it, efforts to control STIs have failed, and we need to try something different,” says Edward Hook, an infectious disease researcher at the University of Alabama at Birmingham.\nScientific American talked with several experts about how well doxy-PEP works, why the CDC is not recommending it for everyone and what the risk of sexually transmitted bacteria becoming resistant to the drug is.\nWho should take doxy-PEP?\nBased on current evidence, the CDC is recommending that doctors only consider it for cisgender men who have sex with men (MSM), as well as for transgender women, when these individuals have had at least one STI within the past year. The prescription would be for a pill that would be taken once within 72 hours of unprotected sex.\nThe agency said that there is not enough evidence to recommend doxy-PEP to cisgender women and transgender men. That’s because few trials in this population have been completed to date. The only major study, conducted in 449 women in Kenya, found no significant reductions in STIs among those who took doxy-PEP, although hair analysis later showed that many of the women weren’t taking the antibiotic.\nJenell Stewart, an infectious disease physician at Hennepin Healthcare in Minneapolis, who led the trial in Kenya, says she agrees with the CDC’s recommendations, given current evidence. She adds that it’s possible doxy-PEP could work differently in men and women because different body parts are exposed to bacteria that go on to colonize the body in different ways. “We shouldn’t assume it’ll work the same in everyone,” Stewart says. Her team is now setting up more studies in the U.S. and Kenya to see whether doxy-PEP works in more populations.\nWhat is the evidence for doxy-PEP?\nPostexposure prophylaxis has long been used in HIV prevention: people at risk are advised to take antiviral drugs within 72 hours after unprotected sex. Researchers took a similar approach with doxycycline for STIs in several recent clinical studies—two conducted in France and one conducted in the U.S. The studies found that a single dose of doxycycline could more than halve the rate of bacterial infection in MSM and transgender women. The treatment was more effective against chlamydia and syphilis than gonorrhea.\nThe CDC has based its new recommendations on the design of the U.S. study, which focused on MSM and transgender women in Seattle and San Francisco who were at very high risk of acquiring STIs because they had frequent unprotected sex. “They’re the group that stands to benefit the most,” says study leader Annie Luetkemeyer of the University of California, San Francisco.\nIn a paper published in April in the New England Journal of Medicine, Luetkemeyer’s group tested doxy-PEP or a placebo in around 500 MSM and transgender women who had a median of nine sexual partners within a three-month period. The participants reported that 90 percent of their sexual encounters were unprotected, and each person had gotten at least one STI within the past year. Taking one dose of doxycycline within 72 hours of unprotected sex, Luetkemeyer found, reduced the risk of a bacterial infection by two thirds.\nAre scientists concerned about doxy-PEP worsening antibiotic resistance?\nSome experts worry that increased doxycycline use could drive antibiotic resistance in sexually transmitted pathogens. This is especially true of gonorrhea, which is particularly good at evading various antibiotics: around 25 percent of gonorrhea infections in the U.S. and the overwhelming majority of those in Kenya are already resistant to the class of antibiotics that includes doxycycline.\nThat could partly explain why one of the doxy-PEP studies in France, where around 60 percent of gonorrhea infections are resistant to antibiotics, found that the treatment had no significant impact on gonorrhea infection rates. “The issue of resistance in gonorrhea is not a matter of whether but when,” Hook says, although he adds he is an “enthusiast” about doxy-PEP in general.\nSo far there is little evidence that chlamydia and syphilis become resistant to antibiotics. Ongoing monitoring is needed, however. Scientists are also concerned that resistant bacteria could transfer genes that that confer antibiotic resistance to other bacterial species, which would be especially concerning because doxycycline is a go-to treatment for the bacteria that cause Lyme disease and leptospirosis.\nCould taking doxycycline have unintended effects on a person’s microbiome? \nResearchers are concerned that frequent doxycycline use could affect the normal, healthy bacteria that colonize the gut, vagina and other parts of the human body. This microbiome is involved in many aspects of health—everything from gut function to mental health—and disrupting the balance of bacterial species can affect these systems or lead to other infections. Luetkemeyer and Stewart both say they are testing rectal swabs and other samples from people in their study to see whether the antibiotic changed the assortment of bacteria that colonize various parts of the body.\nWhat will happen when the CDC finalizes its recommendations?\nIn October 2022 San Francisco’s health department released its own guidelines supporting doxy-PEP in cisgender men and transgender women who have had a bacterial STI and have had unprotected sex with at least one cisgender man or transgender woman in the past year. Several other health departments, including California’s, have issued similar guidelines. Luetkemeyer says it will be helpful to have national guidelines, which will ensure that doctors everywhere know that doxy-PEP works and feel comfortable prescribing it. When health systems were developing guidelines for HIV prevention in the past, “we did a poor job of reaching the people who needed it most,” Luetkemeyer says. “Having guidelines helps start the dialog.”\nResearchers are planning to continue testing doxy-PEP in different populations. If the approach proves successful, the CDC may expand its recommendations in the future to include cisgender women and men who have sex with cisgender women.\nThe CDC will receive comments on the draft guidelines until November 16, 2023, and has not said when it will release a final rule.\nSara Reardon is a freelance journalist based in Bozeman, Mont. She is a former staff reporter at Nature, New Scientist and Science and has a master's degree in molecular biology.\nIna Park | Opinion\nSteven W. Thrasher | Opinion\nJaimie Seaton\nLauren J. Young\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Climate Disasters Displaced 43 Million Children in Just Six Years", "date": "2023-10-06 18:30:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nThe Philippines, India and China have seen the greatest total number of children displaced by disasters—some 23 million—in recent years\nCLIMATEWIRE | Extreme weather events and climate disasters displaced more than 43 million children around the globe between 2016 and 2021, according to a new report from UNICEF. And the United Nations says tens of millions more children will suffer a similar fate as climate change worsens extreme weather worldwide.\nNearly 41 million displacements were driven by storms and floods alone, the report finds. Droughts and wildfires played a smaller, but still significant, role as well.\nThe Philippines, India and China saw the greatest total number of child displacements, with more than 23 million between them during the study period. That’s partly because India and China have the highest total populations in the world.\nBut other countries experienced greater losses relative to the size of their child populations, particularly small island developing nations and countries located in the Horn of Africa, the continent’s easternmost peninsula.\nThe number of displaced children on the island of Dominica from 2016 to 2021, for instance, was equivalent to 76 percent of the nation’s child population. These displacements were driven almost entirely by storms.\nReleased Thursday evening, the new report is among the first to estimate recent weather-related child displacements on a global basis. Children are often “statistically invisible” in existing databases, the report states, where displacement figures are rarely broken down by age.\nThe report doesn’t statistically distinguish between displacements caused by preemptive evacuations and those that were forced in the aftermath of extreme weather events. But it’s an important distinction for future studies to investigate. Properly managed evacuations can save lives and reduce the harm that families suffer when they’re suddenly displaced.\nYet many of the nations highlighted in the new report have limited resources for managed evacuations.\nSouth Sudan and Somalia saw 12 percent and 11 percent, respectively, of their child populations displaced by floods and drought during the study period. Yet these nations implement relatively few evacuations compared to wealthier countries, the report states, adding that “children living in these countries may be even more vulnerable to displacement risk.”\nThe report also employs a special model to predict future rates of child displacement. It suggests that tens of millions more children likely will be forced from their homes by climate disasters in the coming years.\nRiver floods will be a top driver, the model suggests, likely accounting for as many as 96 million displaced children over the next 30 years. A warmer atmosphere holds more moisture, and climate change is causing heavy precipitation events to intensify around the world, increasing the risks of catastrophic floods.\nCyclone winds could cause another 10.3 million child displacements over the next three decades, and storm surge could displace an additional 7.2 million.\nThe report highlights the need for greater investment in climate adaptation measures around the world, particularly in low-income nations, which house the world’s most vulnerable populations.\n“As the impacts of climate change escalate, so too will climate-driven movement,” said Catherine Russell, UNICEF’s executive director, in a statement. “We have the tools and knowledge to respond to this escalating challenge for children, but we are acting far too slowly. We need to strengthen efforts to prepare communities, protect children at risk of displacement, and support those already uprooted.”\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nChelsea Harvey covers climate science for Climatewire. She tracks the big questions being asked by researchers and explains what's known, and what needs to be, about global temperatures. Chelsea began writing about climate science in 2014. Her work has appeared in The Washington Post, Popular Science, Men's Journal and others.\nAndrea Thompson\nAndrea Thompson\nAnna Harwood\nMaya Earls and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "The Flu Vaccine Works--In a Way Most People Don't Appreciate", "date": "2023-10-09 10:45:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nThe CDC is emphasizing how the flu vaccine can turn the virus from “Wild to Mild”\nIt’s like clockwork: first comes a brisk fall breeze, then comes the public health push to get a flu shot. But the U.S. Centers for Disease Control and Prevention’s messaging this year might look a little different from previous vaccination seasons. The agency has launched a messaging campaign dubbed “Wild to Mild” that uses adorable critters to illustrate how a vaccine can tame a bout with the flu by reducing its strength from that of an elephant or a lion to that of a mouse or a kitten.\nThe framing might come as a surprise to those used to a blunter way of talking about vaccines: get vaccinated or get sick. But Wild to Mild is designed to be a more honest, nuanced portrayal of the benefits of the influenza vaccine, which scientists have long recognized is better at reducing serious infections than at preventing infection altogether.\n“We tend to take kind of a black-and-white approach to vaccines of ‘if you get vaccinated, it will keep you from getting that particular disease,’” says Sarah Bauerle Bass, a social and behavioral scientist at Temple University, who focuses on health and risk communication. “The pro is that it’s a very simple message; the con is that it doesn’t necessarily communicate the reality of vaccines, which is that sometimes you do get that disease even though you’re vaccinated.”\nThe amount of protection a vaccine offers depends on the disease it targets. For some shots, such as those for measles and polio, the black-and-white approach is essentially true, says William Schaffner, a professor of infectious diseases at Vanderbilt University. If you received the standard vaccine regimen as a child, your odds of ever catching those particular diseases are tiny: around 1 percent for each.\nBut flu doesn’t work the same way. Measles and polio are static viruses, whereas influenza mutates regularly, allowing it to evade our immune system even if it’s been trained to identify the pathogen via prior infection or vaccination. In addition, influenza is a family of viruses, and typically the flu vaccine administered in the U.S. targets only four strains. These strains are selected based on the ones that are circulating in the Southern Hemisphere more than six months before flu season begins in the North. Selecting which strains to target is a guessing game—one that scientists can’t always win.\nThese factors give the influenza vaccine a spotty record in preventing disease—at least to an untrained eye. “During well-matched seasons, we see [risk reduction] numbers pretty consistently within the range of 40 to 60 percent” among the vaccinated, says Erin Burns, associate director of communications for the influenza division at the CDC. “I think the public perception, maybe, is that that is less than impressive.”\nThe perceived “low” protection can cause people to hesitate about receiving the vaccine. “There’s a very widely held perception that the flu vaccine doesn’t work,” she says. “People think that if they get vaccinated, and then they get sick, the vaccine has failed.”\nBut that’s not an accurate view of what public health experts expect the flu vaccine to accomplish, Schaffner says, adding that he’s been encouraging the messaging pivot for years now. Mild influenza occurs mostly in the respiratory tract, where vaccine-induced defenses aren’t as effective because they can’t reach the surface of the mucus membranes in, for example, your nose, he says. That’s where the virus might first enter your body and cause flu’s mild symptoms, such as a runny nose—so vaccination doesn’t do much against these infections.\nInstead the vaccine produces defenses that are active deeper in the body—in the heart, liver and kidney, for example—and can stop the virus from sneaking into organs, where it can cause a severe to possibly life-threatening infection. For the flu, vaccination isn’t about reducing infections overall but instead about reducing the hundreds of thousands of hospitalizations and tens of thousands of deaths the disease causes in the U.S. each year.\nThe Wild to Mild campaign, Burns says, is designed to counter the idea that the flu vaccine doesn’t work and present a more accurate understanding of the shot’s purpose. “We were realizing that we needed to reset those expectations,” she says. She isn’t concerned that advertising the fact that the flu vaccine doesn’t offer total protection could reduce uptake because the perception of its failure is already so widespread.\nThe Wild to Mild approach also addresses another common misperception: that the flu isn’t a serious illness. CDC scientists are “emphasizing the severity of the disease without scaring people, and they’re empowering [people],” says Saad Omer, an epidemiologist and dean of the O’Donnell School of Public Health at the University of Texas Southwestern. “They’re saying, ‘It can be wild, but you can make it mild because you have the power to do that.’”\nHoward Markel, a physician and historian of medicine at the University of Michigan, says he sees a dramatic shift in the way the public has come to think about vaccines in general. “If you grew up in the 1940s, 1950s and 1960s, vaccines were like a gift,” Markel says. Shots were also mostly for children then, he notes, unlike the modern flu vaccine, with its annual campaigns targeting all adults.\nNow public perception of vaccines in general is much more neutral—and, in some cases, deeply skeptical—and views are politically polarized. “Our tolerance is less, too, for any error [or] anything less than perfection in our science and medicine,” he says.\nMeanwhile the CDC has struggled to sell some Americans on COVID vaccines—particularly in the form of annual shots that are available each fall, like the flu vaccine is. Temple University’s Bass says that the COVID vaccine has suffered from the same perception of ineffectiveness as the flu vaccine for similar reasons.\nBurns says the Wild to Mild campaign came about independently from the agency’s COVID experience, although flu vaccine uptake rates have dipped slightly since the pandemic’s first winter. “People are still more open to flu vaccines than they are to COVID vaccines,” she says.\nStill, public health officials acknowledge that some people will never get the flu vaccine, and they are focusing on vaccine education that will help increase uptake among undecided people. “You go into these campaigns knowing that you’re never going to get 100 percent of people,” Bass says. “What you’re really aiming for is that large group in the middle who might, with either the right messaging or the right messengers, be more likely to do that.”\nIn that way, Wild to Mild is an uncanny embodiment of the flu vaccine itself, which can’t prevent all infections but can nonetheless reduce the disease’s impacts. “We can do a lot of good with this vaccine,” Schaffner says. “We can turn wild to mild while we’re waiting for the perfect science to give us the perfect flu vaccine. It’s not here yet. Let’s do the best we can with what we have today.”\nMeghan Bartels is a science journalist and news reporter for Scientific American who is based in New York City.\nTara Haelle\nJim Daley\nFerris Jabr\nTanya Lewis\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Zoom Time May Be Linked to Discontent with One's Own Appearance", "date": "2023-10-09 11:00:00", "text": "Nobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nNobel Prize Sale!\nHow do people make peace with the image reflected back at them in a video conference?\nThe following essay is reprinted with permission from The Conversation, an online publication covering the latest research.\nThe COVID-19 pandemic ushered in a new era of digital connection: In the absence of in-person gatherings, many people instead found themselves face-to-face with their co-workers and loved ones on a screen.\nVideoconferencing has provided many benefits and conveniences. However, it isn’t surprising that constantly seeing ourselves on screens might come with some downsides as well.\nPrior to the pandemic, studies showed that surgeons were seeing increasing numbers of patients requesting alterations of their image to match filtered or doctored photos from social media apps. Now, several years into the pandemic, surgeons are seeing a new boom of cosmetic surgical requests related to videoconferencing. In one study of cosmetic procedures during the pandemic, 86% of cosmetic surgeons reported videoconferencing as the most common reason for cosmetic concerns among their patients.\nDespite the fact that many aspects of life have returned to some version of pre-pandemic normal, it’s clear that videoconferencing and social media will be with us for the foreseeable future. So what does that mean when it comes to appearance satisfaction and making peace with the image that’s reflected back at us?\nFor the past 10 years, I have worked as a specialist in obsessive-compulsive disorders, eating disorders and anxiety. Since the pandemic, I, too, have seen increasing numbers of therapy clients reporting that they struggle with appearance concerns related to videochatting and social media.\nEvery person has perceptions and thoughts about their appearance. These can be neutral, negative or positive. We all look at ourselves in the mirror and may have even experienced distress while looking at our reflection.\nThere are a number of factors that may lead to appearance dissatisfaction. A preoccupation with thoughts, feelings or images of one’s own appearance is linked to the action of “mirror gazing,” or staring at one’s reflection. Researchers suggest that this type of selective self-focused attention and mirror gazing can lead to negative fixations on specific attributes or minor flaws, which in turn intensify the preoccupation with these attributes.\nOther factors that can contribute to appearance dissatisfaction include low self-esteem, societal beliefs around appearance, peer and parental influences, temperament and genetic predispositions to mental health conditions.\nAppearance dissatisfaction and negative evaluations of self are associated with depression, lower self-esteem, habitual negative thinking and increased social anxiety. What’s more, research suggests that these preoccupations can contribute to the development of eating disorders and disordered eating behaviors, such as frequently restricting food intake or exercising without refueling.\nWith the ubiquity of Zoom meetings, FaceTime calls, selfies and the constancy of documenting our lives on social media, access to our own image can often feel inescapable. And for some people, this can magnify feelings of appearance dissatisfaction that may have been more fleeting before the Zoom era.\nSince the pandemic, screen time has increased for both adults and children. What’s worse, recent research suggests that the video and photo reflections we see of ourselves are distorted.\nVideoconferencing, taking selfies and posting on social media are visually based activities where appearance is often the primary focus. All of them have in common the fact that a person’s image is either live or shared in an immediate manner. Perhaps not surprisingly, these image-based platforms have been significantly associated with appearance dissatisfaction, anxiety, depression and eating disorders.\nOne study found that those who engaged in more videochatting appearance comparisons, meaning those who looked at others’ appearance during a video call and sized up their own appearance in comparison, experienced lower appearance satisfaction. This study also found that people who used more photo-editing features on videochat platforms were more likely to compare themselves with others and spend more time looking at themselves on video calls.\nOne thing that is unique to videoconferencing is that it allows people to easily compare themselves with others and watch themselves sharing and speaking in real time. A 2023 study found that discomfort with one’s appearance during videoconferencing led to an increased fixation on appearance, which in turn led to impaired work performance.\nResearchers also suggest that appearance dissatisfaction is associated with virtual-meeting fatigue. The research reports that this could be due to negative self-focused attention, cognitive overload and anxiety around being stared at or being negatively evaluated based on appearance.\nThis last point is notable because of the difficulty videochatters have determining where other users are looking. Using the concept of the “spotlight effect” − our tendency as humans to overestimate how much others are judging our appearance − this difficulty may lead to more anxiety and individuals believing that others are evaluating their appearance during a video call.\nIf you find yourself criticizing your appearance every time you hop onto a videoconference call, it may be time to evaluate your relationship with your appearance and seek out help from a qualified therapist.\nHere are some questions to consider to help determine whether your thought patterns or behaviors are problematic:\nHow much of my day is spent thinking about my appearance?\nWhat sort of behaviors am I doing around my appearance?\nDo I feel distressed if I do not perform these behaviors?\nDoes this behavior align with my values and how I want to be spending my time?\nAnother strategy is to be intentional about focusing on what other people are saying in a videoconference instead of peering at your own face.\nWhen it comes to helping others who might be struggling with appearance dissatisfaction, it is important to focus on the person’s innate qualities beyond appearance. People should be conscious of their comments, no matter how well intentioned. Negative comments about appearance have been linked to worsened self-esteem and mental health. When viewing yourself or your peers on video and social media, try focusing on the person as a whole and not as parts of a body.\nReducing screen time can make a difference as well. Research shows that reducing social media use by 50% can improve appearance satisfaction in both teens and adults.\nWhen used in moderation, videoconferencing and social media are tools to connect us with others, which ultimately is a key piece in satisfaction and well-being.\nThis article was originally published on The Conversation. Read the original article.\nEmily Hemendinger is an assistant professor of psychiatry at the University of Colorado Anschutz Medical Campus.\nJocie Bentley\nEmily Hemendinger and The Conversation US\nMeghan Bartels\nChelsea Harvey and E&E News\nSara Reardon\nJocie Bentley\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "This Indigenous Community Records the Climate Change That Is Causing Their Town to Erode Away", "date": "2023-10-09 14:00:00", "text": "In a tiny village north of the Arctic Circle in Canada, the Inuvialuit of Tuktoyaktuk have taken climate science into their own hands. \nJocie Bentley: So what’s behind you right now?\nWilliam Dillon, Jr.: What’s behind me? It’s all our old grounds for our garage. It will be falling into the ocean probably next year. It lost five feet this year of ground, fell in. Yeah, lost five feet.\nBentley: I’m in Tuktoyaktuk, a.k.a., Tuk. It’s a tiny village 200 miles north of the Arctic Circle in the Northwest Territories in Canada.\nI’m talking to William Dillon, Jr., aka Billy. He’s a respected elder in the Inuvialuit community that lives here—and also the sweetest guy. Within minutes of meeting us, he made us delicious smoked tea, and now he’s giving us a tour.\nBut it’s a tour of what used to be.\nDillon: And, uh, our old school and old folks’ home is next to go. And our graveyard, we’ve moved our graveyard already, but we haven’t moved the people in the graveyard yet.\nBentley: His community is being taken back by the ocean in real time. But he’s not just watching it happen. He’s documenting it scientifically.\nDillon: It’s just basically recording, recording, recording, and monitoring and just make sure that everybody’s aware of how fast it is melting.\nBentley: I’m Joc Bentley, and this is part two of our three-part Science, Quickly Fascination from a fast-warming Arctic. In today’s episode, I’m riding with Inuvialuit climate monitors. These inspiring locals are taking charge and are measuring climate change in real time. We’re on a boat to Tuk Island, a small but extremely important barrier that’s protecting the village’s harbor. But it’s disappearing.\nDillon: Yeah, basically, if we lose this island, we lose the harbor. The harbor will be too exposed to the Arctic Ocean elements. Yeah, this is our safety barrier island. Nice name, safety barrier.\nJames Keevik: It’ll be gone in 20 years, though, no matter what.\nDillon: Yeah.\nBentley: That was James Keevik talking to Billy, by the way. They’re part of this new citizen      science team. And I asked them ...\nBentley (tape): So what’s happening to the island?\nDillon: It’s eroding with all this new climate change we’re [seeing] happening here. In fall time, we see more erosion than ever before. Like, for now, we’re having a hard time landing our boat here, ’cause the erosion has filled in all this area with sediment. You know, we just, we have to keep aware. Our hunting and traveling, have to keep aware all the time. And nothing is the same anymore.\nShallow all over here, too, James.\nBentley: James and Billy work their magic, and we finally get off the boat and onto the island. Eriel Lugt, the team’s coordinator, is directing the data collection.\nEriel Lugt: We have stakes already in the spots, and we’re going to measure the distance from the stakes.\nBentley: These stakes are a reference point so the team can accurately measure erosion on each side.\nDillon: We centimeters or feet?\nKeevik: Inches.\nDillon: Inches. Ooh, I’m reading nine feet, nine and a quarter.\nBentley: Eriel is only in high school, but she’s already been asked to speak all over the world about what’s happening up here.\nLugt: Uh, we have, like, four climate monitors. Yeah, any local Inuvialuit could be a climate monitor. Right now we’re monitoring the erosion on this island. And the erosion will, like, wipe away our whole town if it keeps happening. This island is, like, a barrier from the ocean to the harbor. It’s really beautiful, and it’s very cultural. Uh, it’s kind of sad. I hope in the future we can find a solution.\nBentley: Hopefully these data can help to create a plan to save the island, save the harbor and save Tuk. Dustin Whalen is a physical scientist at the Geological Survey of Canada. He was here, setting up the program with Billy, Eriel and James, but I just missed him by a couple of weeks. So I gave him a call to chat about the North.\nWhalen: In the community of Tuk, you could argue this is the area in Canada where we see the most impact of climate change. Because of this, the citizens that live in this area want to take a stand. They want to understand what they’re seeing in their own backyard. So community-based monitoring, this idea for, you know, looking at some of the information, the climate information, on their own, taking the observations for themselves, looking at the science so they can be in charge, and they can be the stewards of their own data—this is what really spurred on this community-based monitoring program.\nBentley (tape): The erosion they’re measuring isn’t just a product of increased permafrost thaw, right? How does the reduction in ice coverage come into play?\nWhalen: Now you’re seeing a lot more storms because there’s more open water. As the wind kicks up, it increases the swell in the wave potential in the water, and then that grows, o bviously, if you have more distance between that than the coast—so when the storms reach the coast there, they’re a lot bigger than they were before.\nBentley (tape): What does this mean for the Inuvialuit living in Tuk?\nWhalen: I have learned through my career that the Indigenous peoples are very resilient, and they’re resilient to change. They have seen change over centuries of existing on this planet, and they have learned to adapt. So I have all the confidence in the world that the people living in the North will adapt to this change in some form or another. But I have less, less confidence that if the world is faced with the same changes that the Northerners are seeing, they may not be as resilient.\nBentley: Back in Tuk, Billy is hopeful for the future. I asked Billy what advice he had for the next generation.\nDillon: Keep hugging those trees, kids. Be helpful. Don’t litter, because this is the main problem we have all over the world, with litter. And be respectful to your elders, to your land and water, and be respectful to the air you breathe. Thank you.\nBentley: Science, Quickly is produced by Jeffrey DelViscio, Tulika Bose and Kelso Harper. Our music was composed by Dominic Smith. Like and subscribe wherever you get your podcasts. And for more science news, please go to ScientificAmerican.com.\nThis podcast was produced in partnership with Let's Talk Science.\nI’m Joc Bentley, and this is Science, Quickly.\nFunding for this story was provided in part by Let's Talk Science, a charitable organization that has provided engaging, evidence-based STEM programs for 30 years at no cost for Canadian youth and educators.\nJocelyn Bentley started Science Media Creator in 2015. The science-focused production company has produced over 78 micro-documentaries, podcasts, and 360 videos profiling STEM across Canada. With degrees in film and neuroscience, Bentley has worked on broadcast productions for Smithsonian Channel, TVO, and the CBC. Follow Jocie Bentley on Twitter\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Thousands More Puzzling 'Fairy Circles' Have Been Found around the World", "date": "2023-10-10 10:45:00", "text": "Digital offer!\nDigital offer!\nThese mysterious spots of barren soil have fascinated scientists for years. Now evidence of their existence beyond two known locations is stirring up a fresh round of contention\nIn the remote grasslands of southwestern Africa’s Namib Desert and the Pilbara region of Australia some 6,000 miles away, large, barren circles crowd the landscape, like holes stamped out by a cookie cutter in a sheet of dough. The peculiar pockmarks, called “fairy circles,” were thought to exist exclusively in those two arid stretches. But new research published recently in the Proceedings of the National Academy of Sciences USA has uncovered 263 additional sites where fairy circles might exist in areas from Madagascar to southwestern Asia.\nFor years, fairy circles—named for their resemblance to the circular formation of mushrooms known as “fairy rings”—have fascinated scientists and stirred up an intense debate over their provenance. Even now, there is no obvious reason to explain why these circular patches of soil exist within some of Earth’s most inhospitable and arid terrains. The new study may complicate efforts to answer that question.\nThe researchers trained an artificial intelligence model to comb through more than half a million satellite images of dryland regions looking for patterns that mimicked known fairy circles. Among the new locations with potential fairy circles, the researchers found common soil and climate characteristics, such as low nitrogen and a lack of rainfall, respectively. Because the study used an observational approach, the results can’t pinpoint the mechanism behind the patterns, says lead author Emilio Guirado, applied and environmental scientist at the University of Alicante in Spain. But the findings suggest fairy-circle-like patterns are most likely to exist in soil with very low moisture.\nSeveral explanations offered in the past—such as toxins from the leaves of plants in the genus Euphorbia or gaseous emissions from below the ground—have fallen out of favor. Only two theories seem to persist in the ongoing debate: The first, proposed by ecologist Norbert Jürgens, holds that competing colonies of underground sand termites left the circular stamps. He believes the termites engineer their surroundings by chewing through the roots of the grass to create a kind of reservoir for storing water. The second, endorsed by ecologist Stephan Getzin of the University of Göttingen in Germany, among others, proposes that the grasses are the ecosystem engineers and self-organize into the circular patterns. That theory contends that grass takes advantage of the circular gap as a water resource and wouldn’t be able to survive in the arid landscape without the geometric formation. (Neither Jürgens nor Getzin were involved with the new paper.)\nFiona Walsh, an ethnoecologist and staff member of the University of Western Australia, has studied the phenomenon in Australia but was not involved in the new research. Her work incorporates the knowledge of the local Martu people, an Aboriginal group that calls the circles linyji. Walsh’s research describes the circles as termite pavements. “They’re the roofs of subterranean termite cities; that’s a way to visualize them,” she says. “The roofs are concrete-hard and have very low or no mounds.” But she says the origin of the phenomenon remains unclear, and the termites are one player in a larger system.\nUnderstanding why fairy circles, or FCs, form is just a single piece of the puzzle. Scientists haven’t even yet agreed on a precise definition. “There is no universally agreed definition of what a fairy circle is,” says Fernando Maestre, a University of Alicante ecologist and co-author of the new paper. He and his colleagues used the term “FC-like” for the patterns identified in their research that share the same main characteristics of the fairy circles reported in Namibia and Australia.\nOne of these characteristics is a spatially periodic pattern: the tendency of fairy circles to exist in a gridlike formation with very little variation in the distances between them, Getzin says. His previous research had posited that fairy circles are arranged in a hexagonal formation in which one circle is a focal point, positioned in the center of six others and at approximately the same distance from each.\nNone of the patterns in the new research, Getzin says, fit that description exactly (though he does think the authors did a “very good job” in identifying the environmental drivers of vegetation gaps in dryland areas). “The study dilutes the term fairy circles, and it ignores the definition of fairy circles in the process,” he says. Getzin adds that the findings confirm “true fairy circles” only exist in the Namib Desert and Western Australia. Even with the systematic global search in the new study, he says, “the authors failed to find spatially periodic vegetation gaps that are as strongly ordered as the genuine fairy circles.”\nWalter Tschinkel, a Florida State University biologist, who has previously studied fairy circles and was not involved in the new study, agrees. “You’d have to convince me that they’re fairy circles; they’re not regular enough,” he says. “These are just gaps in vegetation,” a broad description of a variety of distinct, self-organized patterns in nature that usually form to transport water in dry landscapes. “In arid zones, vegetation is rarely a uniform carpet, it always consists of a lumpy distribution,” Tschinkel says.\nMichael Cramer, an ecologist at the University of Cape Town in South Africa, who researches spatial patterns in ecosystems and also was not involved in the new research, says its application of AI technology to this field is a major step forward. He also questions some of the results, however. In particular, he says, a few of the patterns are too small—just six feet across—compared with known fairy circles, which tend to span about seven to 39 feet across. A number of the sites deserve a visit to confirm the existence of the circles, Cramer notes.\nLead author Guirado says the critiques “are not well-founded and do not undermine our findings in any way,” in part because there is not a precise definition of the phenomenon.\nWalsh says the new research “clearly shows this pattern is widespread within Australia” and that the circle formations there don’t exist in isolation—they resemble other patterns found around the world.\nThe study authors remain undeterred by the mixed responses to their paper. “As expected in a topic as hotly debated as fairy circles, some researchers have criticized our work, and others have supported it,” Maestre says. He hopes the findings will open the door to novel research on the patterns in these new locations.\nLori Youmshajekian is a New York-based science journalist covering health and the environment. She was previously a TV and video journalist at Australia's national broadcaster, the ABC, focusing on pandemic policy and international news. In 2020, she won two journalism awards for her contributions to a campaign supporting the survivors of sexual assault. She is currently pursuing her master's degree at NYU in science, health and environmental reporting. Follow Lori Youmshajekian on Twitter\nLisa Margonelli\nChristopher Intagliata\nStephanie Pappas\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "New Glasses Can Transcribe Speech in Real Time", "date": "2023-10-10 12:00:00", "text": "Digital offer!\nDigital offer!\nGlasses that provide subtitles for conversations could be a boon to people with hearing loss\nWhen Paul Shuttleworth bought himself a very expensive pair of eyeglasses for Christmas last year, it was a peculiar gift. The glasses didn’t improve his eyesight, weren’t particularly stylish and uncomfortably pressed down on his nose.\nBut these glasses are a vital tool for him.\nShuttleworth, age 40, a resident of Manchester, England, is profoundly deaf in both ears and uses a mobile live audio transcription app as his main conversational tool. But the glasses have helped him talk and participate in conversations in ways that he had never been able to before. These fancy shades automatically transcribe the words someone is saying and display the text as subtitles on the lenses in front of his eyes.\nThe buzz is building for such “live-captioning glasses,” and a slew of companies have rolled out their own versions in the past few years. These high-tech glasses have the potential to help people who are deaf or hard of hearing communicate more seamlessly with hearing people. But they aren’t perfect, and they may never fully replace human translators.\nIn July Tom Pritsky, co-founder of TranscribeGlass, put out a TikTok video that demonstrated his company’s live-captioning glasses providing subtitles for words that he spoke, and it went viral. These glasses are not just a technological fad for Pritsky, who has moderate to severe bilateral hearing loss. They actively improve his quality of life and ability to converse with people. “It helps me fill in the blanks,” says Pritsky, a graduate student in biomedical informatics at Stanford University. He also wears hearing aids. “The hearing aids give me audio, but it’s unclear, and I miss words,” Pritsky says. “If I can fill in some of those words via captions and subtitles, then it helps me continue to understand the conversation and not lose the thread.”\nLive-captioning glasses are now starting to hit the market, thanks to improvements in speech recognition technology and battery life. Nearly 2.5 billion people are projected to have some kind of hearing loss by 2050. Experts say that older people with hearing loss are the most likely to benefit from these glasses. Many older people need hearing aids but do not wear them because of stigma and difficulty adapting to the technology. Live-captioning glasses often resemble regular glasses, which are already more normalized in society than hearing aids are.\nGiving older people with age-related hearing loss access to live captioning may improve their social relationship with family and friends, says Thad Starner, a computer science professor at the Georgia Institute of Technology. In the early 2010s Starner helped develop Google Glass, a now discontinued device resembling eyeglasses that projected information on a tiny prism in front of the wearer’s eye.\nReal-time captioning is not a totally new technology. People who are deaf or hard of hearing routinely use apps such as Otter to transcribe a conversation as they’re having it. But having to ping-pong between the person they’re talking with and their phone can be frustrating and exhausting. Having captions in your field of vision is a game changer, Pritsky says.\nMost live-captioning glasses are composed of the glasses themselves, a tiny microphone, an onboard computer that processes speech, a battery and some way to display text. Some glasses contain all of these components, whereas other devices sit on top of a regular pair of glasses. Improvements in speech recognition software have really enabled these technological advances, says Dan Scarfe, CEO of XRAI Glass, a company that makes a speech-processing app that can be used with an array of live-captioning glasses. “I don’t think we’re more than six months away from a killer piece of hardware that you can absolutely use for this. Then it’s just a question of finding people who want to use it,” he says.\nDespite the media buzz, a relatively modest number of live-captioning glasses have been sold. Scarfe says more than 5,000 people are part of XRAI Glass’s pilot program, and Pritsky says “thousands” have ordered TranscribeGlass.\nNevertheless, these sales represent a significant step forward for the technology, says Starner, who has been a part of the field since its infancy. Starner, a wearable computing aficionado, has been wearing some kind of head-mounted display almost every day for 30 years. “It used to be that in order to have a head-borne display that had any sort of battery life, you ended up carrying around seven pounds of lead weight with you,” says Starner, who used to carry a battery in a shoulder bag. “Literally, my first battery was a motorcycle battery.”\nStarner has seen a lot of technological failures during the past three decades. But now he believes that the current crop has promise and that live-captioning glasses will soon be a normalized, household technology because of more portable batteries and speech recognition upgrades. For this to happen, society’s attitudes toward the glasses must continue to shift. The devices need to become unremarkable, he says. “Suppose I walk up to somebody at the airport, and I ask, ‘Can I get directions to the bathroom?’ And the person says, ‘Oh, is that the new Apple head-borne display?’ What you really want to do is get to the bathroom. You want the conversation to be about the conversation, not about the technology,” Starner says.\nWhile live-captioning glasses could be an incredibly powerful tool for millions of people, they are not a complete solution. For many people with hearing loss, understanding a hearing friend in a crowded restaurant is a nightmare. Similarly, live-captioning software struggles to capture accurate conversation in these spaces. Background noise remains a thorny issue that these glasses do not yet fully solve.\nMany people who are deaf or hard of hearing are excited by this technology, but some see it as a threat to requests for sign language interpreters. Captions do not display a speaker’s identity, emotions or inflections; interpreters can convey all of that context.\nThese glasses also place the burden of communication on the people using them—expectations that Deaf people are tired of having to meet, says Raja Kushalnagar, a professor and director of the Information Technology program at Gallaudet University. “The hearing person might think that, you know, ‘What’s wrong with you? What’s wrong with the glasses?’” he says. “They think it’s not the tools but the [Deaf people] themselves who are the problem.”\nThese glasses are mainly a tool to interface with the larger hearing public—Deaf communities that primarily use sign language have no need for them. But Kushalnagar has already seen the technology’s impact on his everyday life when conversing with his hearing son. “Say I’m cooking now—chopping vegetables or something in the kitchen. I’ll be able to read the captions while I’m still cutting,” he says. “I would never have been able to have that conversation with my son before like that. Now I can walk, and I can speak with my son at the same time.”\nWhen Shuttleworth took a test a few years ago to become an IT technician, he passed with distinction because he had been given resources necessary for him to understand the information. Shuttleworth now uses his glasses alongside his mobile app at his job. He desperately wishes he had been given access to these tools growing up, tools that could have changed his whole life’s trajectory. “If I had that mobile app and the glasses, I wouldn’t be sitting here talking to you now,” he says.\nTimmy Broderick is a freelance science journalist and former news intern whose work focuses on energy, disability and disaster at Scientific American. Follow them on Twitter @broderick_timmy\nLydia Denworth\nCorinna E. Lathan and Andrew Maynard\nNita A. Farahany | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Broken U.S.-China Science Cooperation Needs Repair, Not Persecution", "date": "2023-10-10 13:00:00", "text": "Digital offer!\nDigital offer!\nScience plays an enormous unseen role in keeping international avenues of contact open, even when political doors slam shut. We need to keep those channels open with China\nWhen Stanford University physicists Steve Kivelson and Peter Michelson received word that the Agreement between the United States and China on Cooperation in Science and Technology might not be renewed just a week before its expiration in late August, they spent the weekend composing a strongly worded letter of objection to the Biden administration. They argued that the agreement, first signed in 1979 and renewed approximately every five years since, should not lapse. Instead every effort should be made to nurture open and transparent scientific cooperation.\nBy August 27 they’d collected more than 1,000 endorsements from distinguished U.S. scientists. The urgency of their message reflects widespread outrage over scientific collaborations in fields ranging from physics to cancer research that were shattered by the Department of Justice’s four-year-long China Initiative, which officially ended in 2022. The initiative’s McCarthy-style bullying, aimed at disrupting research collaborations perceived as benefitting China at the expense of the U.S., cost hundreds of scientists their jobs and funding, wrecked dozens of productive research relationships and spread fear among valued Chinese collaborators. In 2021 thousands of Chinese scientists who previously would have remained at top U.S. research institutions left for China. These were “talented, idealistic and productive immigrants and visitors,” Kivelson told me.\nFailing to repair relations puts the U.S. in danger of what amounts to scientific “suicide,” according to the Guardian. U.S. scientists have lost access to advanced Chinese labs, massive data sets and teams of highly trained graduate students. Kivelson’s own field, quantum materials, he told Nature in August, “is highly dependent on and benefits from cooperation with colleagues in China.” Chinese colleagues sent their best students to Stanford. Once home in China, these students would attest to the freedom and richness of opportunities in the U.S. “That makes it that much harder for the Chinese Communist Party to portray the U.S. as a monolithically and ruthless adversary,” said Kivelson.\nThe increasingly intrusive meddling is based on largely bipartisan fears that China will steal U.S. secrets, turning our own research against us. U.S. scientists are not naive: China’s ever more authoritarian government presents a real threat, especially in terms of economic competitiveness and military capabilities. U.S. universities are built on and committed to open research and publication, however. “A university like Stanford is not Los Alamos National Laboratory,” Kivelson said at a recent talk given to Asia Pacific American Justice Task Force.\nAs someone who has been observing international scientific collaborations for many decades—and seen previous iterations of these kinds of crackdowns—I’ve come to conclude that U.S. policymakers don’t understand what science is actually “for.” Of course, the primary business of science is to discover how the universe and everything in it works. But beyond advancing knowledge, science plays an enormous, often unseen role in keeping avenues of contact open even when political borders slam shut. Like the arts, science is an essential part of our common humanity. Scientists share a common language and have ways of connecting that elude politicians; sometimes they provide the only glue that holds a fracturing world together. They allow enemies as well as allies to keep tabs on each other.\nDuring the Vietnam War, I visited the Stanford Linear Accelerator Center (now the SLAC National Accelerator Laboratory) and was surprised to see that physicists from warring nations were collaborating on experiments. SLAC’s founder and director, Pief Panofsky (who was also deeply involved in the Manhattan Project) explained that these contacts were a critical way to learn, as he put it, “that your enemy isn’t 10 feet tall—or 10 inches tall.” In terms of national defense alone, scientific isolation works against the U.S. Most historians agree that one of the primary reasons the U.S. got the bomb and Hitler didn’t was that Jewish scientists had been forced to flee Germany. Lieutenant General Leslie Groves permitted many brilliant scientists with known left-wing politics to join in the project. Expertise trumped ideology.\nI was introduced to physics by Frank Oppenheimer, J. Robert Oppenheimer’s younger brother, as a young journalist and spent many hours with bomb scientists. I have since spent decades listening to scientists talk not just about their work but also about how they see the role of science in society. I have consistently been impressed by how highly they value collaborations as ways of keeping countries and people connected.\nNobel laureate chemist Roald Hoffmann, a Holocaust survivor, brought together 13 young chemists, six of whom were women, from Israel, Palestine, Iran, Saudi Arabia and Syria to a small village in Jordan to study molecular bonding in 2006. Bombs went off in Amman, Jordan, hotels two months before the conference. A bomb went off in Tel Aviv the day the conference ended. The young people calculated orbitals by day, played music and cooked food for each other in the evening. “An Israeli student had never spoken socially to an Arab scientist,” Hoffmann wrote in an essay. “An Iranian, initially puzzled, learned why Jews wanted to live in Israel.”\nIn a 2006 interview with Nature, Hoffman was asked whether the workshop’s topic, “chemistry bonds,” was a metaphor. He replied, “Atoms bond because they don’t have a choice.... But people do have a choice.”\nFrank Oppenheimer discovered novel properties of cosmic rays before the Red Scare cut his career short. During his years in exile as a cattle rancher, he thought a great deal about science and peace. He thought that politicians would do well to learn from the honesty and transparency required in science, a field where violators are expelled. Politics, he said, would benefit enormously if liars were banned from holding office.\nMore foundationally, Frank saw science as a part of common culture far more deeply embedded in people than nearly always transient geopolitical conflicts. His closest friend, physicist Robert Wilson, famously threw up after learning that the bomb he helped to build was dropped on the people of Hiroshima. He went on to build a world-class scientific laboratory—the Fermi National Accelerator Laboratory (Fermilab)—the whole of the lab intended as an art installation.\nFrank loved to quote his friend’s defense of the expense of Fermilab. When Wilson was repeatedly asked in a 1969 hearing by Senator John Pastore of Rhode Island to explain the value of high-energy physics for national defense and competition with Russia, he answered that it had none:\n“It only has to do with the respect with which we regard one another, the dignity of men, our love of culture.... It has to do with: Are we good painters, good sculptors, great poets? I mean all the things that we really venerate and honor in our country and are patriotic about. In that sense, this new knowledge has all to do with honor and country but it has nothing to do directly with defending our country except to help make it worth defending.”\nThese words should not be forgotten when we ask what science is “for.”\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.\nKC Cole is the author of eight nonfiction books, most recently a personal biography of Frank Oppenheimer. She is senior senior correspondent for Wired and teaches The Science of Human Values, a class in the Honors Program at the University of Washington.\nJoanna Thompson\nJohn Fialka and E&E News\nDavide Castelvecchi and Nature magazine\nAndrea Thompson\nMeghan Bartels\nKC Cole | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Solar Storms Can Hinder Bird Migration", "date": "2023-10-10 16:00:00", "text": "Digital offer!\nDigital offer!\nNew research suggests that solar storms interfere with the magnetic compass that birds use for long-distance travel\nThe same solar storms that can paint the polar skies with dancing lights might also interfere with a very different phenomenon: bird migration.\nNocturnally migrating birds are less likely to fly—and in some cases, more likely to drift where the winds take them—during space weather events that disturb the magnetic field that surrounds our planet. That’s the same field that, among other cues, birds use to guide their paths, according to research published on Monday in the Proceedings of the National Academy of Sciences USA. The study focused on birds that move at night, as most migrators do, particularly perching birds such as warblers, thrushes and sparrows.\n“We really didn’t know what we would find at all, because at face value, [linking] space weather and bird migration sounds kind of wacky,” says Ben Winger, an ornithologist at the University of Michigan and senior author of the new research paper. “But we do know that birds use the magnetic field, and the magnetic fields do get disrupted, so there ought to be a relationship.”\nSpace weather includes the solar wind of charged particles that constantly streams across the solar system; coronal mass ejections that send blobs of the sun’s plasma into space; and solar flares that shoot bursts of radiation from our star.\nEarth’s magnetic field swathes our planet in a protective bubble that blunts the worst of the sun’s outbursts, but strong events can still affect human infrastructure such as GPS satellites and power grids. And some of this weather can affect the magnetic field in ways that are not perceptible to humans.\nTypically, studies of magnetic sensing in birds have focused on individual animals and have tested how they responded to exposure to an artificial magnetic field, for example, or a fake night sky with star positions that didn’t match their magnetic location. But Winger and his colleagues decided to look at bird behavior in real life and on a much larger scale by using data generated by radar stations employed for weather forecasting. During spring and fall migrations, birds take to the sky in such quantity that radar stations can tally the number of animals in flight.\nWhen the researchers compared 23 years’ worth of radar data from across the central U.S. with magnetic field measurements from the stations, the scientists found a noticeable decrease in the sheer number of birds migrating on nights with high geomagnetic activity.\n“I’m not surprised that disturbance in the field has an effect,” says Marilyn Ramenofsky, a behavioral endocrinologist at the University of California, Davis, who specializes in bird migration and was not involved in the new research.\nWinger and his colleagues looked at spring and fall migrations separately and factored in each night’s cloud cover because birds are also known to use the stars to navigate, among other resources. In general, the birds seemed to be more sensitive to space weather disturbances in the fall—when they would have faced less pressure to arrive promptly and when the year’s hatchlings would have been making their first migration—as well as on cloudy nights, the researchers found.\n“It shouldn’t be surprising to us that they can respond and that they’re flexible and that this doesn’t show them for a complete loop and that they use other cues,” Ramenofsky says. “There’s so much information out there, and birds tend to use it all.”\nBoth she and others noted, however, that the study only identified a potential association between magnetic field disturbances and bird behavior. It’s possible that some third variable is affecting both. “With correlations, it’s always very hard to draw conclusions,” says Nele Lefeldt, a neuroscientist at Rice University, who was not involved in the new research. “That being said, this group of scientists definitely did a really good job getting as close as they can to the answer with the means that they had.”\nOverall, the study is a reminder to look beyond humans’ sensory capacities when trying to understand the behavior of nonhuman species.\n“Humans don’t perceive these magnetic fields, so we don’t perceive a magnetic storm the way we would a weather storm, and so we have no idea that there’s something going on that’s a problem, whereas it turns out that birds are perceiving an actual disturbance,” Winger says. “It suggests that these things happening in space that seem like they’re not relevant to Earth actually are.”\nMeghan Bartels is a science journalist and news reporter for Scientific American who is based in New York City.\nMeghan Bartels\nPeter J. Hore and Henrik Mouritsen\nJacob Job\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "South America's Winter Hot Spell Was 100 Times More Likely with Climate Change", "date": "2023-10-10 16:30:00", "text": "Digital offer!\nDigital offer!\nA heat dome that baked parts of South America in late September was made much more likely and at least 1.4 degrees Celsius (2.5 degrees Fahrenheit) hotter by climate change\nAugust and September mark the end of winter in the Southern Hemisphere, but a large swath of South America spent much of that period in deadly heat that felt much more like summer. Late in this past winter, millions of people in Brazil, Bolivia, Argentina and Paraguay experienced temperatures that exceeded 40 degrees Celsius (104 degrees Fahrenheit)—an event that was made 100 times more likely, and significantly hotter, by climate change, according to a new rapid analysis.\n“Worryingly, temperatures above 40 degrees C in spring are becoming common in many parts of the world,” said Izidine Pinto, a researcher at the Royal Netherlands Meteorological Institute and a member of the international World Weather Attribution (WWA) team that conducted the analysis, in a press release. “This is the reality of our rapidly warming climate. We’re now experiencing more and more dangerously hot days each year.”\nSouth America’s unseasonable heat wave has significantly affected crops such as coffee and has killed at least four people—but likely many more because the full scope of the heat-related deaths will take weeks or months to become clear. It has been just one of the many punishing heat events that have affected tens of millions of people around the world in recent months. Such soaring temperatures have combined to help set several global records this year: July was the hottest month in human history, the three months from June to August were the hottest three-month period, and September was likely the most anomalously warm month (meaning its temperatures were the most above a given month’s long-term average).\nA tendency toward more extreme heat events and fewer extreme cold ones is a hallmark of the changing climate as humans continue to burn fossil fuels and add to the heat-trapping greenhouse gases in the atmosphere. In parts of South America, the whole winter period was punctuated by intense heat dome events, in which an atmospheric pattern that ushers in extreme heat becomes entrenched. July and August were the hottest such months for the whole continent, and August was the most anomalously warm month on record there. The latter measured a stunning 2.4 degrees C (4.3 degrees F) above average, according to the U.S. National Oceanic and Atmospheric Administration.\nIn looking for the fingerprints of climate change in extreme weather events, the WWA researchers focused on one of the heat domes that settled over the continent in late September. They looked at the 10 hottest consecutive days in the region where the heat was most extreme, which broadly included Paraguay, central Brazil, and parts of Bolivia and Argentina.\nFor each of its studies, the WWA looks for trends in historical data and uses computer models to compare today’s climate with a theoretical world without human-caused climate change.\nThe researchers found climate change made the recent South American event at least 100 times more likely and from 1.4 to 4.3 degrees C (2.5 to 7.7 degrees F) hotter. (There is some uncertainty because of the sparseness of weather records in some of the areas covered by the study.) Such an event would be expected about every 30 years in today’s climate.\nBut because the world continues to burn fossil fuels, the climate isn’t static. If worldwide average temperatures climb to two degrees C (3.6 degrees F) above the preindustrial period, such an event would be expected to happen every five to six years and would be another 1.1 to 1.6 degrees C (two to 2.9 degrees F) hotter still, the analysis found. The planet has already warmed by about 1.2 degrees C, or 2.2 degrees F, since the preindustrial era.\nFor the recent South American event, the WWA researchers also considered the possible influence of El Niño, which is a natural climate pattern that features warmer than normal ocean waters in the eastern tropical Pacific Ocean. Those hotter waters release heat into the atmosphere and unleash a cascading impact on atmospheric circulation patterns. This affects weather around the planet and often particularly does so in South America because of its proximity to the eastern Pacific. The current El Niño has been gaining steam and is expected to be a strong one. But the WWA analysis showed El Niño had only a minor effect on South America’s unseasonable weather. “A developing El Niño would have contributed some heat, but without climate change, spring heat this intense would have been extremely unlikely,” said WWA team member Lincoln Muniz Alves, a researcher at the Brazil National Institute for Space Research, in the press release.\nOther recent WWA research found climate change exacerbated heat waves in China, North America and Europe earlier in the Northern Hemisphere’s just concluded summer. The team even concluded that the latter two heat waves would have been virtually impossible without the influence of climate change. Another analysis by nonprofit research organization Climate Central found that nearly every person on Earth experienced high temperatures that were made at least twice as likely by global warming, and half of the world's population felt at least 30 days of extreme heat between June and August.\nExtreme heat is a major public health threat, especially when it is unseasonable and where people are less acclimated to higher temperatures. Among the most vulnerable populations are the very young, the elderly, those with existing health conditions such as heart disease and those without access to air-conditioning. People who work outdoors are also particularly susceptible to heat illness and heat stroke.\nThe WWA researchers additionally found that the most affected South American countries lacked mechanisms to help warn people of the impending heat and connect them with resources such as cooling centers. “Good planning for heat can save lives,” said Julie Arrighi, a WWA team member and interim director of the Red Cross Red Crescent Climate Center, in the press release. “It is absolutely critical that every country and city develops a heat plan.”\nThe weight of climate science also underscores that it is critical for governments and companies to act rapidly to reduce the emissions of greenhouse gases that are causing such heat extremes.\nAndrea Thompson is an associate editor covering the environment, energy and earth sciences. She has been covering these issues for 16 years. Prior to joining Scientific American, she was a senior writer covering climate science at Climate Central and a reporter and editor at Live Science, where she primarily covered earth science and the environment. She has moderated panels, including as part of the United Nations Sustainable Development Media Zone, and appeared in radio and television interviews on major networks. She holds a graduate degree in science, health and environmental reporting from New York University, as well as a B.S. and an M.S. in atmospheric chemistry from the Georgia Institute of Technology. Follow Andrea Thompson on Twitter Credit: Nick Higgins\nTanya Lewis\nLucy Tu\nKatherine Harmon\nMeghan Bartels\nJessica E. Martinez, Marcy Goldstein-Gelb and Roger Kerson\nAriel Wittenberg and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Euclid Space Telescope Rescued from Mission-Threatening Glitch", "date": "2023-10-10 17:00:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nThe European Space Agency says a software patch restored stability to its cosmos-mapping Euclid spacecraft — but slower operations could extend the mission\nShortly after launching on 1 July, the European space observatory Euclid started performing tiny, unexpected pirouettes. The problem revealed itself during initial tests of the telescope’s automated pointing system. If left unfixed, it could have severely affected Euclid’s science mission and led to gaps in its map of the Universe.\nNow the European Space Agency (ESA) says that it has resolved the issue by updating some of the telescope’s software. The problem occurred when the on-board pointing system mistook cosmic noise for faint stars in dark patches of sky, and directed the spacecraft to reorient itself while capturing a shot.\nGiuseppe Racca, Euclid project manager at ESA in Noordwijk, the Netherlands, says that the updated pointing system will operate slightly slower than planned. As a result, the main mission, due to last six years, could take up to six months longer. Its scientific goals should not be affected, ESA says.\nEuclid is designed to carry out a deep survey of the Universe by mapping the positions of 1.5 billion galaxies in 3D, looking beyond the stars in the Milky Way. But to do so, it will often have to photograph some of the darkest patches of the sky, which have only very faint stars. Euclid must use the known positions of those stars — as previously mapped by another ESA mission, Gaia — to find the correct patch and continuously adjust its position to extremely high precision for more than 10 minutes at a time.\nInitial tests of this system showed that, in some cases, the telescope was not pointing stably. Instead, it would wobble, producing test images in which some stars appeared to follow tiny looping trails.\nESA says that the Euclid team, together with its principal industrial contractor, Thales Alenia Space, was able to diagnose the problem quickly. The pointing system uses auxiliary sensors inside the telescope to take periodic 2-second exposures of the field of view. It then matches the stars it sees with those in the Gaia catalogue, to make sure they are in the expected positions. But the sensors also pick up noise from energetic particles such as cosmic rays, which continuously rain onto the probe from all directions, explains Giovanni Bosco, a physicist at Thales Alenia Space in Turin, Italy. Within 100 milliseconds, the on-board software has to filter that noise and single out the real stars.\nThis didn’t always work out as planned, says Racca. “Sometimes it had too few stars, and it was getting confused. It was losing the guiding stars and then automatically started to look for them again.”\nBosco worked with the team at subcontractor Leonardo in Florence, Italy, to fix the problem by improving how the algorithms filter out cosmic noise. ESA has now tested the system and announced on 5 October that it is working as planned.\nAnother issue spotted in early imaging tests was that tiny amounts of stray light seemed to be entering the telescope — despite it being protected by a sunshield and wrapped in multiple layers of insulation. The problem was probably caused by a thruster that sticks out to one side of the spacecraft, where it is not protected by the sunshield, says Racca. When the telescope was oriented at certain angles, sunlight was ricocheting off a 1-square-centimetre area on the thruster — the only part of it that is not painted black — and bouncing from the back of the sunshield onto the side of the telescope. A small fraction of this light could be detected by Euclid’s super-sensitive cameras. The mission team found that the problem went away after simply adjusting the orientation of the probe by 2.5 degrees.\nRacca says that the mission can now resume its planned commissioning stages, and expects that it will be able to begin its scientific work some time in November.\n“When I heard about the problems and the solutions they were trying out, to me it sounded like this will work out,” says Anthony Brown, an astronomer at Leiden University in the Netherlands and a senior member of the Gaia science team. Still, he adds, whenever problems with a space mission can be overcome, “it’s always an immense relief.”\nThis article is reproduced with permission and was first published on October 6, 2023.\nDavide Castelvecchi is a staff reporter at Nature who has been obsessed with quantum spin for essentially his entire life. Follow him on Twitter @dcastelvecchi\nMonisha Ravisetti and SPACE.com\nJonathan O'Callaghan\nDhananjay Khadilkar\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Wind Power Will Expand with Larger Turbines but Could Face Pushback", "date": "2023-10-10 20:00:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nWith the expansion of wind power—and the growth of turbines—comes challenges in areas that are unaccustomed to whirring blades\nCLIMATEWIRE | What scientists call the Wind Belt may soon expand with the arrival of taller wind turbines and new construction techniques that could result in an 80 percent increase in U.S. land-based clean energy over the next 10 years.\n“This could go a long way toward helping the nation meet its clean energy goals,” researchers with the National Renewable Energy Laboratory (NREL) found in a recent study.\nLead author Owen Roberts said the possibility of additional wind power is an “unexpected opportunity” brought about by cost reductions in the construction and operation of wind turbines.\nBut he cautioned that not all parts of the U.S. may welcome the evolving turbines.\n“The politics of this will be a balancing act,” Roberts said in an interview, noting that some areas of the country have not been widely exposed to wind farms, including regions in the Southeast and Gulf coasts.\nThe addition of new bigger turbines — which are built to reach higher wind formations — may come as a surprise to some people in those areas, he said. Larger offshore turbines also come with their own challenges.\nThe equipment comes with risks to species of birds and bats. The visual impacts of taller turbines is another consideration. Roberts noted that officials in North Caroline and Tennessee have approved restrictions on the proximity that wind turbines might be built near communities.\nThe study shows that the towers that hold the rotating turbine blades have grown from 98 feet to 295 feet tall since the 1980s, and the reach of the blades has expanded more than fourfold. Towers matching the size of the Washington Monument (554 feet tall) are now possible, holding a blade diameter of 492 feet.\nThe study by NREL, which is part of the Department of Energy, outlines how construction cost reductions could encourage the use of taller towers. They include “mobile cranes” that take factory-made tower segments and climb on top of them to lift up the next segment, rising with the towers as they are assembled on site.\nThat advancement comes as conventional cranes, called crawler cranes, increased in size and are more difficult to move around a wind farm, Roberts said. Ease of construction and the lower assembly and transportation costs of components and machinery is expected to cut the costs of building new wind farms, the study says.\nTheir additional height could also address challenging characteristics of the Wind Belt created by the Rocky Mountains, Roberts explained. The mountain range causes wind patterns flowing over them from the west to temporarily drop — which is good for smaller turbines — before climbing higher as they approach the East Coast, requiring the taller towers to harvest power.\nPrevailing winds in eastern Kansas can be almost 1 1/2 times stronger than those in central Georgia.\nSo building taller towers in Georgia could help offset those power losses. That's where politics comes in. The study indicates that utilities and political leaders may have to explain the benefits of reducing greenhouse gas emissions to help gain support for wind farms — and bigger turbines.\n“We’re talking about bringing a new industry and new technology to parts of the United States that have hardly seen wind energy,” Roberts explained. “The more we can show there’s potential, the more people will understand the opportunity.”\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nJohn Fialka is a reporter with E&E News.\nEveryday Einstein Sabrina Stierwalt\nAnnie Sneed\nBenjamin Storrow and E&E News\nDavid Iaconangelo and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Ancient Skulls Reveal Shifts in Human Violence across Millennia", "date": "2023-10-10 20:15:00", "text": "Digital offer!\nDigital offer!\nLevels of murder, assault, torture, and the like fluctuated greatly in the ancient world, according to new research\nAnthropologists have long debated whether human societies have become more or less violent since the first states rose to power thousands of years ago. Until recently, viewpoints on the matter divided roughly into two camps: the “doves,” who viewed preclassical civilizations as largely harmonious until the dawn of agriculture, and the “hawks,” who perceived early settlements as brutal, warlike places that became more peaceful after people began farming cooperatively.\nThe merits of the arguments on one side or the other have always been suspect because of a lack of solid evidence for either case. A new study takes a crack at answering the question, but its conclusions imply that neat dove-versus-hawk categorizations are overly simplistic. The amount of violence present in any society might not conform to a linear trajectory that moves continuously in an upward or descending direction.\nInstead periods of violence appear to have flared up before later simmering down numerous times in different regions depending on myriad factors, according to the study, which was published in Nature Human Behaviour. The authors looked at a period of Middle Eastern history between 12,000 and 400 B.C.E. and drew from the skeletal remains of more than 3,500 individuals. The scientist found that evidence of interpersonal violence—primarily in the form of head trauma—increased significantly during times of socioeconomic upheaval and shifting climate.\n“It’s great to see such a big dataset from a region where we haven’t had these large-scale studies,” says Linda Fibiger, a bioarchaeologist at the University of Edinburgh, who was not directly involved in the study but helped review the paper.\nInterpersonal violence—defined as murder, assault, slavery, torture and other forms of physical abuse—has plagued humanity for millennia. But historically, it has been difficult for researchers to measure exactly how prominent violence was in ancient civilizations—especially in prehistoric societies, where written records of conflict are nonexistent. Instead of relying on historical documents, the authors of the new study looked directly at skeletons unearthed in present-day Turkey, Iran, Iraq, Syria, Lebanon, Israel and Jordan.\n“Archaeology is actually a very powerful means to distinguish this kind of stuff,” says Giacomo Benati, an interdisciplinary economic historian at the University of Barcelona and co-author of the study. Specifically, he and his team looked for remains whose skulls featured evidence of blunt-force trauma during the person’s lifetime.\nBenati says that the team focused on skulls that had been damaged above the “hat-brim line,” an imaginary tracing across the forehead that anthropologists often use to differentiate an intentional blow from an accident. “There’s good reason for that,” Fibiger says. Injuries sustained in a fall tend to occur around the eyes, nose and brow, whereas the top of the head “has always been a target for violent confrontations.”\nThe researchers also examined other parts of the skeletons for signs of weapon-related injuries, such as puncture marks or arm fractures from self-defense. The team relied less on these trauma patterns, however, because they can be harder to distinguish from accidental wounds. The results showed that violence in the ancient Middle East peaked during a period known as the Chalcolithic, between 6,500 and 5,300 years ago. It then settled down during the early and middle Bronze Age as states consolidated their ability to control aggressive acts, only to spike again at the beginning of the Iron Age, just more than 3,000 years ago.\nThe Chalcolithic represented a transitional time in the region’s history. Early scattered settlements were growing and beginning to form into centralized states, and metal weapons were rapidly replacing wooden and stone implements. Fueled by larger populations, higher stakes and better weapons, violence began to trend upward.\nSimilarly, the Iron Age saw an upgrade in weapons quality, from bronze to more durable iron, and a political realignment as the Assyrian empire rose to power. But in addition to these political and technological upheavals, the region also buckled under the weight of a major “climate shock”: a 300-year-long drought that displaced thousands of people and triggered widespread famine.\nThese findings have the makings of being a stark warning for our current climate-challenged planet. As Earth’s temperature continues to rise, many experts worry that violent conflict will rise along with it. But, Benati cautions, the modern day and the historical record lack a one-to-one correspondence. “There is substantial evidence that extreme climate events could impact levels of conflict,” he says. “But it is also true that from our study, we see that when there are institutions that are capable of reducing and capping violence, the conflict could be reduced.”\nStill, in the coming decades, it may become increasingly critical to look forward by glancing back at the history of violence and the factors that fuel it. “Certainly, now we are in a much better position to understand both,” Benati says.\nJoanna Thompson is an insect enthusiast and former Scientific American intern. She is based in New York City. Follow Thompson on Twitter @jojofoshosho0\nJoanna Thompson\nJohn Fialka and E&E News\nDavide Castelvecchi and Nature magazine\nAndrea Thompson\nMeghan Bartels\nKC Cole | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "We Finally Know Where Oranges and Lemons Come From", "date": "2023-10-11 10:45:00", "text": "Digital offer!\nDigital offer!\nIn addition to finding where citrus come from, researchers have pinpointed the genetic origins of the fruits’ tart taste\nTart citrus fruits vary from olive-sized kumquats to four-pound pomelos. Most are round, but some, such as the finger lime, are elongated like sausages. Others, such as the Buddha’s hand, grow in weirdly gnarled segments.\n“Citrus is fascinating,” says Gayle Volk, a plant physiologist at the U.S. Department of Agriculture, who studies the genetic preservation of citrus and other fruits. “The number of diverse crops produced through hybridization among different citrus species is much higher than that of apples or grapes.”\nTrying to pinpoint exactly where this diverse, heavily cultivated group of fruits originated—previously hypothesized as anywhere from the Himalayan foothills to the balmy jungles of northeastern Australia—has soured the topic for many researchers. But a new paper takes an in-depth genetic approach to fleshing out oranges’ origins, along with those of their citrus kin. The study, published last week in Nature Genetics, analyzed the genomes of hundreds of species across the orange subfamily Aurantioideae—and revealed that citrus-related fruits likely originated on the ancient Indian subcontinent before further diversifying their sharp taste in south-central China.\nAurantioideae is a titanic taxonomic group encompassing more than 33 genera of fruit-bearing plants found throughout Asia, Africa and Polynesia. This includes the Citrus genus, whose members (such as oranges, grapefruit, lemons and limes) are cultivated worldwide.\nHorticulturist Qiang Xu of Huazhong Agricultural University in China and his colleagues recently set out to map the evolutionary journey of the orange subfamily. They assembled the genomes of 12 species and compared those with 314 existing genetic records for members of Aurantioideae. They then organized this genetic database into a phylogenetic tree, which is akin to an evolutionary family tree. Using this, the researchers could determine how different varieties and groups are related. This in turn provides clues to when and where certain species originated.\nThe team found that the precursors to citrus plants originated more than 25 million years ago on the Indian subcontinent as it was ramming into continental Asia (creating the Himalayas in the process). As the continents collided, these ancestral citrus plants spread into Asia, as is evident from citruslike plant fossils discovered in southern China. The researchers posit that true Citrus species, such as mandarins and trifoliate oranges, first evolved in south-central China around eight million years ago. They speculate that other early Citrus species, including the pomelo and citron, emerged slightly later in the Himalayan foothills.\nLocation appears to have been crucial for the success of these early fruits. Xu thinks south-central China provided “a complex situation for citrus.” He speculates that several million years ago drastic local climate change, which transformed the area from relatively dry tropical conditions to a wetter climate dominated by monsoons, provided ideal growing conditions. He thinks the region’s budding citrus diversity exploded when local human populations began cultivating the plants thousands of years ago for things ranging from food to medicine.\nBy building such a thorough genetic database from across the orange subfamily, the researchers also discovered that citrus plants differed greatly from their relatives in the expression of the PH4 gene, which plays a major role in determining the amount of citric acid—a key component of flavor—in a given fruit. Noncitrus fruits had barely any citric acid. Citrus fruits, with their higher expression of PH4 genes, had much greater concentrations.\n“The PH4 gene is important for citric acid accumulation of fruits for both Citrus and Citrus relatives,” Xu says. When his team experimentally overexpressed or decreased the gene’s activity, they found that the citric acid concentrations responded accordingly. This has a big impact on a given fruit’s taste—small concentrations of citric acid provide a sweet tartness to oranges; larger amounts give lemons and limes their mouth-puckering tartness.\nVolk, who was not involved in the new study, thinks learning more about citrus fruits’ past could inform their future preservation. “Refining genetic origins of citrus and related genera is critical for effective conservation of these plants,” she says. The ability to determine where certain species originated could help researchers protect habitats that are rich in wild species. This work also informs which varieties should be preserved in genetic banks to capture the greatest amount of diversity. In the face of climate change, pests and disease, these genetic stockpiles could help prevent a bitter future for the sweetest citrus.\nJack Tamisiea is a science journalist based in Washington, D.C., who covers natural history and the environment. Follow Tamisiea on Twitter @jack_tamisiea\nMeghan Bartels\nDeboki Chakravarti\nHeidi Ledford and Nature magazine\nRowan Jacobsen\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "International Space Station Suffers Leak, But Crew Remains Safe", "date": "2023-10-11 11:00:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nFor the third time in a year, coolant is leaking from a Russian module aboard the International Space Station\nSpace station astronauts were \"never in any danger\" following a coolant leak Monday (Oct. 9) on a Russian module, NASA officials have said.\nToxic ammonia flakes were observed on theInternational Space Station's (ISS) Russian Nauka Multipurpose Laboratory Module (MLM) around 1 p.m. EDT (1700 GMT). Personnel inNASA's Mission Control in Houston first spotted the \"possible\" leak on camera.\nAgency astronaut Jasmin Moghbeli (on board the ISS) confirmed the backup radiator leak after looking at it through the station's wrap-around cupola windows, NASA officialswrote in an updatefive hours later.\nIt is unclear whether the leak will require a spacewalk byRoscosmoscosmonauts for repairs to the science module, or whether the situation will delay an already planned spacewalk by NASA astronauts (in a different kind of spacesuit) expected to take place on Oct. 12. (Ammonia is so toxic that spacewalks nearby the substance must have extra precautions built in to reduce exposure risk to astronauts.)\nBut NASA officials emphasized that for now, the backup radiator leak has \"no impacts to the crew or to space station operations,\" and that the primary radiator for Nauka continues to work normally. NASA officials added the leak, the latest in a series aboard Russian ISS equipment in recent months, remains under investigation.\nRussia's federal space agency, Roscosmos, confirmed the leak to NASA and also in a statement on Telegram. \"The temperature at the MLM is comfortable,\" Russian officialswrote on Telegram(translation provided by Google) and they also said there are no changes to operations, experiments or crew exercise periods.\nThe leaky backup radiator was originally for a different Russian module aboard the space station, called Rassvet, and was delivered to the ISS viaspace shuttlemission STS-132 in 2010. A Roscosmos spacewalk in April 2023transferred the then-functional backup radiatorto Nauka.\nFor now, NASA has asked its Expedition 70 ISS astronauts to close all shutters on the U.S. segment of the space station \"as a precaution against contamination,\" agency officials wrote. (NASA and Roscosmos are both majority stakeholders in the ISS, alongside smaller space station partners.)\nAmmonia is required to cool the ISS because the station's systems produce \"waste heat,\"according to NASA documentation. Waste heat is removed through cold plates (devices that cool electronics) and heat exchangers. Both these device types require circulating ammonia coolant, located in a closed-loop system on the outside of the space station. The warmed ammonia's heat releases into space via radiators, such as the leaky one aboard Nauka, allowing for the liquid's recirculation in the loop for a new round of cooling.\nThe Nauka leak is the latest in a string of ISS Russian equipment coolant escapes in recent months. Roscosmos has said the last two incidents were likely due to micrometeroid impacts, although Harvard-Smithsonian space analyst Jonathan McDowelltold The Guardianhe suspects there is a \"systemic\" problem.\n\"You've got three coolant systems leaking — there's a common thread there. One is whatever, two is a coincidence, three is something systemic,\" McDowell said in the report. McDowell is an astrophysicist and astronomer who also tracks launches, re-entries and other major spaceflight milestones.\nThe most dramatic of the two other Russian leaks was aDecember 2022 incidentaboard the Soyuz MS-22 spacecraft, shortly before a scheduled Roscosmos spacewalk; two cosmonauts were in fact already suited up to exit the station just before the leak happened. The extravehicular activity was canceled due to the risk to the cosmonauts.\nRoscosmos next examined its options for the spacecraft, then set to carry three astronauts home in early 2023. The Russian agency determined it was best to quickly send up an empty replacement Soyuz, MS-23, andreturn MS-22 back to Earthfor analysis.\nSoyuz crews typically launch every six months. As such, the relief Soyuz crew wasn't fully trained yet for theaccelerated MS-23 launchin February 2023, necessitating a wait until yet another spacecraft (MS-24) was ready in September to carry them to the ISS.\nAfter the relief crew arrived, the three MS-22/MS-23 astronauts then returned home in the replacement spacecraft, having been required tospend 12 months on the ISSinstead of six to accommodate the spacecraft changeover. In the meantime, a Russian cargo spacecraft (Progress 82) alsosprung an ammonia leakin February 2023.\nThere have been other incidents with Russian ISS equipment in recent years.Faulty software aboard Naukawhen it first docked with the ISS in July 2021, for example, briefly tilted the space station and caused NASA's Mission Control to declare an emergency, although the crew was never in any danger and the situation was swiftly and safely rectified.\nAnd another Russian Soyuz spacecraft docked with the orbiting complex in 2018 somehow ended up with a hole, which was plugged by orbiting astronauts before the spacecraft safely returned home. The causemay have been a manufacturing defect, although reports also emerged in 2021 that Roscosmos was trying toblame U.S. astronautsfor the situation.\nTensions erupted between Russia and most of the other ISS partners in February 2022 following Russia's unsanctionedinvasion of Ukrainethat year, which is ongoing. Relations regarding the ISS have been normal, NASA officials continue to emphasize, but most other space partnerships between Russia and other ISS partners have been severed amid the war. The ISS is scheduled to continue operations until at least 2030, although Russia has onlycommitted to 2028so far.\nCopyright 2023 Space.com, a Future company. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.\nElizabeth Howell (she/her), Ph.D., is a staff writer in the spaceflight channel since 2022 covering diversity, education and gaming as well. She was contributing writer for Space.com for 10 years before joining full-time.\nBrett Tingley and SPACE.com\nJoanna Thompson\nMike Wall and SPACE.com\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "The Milky Way May Be Missing a Trillion Suns' Worth of Mass", "date": "2023-10-11 12:00:00", "text": "Digital offer!\nDigital offer!\nSlow-moving stars at the Milky Way’s outskirts suggest our galaxy may be far lighter than previously believed, with profound implications for dark matter\nThere’s something strange going on with the Milky Way. Recent measurements suggest that stars at the outskirts of our galaxy are misbehaving. They’re traveling far slower than similarly situated stars in other galaxies. One possible explanation for the Milky Way’s stellar slowpokes is that our galaxy is extraordinarily deficient in dark matter, the invisible substance thought to serve as gravitational scaffolding for cosmic structures. Another is that our core conceptions about dark matter—such as how much of it exists in the universe—are somehow deeply flawed.\nThis head-scratcher stems from the European Space Agency’s Gaia satellite, which provides unparalleled information on the speeds and positions of nearly two billion stars in the Milky Way. Last year the Gaia team released the space-based telescope’s most precise measurements yet, spurring astronomers to refresh their galaxy-spanning assessments of stellar behavior. Several independent groups have now reported the oddly sluggish orbits of stars along the Milky Way’s outer rim, the peripheral edge of our galaxy’s luminous whorl.\nStellar speeds offer a way to weigh a galaxy; the gravitational force each particular star feels depends on the galaxy’s total mass. A Gaia-derived study released on September 27 in the journal Astronomy & Astrophysics pegged the combined mass of our galaxy’s gas, dust, stars and dark matter at some 200 billion times that of our sun—hefty for you and me but on the order of five times less than that found in several other earlier assessments. Because the Milky Way’s visible material hasn’t disappeared, one easy—and especially thought-provoking—way to explain this result is that far less dark matter is floating around than previously believed.\nThen again, weighing a galaxy is a notoriously tricky business, so it’s possible that errors lurk in Gaia’s data or the new analyses that create the illusion of the Milky Way as anomalously trim. But the fact that multiple teams have seen the same result gives more substance to the findings. If true, they could force a rethink of fundamental physics and prompt a reexamination of all other galaxies in the universe.\n“Let me put it this way,” says Stacy McGaugh, an astronomer at Case Western Reserve University, who wasn’t involved in any of the recent studies. “If it worked out that way, it would be revolutionary.”\nIn the 1970s astronomer Vera Rubin and her colleagues began measuring stellar motions in other galaxies. Stars around a galaxy’s periphery were expected to orbit at a more leisurely pace than those closer in, much like how Neptune meanders around our sun every 165 years while Mercury zips about in 88 days. Yet, strangely, Rubin and her associates found that outlying stars were traveling at roughly the same rate as their more central siblings, suggesting that an enormous reservoir of hidden material in and around each galaxy was gravitationally tugging on the far-out stars to boost their speeds. This invisible stuff, already then called dark matter, was surmised to form immense halos surrounding galaxies, outweighing the visible material by a factor of 10 for large galaxies and as much as 100-fold for dwarf galaxies.\nMeasuring how everything in our galaxy moves while stuck inside of it is not the easiest task. So astronomers have tended to assume that stars in the Milky Way behave much like those seen in other galaxies. The sun, located roughly 26,000 light-years from the galactic center, orbits around it at about 500,000 miles per hour (800,000 kilometers per hour), and most observations of other stars within and beyond the Milky Way have supported the idea that stellar speeds farther out should be broadly consistent with that of our home star.\nThe Gaia satellite, which was launched in 2013, offers the best-yet test of this simple notion via the spacecraft’s extraordinarily precise measurements of the three-dimensional positions and motions of stars in the Milky Way. But this testing has been a gradual process because the precision of Gaia’s reckoning improves in lockstep with how long it observes its stellar sample. Using Gaia, theoretical physicist Francesco Sylos Labini of the Enrico Fermi Study and Research Center in Italy and his associates saw subtle hints of a decline in the Milky Way’s stellar speeds a few years ago. Those hints became much more obvious in Gaia’s most recent data release, from 2022, which pegs stellar motions with twice the precision of a previous offering from 2018. Such improvements allow astronomers to plot the paths of stars with greater accuracy and out to much farther distances than before.\nThis year alone, four different papers have revealed a precipitous decline in the speeds of stars out to 100,000 light-years from the Milky Way’s center. The recent Astronomy & Astrophysics study refers to this falloff as “Keplerian,” meaning it is like that seen in the planets in our solar system, whose motions were first accurately described by 17th-century German astronomer Johannes Kepler.\nSuch a finding flies in the face of all expectations. Minus a few minor deviations, plots of stellar orbits in other galaxies consistently show stars from center to rim all whirling with similar speed, as if held in dark matter’s gravitational grip. “But for the moment—and this is what is very interesting—we do not find any other galaxies showing this Keplerian decline,” says François Hammer of the Paris Observatory, a co-author of the recent Astronomy & Astrophysics study.\nIn a broad sense, the idea that the Milky Way is unique among all galaxies contradicts a basic tenet of cosmology, which holds that there’s nothing special about any particular place in the universe. The findings create more specific headaches because of the extrapolated lower mass estimate of 200 billion suns for our galaxy. Astronomers are quite confident in their measurements for the visible material in the Milky Way, which amount to a mass of circa 60 billion suns. If both figures are correct, this implies that the dark-to-ordinary matter ratio is just 2.3 to 1—far less than the 10:1 ratio found in galaxies of similar size.\nGiven that the perception of a downsized Milky Way emerges from several independent analyses, some researchers believe that while the decline may be genuine, it’s not representative of our galaxy as a whole. Stars even farther out and currently beyond the limits of Gaia’s high-precision scrutiny may well display a corresponding rise in speeds to offset the anomalous dip. “I’d be very surprised if it just keeps going because then there’ll be a lot of things that break all at once,” says astrophysicist Lina Necib of the Massachusetts Institute of Technology, a co-author of one of the other papers on the decline in stellar speeds, which was posted on the preprint server arXiv.org.\nHer idea is backed by multiple lines of evidence. The Large Magellanic Cloud, which sits around 160,000 light-years from the galactic center, is a satellite galaxy that orbits our own at more than 650,000 mph (one million kilometers per hour)—a value consistent with standard dark matter models. Another line of evidence comes from stellar streams—remnants of small galaxies and star clusters that got too close to the Milky Way and were shredded by its gravity. These stellar streams arc out to great distances and provide estimates of our galaxy’s mass that line up with the weightier approximations.\nThere’s also the possibility that these different teams are inadvertently misinterpreting their data in some way. At the University of Pennsylvania, astronomer Robyn Sanderson makes simulated Milky Ways on a computer and then imagines what sorts of maps a virtual Gaia satellite would see if placed inside them. Any such plot requires certain assumptions that affect its results, she says, such as the overall shape of the galaxy’s distribution of dark matter. “My group has looked at how those overly simplistic assumptions—which everybody knows are overly simplistic—lead to a strange result where the model still describes the data but doesn’t necessarily correspond with the realities of the underlying system,” she says.\nSanderson, who wasn’t involved in any of the papers, is skeptical of drawing firm conclusions from them. She points out that while Gaia provides unrivaled 3-D information, the uncertainties on its stellar-speed measurements grow the farther out in the galaxy it looks.\nFuture data from facilities such as the Vera C. Rubin Observatory (originally called the Large Synoptic Survey Telescope and renamed in 2019) will hopefully be able to find stars in the outer parts of the Milky Way that can help settle the debate. Gaia’s next release, expected at the end of 2025, could also provide more accurate information. Hammer is eager to more closely examine other galaxies and see if their stellar speeds might also show declines similar to the Milky Way’s.\nFor McGaugh, the episode represents part of a normal, healthy churn expected from any mature research community. “It’s going to take a while to settle out, but I think we’ll learn things in the process,” he says. Necib agrees and says she finds the current debate more exciting than troubling. “Yeah, it’s weird,” she says, “which honestly makes for cool science. I love when things are weird.”\nAdam Mann is a journalist specializing in astronomy and physics. His work has appeared in National Geographic, the Wall Street Journal, Wired, and elsewhere.Credit: Nick Higgins\nMark J. Reid and Xing-Wu Zheng\nJonathan O'Callaghan\nSasha Warren\nLee Billings\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Why Women Earn Less Than Men: Economic Historian Wins Nobel for Work on Gender Pay Gap", "date": "2023-10-11 13:00:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nClaudia Goldin mined 200 years of data to show that greater economic growth did not lead to wageparity or morewomen in the workplace\nThe 2023 Sveriges Riksbank Prize in Economic Sciences — the ‘economics Nobel’ — has been awarded to economic historian Claudia Goldin at Harvard University in Cambridge, Massachusetts, “for having advanced our understanding of women’s labour market outcomes.”\nGoldin’s work has helped to explain why women have been under-represented in the labour market for at least the past two centuries, and why even today they continue to earn less than men on average (by around 13%).\nAlthough such inequalities are widely recognized, they present a puzzle for economic models because they represent not just a potential injustice, but also what economists call a market inefficiency. Women seem to be both under-utilized and under-incentivized in the labour force, even though those in high-income countries typically now have a higher educational level than do men.\nGoldin brought history to bear on this question through rigorous forensic analysis of how changes in women’s participation in the labour force have been influenced by social, political and technological change over the past two centuries.\n“The strength of her work comes from combining careful and innovative historical data with insights from economic theories of wage determination, employment, discrimination and the political economy,” says economist Claudia Olivetti at Dartmouth College in Hanover, New Hampshire.\n“I am delighted to see Claudia’s work recognized,” Olivetti says. “She has been such an inspiration to many women and young researchers. Leading with passion, curiosity, integrity, she taught us to be brave and go for the big questions.”\nBefore Goldin’s studies, it was widely thought that the increase in the proportion of women in work over the course of the twentieth century was a reflection of economic growth — higher growth meant more women in employment. But by looking back carefully at older historical records, Goldin showed that the proportion of married women involved in paid work (for example in agriculture or textiles manufacturing) was at least as high in the late eighteenth century, when economic growth rates were much lower, as it is today. This industry was generally hidden behind an opaque census designation of ‘wife.’\nGoldin showed that industrialization disrupted this pattern by making it harder for women to work from home. Her identification of a U-shaped curve in women’s labour participation over 200 years, published in her 1990 bookUnderstanding the Gender Gap, demolished the notion of a simplistic link to economic growth.\nGoldin also demonstrated that, although work opportunities for women expanded in the twentieth century, especially in societies in which children leave the parental home, they were not exploited as much as they could have been.\nGoldin explained this shortfall as being down to expectations. Influenced by what they saw in their parents’ generation, young women tended to make educational choices that did not reflect an expectation of future career prospects. Only by the 1970s did women anticipate how much they might be able to work and invest their efforts accordingly. As Goldin showed in collaboration with economist Lawrence Katz, that situation was boosted by access to the contraceptive pill from the 1960s, which gave women more control in planning for the future.\nGoldin has also shown how gender inequalities in pay have not followed a simple relationship with economic growth, either. The pay gap was smaller during the industrial revolution of 1820–50, for example, because demand for clerical services increased, but changed little between 1930 and 1980, when rewards for uninterrupted careers promoted de facto wage discrimination. Goldin and Katz, with economist Marianne Bertrand, showed in 2010 that parenthood has a key role in maintaining pay inequality, largely through loss of earnings when women suspend or restrict work in favour of child-rearing.\nGoldin’s research has dismantled simple ideas about how gender inequalities in labour markets have changed and the reasons for these changes. Although she has tended not to make policy recommendations for how the problems might be addressed, her scrupulous work in looking at the issues through the lens of history can help to show which interventions are more or less likely to succeed.\n“Goldin has been saying for many years that the way work is organized in many professions is especially female-unfriendly,” says Barbara Petrongolo, an economist at the University of Oxford, UK. Petrongolo says that companies are now starting to change their practices with the introduction of flexible, family-friendly working arrangements and the provision of on-site creches. Some of these changes have happened as a result of policy interventions, but some are coming bottom-up from firms that see the advantages of attracting female talent.\nHowever, not all of these ideas and solutions will have universal applicability. Naila Kabeer, who studies gender in international development at the London School of Economics, points out, for example, that the U-shaped curve in female labour-force participation has not proved to hold globally.\n“It was based on the idea that developing countries would go through the same processes as did advanced industrialized ones,” she says, “and did not take account that globalization would allow countries to move from farming to female-intensive industrialization processes quite as fast as they did.”\nThis article is reproduced with permission and was first published on October 9,2023.\nPhilip Ball is a science writer based in London. His next book, How Life Works (University of Chicago Press), will be published in the fall of 2023.Credit: Nick Higgins\nSophie Arnold and Katherine McAuliffe | Opinion\nAna L. Revenga and Ana Maria Munoz Boudet\nEmily Willingham\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "A Soggy Mission to Sniff Out a Greenhouse Gas 'Bomb' in the High Arctic", "date": "2023-10-11 14:00:00", "text": "A needle-like tower, hung with sensors, \"sniffs\" the air above the Arctic circle for signs of catastrophic thaw in the sodden ground below.\nJocie Bentley (tape): PSA: don’t bring hiking boots when walking the tundra. Your feet will get soaked like a wet sponge.\nGabriel Hould Gosselin (tape): Almostthere. [laughs] About halfway. Well, it’s a lot faster with snowmobiles.\nBentley: Hey, I’m Jocie Bentley, and this is the final episode of a three-part Science, Quickly Fascination series from a fast-warming Arctic.\nToday I’m heading to a place called the Trail Valley Creek Research Station, high in the Canadian Arctic. I’m sloshing along with Gabriel Hould Gosselin. Gabriel is a research assistant for Wilfrid Laurier University in Ontario and the University of Montreal.\nWe actually did his original interviews in French, so you are listening to a combination of field audio and a new interview in English.\nGosselin: Alright, so I brought you about 60 kilometers north of Inuvik, which is a little town at the top of the Northwest Territories, out near the Tuktoyaktuk highway in the tundra.\nBentley: We passed the tree line on our drive. No more trees, just a flat carpet of orange and red tundra, covering softly rolling hills. It’s unlike any landscape I’ve ever seen.\nGosselin: There’s permafrost all over the place. It’s super deep. It’s, like, four- to 600 meters, depending, deep.\nBentley: So for all you non-Metric listeners, that’s 1,300 to almost 2,000 feet deep. That’s deeper than almost all of the world’s tallest skyscrapers.\nGosselin: And that’s permafrost being permanently frozen ground, ground that doesn’t go above zero degrees Celsius. Of course, the top layer kind of thaws over summer and then refreezes over winter.\nBentley: And that is exactly the part that Gabriel is most interested in.\nGosselin: That’s the area that is active, that has bacteria kind of decomposing organic matter and farting out carbon dioxide and methane ...\nBentley: [Laughs]\nGosselin: I mean, there’s this kind of methane bomb. That's what people are thinking about, and thinking ...\nBentley: The more there is, the more trouble we’re in.\nGosselin: Oh, boy, if things keep on warming, there’s a whole bunch of ground that’s been frozen for a long time with basically a huge pool of carbon that’s just ready to be digested by those methane-producing bacteria.\nBentley: And that’s a huge concern for researchers such as Gabriel.\nGosselin: What’s going to happen? And that’s, that’s a concern. What’s going on in the Arctic?\nBentley: And that’s why he’s here. There’s only one way to learn the answer to that question, and it’s with data.\nGosselin: There’s been very little real sampling that’s been done. I mean, there’s more and more stuff that comes out. There’s more and more satellites that are put out there that are much better and better at looking at different wavelengths. Some of them use radar. Some of them use infrared. Some of them actually see, measure directly, the amount of methane that’s in the air in certain areas.\nBentley: But those methods are less reliable without actual measurements from the ground.\nGosselin: To validate those measurements, we need ground-truthing data, so, data that comes from the area that that satellite’s looking at to kind of compare what’s being measured and from up there and then what’s being measured from the ground.\nBentley: And that’s why we’re standing among a bunch of white tents on red tundra. It’s all cleaned up for the offseason.\nBentley (tape): Is it not normally this clean?\nGosselin: I mean, normally there’s a bunch of people living here, so there’s stuff everywhere.\nUh, normally we have a bug net, like, uh, one of those, uh, kind of gazebo bug net things. Yeah. And then we set up tents all around here. I mean, normally there’s a whole bunch of chairs, and, uh, you know, when we get a heater going, people kind of, it’s where we eat and just spend our time. It’s tea! And it’s nice and clean.\nBentley: We make our way to Gabriel’s main research station. It’s called an eddy covariance tower.\nGosselin: A private company installed the tower. I just installed the instruments on it. Yeah, I spent 30 hours on it.\nBentley: So he climbed 20 meters, or 65 feet, up this skinny tower carrying giant pieces of equipment. Here’s what he installed.\nGosselin: So on the tower for eddy covariance, in principle, there’s two main instruments: one instrument that measures the concentration of gas that we’re interested in in the air and [another] that uses infrared.\nBentley: Remember those greenhouse gas farts? This is how science “sniffs” them out.\nGosselin: So basically, we know, per volume, the amount of carbon dioxide or water vapor that’s in that parcel there. And  we’re using ultrasound to measure it about 10 times a second—the speed of wind and the X, Y and Z direction. And then we do the covariance between the vertical movements of wind and the concentration of gas.\nBentley (tape): Do we have enough towers in the North to get an accurate picture?\nGosselin (tape): No, we do not. It’s incredibly difficult and costly to just get something out there. Just to go in those environments is really expensive. The biggest challenge that I found doing stuff out there is not necessarily the cold or, like, the mosquitoes or whatever. It’s getting enough power for all of those instruments that measure 24 hours a day, 10 times a second.\nBentley: Is tundra really that different that we need testing in all these different locations? How does it differ?\nGosselin (tape): You try to draw, like, not a paint-by-numbers but, you know, one of those little, and then you have to kind of draw a line.\nBentley (tape): Connect the dots!\nGosselin (tape): Yeah. But basically, you get an entire image with four points, and you have to draw an elephant. Like, it’s not going to look like an elephant. It’s going to look like a square.\nSo it’s the same thing. Like, you’re trying to get a detailed image of what, like, how different types of landscapes in the North behave. But if we only have four points, we’re going to be missing a lot of detail, and maybe some of the details are going to be important.\nBentley: How big of a problem is this? How worried should we be?\nGosselin: There’s been very littlereal sampling that’s been done. I don’t want to be alarmist. There’s always the kind of trap for scientists. They just go, “Well, I don’t know. I’m not qualified enough.” And then basically that’s taken, um, by the media saying, “Well, we’re not sure whether it’s a problem.”\nOf course it’s concerning. Of course we have to do something. In fact, we’re past the point of no return. Things are going to happen. Things are warming up already beyond our control. And the consequences of that are happening now and are going to happen. By how much, I can’t say.\nBentley: Science, Quickly is produced by Jeffrey DelViscio, Tulika Bose and Kelso Harper. Our music was composed by Dominic Smith. Like and subscribe wherever you get your podcasts. And for more science news, please go to ScientificAmerican.com.\nThis podcast was produced in partnership withLet's Talk Science.\nThanks for joining us for our Arctic series. I’m Joc Bentley, and this is Science, Quickly.\nFunding for this story was provided in part byLet's Talk Science,a charitable organization that has provided engaging, evidence-based STEM programs for 30 years at no cost for Canadian youth and educators\nJocelyn Bentley started Science Media Creator in 2015. The science-focused production company has produced over 78 micro-documentaries, podcasts, and 360 videos profiling STEM across Canada. With degrees in film and neuroscience, Bentley has worked on broadcast productions for Smithsonian Channel, TVO, and the CBC.Follow Jocie Bentley on Twitter\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Monkeys with Transplanted Pig Kidneys Live for Up to Two Years or More", "date": "2023-10-11 15:00:00", "text": "Digital offer!\nDigital offer!\nA company that creates genetically modified pig organs for transplants hopes to test its product in human trials if regulators approve them\nPeople seeking a kidney transplant often have to wait years for a donor organ to become available—and many die before ever receiving one. Xenotransplantation, in which organs from one species are transplanted into another, could alleviate the organ shortage. But bridging millions of years of evolutionary divergence between two species is a tall order, so for decades organ xenotransplantation was largely impractical.\nA new study that was published on Wednesday in Nature demonstrates a key metric of xenotransplantation: the long-term survival of organ recipients. The study authors transplanted the kidneys of genetically engineered Yucatán pigs into cynomolgus monkeys, and the recipients survived for a median of six months, with at least two out of 15 monkeys bearing the desired edits living for more than two years. Prior to the study, xenografts usually survived in nonhuman primates for around three months or less. The new data could help convince regulators that xenotransplantation is ready for clinical trials in humans.\nAccording to eGenesis, the company that led the study, the U.S. Food and Drug Administration requires data showing at least one-year survival of xenografts in nonhuman primates before it will approve clinical studies. “Not only can we get up to a year, we can reach up to two years in the monkey,” says CEO Michael Curtis. “It sets the foundation to go to the clinic with confidence.”\nThe eGenesis researchers aren’t the first to show a xenotransplant survival rate of more than a year in nonhuman primates. But previous studies relied on aggressive immunosuppressants to tame the body’s immune responses, and their successes were often positive outliers rather than consistent outcomes. In the new study, a third of the monkeys survived for a year or longer while on standard immunosuppressants.\n“It's the consistency that impressed me in this paper,” says Muhammad M. Mohiuddin, a professor of surgery at the University of Maryland School of Medicine, who wasn’t directly involved in the research but reviewed the study and wrote an accompanying commentary.\nXenotransplants have been carried out in humans in the past. In late September Mohiuddin and his colleagues successfully transplanted a heart from a genetically modified pig into a 58-year-old man, who is currently being monitored in the hospital. The same team performed a similar surgery in January 2022, and the recipient lived for two months before passing away. But these surgeries were exceptions—they only received the FDA’s go-ahead because the participants were terminally ill people who didn’t have any other option. And it’s harder to argue for this expanded access, or “compassionate use,” of kidney xenotransplants when dialysis exists as a stopgap measure. Dialysis is a traumatic and arduous experience, however.\nGenetically engineered pig kidneys and hearts have also been tested in people who have suffered brain death when their family has consented to the experiment. Such investigations allow scientists to assess the procedures’ safety and performance in a setting closer to the human body, says Jayme Locke, a surgeon at the University of Alabama at Birmingham, who has carried out some of these experiments. But these so-called decedent models come with their own challenges: they usually involve just one person and usually only last for days to weeks. Although these studies provide valuable information, the FDA does not consider them a substitute for clinical trials, for which it requires preclinical data in nonhuman primates.\nThe strategy eGenesis has employed for making xenografts last longer is to genetically engineer the pig donor to be more biologically compatible. In the new study, the researchers reported making a total of 69 genetic edits. By contrast, previous attempts by other companies introduced 10 tweaks or fewer to pigs’ genome.\nMany of eGenesis’s edits serve to coax the host’s immune system to accept the foreign organ instead of attacking it. Pig tissues contain three types of sugar molecules that can trigger the primate immune system to reject the transplanted tissues, so three of eGenesis’s 69 genetic tweaks prevented the donor animal from making these molecules. Another seven of the changes were human gene additions to essentially “make the pig cells behave a little bit more like human cells,” says study co-author Wenning Qin, eGenesis’s senior vice president of innovation. It’s the equivalent of disguising the foreign substrates as the host’s own.\nThe biggest hurdle—which the remaining 59 edits aimed to overcome—was the risk of transmitting a zoonotic disease from the pigs to the monkeys. The porcine genome contains 40 to 70 copies of DNA from porcine endogenous retroviruses (PERV) that are harmless to modern pigs but could be reactivated in humans. Inthe late 1990s concern over these viruses infecting transplant recipients promptedcalls for amoratoriumon xenotransplantation, but ultimately the FDA allowed research to resume.\nThese viral genes were challenging to address because there are so many of them—beyond what traditional gene-editing techniques could disable on a practical timeline. But in the 2000s the scientific field gained a new ally: the Nobel Prize–winning gene-editing toolkit CRISPR-Cas9. Now scientists could make more edits to the genome in one go and do so more accurately to boot. Qin estimates that relying on pre-CRISPR techniques to disable all the viral fragments in the Yucatán pig genome would take her more than 50 years to complete, as opposed to the mere months that were needed with CRISPR.\nThese data will be used by eGenesis to apply for regulatory approval to run phase I clinical trials, which the company hopes to start in 2025. “I really look forward to seeing it go all the way to humans and make a positive impact on human health care,” Qin says. “I have been in the field for a long, long time. I think it would be a good way to conclude my professional career if I had a product [going] to the clinic.”\nIt remains to be seen which cluster of gene edits makes for the best xenograft—or even which ones are necessary. For example, the company Revivicor, which is owned by United Therapeutics and provided the pigs used in the University of Maryland transplants, leaves the porcine viral genes intact. Instead Revivicor has opted for a different pig breed that carries fewer viral sequences in the first place. In Mohiuddin and his team’s experience conducting xenotransplants so far, they haven’t observed zoonotic activation in humans, he says. (The pig heart his team transplanted into a human in 2022 contained traces of a different pig virus, but the physicians saw no evidence of a viral infection while the recipient was alive.) In addition, removing all the PERV genes may have unintended side effects. Mohiuddin says he’s concerned that overtampering with the pig genome could lead to unhealthier pigs and lower-performing donor kidneys.\nOther factors besides gene edits can also influence xenotransplantation outcomes. A regimen of immunosuppressants can help stave off organ rejection for some time. A goal of xenotransplantation is to one day genetically engineer away the need for such medication, however. Monkey models are an imperfect proxy for people, in part because monkeys aren’t cooperative patients and are challenging to take care of postsurgery. Additionally, monkeys are thought to be immune to endogenous pig viruses. The success of xenografted kidneys in a monkey isn’t necessarily indicative of how they would eventually function in a human.\n“Understanding pig kidney physiology in a human is going to become a whole new field,” Locke says. Survival is only one part of the picture; the kidney’s long-term function, from its blood filtration rate to its hormonal regulation, is another important measure that scientists have barely explored. For now, it’s still too early to tell which research group has the best approach to xenotransplantation, she says. “That’s part of why we need to be able to study all of them,” Locke adds.\nShi En Kim is a science writer based in Washington, D.C. Her work has appeared in Chemical & Engineering News, National Geographic, Hakai Magazine, Slate, Science News, and more. Follow her on Twitter @goes_by_kim\nTanya Lewis, Jeffery DelViscio and Alexa Lim\nJoanna Thompson\nAngus Chen\nKaren Weintraub\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Key Biden Climate Pollution Metric Is Safe--For Now", "date": "2023-10-11 16:30:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nSupreme Court justices declined to decide whether the Biden administration is placing too high a value on the cost to society of spewing carbon and other planet-warming gases\nCLIMATEWIRE |The Supreme Court on Tuesday declined to take up a fight by Republican-led states over the federal government's method of estimating the costs of climate change, in a win for President Joe Biden's push to address rising emissions.\nIn a short, unexplained order, the justices rejected a challenge led by Missouri Attorney General Andrew Bailey (R) to the Biden administration's use of interim formulas that calculate the societal costs of greenhouse gas emissions.\nIn a statement, Bailey vowed to \"continue to combat government overreach at every turn.”\nMissouri, he said, \"was the first state to challenge the Biden administration’s flawed social cost of greenhouse gases model that seeks to cripple American businesses in the name of a radical climate agenda.\"\nEnergy analysts, too, predicted the fight may not be over as federal agencies rely on the metric to back new regulations.\nFederal agencies use the social cost metric to assess the hidden financial impact of rising levels of planet-warming emissions when drafting regulations and evaluating major projects. For carbon, Biden officials have set the price at about $51 per metric ton, up from about $1 during the Trump administration. The Biden-era figure reflects the price set by the Obama administration, adjusted for inflation.\nThe court's decision to rejectMissouri v. Bidenfollows the justices' denial last year ofan emergency requestled by Louisiana Attorney General Jeff Landry (R) to block the Biden administration from using its updated social cost estimates.\nBoth of the challenges from Louisiana and Missouri faltered in federal appeals courts, where three-judge panels ruled the red states should have challenged agencies' use of the social cost metric in rulemaking — rather than oppose the estimates themselves.\nBailey and other state attorneys general made the case to the justices that Biden overstepped his authority by imposing interim values as an interagency working group finalizes updated estimates.\nSolicitor General Elizabeth Prelogar has maintained that Missouri and other states cannot show they have been harmed by the application of the climate metric in agency analyses.\nThe Department of Justice declined comment Tuesday on the court’s decision.\nThe court’s decision does not prevent the states or other parties from challenging specific agency actions and rulemaking that relies on the interim estimates, the research firm ClearView Energy Partners said in a note to clients.\n“We expect the fight over SC-GHGs to return to the courts in the future as agencies rely on them to justify regulations and project permitting decisions,” ClearView analysts wrote.\nThe decision suggests the high court agreed with the appeals court that states must show “concrete injury” from the interim values, ClearView wrote, adding that the 8th U.S. Circuit Court of Appeals found that the states failed to establish standing due to the lack of a “plausible injury” that could be traced to the interim values.\nThe Supreme Court's decision comes as an interagency working group is in the midst of finalizing new values for the social cost of greenhouse gases and as the Biden administration is rethinking the scope of how the metric has been applied.\nIn September, theWhite House announcedit was considering using the metric in regulatory activities such as annual budgets, permitting decisions and foreign assistance programs.\nThe White House also said last monthit was consideringexpanding the use of metric beyond regulatory and project analysis, to also help calculate penalties for violations of regulations.\nEPA has separately proposed an updated value for carbon of about $190 per metric ton.\nIn its note, ClearView said it does not expect final SC-GHG estimates to appear until after EPA’s peer review of its estimates.\nThe Supreme Court also rejecteda petition from Minnesota auto dealerswho had asked the court to stop their state from modeling the state of California's strict vehicle emissions standards.\nThe Minnesota Automobile Dealers Association had argued that the North Star State's air doesn’t meet the criteria to qualify for the tough pollution standards that California has adopted.\nThe group sued the Minnesota government, claiming that Gov. Tim Walz (D) — who adopted the standards as part of his climate agenda — had violated the state constitution by improperly delegating legislative authority by adopting emissions standards written by California regulators.\nThe Minnesota Court of Appeals in January rejected the auto dealers’ argument, finding that the emissions plan did not violate the state constitution’s “non-delegation doctrine\" because any major change to the California emissions standards would require the Minnesota Pollution Control Agency to initiate a new rulemaking process.\nThe Minnesota-based Upper Midwest Law Center, which represents the dealers, had pitched the case to the Supreme Court as the “ideal vehicle” for the justices to decide whether the Clean Air Act waiver that allows states to adopt California's standards applies to states that meet federal air pollution standards.\nThe Supreme Court also declined a request from former coal magnate Don Blankenship, who alleges that media outlets like MSNBC defamed him by referring to him as a “felon.”\nFollowing the 2010 explosion of the Upper Big Branch coal mine in West Virginia that killed 29 workers, Blankenship, the former CEO of Massey Energy, spent a year in prison after he was convicted of a misdemeanor charge of conspiring to violate safety rules. Blankenship contended that news outlets erroneously called him a “felon” during their coverage of his unsuccessful 2018 U.S. Senate campaign.\nThe 4th U.S. Circuit Court of Appeals found that the media organizations had not acted with “actual malice,” the legal standard for libel claims against public figures established in the 1964 caseNew York Times v. Sullivan. The Supreme Court’s Tuesday order allows the 4th Circuit decision to stand.\nJustice Clarence Thomas voted with his colleagues to reject Blankenship’s plea but wrote a concurrence calling for the court to revisitSullivan.\n“[T]he actual-malice standard comes at a heavy cost, allowing media organizations and interest groups ‘to cast false aspersions on public figures with near impunity,’” Thomas wrote.\nThe Supreme Court last yearrejected a pleaby Blankenship to overturn his conviction in the Upper Big Branch mine disaster.\nReporter Pamela King contributed.\nThis story first appeared inGreenwire.\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nNiina H. Farah is a reporter for Climatewire.\nLesley Clark is a reporter for Climatewire.\nGilbert E. Metcalf\nJean Chemnick and E&E News\nJames K. Boyce | Opinion\nJean Chemnick and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Many-Mirrored Galaxies Deepen Dark Matter Mystery", "date": "2023-10-11 17:00:00", "text": "Digital offer!\nDigital offer!\nA surprisingly complex galaxy cluster suggests that in the search for dark matter, nothing is as simple as it seems\nIf you’re looking for intergalactic eye candy and cosmic bling, it’s hard to beat Abell 3827, a crowded cluster of hundreds of galaxies about 1.3 billion light-years from Earth. Hubble Space Telescope images of the cluster show a bright central quartet of merging galaxies shimmering like diamonds and perched on an ethereal azure engagement ring. But Abell 3827 boasts more than superficial beauty—it offers deeper allure for curious astrophysicists.\nFor all its gleam, only some 10 percent of the cluster’s mass is visible. The remaining 90 percent exists in halos of an invisible substance called dark matter—halos so massive that the cluster bends nearby spacetime to act as a giant magnifying glass, which astronomers call a gravitational lens. The wispy, glowing “engagement ring” wrapped around the cluster’s center is actually a set of amplified, warped and multiplied apparitions of a fortuitously aligned, far-distant background galaxy. And theorists have been puzzling over the mirror images’ strange dark-matter-sculpted specifics for years.\n“I’ve never seen something like this before,” says Jenny Wagner, a theoretical astrophysicist at the Bahamas Advanced Study Institute and Conferences. “When I looked at the cluster, I thought, ‘Something is not right here,’” she recalls. “I couldn’t point my finger at what was not right.”\nBecause of its unique circumstances and appearance, Abell 3827 is one of the best places astronomers can look for clues about what exactly dark matter actually is. The mysterious substance constitutes 80 percent of the universe’s mass and is central to modern cosmological models, yet it has eluded direct detection for nearly 90 years. Precisely mapping the gravitationally lensed arcs of light and mirror images that surround Abell 3827 allows scientists to weigh the cluster and determine where and how much dark matter it holds.\nBut how many contorted images does Abell 3827 display? It depends on who you ask. For more than a decade, many teams of physicists have squinted to identify and trace each of its accompanying distorted images by eye. They have variously reported four, six or even eight mirages of the background galaxy circling the cluster, with each number suggesting a slightly different distribution for Abell 3827’s dark matter. Many of the apparent mirror images are also unusually rotated with respect to one another. Additionally, previous research has flagged the motions of its four central merging galaxies as a potential probe for the presence of self-interacting dark matter (SIDM), a hypothetical variety of dark matter that could form more complex structures than the standard type, which is thought to be more cosmically inert. But there, too, researchers have reached conflicting conclusions, with some reporting evidence consistent with SIDM and others finding no such thing. Despite Abell 3827’s vast potential, for astronomers seeking to clarify its hidden workings, the galaxy cluster remains a muddled mess. “It’s a big car crash that’s happening,” says Richard Massey of England’s Durham University, who was not involved in the new research but has studied Abell 3827 in detail. “As the police say, everyone who witnesses a car crash tells a completely different version of events.”\nNow Wagner and two of her colleagues have proposed a new theory that might settle some of these discrepancies. Instead of some elusive quirk of dark matter causing Abell 3827’s uniquely hazy and askew gravitationally lensed images of a background galaxy, the researchers argue that the real culprit is the galaxy cluster’s unexpectedly complex lensing morphology. The trio proposes that rather than being “flat as a pancake,” as standard lensing models assume, Abell 3827 is acting as a thicker, more three-dimensional lens with correspondingly stronger aberrations on its projected fuzzy wreath of images. “Imagine you have a Belgian waffle, and you put it very far from you; it will look like a pancake,” Wagner says. “But the closer it gets, the more you will see that it actually has a thick structure along the line of sight.”\nDark matter researchers studying gravitationally lensing galaxy clusters have long preferred pancake-flat models for the sake of simplicity because a lensing cluster’s thickness is negligible, compared with the billion-light-year distances that separate most of them from Earth. That approach, however, can only explain the shearing or stretching of images, not the puzzling orientations that are seen in Abell 3827, Wagner says.\nThe new theory, which the team recently published in the Monthly Notices of the Royal Astronomical Society, relies on the premise that the galaxies in the central quartet do not lie at a single distance and are instead spread along our line of sight. So the background galaxy’s light must be lensed not instantaneously, as conventionally modeled, Wagner says, but multiple times along a distance of 46 million light-years, which is the estimated thickness of the Abell 3827 galaxy cluster. According to the team’s “waffle” hypothesis, one lensing galaxy in the central quartet that is significantly closer to Earth than the rest could be partly responsible. Previous research has shown that three of the galaxies are akin to pearls on a string, roughly equidistant from us in the plane of the sky. the fourth appears to be closer to us by about 32 million light-years, however. So the background galaxy’s light is very likely lensed not once but at least twice before it hits our telescopes, Wagner says.\nThe cluster is a “chaos of galaxies running around in an unprecedented fashion,” Wagner says, so future observations that precisely measure speeds of galaxies relative to each other would help validate this hypothesis. If her new theory stands up, it would also strengthen the case that putative signs of SIDM that were previously glimpsed in the cluster can be better explained as spurious products of flawed dark matter models. And physicists may also have to revise those models to incorporate multiple gravitational lenses within other light-warping galaxy clusters. “The role of other structures along the line of sight has been an important question for lensing analysis,” says Adi Zitrin, an expert in galaxy cluster analysis at Ben-Gurion University of the Negev in Israel, who was not involved in the new study. “In practice, however, it is something that we often neglect, either because we want to make things simpler or because we don’t have the data.”\nTo better map the distribution of mirror images around Abell 3827, Wagner and her team developed an image analysis tool to automatically identify and correlate distinguishing features between the warped arcs of light. When the tool failed to identify a few features reported in earlier works, the team traced this discrepancy to previous human errors in mapping the lensed images—errors that had then compounded after being incorporated into subsequent models. “We should bear in mind: we have models. They have their limitations,” Wagner says, “and the question for me always is: How crazy can physics be, and when am I just wrong in my modeling?”\nOther scientists agree current dark matter models—many of which simulate a gravitational lens as a flat, two-dimensional object—are prone to human errors and inevitably rely on guesswork. A common problem with the models, Wagner and her team noticed, was the presence of “ghost clumps”—anomalous globs of mass that the models predicted to exist around the cluster where observations suggested there is only empty space. As per the “waffle” hypothesis, adding a second gravitational lens to the models that better simulate the thickness of the galaxy cluster should resolve the problem of ghost clumps, Wagner says, although “one would need to set up a new way of lens modeling” to really confirm it.\nNot everyone is convinced just yet, however, that the new theory can satisfactorily explain Abell 3827’s confusing assortment of distorted images. Liliya Williams of the University of Minnesota, who has studied the galaxy cluster, suspects the math behind Wagner and her colleagues’ image analysis tool breaks down for the cluster’s lensed images, which are about four times larger in angular size than those of most other known gravitational lenses. “I wonder if the conclusion of the thick lens comes from pushing their method beyond the limit where it is applicable,” says Williams, who was not involved in the study.\n“I don’t know that it is the most compelling, but I think that it is at least as plausible as other interpretations that have been out there,” says Tim Hamilton of Shawnee State University, who was not part of the study. “With the amount of information we have at this point, it is probably the simplest way of modeling it without trying to introduce extra complications.”\nContrary to Wagner and her team’s conclusions, other experts say one of those interpretations remains the tantalizing possibility of SIDM, which may be interacting with itself below our current detection limits. More images of the cluster and its baffling lensed images will help astronomers better map the distribution of mass within Abell 3827, which can then reveal whether the cluster’s stars are offset from its dark matter—a potential smoking-gun signature of SIDM.\nMassey, who spearheaded much of the work tying Abell 3827 to SIDM models, remains convinced that dark matter must self-interact in at least a minuscule way to exist in the first place. Spotting such subtle and elusive behavior written in the warped light of distant galaxies, he says, is something “we might be able to achieve within the next decade.”\nSharmila Kuthunur is a Seattle-basedscience journalist covering astronomy, astrophysics and space exploration. Follow her on Twitter@skuthunur\nClara Moskowitz\nJoseph Howlett | Opinion\nChanda Prescod-Weinstein\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Your Brain Finds It Easy to Size Up Four Objects But Not Five--Here's Why", "date": "2023-10-11 18:30:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nNeuron activity shows that the brain uses different systems for counting up to four, and for five or more\nFor more than a century, researchers have known that people are generally very good at eyeballing quantities of four or fewer items. But performance at sizing up numbers drops markedly — becoming slower and more prone to error — in the face of larger numbers.\nNow scientists have discovered why: thehuman brainuses one mechanism to assess four or fewer items and a different one for when there are five or more. The findings, obtained byrecording the neuron activityof 17 human participants, settle a long-standing debate on how the brain estimates how many objects a person sees. The results were published inNature Human Behaviouron 2 October.\nThe finding is relevant to the understanding of thenature of thinking, says psychologist Lisa Feigenson, the co-director of the Johns Hopkins University Laboratory for Child Development in Baltimore, Maryland. “Fundamentally, the question is one of mental architecture: what are the building blocks that give rise to human thought?”\nThe limits of the human ability to estimate large quantities have puzzled many generations of scientists. In an 1871Naturearticle, economist and logician William Stanley Jevons described his investigations into his own counting skills and concluded “that the number five is beyond the limit of perfect discrimination, by some persons at least.”\nSome researchers have argued that the brain uses a single estimation system, one that is simply less precise for higher numbers. Others hypothesize that the performance discrepancy arises from there being two separate neuronal systems to quantify objects. But experiments have failed to determine which model is correct.\nThen, a team of researchers had a rare opportunity to record the activity of individual neurons inside the brains of people who were awake. All were being treated for seizures at the University Hospital Bonn in Germany, and had microelectrodes inserted in their brains in preparation for surgery.\nThe authors showed 17 participants images of anywhere from zero to nine dots on a screen for half a second, and asked them whether they had seen an odd or even number of items. As expected, the participants’ answers were much more precise when they saw four or fewer dots.\nThe researchers had already learned from previous researchthat there are specialized neurons associated with specific numbers of items. Some fire primarily when presented with one object, others when presented with two objects and so forth.\nAnalysis of the participants’ neuronal activity showed that neurons specializing in numbers of four or less responded very specifically and selectively to their preferred number. Neurons that specialize in five through nine, however, responded strongly to their preferred number but also to numbers immediately adjacent to theirs.\n“The higher the preferred number, the less selective these neurons were,” says co-author Andreas Nieder, an animal physiologist at the University of Tubingen in Germany. For example, neurons specific to three would only fire in response to that number, whereas neurons that prefer eight would respond to eight but also to seven and nine. As a result, people made more mistakes when trying to quantify a larger number of objects.\nThis suggests two distinct ‘number systems’ in the brain. Nieder was surprised, as he previously thought that there was only one mechanism. “I had a hard time believing that there’s really this dividing line. But, based on these data, I must accept it,” he says.\nFeigenson agrees with the conclusion. “These are gorgeous findings,” she says, which add to behavioural research suggesting that two mental systems help to represent numbers of objects.\nThis article is reproduced with permission and was first published on October 6,2023.\nMariana Lenharo is a life sciences reporter at Nature. Follow Lenharo on Twitter @marilenharo\nKatie Hafner, Carol Sutton Lewis and The Lost Women of Science Initiative\nStephanie Pappas\nJasper van Wezel, Lotte Mertens and Jans Henke | Opinion\nMaría de los Ángeles Orfila\nMike Wall and SPACE.com\nMariana Lenharo and Nature magazine\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "NASA Reveals Sneak Peek of Historic Asteroid Sample", "date": "2023-10-11 19:30:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nOSIRIS-REx’s treasure trove from asteroid Bennu includes material rich in water and carbon\nIt looks like Bennu was indeed the right target for NASA's first-ever asteroid sample-return mission.\nThat mission,OSIRIS-REx, delivered pieces of the 1,650-foot-wide (500 meters) Bennu to Earthlate last month. NASA gave the world its first look at the sample today (Oct. 11) during a live webcast event, which also provided a rundown of the first analyses performed on the off-Earth material.\n\"The OSIRIS-REx sample is the biggest carbon-richasteroidsample ever delivered to Earth and will help scientists investigate the origins of life on our own planet for generations to come,\" NASA Administrator Bill Nelsonsaid in a statement today.\n\"Almost everything we do at NASA seeks to answer questions about who we are and where we come from,\" Nelson added. \"NASA missions like OSIRIS-REx will improve our understanding of asteroids that could threaten Earth while giving us a glimpse into what lies beyond. The sample has made it back to Earth, but there is still so much science to come — science like we've never seen before.\"\nOSIRIS-REx launched in September 2016 and arrived atBennuin December 2018. The probe spent the next 22 months studying the space rock from orbit and searching for the right place to swoop down and grab a sample.\nThat sampling run took place inOctober 2020, and it provided a fair bit of drama: Bennu's surface turned out to be surprisingly porous, and OSIRIS-RExsank deeply into it.\nBut the probe emerged with a bounty — so much material that its collection mechanism got clogged, allowing some asteroid dirt and pebbles to escape into space. OSIRIS-REx still managed to secure most of the Bennu bits in its sample container, and the probe headed toward Earth in May 2021.\nThe journey home wrapped up on Sept. 24, when OSIRIS-REx's return capsule landed in the desert of northern Utah. A day later, the sample arrived at NASA'sJohnson Space Center(JSC) in Houston, where it's being processed, curated and stored.\nThat work has only just begun. For example, mission team members still don't know exactly how much material OSIRIS-REx hauled home. They think it's about 8.8 ounces (250 grams) —far higher than the mission requirement of 2.1 ounces (60 g) —but that's just an estimate, calculated while the return capsule was still in space.\nJSC will distribute parts of the Bennu sample over the coming months and years to researchers around the world, who will study it in great detail.\nTheir work will determine, among other things, the identity of the carbon compounds, which could shed light on how life got started here onEarth. (Many researchers think carbon-rich asteroids like Bennu seeded our planet with life's building blocks long ago, via impacts.)\nAnd Bennu is a relic of oursolar system's planet-building era, so taking the rock's measure will help us understand the formation and evolution of our cosmic backyard on a larger scale, mission team members said.\n\"As we peer into the ancient secrets preserved within the dust and rocks of asteroid Bennu, we are unlocking a time capsule that offers us profound insights into the origins of our solar system,\" Dante Lauretta, OSIRIS-REx principal investigator at the University of Arizona, said in the same statement.\n\"The bounty of carbon-rich material and the abundant presence of water-bearing clay minerals are just the tip of the cosmic iceberg,\" he said. \"These discoveries, made possible through years of dedicated collaboration and cutting-edge science, propel us on a journey to understand not only our celestial neighborhood but also the potential for life's beginnings. With each revelation from Bennu, we draw closer to unraveling the mysteries of our cosmic heritage.\"\nThe journey isn't over for the OSIRIS-REx spacecraft, by the way. Though its return capsule is now back on Earth, the probe keeps on flying, toward another asteroid calledApophis. OSIRIS-REx is scheduled to arrive at that space rock in 2029 and study it up close, on an extended mission calledOSIRIS-APEX.\nCopyright 2023 Space.com, a Future company. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.\nMike Wall has been writing for Space.com since 2010. His book about the search for alien life, “Out There,” was published on Nov. 13, 2018. Before becoming a science writer, Michael worked as a herpetologist and wildlife biologist. He has a Ph.D. in evolutionary biology from the University of Sydney, Australia, a bachelor’s degree from the University of Arizona, and a graduate certificate in science writing from the University of California, Santa Cruz.Follow Mike Wall on Twitter\nLeonard David\nLeonard David\nClara Moskowitz\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "People Who Speak Backward Reveal the Brain's Endless Ability to Play with Language", "date": "2023-10-12 10:45:00", "text": "Digital offer!\nDigital offer!\nArgentine researchers studied a regional slang that reverses the order of word syllables or letters. Their findings give insight into our natural ability to engage in wordplay\nIn 2020 Adolfo García, a neurolinguist at Argentina’s University of San Andrés, had a chance encounter with a photographer who amused his models by chattering to them backward—the Spanish word casa(house) became “asac,” for instance. Upon learning that the photographer had been fluent in “backward speech” since childhood and was capable of holding a conversation entirely in reverse, García set out to study the phenomenon.\nHis research on this amusing speaking style drew enough attention to garner him an Ig Nobel Prize, an award sponsored by Harvard University since 1991 for research that “first makes people laugh and then think.” Backward speech confers no practical advantage to its speakers. Perhaps it merely exists for the sheer enjoyment of the speaker and listener, who recognize the sounds in asac or “onom,” which is from the Spanish word mono (monkey). Nevertheless, this skill, which García says was initially dismissed by his acquaintances and colleagues as “ridiculous and useless,” is by no means a total waste because it offers insights into how the human brain processes language in atypical ways.\n“We had the opportunity to explore something unusual, even, at times, absurd,” García says of the 2020 Scientific Reports study for which he and his team won the Ig Nobel. This recognition took him by surprise, especially considering that he did not continue to pursue this particular line of research after the study was published. His research now focuses on addressing language difficulties in autistic people and in people with ataxia, Parkinson’s disease or neurodegenerative disorders. But García remains an ardent advocate for making backward talk more than a linguistic oddity. He hopes, in fact, that his work will prove valuable in developing more effective therapies for language disorders.\nAround the La Plata River estuary, which abuts the province of Buenos Aires and some parts of southern Uruguay, the language of word inversion belongs to a type of slang called lunfardo, which is the product of immigrant languages from the late 19th and early 20th centuries. This linguistic marvel uses only letters or syllables swapped from back to front. In lunfardo, the word vesre represents the Spanish word for “reverse”—revés—with its syllables pronounced backward.\nThere are still legions of passionate lunfardo speakers today. Thousands of exchanges turn up in ordinary conversation: feca (café, or coffee), choborra (borracho, or drunk) or rioba (barrio, or neighborhood). In Argentina and Uruguay these words are part of the culture. They often show up in tango lyrics but are sprinkled as single words into conversation by almost everyone, though not as continuous backward speech as demonstrated by the photographer encountered by García.\nBackward speech can be practiced in any language that has a “transparent” grammar, meaning that phonemes—the distinct sound units of a language—have the same sound regardless of their position relative to other parts of a word, according to María José Torres Prioris, a researcher in the faculty of psychology at the University of Málaga in Spain and at the Biomedical Research Institute of Málaga, who co-authored the Scientific Reports study.\nWord reversals are possible in languages such as Spanish, Basque or some Mayan languages, in which there is a direct one-to-one correspondence between letters and sounds. For instance, Spanish has five vowels, and each one has a distinct sound that remains consistent across all words. In contrast, English, considered an “opaque” language, has 12 different sounds for these same five vowels. In Spanish, the letter A has a consistent sound and is written the same way, while in English, it can produce varied sounds, as seen in words such as “back” (/æ/) or “far” (/ɑ/). In some cases, it may be heard without being explicitly written, such as in “cup” (/ʌ/). Torres Prioris acknowledges that people can speak backwards in English as well, but the speaker and listener can get confused between how a word is pronounced and how it is written. That confusion of sounds does not exist in Spanish.\nBackward speaking is not confined to the La Plata River area. In France speaking backward is called verlan, a term that is the inversion of the syllables of l’envers, meaning “the inverse.” Verlan includes expressions such as cimer for merci (thank you) or jourbon for bonjour (hello). Something similar exists in Medellín, Colombia, where people carry on in parlache, and in Panama, which has slang called reversina.\nCultural adoration for backward speak perhaps reaches an apex in San Cristóbal de La Laguna, a city in Spain’s Canary Islands where residents are pushing for official recognition of backward speak. Here the tradition got started in the 1930s by a barber who spoke backward. Today those he influenced have asked the United Nations Educational, Scientific and Cultural Organization (UNESCO) to declare the practice an “intangible cultural heritage of humanity.” Some San Cristóbal residents have even quarreled with Spanish-language professors and authorities at the Canarian Language Academy who contend that this way of speaking equates to nothing more than a linguistic game. \nThe Ig Nobel–winning researchers’ prize consisted of an out-of-circulation Zimbabwean banknote and a PDF that could be printed out and folded to form a miniature cola box. The backward speakers in their study possessed an “extraordinary ability” to quickly reverse words (even invented ones), sentences and texts. These individuals could rearrange sounds but preserve a word’s identity effortlessly, García and Torres Prioris’s team found. Instead of saying plata (money), for example, they said atalp. They reversed the letters in the word, not the syllables, and even maintained the appropriate accents. “It is a much more complex mechanism” than a silly game, Garcia emphasizes.\nIn the Scientific Reports study,the scientists designed various tasks to assess the participants’ ability to produce words backward and forward. The researchers measured accuracy and speed in rearranging phoneme sequences, and they obtained structural and functional magnetic resonance imaging recordings.\nOne of the study’s findings shows that the participants had an ability to instantly engage in word reversal that could not be explained by, say, having a superior working memory (the type of memory that allows people to briefly remember a telephone number, for example). Additionally, these individuals did not exhibit any other reversal skills, such as mirror writing, or writing in reverse.\nNeuroimaging revealed that backward speakers had more gray matter volume and connections among neurons, not only in regions associated with phoneme processing (along what is called the dorsal pathway of the left hemisphere) but also in other brain areas involved in semantic processes, certain visual functions and cognitive control. Backward speech therefore brings into play cognitive mechanisms beyond classical language circuits.\nAnother intriguing aspect of the team’s findings, according to Torres Prioris, shows that the brain plasticity demonstrated by the study’s backward speakers enabled them to “accomplish the same task with different neural resources.”\nMaría Castelló, an associate professor of research in integrative and computational neurosciences at Clemente Estable Biological Research Institute in Uruguay, who was not involved in this study, believes that it has opened “a window into the mechanisms of phonological coding”—the recording of written, orthographic information into a sound-based code. Specifically, it sheds light on “an area that has been little explored in neurolinguistics,” Castelló says.\n“Neuroimaging studies have revealed that the specific brain regions involved can vary among individuals, underscoring the plasticity of the human brain in adapting to exceptional linguistic abilities,” she adds. The most significant contribution of this study, Castelló says, is that it offering insights that enhance understanding of the neural mechanisms involved in processing sounds and constructing words.\nBackward speak may seem to some like an absurd indulgence that does nothing more than provoke laughter among friends in places such as San Cristóbal de La Laguna. But García and Torres Prioris argue that this research is relevant for a deeper understanding of neurological disorders that affect language. “I can’t say that this study has a direct clinical impact, but I do think it goes in that direction,” Torres Prioris says.\nSince the publication of the team’s article, Torres Prioris has focused on studying characteristic symptoms of poststroke aphasia, which affects the ability to speak and results from injuries to the brain regions responsible for language. People with aphasia may exhibit linguistic errors such as the inversion, substitution, addition or subtraction of phonemes when communicating. In this context, the identification of neural circuits associated with backward speech is, in her view, “a step forward” for the development of noninvasive brain stimulation treatments for people with this condition. And in the future, she hopes to derive an effective therapy from the results of studying backward speech.\n“When confronted with something seemingly ridiculous or absurd, it is quite easy to dismiss it as if scientific value lies in grandiose, revolutionary and transcendent matters,” García says. “A lesson from this study is that if we see something absurd, and we fail to find inspiration, we are not thinking deeply enough.”\nMaría de los Ángeles Orfila is a journalist in Montevideo, Uruguay.\nKatie Hafner, Carol Sutton Lewis and The Lost Women of Science Initiative\nStephanie Pappas\nJasper van Wezel, Lotte Mertens and Jans Henke | Opinion\nMaría de los Ángeles Orfila\nMike Wall and SPACE.com\nMariana Lenharo and Nature magazine\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Quantum Physics Isn't as Weird as You Think. It's Weirder", "date": "2023-10-12 11:30:00", "text": "Digital offer!\nDigital offer!\nQuantum physics’ oddities seem less surprising if you stop thinking of atoms as tennis balls, and instead more like waves pushing through water\nDown at the level of atoms and electrons, quantum physics describes the behavior of the very smallest objects. Solar panels, LED lights, your mobile phone and MRI scanners in hospitals: all of these rely on quantum behavior. It is one of the best-tested theories of physics, and we use it all the time.\nOn the face of it, however, the quantum realm is extraordinary: Within it, quantum objects can be “in two places at once”; they can move through barriers; and share a connection no matter how far apart they are. Compared to what you would expect of, say, a tennis ball, their properties are certainly weird and counterintuitive.\nBut don’t let this scare you off! Much of quantum physics’ odd behavior becomes a lot less surprising if you stop thinking of atoms and electrons as minuscule tennis balls, and instead imagine any “quantum object” as something like a wave you create by pushing your hand through water. You could say that, at small scales, everything is made of waves.\nIn the spirit of demystifying quantum behavior, here are three key types of “weird” quantum phenomena that normal water waves can do just as well, and the one thing that sets the quantum world apart.\nImagine throwing a tennis ball. If we wanted to, we could track the ball’s exact position and velocity throughout its flight. Strangely enough, if we were to shrink the ball down to the size of, say, an atom, this kind of tracking becomes impossible.\nThis limitation is called Heisenberg’s uncertainty principle. In quantum physics, it is impossible to know an object’sprecise position and momentum (its velocity times its mass) at the same time. A tennis ball’s momentum is just its mass multiplied by its velocity, but for waves we determine momentum by measuring the distance between successive wave crests, a factor called the wavelength.\nWaves are fickle, however, making it impossible to determine their position and wavelengths with 100 percent precision. In practice, any wave, whether watery or quantum, will always cover a range of positions, and consist of a range of wavelengths. The more you restrict one of those ranges, the less you can control the other.\nConsider two extreme types of water waves: The first is an infinitely repeating wave of regularly spaced ripples made by the wind on an endlessly long canal. There you could measure the wavelength by identifying the repeating pattern of wave crests and troughs. But you can’t say anything about the wave’s “position” in the canal because it doesn’t have a start or end point. Conversely, for a wave consisting of a single, thin crest in an otherwise calm pond, you can measure its position, but it doesn’t have a well-defined wavelength because it never repeats.\nIn practice, all waves lie somewhere in between these two limits.Quantum waves are no different.\nA quantum object can “be in two places at once” by being in a so-called superposition of states. Thinking about waves, this is no surprise. A wave can be in two places at once. If you send a wave down a forked channel, it will easily split and flow through both channels at the same time.\nA related quantum concept is entanglement, which combines superpositions in two waves. In a salad dressing that has been left to stand, for example, oil will float on top of the vinegar. Carefully making a wave in the oil will then also cause a wave in the vinegar, which looks like ripples in their interface. Measuring the wavelength of the oil wave also tells us about the wavelength of the vinegar wave. In other words: the two waves are linked, and their properties depend on one another.\nPouring the separated salad dressing down a forked channel, this remains true, so that the combined oil-vinegar ripples move down two channels at the same time. Measuring the wavelength of just the oil wave in one channel, you immediately know all wavelengths in both channels, even if they are far apart. Had the salad dressing been quantum, you would say that the waves in the two channels are “entangled” with one another.Quantum technology uses entanglement to create unbreakable encryption or speed up computations. For your salad, breaking the entanglement by shaking the dressing into a vinaigrette is probably more useful.\nAnother seemingly peculiar feat of quantum objects is that with some probability they can pass through barriers. This is called tunneling. Throw a tennis ball at a wall and (as long as the wall remains standing) it will bounce back. Do this with an atom, and you might find it on the other side.\nIn some cases, a water wave can move through a barrier just like a quantum particle, something you can demonstrate in your bathtub. To do so, build an underwater wall in the tub, one tall enough that it almost touches the water’s surface, but not quite. If you send a wave at this wall at a glancing angle, it will always bounce back from the wall. This is analogous to so-called total internal reflection of light rays. It depends only on the height of the barrier and the angle with which the wave approaches the wall.\nAlthough the wave cannot travel over the barrier, a small tail of it can probe the other side. If the wall is thin enough, you will see the tail remembering its original motion and magically reappearing as a traveling wave. Voilà, your water wave has tunneled through a wall!The same phenomenon of “broken” total internal reflection, but with light rays instead of water waves, is used in certain types of touch screen displays.\nWhereas most weird quantum behaviors are demystified by thinking of small particles as waves instead of minuscule balls, genuine quantum weirdness arises when you measure a quantum object. Whether it’s a wave traveling through two different channels, or one that’s tunneled through a barrier, measuring a quantum wave results in the entirety of that wave suddenly appearing in a single location: in one channel and not the other, or on one side of the barrier and not the other.This doesn’t happen with salad dressing.\nFunnily enough, the mathematical equations that describe quantum waves do not explain what happens when we measure them. Physicists don’t yet agree on how best to describe or interpret this process. Quantum measurement is the one thing that sets quantum behavior apart from water waves, truly making quantum physics strange.\nTo appreciate how unusual quantum measurement is, imagine someone speaking to a crowd of people. Sound waves spread out across the crowd, and everyone hears the speech. In the quantum world, however, the sound wave would spread out just as expected, but as soon as a single person in the crowd perceives (or measures) it, the entire sound wave would concentrate itself in that single person’s ear, and no one else would hear it.\nNow that is weird.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those ofScientific American.\nJasper van Wezel is associate professor in theoretical condensed matter physics at the University of Amsterdam, the Netherlands.\nLotte Mertens is a Ph.D. candidate in theoretical physics at the University of Amsterdam (the Netherlands) and the Leibniz Institute Dresden (Germany).\nJans Henke obtained her Ph.D. in theoretical condensed matter physics in 2022, and now works as science writer and editor in the Netherlands.\nKatie Hafner, Carol Sutton Lewis and The Lost Women of Science Initiative\nStephanie Pappas\nJasper van Wezel, Lotte Mertens and Jans Henke | Opinion\nMaría de los Ángeles Orfila\nMike Wall and SPACE.com\nMariana Lenharo and Nature magazine\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "AI Designs Little Robots in 30 Seconds and They Keep Sprouting Legs", "date": "2023-10-12 12:40:00", "text": "Digital offer!\nDigital offer!\nAn AI used to build artificial neural networks can also create autonomous robot bodies with remarkable speed\nArtificial intelligence can design an autonomous robot in 30 seconds flat on a laptop or smartphone.\nIt’s not quite time to panic about just anybody being able to create the Terminator while waiting at the bus stop: as reported in a recent study, the robots are simple machines that scoot along in straight lines without doing more complex tasks. (Intriguingly, however, they always seem to develop legs rather than an arrangement that involves wiggling, moving like an inch worm or slithering.) But with more work, the method could democratize robot design, says study author Sam Kriegman, a computer scientist and engineer at Northwestern University.\n“When only large companies, governments and large academic institutions have enough computational power [to design with artificial intelligence], it really limits the diversity of the questions being asked,” Kriegman says. “Increasing the accessibility of these tools is something that’s really exciting.”\nAI can now write essays and drive cars, so design might seem like a logical next step. But it’s not easy to create an algorithm that can effectively engineer a real-world product, says Hod Lipson, a roboticist at Columbia University, who was not involved in the research. “Many questions remain,” Lipson says of the new study, “but I think it’s a huge step forward.”\nThe method uses a version of simulated evolution to create robots that can do a specific task—in this case, forward locomotion. Previously, creating evolved robots involved generating random variations, testing them, refining the best performers with new variations and testing those versions again. That requires a lot of computing power, Kriegman says.\nHe and his colleagues instead turned to a method called gradient descent, which is more like directed evolution. The process starts with a randomly generated body design for the robot, but it differs from random evolution by giving the algorithm the ability to gauge how well a given body plan will perform, compared with the ideal. For each iteration, the AI can home in on the pathways most likely to lead to success. “We provided the [algorithm] a way to see if a mutation would be good or bad,” Kriegman says.\nIn their computer simulations, the researchers started their robots as random shapes, gave the AI the target of developing terrestrial locomotion and then set the nascent bots loose in a virtual environment to evolve. It took just 10 simulations and a matter of seconds to reach an optimal state. From the original, nonmoving body plan, the robots were able to start moving at up to 0.5 body length per second, about half of the average human walking speed, the researchers reported on October 3 in the Proceedings of the National Academy of Sciences USA. The robots also consistently evolved legs and started walking, the team found. It was impressive that with just a few iterations, the AI could build something functional from a random form, Lipson says.\nTo see if the simulations worked in practice, the researchers built examples of their best-performing robot by 3-D printing a mold of the design and filling it with silicone. They pumped air into small voids in the shape to simulate muscles contracting and expanding. The resulting robots, each about the size of a bar of soap, crept along like blocky little cartoon characters.\n“We’re really excited about it just moving in the right direction and moving at all,” Kriegman says, because AI-simulated robots don’t necessarily translate into the real world.\nThe research represents a step toward more advanced robot design, even though the robots are quite simple and can complete only one task, says N. Katherine Hayles, a professor emerita at Duke University and a research professor at the University of California, Los Angeles. She is also author of How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics (University of Chicago Press, 1999). The gradient descent method is already well-established in designing artificial neural networks, or neural nets—approaches to AI inspired by the human brain—so it would be powerful to put brains and bodies together, she says.\n“The real breakthrough here, in my opinion, is going to be when you take the gradient descent methods to evolve neural nets and connect them up with an evolvable body,” Hayles says. The two can then coevolve, as happens in living organisms.\nAI that can design new products could get humans unstuck from a variety of pernicious problems, Lipson says, from designing the next-generation batteries that could help ameliorate climate change to finding new antibiotics and medications for currently uncurable diseases. These simple, chunky robots are a step toward this goal, he says.\n“If we can design algorithms that can design things for us, all bets are off,” Lipson says. “We are going to experience an incredible boost.”\nStephanie Pappas is a freelance science journalist. She is based in Denver, Colo.\nLuke Groskin\nNora Bradford\nLois Parshley\nGeorge Musser\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "This Code Breaking Quaker Poet Hunted Nazis", "date": "2023-10-12 13:00:00", "text": "Digital offer!\nDigital offer!\nHow Elizebeth Smith Friedman went from scouring Shakespeare for secret codes to taking down a Nazi spy ring\nKnown as “America’s first female cryptanalyst,” Elizebeth Smith Friedman was a master code breaker who played a pivotal role in both World Wars. For many years, no one knew what she had done, not even her own family. Code breaking wasn’t Smith Friedman’s plan to begin with.\nIn the mid-1910s she was a 23-year-old college graduate in English literature looking for an interesting job. That all changed when an eccentric millionaire whisked her off to his lavish country estate and recruited her to work on his passion project: finding the secret codes in Shakespeare’s plays.\nSmith Friedman scoured the texts alongside a tiny team of self-taught code breakers. They didn’t turn up any hidden messages. But soon the U.S. government came knocking with a slightly higher-priority mission. Perhaps her greatest coup was when she uncovered a Nazi spy ring in South America. J. Edgar Hoover took credit on behalf of the FBI, while Smith Friedman signed an oath to never speak of her achievements and fell into obscurity. Records of what she had done were found in the National Archives annex in College Park, Md.\nLISTEN TO THE PODCAST\n[New to this season of 30-minute episodes of Lost Women of Science? Listen to Gillian Gilbreth here and Lise Meitner: Episode One and Episode Two]\nLost Women of Science is produced for the ear. Where possible, we recommend listening to the audio for the most accurate representation of what was said.\nEPISODE TRANSCRIPT\nKatie Hafner: In 1917, the US was about to enter the first world war. The Germans and their allies were sending telegram and radio messages all over the world at record speeds, carrying secret military intelligence.\nAnd the US was successfully intercepting these messages…\nwhich would have been great if they could actually understand what the messages were saying. Because of course, these messages were all encoded.\nCarol Sutton Lewis: To crack these codes, the US government turned not to expert cryptologists, not to military intelligence, but to a team of rookie codebreakers living in the Illinois countryside—\nJason Fagone: She was a code breaking Quaker poet who caught gangsters and hunted Nazis. She also like laid the foundation for the American intelligence community as we know it.\nCarol Sutton Lewis: But when the government first tapped her to help the war effort, Elizebeth wasn’t a trained cryptologist, not remotely. She was a 24-year-old poet and English lit major just two years out of college. But she would go on to change the world of codebreaking for decades to come.\n[music]\nKatie Hafner: I'm Katie Hafner\nCarol Sutton Lewis: and I’m Carol Sutton Lewis.\nKatie Hafner: This is Lost Women of Science.\nCarol Sutton Lewis: And today, we’re talking about Elizebeth Smith Friedman.\n[music ends]\nCarol Sutton Lewis: In the mid-1910s, Elizebeth Smith was not just one of the best codebreakers of her time — she was one of the ONLY ones in the country. And she fell into the career by accident... through poetry.\nNothing in Elizebeth’s early life suggested she’d go on to be a master code breaker. She’d grown up in a Quaker family on a dairy farm in Indiana, the youngest of nine children, and her father hadn’t wanted her to go to college. But like so many of the women in our series, Elizebeth was determined and went anyway. Off to college… to study English lit.\nKatie Hafner: Elizebeth’s introduction to codebreaking was completely serendipitous. She was 23 when it happened. She’d just graduated from Hillsdale College in Michigan, and she was looking for a job. But she wasn’t interested in working as a schoolteacher — the only real job for an educated woman at that time. So she went to Chicago to see what she could find.\nOne day, she went to the library and asked the librarian if she had any tips. She told the librarian she was especially interested in literature and would like something “unusual.”\nThe librarian told her about a man named George - George Fabyan. He was a multimillionaire who lived outside Chicago on this big estate called Riverbank. He had an array of quirky projects and he also seemed to have an endless amount of money to throw at them. And he had one project in particular that an English lit major like Elizebeth might be able to help with: Finding and deciphering hidden messages in Shakespeare. Ok, he wasn’t the only one. This idea that there were secret codes in Shakespeare had already been circulating for more than a century.\nThe librarian asked Elizebeth if she should introduce them. Elizebeth told this whole story in an oral history interview in 1973.\nElizebeth Friedman: She said, \"Shall I call him up?\"And I said, \"Well, yes, I wish you would please.\"\nKatie Hafner: So the librarian called George Fabyan, who was actually visiting Chicago at the time. And he decided to drive over on the spot and meet Elizebeth in person.\nElizebeth Friedman: She introduced us and um, the first words he said to me nearly bowled me over. He said, \"Will you come out to Riverbank and spend the night with me?\"\nCarol Sutton Lewis: Yikes!\nKatie Hafner: Yeah, I know. And George Fabyan did turn out to be a bit of a creep later on, making passes at Elizebeth… But at this point, he was actually making her a legitimate job offer. The work would take place on his fancy Riverbank estate, and he wanted Elizebeth to come out and see it so she would agree to work for him.\nElizebeth Friedman: I said, \"Oh, sir, I don't have anything with me to, um, spend the night away from my room,\" and he said, \"Well, never mind that. We can supply that.\"\nKatie Hafner: She didn't even pack a bag. George’s chauffeur took them to the train station, and they got on this train to the Illinois countryside. It was 1916, and Elizebeth was about to start a job that was far more unusual than she had bargained for.\nJason Fagone: Riverbank was, on the face of it, a wealthy man's country retreat outside of Chicago.\nCarol Sutton Lewis: Jason Fagone is a writer who dug deep into Elizebeth's story in his book \"The Woman Who Smashed Codes.\"\nJason Fagone: It had these beautiful sort of, uh, gardens; it had a lighthouse along a river... You know, famous people of the day would come and, and visit and stroll the gardens... But there was another half of Riverbank that was essentially like a private scientific laboratory. There were all kinds of laboratory buildings that were scattered around Riverbank that were intended to sort of investigate some of the secrets of nature.\nCarol Sutton Lewis: Elizebeth would be working on the investigation that was closest to George’s heart.\nJason Fagone: George Fabyan's sort of preoccupation, the thing that he cared most about in the world of science was he had this theory —\nCarol Sutton Lewis: —the theory that there were secret codes in Shakespeare… AND that…\nJason Fagone: …those encoded messages in the plays would reveal the true author of William Shakespeare's plays, which he believed was not actually Shakespeare, but was a, a noble of the time named Francis Bacon.\nCarol Sutton Lewis: That’s right. Sir Francis Bacon, the 17th century aristocrat and philosopher.\nFor centuries, thousands of people debated whether or not Shakespeare wrote his own works. Many people thought he wasn’t educated or cultured enough to have been the author of such worldly, sophisticated plays.\nMeanwhile, Bacon who was Shakespeare’s contemporary, was worldly and sophisticated. And Baconians\nKatie Hafner: But wait, Baconians?\nCarol Sutton Lewis: Yeah, Baconians. They tried to prove he was the real author in different ways. One woman thought evidence was buried in Shakespeare’s tomb and asked to pry it open. Another thought secret manuscripts were hidden in panels in Bacon’s old home. And a lot of people thought the proof was in Shakespeare’s plays themselves, written in code. Because Francis Bacon was very interested in codes —he even came up with his own cipher system for encrypting letters. So in the 19th century, a theory started brewing that he’d put coded messages into the plays.\nJason Fagone: This was a pretty widely held opinion, sort of in the early 20th century, but Fabyan really believed it fully, and he believed it so intently that he hired a group of about 10 or 15, Shakespeare scholars and poets and, and brought them to Riverbank and set them on this task of trying to find these secret messages in Shakespeare.\nAnd so that was at, at age 23, she was essentially plucked from obscurity, plucked from her normal life, brought to Riverbank, immersed in this absolute sort of crazy world. That was day zero of her code breaking adventure.\nCarol Sutton Lewis: Little did Elizebeth know, this ragtag bunch of scholars and poets she’d just joined would end up being pioneers in something completely unforeseen: the country’s wartime code breaking efforts. But for now, in the mid-1900s, it was all about Shakespeare. That was her assignment: to find those codes!\nKatie Hafner: Wait a minute, so how would you even start to look for secret codes in Shakespeare? Read it upside down? Read every other word?\nCarol Sutton Lewis: Well, the idea was that Shakespeare's plays were printed in two slightly different fonts.\nThe supposed differences were really subtle — but for the sake of picturing how this would work, let’s imagine that, say, one font has a dot under every letter, and the other font has a dash under every letter. So, if you mix up these fonts as you're writing the play, you could encode a message spelled out in dots and dashes. A kind of binary code made up of just two symbols.\nSo the Shakespeare skeptics were convinced that by looking closely at the letters used to spell each word in Shakespeare’s works, they could make out two different alphabets and uncover a code from Francis Bacon.\nThere was just one problem.\nJason Fagone: So, the Shakespeare project turned out to be a wild goose chase, right? There were no secret messages in, in Shakespeare. Fabyan was sort of chasing a delusion.\nCarol Sutton Lewis: So Elizebeth realized this pretty quickly. As did one of the men working with her on the project: William Friedman.\nKatie Hafner: William was the son of Orthodox Jews who’d escaped pogroms and come to America. And like Elizebeth, he had no background in codebreaking before coming to Riverbank. George Fabyan had originally hired William to work in one of his labs as an agricultural geneticist, but while he was there, William also helped out with the Shakespeare project. And he and Elizebeth worked together closely.\nSo after puzzling over tons of these pages, Elizebeth and William figured out that the whole project was bunk.\nNo secret messages emerged from the text. But something else did. She and William fell in love. Riverbank briefly seemed like some remote fairyland. They rode bikes, swam in the pool, strolled the grounds…\nElizebeth Friedman: We always had pitchers of ice water and fresh fruit with fruit knives by our bedside when we went to bed. We really led the life of the, what you might call the minor idol rich.\nKatie Hafner: That sounds so idyllic, but the world around them was changing, and even though they were off on this remote estate, that change was about to reach them.\nElizebeth Friedman: The world began to pop! Things began to happen.\nCarol Sutton Lewis: In 1917, the U.S. entered World War I. And it wasn't fought quite like other wars.\nJennifer Wilcox: This was the first time that the military had the ability to communicate with their forces across great distances without having to physically carry a message by courier or run a cable or a telegraph line to their individual headquarters and things like that.\nCarol Sutton Lewis: Jennifer Wilcox is the director of education at the National Cryptologic Museum.\nJennifer Wilcox: Now with radio, all they have to do is listen in and they can pick up that radio signal as well. So that really increased the need for cryptography. If you can't stop the enemy from getting the message, you need to make it so that they don't understand the message. Which meant that on the flip side, you have to be able to break those messages to understand what the enemy is doing.\nCarol Sutton Lewis: It wasn't just a war of weapons and force anymore. It had this other dimension to it: code and codebreaking.\nThe US military wanted to understand the messages sent between their enemies. The problem was there were almost no codebreakers in the U.S. There was no real need for them before this war. But…\nJennifer Wilcox: ...there was a very small select group of people working on this at a place called Riverbank Laboratory outside of Chicago, Illinois.\nCarol Sutton Lewis: George Fabyan was an ambitious man. As passionate as he was about his oddball Shakespeare theory, he had bigger dreams. As tensions built in the lead-up to World War I, George anticipated the government would soon need codebreakers. And so he actually recruited more people to his codebreaking team, so that by the time the US entered the war, he’d have a whole little unit trained and ready to go. As Elizebeth wrote in her memoir, George Fabyan liked being powerful, and he wanted to be needed by the government.\nAnd when the time came, in April 1917, the government didn't really have a choice.\nJason Fagone: Because the military has nobody else to turn to, they turn to George Fabian and they say, can you lend us your code breaking team to start working on these military messages?\nAnd he says, yes, of course, they're all yours. And so, for the first six to 12 months of the war, the bulk of America's military code breaking was handled by these sort of poets.\nKatie Hafner: So, a month after the US entered the war, Elizebeth and William quietly got married. And they began their married life in a new role: as the heads of George’s new, military code-breaking unit.\nAnd soon Elizebeth and William were training military officers to do this work too. So Elizebeth, this English lit major, is suddenly a key player in military operations.\nJason Fagone: Elizebeth, she didn't really have time to pause and think about what was happening. It was so fast. Many, many years later, when she was looking back, and people were asking her, \"How did you do this incredible thing? How did you transition from being a poet to being a champion codebreaker almost overnight?\" She was never able to really give a satisfying answer. All she ever said was kind of, \"Nobody would believe it unless you had been there.\"\nKatie Hafner: But she and William themselves were brand new to this, and codes were getting more complicated — I mean enemy armies, of course, weren't using Francis Bacon's cipher—WIlliam and Elizebeth had no one to teach them!\nThe only guidance they had was one manual an army officer had published in 1916, just a year earlier, with helpful little tips, like… how frequently different letters occurred in different languages and things like that. So if it's a really basic code where the original letters have been replaced with substitute letters, you can guess what each letter really is based on how often it appears in the code.\nJason Fagone: It was not a very highfalutin sort of theorizing environment of, of thinking about how to do these incredible things. They were just sort of in a, in a very nitty gritty way, trying to solve the problems that were put in front of them. But, you know, in the process of churning through all of these puzzles, they figured out some tricks essentially that made the work easier. And it was those, those tricks, those methods that turned out to be enormously important.\nCarol Sutton Lewis: Up to this point, codebreaking was not a rigorous, methodical practice. It was more like any kind of puzzle that you just work at until the solution comes to you. But Elizebeth, William, and their team were developing methods for codebreaking that could make it more systematic and more efficient. They used statistics to figure out what kinds of encryptions they were dealing with. They stacked different coded messages on top of one another so they had a better chance of picking out a pattern.\nBut this wasn't a long-term arrangement. The government didn't want to rely on this random millionaire out in the prairie to do all its codebreaking, so within months, it created its own unit in Washington.\nKatie Hafner: Meanwhile, Elizabeth and William were also starting to think about moving on from their work with George Fabyan. George turned out to be a moody and controlling man. And kinda creepy. He made sexual advances at Elizabeth when William was away. They were fed up.\nAnd this might have been the end of Elizebeth’s codebreaking career. The government had cut her out, and the war ended in 1918 anyway. But it turned out her country still needed her. Because even though the war was over, the government was about to have a new problem on its hands: alcohol.\nBREAK\nKatie Hafner: 1920 marked the start of Prohibition.\nJason Fagone: In the beginning of Prohibition, I think there were some like normal dudes, who just happened to have a boat and they would, you know, they would sneak some shipments around and they liked to be out on the water and they weren't like necessarily terrible guys.\nKatie Hafner: But within a few years, organized crime had taken over.\nJason Fagone: …and this is the rise of the mafia of, of the mob. And at that point they were making so much money that they were able to hire cryptologic experts to create really secure codes for them to protect their communications and their shipments by creating these sort of ingenious systems of, you know, radio networks. where they would they would send, encoded, radio messages from a ship to a pirate radio station on shore.\nAnd by doing that, these rumrunners, you know, who worked for Al Capone or whoever else, were able to sort of run circles around the Coast Guard.\nKatie Hafner: This is what actually brought the Coast Guard knocking on Elizebeth's door in 1925. She and William were living in Washington D.C. He was working for the Army, and she had left her work as a codebreaker to work on some books and start a family. But the Coast Guard needed someone like her, someone who could help them crack the rum runners' codes.\nJason Fagone: And at first they're basically bringing these packets of puzzles to her doorstep. And she's sort of like, taking care of her infant kid, and, and breaking codes at home. And then like bringing the, the solved puzzles back to the treasury.\nKatie Hafner: The Coast Guard was actually part of the Treasury back then. Anyway, every time Elizebeth dropped off a packet of solved codes, they’d give her a new one.\nAnd it was tough for her to keep up.\nJason Fagone: …and the gangsters are getting wealthier and wealthier and more violent.\nKatie Hafner: In 1931, Elizebeth convinced the Coast Guard to let her lead her own code-breaking unit.\nA role like this in the U.S. government was pretty unheard of for a woman at the time. And it was a much more public-facing one than Elizebeth’s wartime codebreaking work. Not only was her unit just smashing through thousands of codes, but they were also testifying against the mob.\nElizebeth Friedman: I was called to give testimony on the messages that had been sent between these people at sea and those on shore in the smuggling operation. And the messages, once they were deciphered, were as plain as day.\n\"Send me so many cases of this and so many cases of that\" and, uh, they were very, very explicit messages. And, of course, I was attacked and said that this was just made up, it didn't really exist and so on. Well, I, in some case I remember I called for a blackboard and demonstrated a simple message that was going through.\nJason Fagone: Over and over, there's this, this spectacle, which was covered by newspapers of the day. It was kind of like an irresistible story. You would have this like Washington, DC mother walk into a courtroom and basically like, stare down guys who worked for Al Capone and explain just what code breaking was, how she did what she did, how, how she sort of stole the words of these gangsters from their own lips.\nKatie Hafner: So for a time, Elizebeth was a media sensation. She’d become such a formidable codebreaker that the government gave her a security detail.\nBut then, Prohibition ended. She kept working for the Coast Guard busting organized crime rings but by the end of the decade, she’d largely disappeared from the public eye. She and William went back to their quiet life in their house in DC.\nCarol Sutton Lewis: And this is where many accounts of her career end….\nBut in 2014, Jason was reading up on the history of the NSA, and he found some offhand mentions of Elizebeth’s work. And he just wasn’t buying the idea that her career had ended in the 30s. Because World War II was just around the corner.\nJason Fagone: It didn't seem plausible to me that she just would've been allowed to sit out World War II even if she had wanted to, because she was like the secret weapon for the government, right?\nCarol Sutton Lewis: Cracking the right codes could easily change the course of the war. And the U.S. understood this. Whereas in the First World War, the government scrambled to find even a handful of codebreakers, this time, decryption was a top priority, and early on, they recruited thousands of codebreakers. And most of these were young women straight out of college. That’s partly because men were focused on the actual fighting… but also because, in a way, codebreaking was seen as women’s work.\nThese women worked in crowded rooms, doing hard code breaking work, like Elizebeth had done back in World War I. But even though Elizebeth had earned a lot of fame and respect for her work, the actual task of puzzling over codes with a pencil and paper, looking for a clue, wasn’t glamorous. It was slow and often tedious … and I find this hard to imagine, but apparently, by World War II, it was seen as sort of secretarial work.\nAnyway, at the start of the war, you have all these codebreaking women working in and around Washington DC, and Jason just couldn't see how Elizebeth could have been right there, working in the same city, and not involved at all.\nJason Fagone: So I spent about a year and a half, hunting through the National Archives Annex in College Park, Maryland, looking for Elizebeth's World War II record.\nCarol Sutton Lewis: And he found it. In some dusty box in the National Archives, was a collection of plastic-bound folders with hundreds of messages that Elizebeth decoded during World War II.\nAnd he figured out what she was doing: hunting down Nazi spies in South America.\nJennifer Wilcox: Most people don't think about South America when they're thinking about World War II because those countries were actually not combatant countries, but, as it turns out, the Nazis are down there trying to get these countries to openly side with the Third Reich.\nAnd so there were spy- Nazi spy networks, being established down there. Pressure was being put onto South American governments to uh, aid the Nazi Party. And so getting that information was very valuable in protecting US and Allied concerns in this hemisphere.\nCarol Sutton Lewis: And Elizebeth was on it. By this point, the Coast Guard had been absorbed into the U.S. Navy, but she was still working in her same old codebreaking unit, cracking codes. And she was on top of everything that the Nazis were talking about in South America.\nJason Fagone: She knew what they were gossiping to each other about. She knew what the names of their girlfriends were back in Germany.\nThere was, one grandmother in Germany who was using the clandestine radio network to urge her, her son, who was a Nazi spy in, Rio de Janeiro to remember to brush his teeth. And, and in addition to those windows into the personal lives of these spies during war time, you get, you know, these incredibly sort of dire and ominous, messages from the SS, you know, targeting Allied ships, sending coordinates to Nazi U-boats so that they would be able to obliterate and, and sort of murder everybody on, on board.\nKatie Hafner: The messages sent around by the South American spies were using pretty classic methods of encryption, like book ciphers. What’s a book cipher? A book cipher is what it sounds like. The secret key is an ordinary book. Say, for example, you get a sequence of numbers, like 10-4-27. You’d take your book, flip to page 10, go line 4, and scan for the 27th letter on that line. Ok let’s say it’s a P. That’s the first letter. Elizebeth and William had actually developed a system for breaking these without even needing the book!\nBut the Nazis had developed much more sophisticated methods of encryption. They were encrypting with machines. So you might have heard of the Enigma machine. In fact I have to tell you, someone I know actually owns an original Enigma, and it just sits in his library in his house These are usually things you see in the Smithsonian. It blew my mind when I saw this thing. I was at a party and there it was and I asked him about it and he goes, Oh yeah, my Enigma.\nAnyway, these machines could encrypt messages under layers and layers of code, making them incredibly hard to break. But Elizebeth was able to crack some of these messages too.\nStuart Boersma: She was the first in the US as far as I know.\nKatie Hafner: Stuart Boersma is a professor of mathematics at Central Washington University. He was at a cryptology conference a few years ago, when he saw a presentation about Elizebeth Friedman.\nStuart Boersma: - this woman who I'd never heard of, even though I was interested in cryptology and the history of cryptology, it just kind of blew me away that how come nobody knows about this person?\nKatie Hafner: So he started reading up, and learned that Elizebeth had cracked Enigma messages, a feat she shared with only a handful around the world, most famously of course Alan Turing and the whole Bletchley Park crowd in the UK. A team of Polish mathematicians had done it even earlier.\nStuart Boersma: A lot of people refer to like the Enigma, as if there's one machine, but there were many different iterations of Enigma from the original commercial version well before World War II, to even, you know, during World War II, there are many different types of Enigma that were developed and just improved upon as the war went on.\nKatie Hafner: Elizabeth broke one called the Enigma D.\nStuart Boersma: And broke with really very little, as far as I can tell, very little intelligence from any other agency.This is before I think there was any communication with the folks at Bletchley, for instance.\nKatie Hafner: She had a couple of things working in her favor. First, the messages that she worked on came from a relatively simple machine.\nStuart Boersma: In particular, it didn't have the plug board. So if you're familiar with the pieces of Enigma there's one piece in the front of the machine called the plug board, which the German military added that feature to the commercial machine and that plug board does make it a lot more complicated.\nKatie Hafner: So no plugboard, that made it a bit easier. And second, the people who had configured this machine…had made a mistake.\nStuart Boersma: In the sense that they had their machine set up the exact same way every time they encrypted a new message and that's a big no no. The big power of the Enigma machine is that every message you encrypt you can put it at a new starting position and essentially it becomes a different cipher every time you send a message. But this person or this entity, sent about 60 or 70 messages, all using the same starting point or the same key.\nKatie Hafner: Thanks to that slip-up, Elizabeth had everything she needed to crack the codes. The actual messages, in this case, turned out to be not so interesting. Still, just cracking the codes was impressive.\nStuart Boersma: But she went well beyond that. She used the fact that she decrypted those messages. She then looked at the information she had and she could then deduce how the internal wirings of this machine was built.\nIn other words, She could figure out enough information that she could almost reproduce this entire machine on her own.\nKatie Hafner: So, the Enigma machines looked kind of like a typewriter, with a keyboard on top, but underneath it there were a few rotors and each of those rotors had all the letters of the alphabet on it.\nStuart Boersma: and a wire kind of randomly strung from one letter on the right to one letter on the left.\nKatie Hafner: To change the code, you have to change the wiring.\nStuart Boersma: And until somebody could actually capture one of these machines, they didn't know how these were wired together. And that's what made this sort of a big secret cryptologic machine. She just, she deduced how two of those rotors were wired, which was a pretty amazing feat.\nKatie Hafner: Cracking Nazi codes—those created by Enigma and simpler ones too—it gave Elizebeth incredible power. Not all the messages were mothers reminding their Nazi sons to brush their teeth. Some of them were of vital tactical importance, and in March, 1942, Elizebeth cracked a particularly important message. It revealed that the Nazis were planning to attack the Queen Mary—an Allied ship, carrying more than 8,000 US soldiers. But thanks to Elizebeth's codebreaking, the captain was warned in time and managed to evade the attack and get the ship safely to port.. By methodically undermining the Nazis' plans at every turn, her unit's work ultimately helped bring down the entire Nazi network in South America.\nBut as critical as Elizebeth’s work was, few people knew she was doing it.\nJason Fagone: She was a combatant in what Winston Churchill talked about as the Secret War, the shadow war, not a war of soldiers, but a war of languages and codes, conspiracies, radio transmitters, cipher machines. This is the war that was being fought under the surface, but was being fought to affect that hot war and give the commanders of the hot war an edge. And, it was the biggest secret in the world, probably.\nCarol Sutton Lewis: In the end, this woman who was a master of breaking secrets and making the unseen seen... was largely unseen and unrecognized herself.\nJennifer Wilcox: Like anybody who is involved in, uh, code breaking she had signed that she would not discuss her duties with anyone, and she kept that.\nCarol Sutton Lewis: When the Nazi spy ring came down, the FBI, led by J. Edgar Hoover, took credit for the takedown, without even a nod to Elizebeth’s code breaking unit at the Coast Guard.\nJennifer Wilcox: Hoover liked publicity and so he was actively out there saying Look at what we've got. He actually would strip off the Coast Guard and Navy, um, nomenclature and Elizebeth's signature on these things and put down FBI serial numbers on them to claim that this was FBI information and \"oh, look how great the FBI is. We broke this spy network in South America.\" And so, Elizebeth, who'd signed this non-disclosure form, couldn't really say or do anything about that.\nKatie Hafner: You might think that’s why Elizebeth has been lost to the historical record. She signed an NDA. End of story. But\nStuart Boersma: When people took oaths of secrecy when they were doing intelligence work during the war, it seems like all the women really took that seriously and never talked about it for their whole lives, whereas the men, you know, they have memoirs or they get books written about them. And for some reason they are not held to any of those secrecy requirements. Her husband is a good counter example. He worked in the army as opposed to the coast guard where Elizabeth worked.\nBut his work was all top secret too. A lot of people know about him and still nobody knows about Elizabeth. So I, I think there's a, a gender issue there somewhere.\nKatie Hafner: : Maybe pretty close to the surface, in fact, but in any event, long after the war was over, and she’d retired from codebreaking, Elizebeth kept quiet. No one ever knew what she had been up to in World War II. She was a lost woman of science…even to her own grandson.\nChris Atchison: Nothing was allowed to be really talked about. And my grandmother quite frankly, never mentioned any of it to anybody. And I've checked with other cousins that knew her and they said, \"Nope, not a word.\"\nCarol Sutton Lewis: Chris Atchison lived with his grandparents for a few years in D.C. in the 1960s. Chris wasn’t entirely clueless about her career. He knew that she’d been a codebreaker for the Coast Guard. His mom had mentioned that. But cracking Nazi spy messages? Helping to save ships carrying thousands of soldiers? He just had no idea what a big deal she was.\nAnd to Chris and the rest of her family, Elizebeth was just a regular person. She was a mother, a grandmother… But looking back…it fits.\nChris Atchison: If she was against something, it was really funny to listen to because she had this voice —she was the sweetest person until you backed her up against a wall. Then she, she had this thing: \"NOOOOO!\" So she had a tremendous force of will, and I think that her story reads that way.\nCarol Sutton Lewis: And in photos of a younger Elizebeth, Chris sees hints of who his grandmother would become.\nChris Atchison: If you look at early portraits of her, you can see there's a determination her in her eyes, in her, in her lips. She appears to be unamused and she's just like, she was cut from a different cloth.\nKatie Hafner: Elizebeth died in 1980, when she was 88 years old.\nBut her work lives on. Codebreaking today is a very different beast. In Elizebeth’s time, if you got your hands on the secret key or cracked it, you could decipher a message. But since then, mathematicians have developed methods for encryption using public keys. Very counterintuitive, and involves some very sophisticated math, but you can protect a message even when everyone in the world can see the encryption key. So not much of what Elizebeth did is relevant today. And today’s encryption probably won’t look much like the encryption of the future. That’s kind of the nature of codebreaking. A perpetual arms race between codemakers and codebreakers, developing ever more sophisticated methods to disguise and reveal their messages. The encryption is ephemeral but at any given time, incredibly important.\nIt’s impossible to know how world events might have shaped up differently without Elizebeth Smith Friedman—a woman who, at 23 years old, followed a strange rich man to the middle-of-nowhere Illinois in the hopes of finding an interesting job. If she hadn’t, what would the world look like? Nazi spy rings operating unchecked? Thousands of soldiers killed? Well, that's maybe a little hyperbolic, and Elizebeth herself would never be that dramatic.\nChris Atchison: Oh, she would... she would just go, \"Oh, it wasn't a big deal. I was just doing my job. That's what people are supposed to do.\" She would not be prideful. She would not be boastful. She would just go, \"Yeah, I was doing my job. That's all.\"\nCREDITS:\nKatie Hafner: Lost Women of Science is hosted by me, Katie Hafner.\nCarol Sutton Lewis: And me, Carol Sutton Lewis. Samia Bouzid wrote and produced this episode, with help from our senior producer, Elah Feder.\nKatie Hafner: Lizzie Younan composes all of our music. We had sound design from Alvaro Morello and Erica Huang, who also mastered this episode.\nI also want to thank Jeff DelViscio, chief multimedia editor at our publishing partner, Scientific American, my co-executive producer Amy Scharf, and Deborah Unger.\nCarol Sutton Lewis: We had fact checking help from Danya AbdelHameid. Lost Women of Science is funded in part by the Alfred P. Sloan Foundation and Schmidt Futures. We're distributed by PRX.\nKatie Hafner: You can learn more about Elizebeth Smith-Friedman at our website, LostWomenofScience.org, and please consider clicking on that all-important donate button. We had a story recently in the New York Times and someone saw it and gave us $100. We can’t get over it. $200 gets you a Lost Women of Science tote bag. But seriously, any donation would thrill and delight us. See you next week.\n---\nFURTHER READING:\nThe Woman Who Smashed Codes, Jason Fagone, Dey Street Books, 2017.\nElizabeth’s unfinished memoir, Internet Archive, 1966\nElizebeth Smith Friedman’s recovery of the wiring of two rotors from an enigma D machine, Stuart Boersma, Cryptologia, September, 2022 (behind a paywall)\nThe Woman All Spies Fear: Code Breaker Elizebeth Smith Friedman and Her Hidden Life Hardcover, Amy Butler Greenfield, Random House, October 2021\nThe Cryptanalyst Who Brought Down the Mob, Text by Chad Bowers, Illustration by Deborah Lee, web comic (PBS) 2021.\nCode Breaker, Spy Hunter: How Elizebeth Friedman Changed the Course of Two World Wars, Laurie Wallmark (author), Brooke Smart (illustrator), Abrams Books for young readers, 2021.\nGUESTS:\nJason Fagone, journalist and the author of the Woman Who Smashed Codes\nJennifer Wilcox, director of education at the National Cryptologic Museum\nStuart Boersma, professor of mathematics at Central Washington University\nChris Atchison, grandson of Elizebeth Smith Friedman\nKatie Hafner is host and co-executive producer of Lost Women of Science. She was a longtime reporter for the New York Times,, where she remains a frequent contributor. Hafner is uniquely positioned to tell these stories. Not only does she bring a skilled hand to complex narratives, but she has been writing about women in STEM for more than 30 years. She is also host and executive producer of Our Mothers Ourselves, an interview podcast, and the author of six nonfiction books. Her first novel, The Boys, was published by Spiegel & Grau in July. Follow Hafner on Twitter @katiehafner\nCarol Sutton Lewis is co-host and producer of Season 3 of Lost Women of Science. An attorney who has focused on education and parenting issues for decades, she is passionate about sharing inspirational stories and helpful resources with learners of all ages. She is also the creator and host of Ground Control Parenting with Carol Sutton Lewis, an interview podcast about the job and the joy of raising Black and brown children. Follow Sutton Lewis on Instagram @groundcontrolparenting and on Twitter @gndctrlparentg\nThe Lost Women of Science Initiative is a 501(c)(3) nonprofit with two overarching and interrelated missions: to tell the story of female scientists who made groundbreaking achievements in their fields--yet remain largely unknown to the general public--and to inspire girls and young women to embark on careers in STEM (science, technology, engineering and math).Follow The Lost Women of Science Initiative on Twitter\nKatie Hafner, Carol Sutton Lewis and The Lost Women of Science Initiative\nStephanie Pappas\nJasper van Wezel, Lotte Mertens and Jans Henke | Opinion\nMaría de los Ángeles Orfila\nMike Wall and SPACE.com\nMariana Lenharo and Nature magazine\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Here's Why Salt Water Is Invading the Mississippi and Whether It Will Happen More Often", "date": "2023-10-12 17:00:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nRaging floods, intensifying drought and rising seas could affect saltwater intrusion\nCLIMATEWIRE |The drought-driven wedge of salt water creeping up the Mississippi River is deepening a mystery about one of the world's mightiest waterways.\nHow will climate change affect the river?\nThere are relatively few scientific studies on how warming is reshaping the Mississippi, and even fewer on saltwater intrusion from the Gulf of Mexico. The void comes as climate change threatens to alter the second-longest river in North America through raging floods, rising seas and prolonged drought, having extraordinary effects on the people who live in more than 100 cities and towns nestled along its banks.\nScientists admit that gaps in their understanding about the effects of rising temperatures on the river have left them searching for answers about the saltwater wedge that is slowly moving upriver toward New Orleans, where it could jeopardize freshwater supplies by next month.\nBut they say there are a number of ways climate change could be affecting the wedge.\nDroughts are expected to grow more frequent and intense across much of the U.S., meaning dry spells like the one affecting the river now could happen more often. That has helped the wedge move upriver from the Gulf because the depleted river flow isn't strong enough to stop it.\nBut heavy rainfall events are also intensifying, potentially increasing the risk of floods — and preventing salt water from creeping into the channel. It’s still unclear which factor is likely to have the greater influence.\nSea levels are also rapidly rising along the Gulf Coast. That could increase the risk of saltwater intrusion on the river, scientists say — but they aren’t sure by how much.\nAnd there are plenty of other human factors to consider. The Mississippi is one of the most heavily engineered rivers in the country, with dams, levees, reservoirs and frequent dredging. These practices can affect the river’s flow, making it difficult to parse out the influence of climate change compared with other forces. This is the second year in a row that salt water has entered the river, and the fourth time since 1999.\n“It’s still very much an open question what’s going to happen in the future of the Mississippi and the degree to which the trends we’ve been seeing over the last few years is the result of climate change,” said Samuel Muñoz, a hydrology expert at Northeastern University.\nThe wedges over the last two years will likely spur more research, said Tor Törnqvist, a geologist at Tulane University in New Orleans.\n“I wouldn’t be surprised if more people are gonna jump on this,” he said.\nExtended drought across the Mississippi River Basin is largely responsible for this year’s event, weakening the river’s flow and causing water levels to approach record lows in some areas. The Mississippi's powerful flow prevents much salt water from seeping upstream in ordinary years, even as the Gulf of Mexico presses up against its mouth.\nA similar situation occurred in 2022, when water levels in some stretches of the river — including Memphis, a key shipping hub — dropped to some of their lowest levels ever observed.\nThe U.S. Army Corps of Engineers has already constructedan underwater sill at the bottom of the river, designed to slow the salt water’s progress, and is in the process of raising it even higher. Still, residents in some areas, including parts of Louisiana’s Plaquemines Parish, have been using bottled water for weeks.\nAnd while the salt water’s incursion has slowed over the last two weeks, experts say itcould still hit New Orleansby the end of November, leaving officials two months to decide how to protect the city’s drinking water.\nWorsening droughts could increase the risk of saltwater wedges. But intensifying downpours could have the opposite effect. There’s the potential for a kind of climate tug of war between intense wet and dry periods on the Mississippi River, and scientists don’t have a clear answer about which effect will win out.\nThat’s because climate models tend to disagree in their projections for the Mississippi River’s climate future, Muñoz said.\n“There’s really no consensus,” he said. “Some of the models say that river flow discharge will go up. Other models say it will go down.”\nMuñoz and other researchers publisheda scientific paperearlier this year presenting the results of a single model suggesting that flow will generally increase in a warming climate, increasing the odds of floods.\nBut it’s “just one model,” he cautioned. “There are others, and they would probably tell a different story if we really dug into them.”\nAnother study, published last year by researchers from the Army Corps, explored simulations from a suite of 16 models. Most projections suggested stronger flow as the climate warms, although the study notes that some models predicted the opposite.\nScientists are working to solve the mystery. Muñoz is involved in a project, funded by the National Science Foundation, to investigate how climate change will affect large-scale weather patterns like heavy precipitation and drought on the Mississippi River Basin, along with several researchers from Rice University.\nStill, he said, there are other factors that could affect saltwater intrusion in the future.\nDredging, the construction of dams and reservoirs, and other human activities on the river are one factor. Americans have dramatically engineered the Mississippi River to control floods and increase navigability. And the Army Corps regularly dredges the river so barges can travel the waterway.\nBut “deepening the channel obviously makes things much more vulnerable,” said Törnqvist of Tulane, who noted that it can increase saltwater intrusion.\nSea levels are also rapidly rising along the Gulf Coast, as much as three times faster than the global average.\nAt the same time, the land itself is slowly sinking into the sea. Known as subsidence, the process has a variety of causes, some natural and some driven by human activities, like groundwater withdrawal.\nThe combination of rising seas and subsidence likely raises the potential risk of saltwater intrusion, Törnqvist said. But it's unclear by how much — another question that few studies have addressed.\n“I’m not sure if anyone has ever studied this in any detail,” he said. “That will remain probably a matter of some speculation for now. But I think it’s safe to say it’s something we need to understand for sure.\n“I would also expect, because of this situation we’re facing right now, that it’s gonna happen pretty soon,” he added.\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nChelsea Harvey covers climate science forClimatewire. She tracks the big questions being asked by researchers and explains what's known, and what needs to be, about global temperatures. Chelsea began writing about climate science in 2014. Her work has appeared inThe Washington Post,Popular Science,Men's Journaland others.\nDaniel Cusick and E&E News\nDuy Linh Tu and Julian Lim\nStephenie Livingston\nStephanie Pappas\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "How to Watch the Northern Lights and Other Awesome Auroras", "date": "2023-10-13 10:45:00", "text": "Digital offer!\nDigital offer!\nWhen the sun gets feisty, Earth’s atmosphere can literally light up. But seeing the resulting aurora isn’t always easy\nImagine standing under the starry vault, bundled against the cold, when the sky erupts overhead. Rippling curtains, ribbons and streamers of colors across the rainbow light up the night, shimmering and majestic and all eerily silent.\nThat’s what it’s like to see a vivid auroral display, and being able to witness one for yourself is getting more likely every day. The sun’s been getting feisty lately, blasting out flares of radiation and burps of gas that can wash over Earth. This uptick in solar outbursts—which is an expected part of our sun’s activity cycle—boosts the chances for the occurrence of the aurora borealis, or northern lights, in the Northern Hemisphere. (In the Southern Hemisphere, the phenomenon is the aurora australis, or southern lights.) Beautiful, fantastic and still in many ways mysterious, these dancing multihued displays tend to be visible only at high latitudes, but in recent weeks they have been spotted in the Northern Hemisphere as far south as Virginia!\nMany ancient peoples associated the auroras with fire, which is understandable: the sky can glow with ripples of yellow and red, as if it is itself aflame or perhaps instead reflecting some distant over-the-horizon conflagration on the ground. But the lights come in many other colors, too: green is the most common, and purple and pink can make appearances, too. Sometimes auroras can even glow an electric blue.\nThey come in many shapes as well, from curtains and sheets to streaks, undulating “dunes” and even spirals. Sometimes they seem stable and unmoving, and other times they can flicker and dance like waves that crash across the sky in seconds.\nWhat they all have in common, besides their unearthly beauty, is their root cause: magnetism.\nThe sun has a fiendishly complex magnetic field created by the motions of ionized gas called plasma in its interior. The magnetic lines of force at the surface create many observable effects, including sunspots, which are dark regions where solar plasma cools and emits less light than surrounding areas. These lines also contain vast amounts of energy. If they tangle up, they can snap like rubber bands, releasing that energy as a mind-stompingly powerful solar flare—equivalent to the simultaneous detonation of billions of thermonuclear bombs—or a coronal mass ejection, which is faint in visible light but blasts away billions of metric tons of plasma from the sun at speeds upward of a million kilometers per hour.\nNear the sun, these solar storms are apocalyptically intense—so strong that they can erode a planet’s atmosphere. But even on Earth, 150 million kilometers away, there can still be profound effects.\nOur planet, too, has a magnetic field—and so does a cloud of plasma blasted out by a solar storm. When such outbursts hit Earth, the two magnetic fields interact in very complicated and, honestly, not terribly well-understood ways. Streams of charged particles flow along Earth’s field lines to the planet’s poles, funneling down into our atmosphere, where they strike at high speed.\nThese ions are like subatomic bullets that hit atoms and molecules in our upper atmosphere and rip away their electrons, which are like shrapnel. When these charged particles reconnect, a little bit of light is emitted with a color that is characteristic of the particular atom or molecule involved.\nRecombining with electrons can make atomic oxygen emit red or green light, depending on atmospheric conditions. Much of Earth’s atmosphere is thick with other atoms that collide with the atomic oxygen and absorb the energy needed to emit light, so these colors are mostly seen at very high altitudes where the atmosphere is more rarified. Red can be seen at 200 kilometers or higher, and green is visible from about 100 to 200 km. Lower than that, the air is too dense for the atoms to glow, and this causes an abrupt cutoff to the green auroras at that height, which is why they commonly display a sharp lower edge.\nIf the particles from the sun penetrate lower into the atmosphere, they can impact nitrogen molecules, which emit light in blue and red. In a strong event, these emissions can intermix, and our eyes see this as a dazzling assortment of purple, pink, yellow and other colors. Even then, this all happens so far above our heads that the display is completely silent.\nOutside of colors, the forms an aurora can take arise from exactly how a solar outburst reshapes a portion of Earth’s magnetic field. Sometimes the interaction is weak, and only a soft glow is seen. Other times the impact of the particles forms long vertical sheets, which can appear as wavy folds like a drape—in fact, these kinds of auroral shapes are called curtains. If seen from directly underneath, these curtains can seem to surround you, and perspective makes them look like they’re a series of parallel lines and waves radiating away from a single point. This is called a corona. Sometimes the magnetic field wraps around itself like a rolled-up carpet, creating a very dramatic (and somewhat rare) spiral-shaped sheet.\nBecause Earth’s magnetic field is dipolar like a bar magnet and aligned roughly perpendicular to our world’s rotation, geomagnetic field lines extend most prominently from the vicinity of our planet’s North and South poles. These geomagnetic lines collect incoming solar particles and channel them to polar regions, which is why vivid auroras are more common at higher latitudes. When an especially strong solar storm strikes, its particles can overflow to cascade down from the poles, creating vibrant auroras at midlatitudes. Extremely powerful solar eruptions can even spark auroras near the equator; that happened in 1859 during the very first solar storm ever detected.\nSeeing an aurora depends on many factors. Although they can happen even when the sun is relatively quiet, they’re brighter during a solar storm. Several websites can alert you to such an event, including the popular SpaceWeather.com and the National Oceanic and Atmospheric Administration’s Space Weather Prediction Center. There are apps for mobile devices that can alert you as well.\nIf you live in the midlatitudes, as most people in the U.S. do, and you get an alert that a solar storm is occurring, your best bet to see an aurora is to find a dark site away from city lights. It’s particularly important to have no bright lights to your north because the auroras will lie in that direction. (I used to live south of a medium-sized town, and seeing auroras was hopeless from there.) Once you’ve reached your dark site and your eyes have adapted to the darkness, first look toward the horizon; our round planet makes more distant events appear close to the ground. If you live farther north, you can try looking higher up, especially if the storm is strong.\nYou can try photographing the auroras if you have a decent camera and a steady mount such as a tripod. A phone camera might work as well if you have a way to hold it motionless, such as propping it up against a fence or tree (that’s worked for me when trying to photograph stars). My advice is to simply look, though, before trying to get any photographs. Just enjoy the experience!\nThe sun goes through magnetic cycles, with the strength of its field waxing and waning every 11 years. The next maximum was originally predicted for July 2025, but our star has already been blasting off storms that create intense auroras on Earth, suggesting that the solar cycle’s peak may occur in 2024. Even for a year or two after the peak, the sun is still capable of some pretty big events. Because of complicated physics, the best times to see auroras are usually at the equinoxes in March and September, but any time of year can have brilliant apparitions, so be alert.\nI’ve never seen a strong auroral display, despite many years of trying—I’ve just never been at the right place at the right time with good weather. This cycle may finally be my chance. I’ll keep my hopes—and my eyes—high.\nPhil Plait is a professional astronomer and science communicator in Colorado. He writes the Bad Astronomy Newsletter. Follow him on Substack.Credit: Nick Higgins\nAllison Parshall\nPaul Brooke\nKatherine Wright\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "The AI Boom Could Use a Shocking Amount of Electricity", "date": "2023-10-13 11:00:00", "text": "Digital offer!\nDigital offer!\nPowering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become\nEvery online interaction relies on a scaffolding of information stored in remote servers—and those machines, stacked together in data centers worldwide, require a lot of energy. Around the globe, data centers currently account for about 1 to 1.5 percent of global electricity use, according to the International Energy Agency. And the world’s still-exploding boom in artificial intelligence could drive that number up a lot—and fast.\nResearchers have been raising general alarms about AI’s hefty energy requirements over the past few months. But a peer-reviewed analysis published this week in Joule is one of the first to quantify the demand that is quickly materializing. A continuation of the current trends in AI capacity and adoption are set to lead to NVIDIA shipping 1.5 million AI server units per year by 2027. These 1.5 million servers, running at full capacity, would consume at least 85.4 terawatt-hours of electricity annually—more than what many small countries use in a year, according to the new assessment.\nThe analysis was conducted by Alex de Vries, a data scientist at the central bank of the Netherlands and a Ph.D. candidate at Vrije University Amsterdam, where he studies the energy costs of emerging technologies. Earlier de Vries gained prominence for sounding the alarm on the enormous energy costs of cryptocurrency mining and transactions. Now he has turned his attention to the latest tech fad. Scientific American spoke with him about AI’s shocking appetite for electricity.\n[An edited and condensed transcript of the interview follows.]\nWhy do you think it’s important to examine the energy consumption of artificial intelligence?\nBecause AI is energy-intensive. I put one example of this in my research article: I highlighted that if you were to fully turn Google’s search engine into something like ChatGPT, and everyone used it that way—so you would have nine billion chatbot interactions instead of nine billion regular searches per day—then the energy use of Google would spike. Google would need as much power as Ireland just to run its search engine.\nNow, it’s not going to happen like that because Google would also have to invest $100 billion in hardware to make that possible. And even if [the company] had the money to invest, the supply chain couldn’t deliver all those servers right away. But I still think it’s useful to illustrate that if you’re going to be using generative AI in applications [such as a search engine], that has the potential to make every online interaction much more resource-heavy.\nI think it’s healthy to at least include sustainability when we talk about the risk of AI. When we talk about the potential risk of errors, the unknowns of the black box, or AI discrimination bias, we should be including sustainability as a risk factor as well. I hope that my article will at least encourage the thought process in that direction. If we’re going to be using AI, is it going to help? Can we do it in a responsible way? Do we really need to be using this technology in the first place? What is it that an end user wants and needs, and how do we best help them? If AI is part of that solution, okay, go ahead. But if it’s not, then don’t put it in.\nWhat parts of AI’s processes are using all that energy?\nYou generally have two big phases when it comes to AI. One is a training phase, which is where you’re setting up and getting the model to teach itself how to behave. And then you have an inference phase, where you just put the model into a live operation and start feeding it prompts so it can produce original responses. Both phases are very energy-intensive, and we don’t really know what the energy ratio there is. Historically, with Google, the balance was 60 percent inference, 40 percent training. But then with ChatGPT that kind of broke down—because training ChatGPT took comparatively very little energy consumption, compared with applying the model.\nIt’s dependent on a lot of factors, such as how much data are included in these models. I mean, these large language models that ChatGPT is powered by are notorious for using huge data sets and having billions of parameters. And of course, making these models larger is a factor that contributes to them just needing more power—but it is also how companies make their models more robust.\nWhat are some of the other variables to consider when thinking about AI energy usage?\nCooling is not included in my article, but if there were any data to go on, it would have been. A big unknown is where those servers are going to end up. That matters a whole lot, because if they’re at Google, then the additional cooling energy use is going to be somewhere in the range of a 10 percent increase. But global data centers, on average, will add 50 percent to the energy cost just to keep the machines cool. There are data centers that perform even worse than that.\nWhat type of hardware you’re using also matters. The latest servers are more efficient than older ones. What you’re going to be using the AI technology for matters, too. The more complicated a request, and the longer the servers are working to fulfill it, the more power is consumed.\nIn your assessment, you outline a few different energy-use scenarios from worst- to best-case. Which is the most likely?\nIn the worst-case scenario, if we decide we’re going to do everything on AI, then every data center is going to experience effectively a 10-fold increase in energy consumption. That would be a massive explosion in global electricity consumption because data centers, not including cryptocurrency mining, are already responsible for consuming about 1 percent of global electricity. Now, again, that’s not going to happen—that’s not realistic at all. It’s a useful example to illustrate that AI is very energy-intensive.\nOn the opposite end, you have this idea of no growth—zero. You have people saying that the growth in demand will be completely offset by improving efficiency, but that’s a very optimistic take that doesn’t include what we understand about demand and efficiency. Every time a major new technology makes a process more efficient, it actually leads to more people demanding whatever is being produced. Efficiency boosts demand, so boosting efficiency is not really saving energy in the end.\nWhat do I think is the most likely path going forward? I think the answer is that there’s going to be a growth in AI-related electricity consumption. At least initially, it’s going to be somewhat slow. But there’s the possibility that it accelerates in a couple of years as server production increases. Knowing this gives us some time to think about what we’re doing.\nWhat additional research or other steps might be needed?\nWe need a higher quality of data. We need to know where these servers are going. We need to know the source of the energy itself. Carbon emissions are the real numbers that we care about when it comes to environmental impact. Energy demand is one thing, but is it coming from renewables? Is it coming from fossil fuels?\nMaybe regulators should start requiring energy use disclosures from AI developers because there’s just very little information to go on. It was really hard to do this analysis—anyone who is trying to work on AI at the moment is facing the same challenges, where information is limited. I think it would help if there was more transparency. And if that transparency doesn’t come naturally, which it hasn’t so far, then we should think about giving it a little bit of a push.\nLauren Leffer is a tech reporting fellow at Scientific American. Previously, she has covered environmental issues, science and health. Follow her on Twitter @lauren_leffer\nKate Saenko and The Conversation US | Opinion\nThe Editors\nVarun Sivaram and Madison Freeman\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Bed Bugs and Influencers Spark Pest Panic in Paris. Here's What You Need to Know", "date": "2023-10-13 11:30:00", "text": "Digital offer!\nDigital offer!\nMedia reports suggest an unprecedented outbreak of bed bugs in Paris, but experts aren’t so sure anything is out of the ordinary\nIt was hard to miss the dire headlines: bed bugs were reportedly all over Paris during the city’s Fashion Week, from the metro to a high-end restaurant. As fashionistas made their way home—and in light of the fact that Paris has been preparing to host the Olympics next summer—people asked, why did this happen all of a sudden? Why did it occur here? And are we headed for more outbreaks worldwide?\nThe situation echoes another bedbug resurgence from more than a decade ago—in particular, in New York City—when the pests made daily headlines for popping up in hotels, apartment complexes, movie theaters, subways, and more. “It feels a lot like 2010 in the U.S. all over again,” says Richard Cooper, a pest control expert at R. Cooper Consulting and a research associate in the Urban Entomology Lab at Rutgers University.\nWhile Paris Fashion Week may mark the first major bedbug headlines since then, Cooper isn’t convinced that this is a resurgence: “I think a lot of it is probably getting hyped up,” he says. Other experts agree. “It has the media excited, but in all honesty, these populations don’t develop just overnight,” says Dini Miller, a professor and urban pest management specialist at Virginia Tech. “This is just getting attention again. And I promise these bed bugs have been there for a while.”\nBed bugs are pests that feed mainly on humans; their preferred meal is our blood, and they congregate in places where their food is as easy to get as possible. They particularly like to hunker down anywhere near where people sleep, such as in mattresses, furniture and baseboards. Bed bugs have lived with humans for millennia, and although their numbers may have waxed and waned over that time, they’ve never truly disappeared.\nSo what made the recent Paris sightings big news? According to both Cooper and Miller, in some cases, bedbug infestations may have decreased during the COVID pandemic. After all, the insects often move around by hitching a ride when people travel and socialize. During the pandemic, many people were in lockdown or practicing social distancing. “I think the pandemic really crashed the spread of bed bugs,” Cooper says. Even passing the insects between apartments within a single building was unlikely, he says, because people weren’t mingling with their neighbors.\nWith the world opening back up over the past couple of years, the Paris cases are right on schedule, Cooper adds. “I always thought it was going to be about a two- to three-year lag from when we started traveling again,” he says.\nBed bugs may not have been spreading a lot during the pandemic, but deep reservoirs of them were still thriving worldwide. Although the pests can affect anyone across the socioeconomic spectrum, the worst infestations often strike people living in poverty, as well as older or disabled people. These are the groups of people who have continued to suffer from infestations despite the pandemic, both Cooper and Miller note. It’s expensive to treat a bedbug infestation—and to keep up on high-quality pest control in general, which can involve regular application of chemicals and other products, along with inspections. Getting rid of the pests is also physically demanding: once you have an infestation, you need to wash all of your laundry and bedding on high heat, inspect and treat furniture, and more. It’s hard, expensive labor.\n“Let’s say the middle class and above will pay whatever it takes to get rid of [bed bugs in] their home. And if they’re not traveling, and their kids aren’t sleeping over at other people’s houses, then, yes, we did see a decline in that situation,” Miller says of the pandemic trends. “But one of the upticks that became very, very apparent was with elderly and disabled people.”\nSo now that people who can afford it are traveling more—say, for Fashion Week and the Olympics—will there be a new surge?\n“I don’t think we’ll ever see what we saw in the first go-round with the resurgence,” Cooper says, referencing the outbreaks in the 2010s. “I think there are too many people who are aware of bed bugs now.” In that earlier case, he adds, there was close to a 10-year period “where people weren’t very aware, which gave the bed bugs a chance to spread pretty much unbridled.”\nCooper emphasizes that the chances of travelers in Paris actually sparking an outbreak elsewhere are slim to none. The likelihood that a specific hotel has some bed bugs in it is fairly high, he says, but the numbers are still low overall. The chances that the insects are in your room, specifically, are even lower, and the chances that you’ll bring enough of them home to actually start an infestation are lower still. (You’d have to either bring home both a mature male and female or a female that just happened to be pregnant.)\nTo avoid even that slim chance, there are relatively simple steps anyone can take to avoid bed bugs. First of all, remember that the insects and their eggs are visible to the human eye. Any time you enter a hotel room, take a look along the seams of the mattress and edges of the headboard to look for an infestation. Classic signs: bedbug feces, which appear as small black splatters; eggs, which look like miniature grains of rice; and actual bed bugs, which are about the size of a lentil and dark reddish brown, with a flat body if they haven’t fed or a bloated one if they have. If you see signs of the insects, leave that room immediately.\nWhen departing from a hotel (whether you’ve spotted bed bugs or not), check your baggage and clothing. Miller suggests using a sticky lint roller. “Just roll that over yourself,” she says. If you don’t see any bed bugs or eggs, “then there is nothing there.”\nOnce you are home, wash all of the clothes that can withstand it on high heat and dry them on high for about 20 minutes. For more delicate clothes, try a steamer. And for other fabrics, simply inspect them carefully. Luggage can also be steamed or placed in special heat boxes that are available for the sole purpose of killing errant bed bugs.\nAnd don’t pay attention to the hype. “Realize that bed bugs are an issue that we’re going to be living with for quite some time,” Miller says. “When they end up in the media, it’s because people start paying attention to them again.”\nBrooke Borel is articles editor at Undark magazine and author of Infested: How the Bed Bug Infiltrated Our Bedrooms and Took Over the World.Credit: Nick Higgins\nKate Wong\nChristopher Intagliata\nKenneth F. Haynes\nRossella Lorenzi and LiveScience\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Climate Change Is Making Saltwater Intrusion Worse in Coastal Areas", "date": "2023-10-13 13:00:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nA hydrogeologist explains the shifting balance between fresh and salt water at thecoast as sea levels rise\nThe following essay is reprinted with permission from The Conversation, an online publication covering the latest research.\nSeawater intrusion is the movement of saline water from the ocean or estuaries into freshwater systems. The seawater that hascrept up the Mississippi Riverin the summer and early fall of 2023 is a reminder that coastal communities teeter in a fragile land-sea balance.\nFresh water is essential for drinking, irrigation and healthy ecosystems. When seawater moves inland, the salt it contains can wreak havoc on farmlands, ecosystems, lives and livelihoods.\nI am acoastal hydrogeologistand have studied water across the land-sea interface for 25 years. I think of seawater intrusion as being like a seesaw: The place where fresh water and salt water meet is the balance point between forces from land and forces from the sea.\nA push from the land side, such as heavy rainfall or high river flows, moves the balance point seaward. A push from the sea side – whether it’s sea-level rise, storm surge or high tides – moves the balance point landward. Droughts or heavy use of fresh water can also cause seawater to move inland. As climate change and population growth stress freshwater supplies, one result will bemore seawater intrusion.\nThe current seawater intrusion in the lower Mississippi River is due primarily todrought in the Midwest, which has reduced the river’s volume. Both the magnitude of reduction in river flow and the length of time that the river is low influence how far upriver the salt water moves. As of Oct. 2, 2023, the saltwater “wedge” in the Mississippi had movednearly 70 miles upstreamfrom the river’s mouth.\nThisisn’t the first timethat low water on the river has allowed seawater to move inland. But as climate change raises sea levels and causes more severe weather anomalies, intrusion will become more common and will inch farther upstream.\nAnd the problem isn’t unique to the Mississippi. In Delaware, seawater istraveling farther up small tidal streamsduring storms and the highest tides, flooding farmland and killing crops.\nIn the Sundarbans of India and Bangladesh – one of the largest coastal mangrove forests in the world – seawater is intruding into the mouth of the Ganges River. The main causes there are upstream dams and water diversions from the river for irrigation and navigability, plus encroachment due to sea-level rise. Seawater intrusion couldthreaten many types of plants and animalsin thisUNESCO World Heritage Site, which is home to countless rare and endangered species.\nAnother interface between fresh water and salt water at the coast is less obvious becauseit’s underground. Many coastal communities draw their freshwater supply from groundwater – clean water that moves through pore spaces between grains of sand and soil.\nGroundwater doesn’t just stop at the coastline: Under the ocean floor, the groundwater is salty, and somewhere between land and the ocean, there is an underground meeting point. It typically is landward of the coastline because salt water is denser than fresh water, so it has a greater force and naturally pushes in. But just as with a river,that interface moveswhen groundwater levels drop on land or water levels rise offshore.\nIngroundwater basinsof central and southern California,widespread pumpinghas caused groundwater levels to drop hundreds of feet in some areas. This is tipping the seesaw and causing groundwater from the sea to move far inland. Accessible groundwater has supported irrigated agriculture in these areas, but now the double hazard of reduced groundwater availability and seawater intrusionthreatens crops like strawberries and lettuce.\nSeawater intrusion into groundwater is happening all over the world, but perhaps the most threatened places are communities onlow-lying islands. Fresh groundwater is often the sole source of water for drinking and irrigation on small islands, and it exists in a thin lens that floats on top of saline groundwater.\nThe lens can shrink in response to droughts, pumping and sea-level rise. It can also become salty from floodwater infiltration during storms or high tides.\nIn the Marshall Islands, for example, a combination of sea-level rise and wave-driven flooding is predicted to make many islandsuninhabitable by the end of the century.\nAs salt water continues to encroach on freshwater systems, there will be consequences. Drinking water that contains even 2% seawater canincrease blood pressure and stress kidneys. If salt water gets into supply lines, it cancorrode pipesand producetoxic disinfection by-productsin water treatment plants.\nSeawater intrusion reduces the life span of roads, bridges and other infrastructure. It has been implicated as a contributor to theChamplain Towers South condominium collapsein Surfside, Florida, in 2021. Seawater intrusion changes ecosystems, creatingghost forestsas trees die and marshes move inland.\nSmart managementcan tip the seesaw back toward the sea. Limiting surface water extraction and groundwater pumping, or injecting treated wastewater into vulnerable aquifers, can increase the force pushing against intruding salt water.\nConstructingseawallsor maintaininghealthy dune systemsalso can help hold seawater at bay, though these approaches protect only against saltwater flooding and infiltration at the surface, not underground. Pumping out saline groundwater or installing underground barriers can keep deeper salt water from moving inland.\nBeing proactive is best, because once groundwater is contaminated, it’s hard to remove the salt. If salt water does penetrate inland, communities can manage water quality by constructingdesalination plantsand switching to salt-tolerant crops.\nAnother option is to let nature take its course. Allowing marshes to migrate inland cancompensate for losses at the coastlineas sea level rises. This preserves critical habitats, enhances flood protection and stores carbon at ratesfar exceeding most terrestrial ecosystems– dialing back the acceleration of climate change.\nThis article was originally published on The Conversation. Read the original article.\nHolly Michael is the director of the Delaware Environmental Institute and a professor of earth sciences and civil and environmental engineering at the University of Delaware.\nChelsea Harvey and E&E News\nDaniel Cusick and E&E News\nDuy Linh Tu and Julian Lim\nDaniel Cusick and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Scientists Argue Conservation Is under Threat in Indonesia", "date": "2023-10-13 14:00:00", "text": "Researchers have been banned from working in Indonesia’s tropical rain forests after the government disagreed with their scientific conclusions.\nChristopher Intagliata: For Science, Quickly, I’m Christopher Intagliata.\nIndonesia’s more than 17,000 islands contain the largest expanse of tropical rain forest in Southeast Asia. And they’re teeming with biodiversity.\n[CLIP: Sound of hiking through the jungle]\nErik Meijaard: These forests are just incredibly rich.\nIntagliata: Conservation scientist Erik Meijaard has worked for more than three decades in these forests. He heads up the scientific consulting company Borneo Futures.\nMeijaard: It’s hot and sweaty and humid, but there’s so much diversity in these forests. There’s bird calls everywhere.\n[CLIP: Black-capped Lory call]\nBill Laurance: Everywhere you look, you see life.\nIntagliata: Bill Laurance is a tropical ecologist at James Cook University in Australia.\nLaurance: I mean, it’s just—the forests are just festooned with plants, animals, birds.... everything’s just chirping away. It’s just this giant bastion of life.\nIntagliata: That life— is on the brink, because Laurance says Indonesia has an incredible concentration of the world’s endangered and critically endangered species. It’s ...\nLaurance: Sort of an incredible magical place, in one sense, but one that’s greatly imperiled right now.\nIntagliata: And then there’s another sort of peril—one facing the scientists who do conservation work there. That’s the topic of a recent letter Laurance and Meijaard published in the journal Current Biology. Writing with several Indonesian colleagues, they warn that conservation science in the island nation is under threat.\nLaurance: We were seeing colleagues and researchers we knew and respected being essentially booted out of Indonesia …\nIntagliata: Including Meijaard himself.\nMeijaard: We published a critical letter in an Indonesian newspaper where we questioned the Ministry of Forestry and Environment’s statements about growing orangutan populations, and we said, “Look, we’ve been looking at this problem for over 30 years, and orangutan populations are simply not growing.... All three species of orangutans are in continuous decline.”\nIntagliata: He says the government responded quickly by banning him and his colleagues from doing research in the country. A leaked letter from the Indonesian Ministry of Environment and Forestry instructs the country’s national parks not to work with Meijaard or approve his research requests, saying his writings could “discredit the government.”\nMeijaard: And it’s really made it much more difficult to collaborate with foreign and Indonesian scientists working on conservation issues in Indonesia.\nIntagliata: We reached out to the Indonesian government but have not, at time of publication, received a response.\nThe scientists’ paper in Current Biology points out that Indonesia is far from the only country suppressing scientific work. They cite examples from Turkey, Sweden, the U.S. and Australia, too. But in a nation such as Indonesia, with so much biodiversity on the brink, the stakes for endangered species are especially high.\nMeijaard: If everyone says that orangutan populations are growing, and no one is there to question that, then orangutan populations “are” growing.\nIntagliata: And that perception becomes reality, he says.\nMeijaard: Without independent science, the government and other groups can completely change the narrative and generate fake realities about what is happening.\nIntagliata: And in a world where fake realities have been used to discredit lifesaving vaccines or to undermine free and fair elections, it’s easy to imagine how “fake realities” about the state of Indonesia’s forests could have very real repercussions for critically endangered species.\nScience, Quickly is produced by Jeff DelViscio, Tulika Bose, Kelso Harper and Carin Leong. Our theme music was composed by Dominic Smith.\nDon’t forget to subscribe to Science, Quickly wherever you get your podcasts. For more in-depth science news and features, go to ScientificAmerican.com. And if you liked the show, give us a rating or review.\nFor Science, Quickly, I’m Christopher Intagliata.\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "NASA's Psyche Mission Launches to Mysterious Metallic Asteroid", "date": "2023-10-13 14:28:00", "text": "Digital offer!\nDigital offer!\nNASA’s Psyche mission is on its way to a heavy-metal asteroid of the same name—a type of object that scientists have never seen up close before\nDeep in the asteroid belt, between Mars and Jupiter, lies a strange, metal-rich asteroid unlike anything anyone has ever seen before. Dubbed Psyche, the unique object may offer investigators a truly alien landscape to explore—one that could yield new insights about the origin of our solar system and perhaps even about Earth’s most remote region: our planet’s enigmatic, unreachable core.\nNow, finally, researchers are one step closer to revealing Psyche’s secrets, thanks to a newly launched NASA mission of the same name. The Psyche spacecraft blasted off on Friday morning atop a SpaceX Falcon Heavy rocket from the agency’s Kennedy Space Center in Florida. With the launch, the craft wrapped up a troubled stay on Earth and began an eight-year mission that is destined to reveal untold surprises about the mysterious metallic space rock. Suffice to say, scientists are psyched about Psyche.\n“That’s really a thrill of a lifetime, to sit on console in mission ops and watch your spacecraft launch on the rocket,” says Lindy Elkins-Tanton, a planetary scientist at Arizona State University and the mission’s principal investigator. “The moment after launch, when we’re in communications, the spacecraft is power-positive, and it’s thermally stable—that’s the jumping-up-and-down-screaming moment.”\nThe Falcon Heavy roared off the launch pad at 10:19 A.M. local time; less than five minutes later, it had ascended through the rough-and-tumble aerodynamics of Earth’s atmosphere, shedding the protective fairings encasing its interplanetary payload. Nearly an hour after launch and a subsequent two-minute burn of the Falcon Heavy’s second-stage engine, Psyche separated from the booster and begin its solitary voyage through space. The spacecraft also sent an initial signal suggesting all was well.*\nDuring the following hour or two, the spacecraft will deploy its two cross-shaped solar-power arrays, orient itself with regards to the sun and establish contact with mission controllers on Earth. These steps mark the start of a 100-day initial checkout period to establish Psyche’s tenure in space.\nThe launch marks the first of a trio of key NASA science flights that are reliant on the powerful Falcon Heavy rocket, which debuted in 2018. Falcon Heavy is a three-booster variant of SpaceX’s workhorse Falcon 9 launcher. Next year NASA’s Europa Clipper spacecraft is due to launch onboard a Falcon Heavy on a mission designed to explore Jupiter’s icy and astrobiologically intriguing moon Europa. A Falcon Heavy is also slated to launch the agency’s Nancy Grace Roman Space Telescope in 2027.\nToday’s launch ends a challenging beginning on Earth for the Psyche mission. The spacecraft was initially scheduled to depart during a window that opened in August 2022, but months before that appointed time, NASA announced that the mission wouldn’t manage a launch that year because of an issue with the spacecraft’s navigation software. Psyche was forced to undergo an agency-level review that could, in principle, have resulted in the mission’s cancellation.\nInstead the review made recommendations that helped put Psyche back on track, although the mission suffered an additional slight delay about a week before its three-week 2023 launch window was due to open when NASA announced that the spacecraft would sit the first week out because of a problem with its nitrogen thrusters. The launch also faced a one-day delay because of bad weather.\nBut to the mission team’s relief, Psyche now begins a six-year cruise through the solar system out to the asteroid belt, giving the team plenty of time to test the spacecraft instruments and fine-tune the plan for on-site operations. During the first two years of its flight, Psyche will also host the Deep Space Optical Communications experiment, a separate project testing laser communication technology in deep space. A highlight of the cruise will come in 2026 when the spacecraft flies past Mars to boost its speed, turning its instruments toward the Red Planet as it goes. The mission arrives at Psyche in August 2029, where nominal operations are planned for a little more than two Earth years—a little less than half the time it takes the asteroid to complete an orbit around the sun.\nUpon arrival, the Psyche spacecraft will set to work. It will use a pair of twin cameras to photograph the surface of the eponymous asteroid, a spectrometer to analyze its chemical composition, a magnetometer to hunt for signs of an ancient magnetic field and a radio communications system to map the object’s gravity—which will allow scientists to remotely probe its hidden subsurface.\nScientists hope the results will solve the biggest mystery about the asteroid Psyche: what it actually is. Right now astronomers are only confident about its orbit, size and shape—as well as the fact that its density and surface are both consistent with a metallic composition that is much richer than that of typical space rocks, such as the ones that NASA’s OSIRIS-REx mission just delivered to Earth.\nBut that’s about all anyone can confidently say about Psyche—and the mystery is the essence of the mission’s appeal. “So many of the things that we study are part of a population,” Elkins-Tanton says. “We don’t have that for Psyche. There are just not very many objects that are even similar to it, and it’s the only one that’s big, so it’s singular. So it probably came from an unusual process that only created one of it.”\nWhat scientists lack in knowledge about Psyche, they make up for with a host of hypotheses. Of those, mission personnel admit that their favorite is the notion that Psyche formed as the metallic heart of a miniature planetlike body and then lost much of its rocky outer layers to a truly world-shattering collision. If this is indeed Psyche’s story, studying the strange asteroid would offer scientists their first peek at the heavy-metal cores lurking inaccessibly deep inside Earth and other rocky planets.\n“We basically have no access to the core of anything,” says Katherine de Kleer, a planetary astronomer at the California Institute of Technology, who is not involved in the Psyche mission. “We can’t observe Earth’s core directly. We can’t observe the core of any other planet directly. Everything is indirect inference.”\nAnother potential explanation for Psyche’s strangeness holds that the asteroid formed close to the sun, where high temperatures would have allowed metal to solidify and endure while rock remained molten and was somehow stripped away. Some sort of orbital reshuffling—perhaps driven by the gravitational influence of Jupiter and Saturn, which are thought to have thrown their weight around in the early solar system—then must have carried the metallic body out to the asteroid belt.\nOr perhaps the mysterious object was created by some other process that is entirely different. In the eyes of mission scientists, there’s no bad answer. “Even if this isn’t the core of an ancient planetesimal, in that new ‘other’ hypothesis, it’s still something really interesting and different and a kind of object we’ve never seen up close before,” says Jim Bell, a planetary scientist at Arizona State University and imaging lead on the Psyche mission. “It’s not like the mission fails if [the asteroid] is not a core. We’re still going to learn something really, really interesting.”\nThat hoped-for novelty may well manifest as soon as the spacecraft arrives at its otherworldly destination. NASA has only visited rocky and icy worlds before—never a heavy-metal world, where familiar geologic processes may unfold in a very alien way.\nOne question is whether Psyche ever harbored volcanic activity, with flows of molten metal lava seeping from fissures in the world’s shiny surface. Lab experiments suggest that such flows would form low, braided channels of spectacular intricacy—although scientists can’t yet be certain.\n“There are some big caveats to that because those experiments that we did were here on Earth,” says Arianna Soldati, a volcanologist at North Carolina State University, who is not involved in the Psyche mission but took part in research attempting to replicate metallic lava flows on Earth. “It’s unclear what that would look like on Psyche, which has completely different conditions.”\nScientists are more confident that they’ll find impact craters, which could also look different on a metallic world, compared with a rocky surface such as Earth’s impact-battered moon. Lab experiments suggest that Psyche’s craters might be ringed by spiky crowns of metal droplets that froze when they splashed up from the surface—although again, there’s no telling in advance what the spacecraft will reveal.\n“It’s so fun to go to a place where we don’t know that much,” Elkins-Tanton says. “We’ve gotten kind of used to going to places where we know [more].”\n*Editor’s Note (10/13/23): This paragraph was updated after posting to reflect that the spacecraft successfully separated from the rocket.\nMeghan Bartels is a science journalist and news reporter for Scientific American who is based in New York City.\nRobin George Andrews\nLeonard David\nTim Gregory | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Climate Misinformation Persists in New Middle School Textbooks", "date": "2023-10-13 15:00:00", "text": "Digital offer!\nDigital offer!\nStudents could be taught for the next decade that humans are only partly responsible for climate change\nScientists have found no evidence that natural forces have contributed to our planet’s current global warming problem, but a middle school student reading a crisp new book from the nation’s top science textbook publisher might think otherwise. “Due to both human and natural activities,” the child would read, “the amount of carbon dioxide in the air has increased.”\nThat statement can be found in McGraw Hill’s seventh-grade textbook Texas Science, one of dozens of books up for adoption in the state’s first major consideration of new science instructional materials since 2013. The Texas State Board of Education held its initial public hearing about the proposed materials on August 29 and is expected to make a final decision about them after a second hearing in November. Textbooks that the board adopts will sit on classroom shelves in Texas beginning next fall, and they are likely to influence textbooks across the country.\nThe books have already engendered controversy. Climate education advocates have asked the state to adopt the new materials because despite their flaws, they include substantial climate content that explains the science underlying the climate crisis; the last set of textbooks adopted by the state a decade ago largely did not. Yet some supporters of the fossil-fuel industry, including a congressional representative, say the books represent, in the words of that representative, an infiltration of “the radical climate lobby” into education, and have asked people to pressure the state to reject them.\nThe books have been written expressly to conform to Texas’s new science standards—expectations about what students learn in each class and grade. When the State Board of Education updated the standards in 2021, it chose to include information about the climate crisis in a required class—middle school science—for the first time in Texas history. As first reported by Scientific American in 2022, however, the new climate standards did not go as far as many educators hoped. After a concerted campaign by the Texas Energy Council, an industry association that primarily represents oil and gas companies, the board limited the breadth and depth of its new climate science standards. This spring, as reported by E&E News, the board took the additional step of changing its textbook policy to explicitly favor books that emphasize fossil fuels’ “positive” aspects.\nBecause Texas is among the largest textbook markets in the U.S., the state has had long-standing influence over textbooks published nationwide. That means content written with Texan politics—and the state’s fossil-fuel industry—in mind winds up in classrooms across the country. Textbooks often have a long shelf life, so the approved materials will likely be read by children into the 2030s.\nThe bulk of public comment at the hour-long public hearing on August 29 comprised testimony by climate education advocates encouraging the board to approve the proposed books as they are because for the most part, their content about the climate crisis is accurate and direct. An 11th-grade student who testified at the hearing, Marygrace Beinke, argued that it is essential that her fellow students—as well as “our future presidents, teachers and scientists”—understand the threat the climate crisis poses. “Climate change isn’t patient or ineffable,” she said. “It’s a simple cause and effect, something we can and have to stop. Leaving these kids blind to that—it’s not just poor form but dangerous.”\nSome members of the board appeared sensitive to the effect that teaching about climate change would have on students’ perception of the oil and gas industry. Board member Will Hickman, who works as an in-house attorney for Shell Oil, asked a testifier whether instructional materials “should also include the benefits” of burning carbon. “We could turn the lights off and turn off the air-conditioning in here. It’d be 110 degrees, and we’d be sitting in the dark,” he said. “Is there a benefit to turning the lights on, turning on the air-conditioning?” The testifier responded that Hickman had conflated the use of fossil fuels with the benefits of electricity, which can be produced with renewable sources.\nA few weeks after the meeting, the aforementioned congressperson, Representative August Pfluger of Texas, who represents a portion of the state’s fossil-fuel-rich Permian Basin, wrote a post on Facebook in which he requested that his followers submit a comment to the State Board of Education asking for students to be taught “the truth about the importance of secure, reliable energy produced in the Permian Basin.” He noted that the new science standards require eighth graders to learn about climate change. “We cannot allow the radical climate lobby to infiltrate Texas middle schools and brainwash our children,” he wrote. Pfluger sits on the U.S. House Committee on Energy and Commerce. His office did not return a call for comment.\nTo examine how political tensions have affected the upcoming textbooks, I reviewed the climate content in the new middle school science textbook sets put forth by the three largest K–12 publishers: McGraw Hill, Savvas Learning Company (formerly Pearson K12 Learning) and Houghton Mifflin Harcourt (HMH), which together accounted for four of every five textbooks in U.S. public middle school science classrooms as of 2018. My review found that the proposed new textbooks include much more robust information about the climate crisis than their earlier editions did. In some cases, however, the books appear to cloud the human causes of the crisis.\nEach of the three sets—McGraw Hill’s Texas Science, Savvas’s Texas Experience Science and HMH’s Into Science Texas—put the bulk of their climate content in a chapter of an eighth-grade science textbook. Overall, these respective chapters describe recent climate change’s mechanism, impact and human origins without equivocation. But in places, they seem to downplay the role of fossil fuels. Oil, gas and coal account for more than 75 percent of global greenhouse gas emissions, according to the United Nations, yet the chapters each spend more words on the contributions of deforestation, agriculture and urbanization than they do on fossil fuels. In places, the books lean on the phrase “releasing greenhouse gases” rather than “emitting greenhouse gases” or “burning fossil fuels.” The HMH book closes its chapter by highlighting the climate contributions of deforestation, urbanization and “carbon dioxide and other greenhouse gases released by human activities.” Representatives from HMH did not respond to requests for comment about that language.\nMcGraw Hill’s eighth-grade climate section begins with a scenario for students to evaluate in which four friends are discussing recent climate change. One suggests that while there is evidence of humans impacting the climate, it’s “not considered scientific evidence.” A second says, “I think we now have evidence that supports the idea that humans are affecting Earth’s climate.” A third suggests that “we need more evidence,” while a fourth asserts that climate change “is a natural event. There is no evidence that human activities affect climate.” The book instructs students to evaluate which of the four characters they agree with.\nAsking students to debate the causes of climate change is not uncommon: more than half of science teachers across the U.S. say they teach the causes of climate change as a debate. Expert climate educators discourage this approach, however, noting that it could leave students with the misunderstanding that the causes of the climate crisis are also debated by scientists, which they are not.\nOutside of the eighth-grade chapters specific to recent climate change, the subject appears in a smattering of other places but not always robustly. In two places, McGraw Hill’s seventh-grade book asserts that both human and natural activities have recently increased carbon levels in the atmosphere. In a response to questions about Texas Science’s climate content, a McGraw Hill representative said that the company “is committed to developing accurate and effective educational materials aligned to the standards and curriculum requirements of our customers. We highly value the insight that our customers and the public bring to discussions of our content during this adoption process, which is ongoing.”\nA section in Savvas’s eighth-grade Texas Experience Science about how scientists learn about past climates by studying glaciers lists natural factors that have caused the climate to change over the course of time, including “distance from the sun” and “ups and downs” in ocean temperature. “But these naturally occurring events do not entirely explain the Earth’s temperature changes over the last few centuries. Human activities are another cause,” the section states. “Greenhouse gases are playing a role in warming the planet.”\nIn an e-mail to Scientific American, representatives of Savvas defended this language, saying that it and other climate content in the book are “fully aligned” with Texas’s new middle school science standards and that Savvas is “committed to ensuring our learning solutions provide the teachers and students we serve with the most accurate, relevant, fact-based, and pedagogically sound content.” Jesse Wilcox of the University of Northern Iowa, a co-author of the textbook, wrote in an e-mail that “we recognize humans are causing climate change. We note in the curriculum that nature, by itself, doesn’t account for the climate change we are experiencing and that greenhouse gases are warming the planet. While we want students to understand that our current climate is a human-caused problem, we also want students to recognize that natural factors (e.g., changes in radiation, orbital changes, and volcanic eruptions) influence climate. This is not a denial of human-caused climate change, but rather, a more complete understanding of factors that impact our climate on Earth.”\nThe textbooks are still drafts and were initially submitted for public review in April. As part of the adoption process, the Texas Education Agency organized two panels of reviewers to examine them. Neither set of panels asked for changes to the climate content of the three major textbook companies’ middle school books.\nNevertheless, when McGraw Hill presented the changes it planned to make to these drafts, it included tweaks to the eighth-grade climate change material. In one case, the original language said:\n“The main way humans have contributed to climate change is by burning fossil fuels to power automobiles and to produce electrical energy. Burning the fuels releases carbon dioxide into the atmosphere, which increases the amount of solar energy that is trapped in the atmosphere. Deforestation also increases carbon dioxide emissions, contributing to global warming.”\nIn the edited version, this language was changed, and another reference to urbanization was added:\n“The main way humans have contributed to climate change is by burning fossil fuels to meet energy demand. Burning fossil fuels releases carbon dioxide into the atmosphere. Deforestation and urbanization also increase carbon dioxide emissions, contributing to global warming.”\nWhen asked about these and other proposed edits by Scientific American, a McGraw Hill representative said changes were made for editorial reasons, “such as clarity, length, consistency, and alignment to standards.”\nThe previous set of middle school science textbooks McGraw Hill put up for adoption in Texas was called iScience and published in 2012. A book in the set suggested that the cause of the climate crisis wasn’t fully understood: “Although many scientists agree with” the U.N. Intergovernmental Panel on Climate Change’s conclusion that human industry has caused the crisis, “some scientists propose that global warming is due to natural climate cycles.” Editions of the textbook were also sold in Alabama, Florida, Georgia, Indiana, Massachusetts, Mississippi, New York, North Carolina, North Carolina, Tennessee, Virginia and Oklahoma. By 2018 versions of iScience sat on the shelves of a quarter of American middle school science classrooms, all with that language intact. In 2021 when I asked why that and other inaccurate language about climate change had been written into their science textbooks, McGraw Hill representatives responded that the content had been written between 2007 and 2009, when, they said, the U.N. IPCC “was still in its infancy,” and the science for the human causes of climate change wasn’t as settled as it is today. Yet the IPCC was formed in 1988 and issued its first warning about global warming in 1990.\nTwo groups of climate education advocates, the Texas Freedom Network and the National Center for Science Education (NCSE), conducted their own joint review of the proposed new textbooks’ climate content and found it overall met the limited requirements of the new standards. But in an interview, NCSE’s deputy director Glenn Branch noted that “even the best of the books have lots of room for improvement.”\nJudy Dickey, a doctoral student at Texas A&M’s Atmospheric Sciences program and former high school teacher, was one of the reviewers. She says the middle school textbooks left her with the impression that the publishers had watered down the contributions of fossil fuels to the crisis while overemphasizing the contributions of urbanization and deforestation.\n“I don’t know if this is intentional or not, but it felt like they were trying to shift the blame to other countries,” she says. “Deforestation and urbanization are not a North American problem, so it’s like saying that it’s all these other evil countries that are responsible for climate change.”\nThe textbooks’ suggestions that nature is contributing to the crisis are “100 percent false,” Dickey says, because while there are natural sources of greenhouse gases, the evidence suggests the planet would be in a cooling cycle if it were not for human emissions.\nThe Texas State Board of Education is expected to make its final decision about the textbooks at its next meeting, which will take place during the week of November 14. Texas residents can submit written comments on the proposed textbooks until October 30.\nKatie Worth is a freelance writer in Boston. She is author of Miseducation: How Climate Change Is Taught in America (Columbia Global Reports, 2021).Credit: Nick Higgins\nKatie Worth\nScott Waldman and E&E News\nMatthew Schneider-Mayerson | Opinion\nDana Hunter\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Dangerous 'Superbugs' Are on the Rise. What Can Stop Them?", "date": "2023-10-13 17:00:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nTraditional antibiotics drive bacteria toward drug resistance, so scientists are looking to viruses, CRISPR, designer molecules and protein swords for better superbug treatments\nThe bacteria may have entered her flesh along with shrapnel from the bomb detonated in Brussels Airport in 2016. Or perhaps the microbes hitched a ride on the surgical instruments used to treat her wounds. Either way, the \"superbug\" refused to be vanquished, despite years of antibiotic treatment.\nThe woman had survived a terrorist attack but was held hostage by drug-resistantKlebsiella pneumoniae, a bacterial strain often picked up by surgery patients in hospitals. Only by combining antibiotics with a new, experimental treatment did doctorsfinally rid her of the superbug.\nDevastating drug-resistant bacterial infections like this one are all too common, and they represent an ever-growing threat to global health. In 2019, antibiotic-resistant bacteria directly killedroughly 1.27 million people worldwideand contributed to an additional 3.68 million deaths. In the U.S. alone, drug-resistant bacteria and fungi together cause an estimated2.8 million infections and 35,000 deathseach year.\nAnd the problem is getting worse:Seven of the 18 concerning bacteriatracked by the Centers for Disease Control and Prevention (CDC) are becoming more resistant to common antibioticsconsidered essentialfor maintaining public health. Meanwhile, drug companies have been slow to make new antibiotics capable of beating the microbes.Fewer than 30 antibioticscurrently in the development pipeline target\"priority\" bacteria, as defined by the World Health Organization (WHO), and most of those drugs are still vulnerable to resistance, just like their predecessors.\nSo some scientists are looking beyond traditional antibiotics for new weapons that won't fuel the rise of superbugs. Their emerging arsenal features viruses that kill bacteria;CRISPR; and microbe-slaying molecules. They hope that these experimental treatments, some of which have been tested in patients, will kill superbugs without promoting resistance.\n\"The vision, for me, is that we move beyond antibiotics and really just see a much broader palate of options,\"Chase Beisel, leader of the RNA synthetic biology research group at the Helmholtz Institute for RNA-based Infection Research in Germany, told Live Science.\nBut until these new therapeutics are ready for prime time, the world needs to curtail its overuse and misuse of antibiotics, which experts say is speeding up the rate at which these lifesaving drugs become obsolete.\nRelated:Superbugs are on the rise. How can we prevent antibiotics from becoming obsolete?\nAntibiotics eitherdirectly kill bacteria or slow their growth, leaving the immune system to finish the job. The drugs work in several ways — by preventing bacteria from building sturdy walls or making copies of theirDNA, for instance. Growth-slowing antibiotics usually disrupt ribosomes, the factories in which bacterial cells make proteins.\nMany antibioticsshoot for the exact same molecular targets, and so-called broad-spectrum antibiotics' mechanisms are so universal that they work on both major classes ofbacteria: gram-positive and gram-negative, which are distinguished by the makeup and thickness of their cell walls. Broad-spectrum antibiotics, in particular, pressure both harmful and helpful bacteria in the body toevolve defensive strategiesthat eject or disable the drugs, or else alter their targets.\nBacteria can pick up such defenses through random DNA mutations, or by swapping \"resistance genes\" with other bacteria via a process called horizontal gene transfer. By making these gene transfers, bacteria can quickly spread such mutations to additional bacterial populations in the body and in the environment.\nThe misuse of antibiotics in health care, as well as in agriculture, has given bacteria endless opportunities to develop resistance, raising the chance that once-treatable infections will become life-threatening.\nRelated:New 'concerning' strain of drug-resistant gonorrhea found in U.S. for 1st time\nOne of the proposed alternatives to antibiotics wasfirst conceived more than a century ago, before the 1928 discovery ofpenicillin. Called phage therapy, it uses bacteria-infectingvirusescalled bacteriophages, or simply \"phages,\" which typically kill the germs by invading their cells and splitting them open from the inside.\nPhages can also pressure bacteria into giving up key tools in their drug resistance tool kits. For example, aphage called U136B can have this effect onE. coli. To infiltrateE. coli, the phage uses an efflux pump, a proteinE. colinormally uses to pump antibiotics out of the cell. If theE. colitries to change this pump to escape the phage, it reduces the bacterium's ability to pump out antibiotics.\nAnd unlike with antibiotics,bacteria are unlikely to gain widespread resistance to phage therapy, saidPaul Turner, director of the Center for Phage Biology and Therapy at Yale University.\nTurner and other experts have concluded that, \"if phage therapy were used at a global scale, that it would not lead to the same problem of widespread resistance to it, the way that antibiotic use has led to that problem,\" he told Live Science.\nHere's why: Antibiotic resistance has been dramatically accelerated by themisuse and overuse of antibiotics, especiallybroad-spectrum antibioticsthat work on a variety of bacteria. Phages, by contrast, can have much narrower targets than even narrow-spectrum antibiotics — for instance, targeting a protein found in onlyone or a few strainswithin one bacterial species.\nRelated:New drugs could stymie superbugs by freezing evolution\nThe target bacterium can still evolve resistance to an individual phage — but by picking the right combination of phages, scientists can make it so that the bacterium's evolution comes at a cost, Turner said. This cost might be a decrease in virulence or an increased vulnerability to antibiotics.\nTo date, phage therapy has mostly been tested through a regulatory framework known as \"compassionate use\" in patients like the Brussels Airport bombing victim, whose infections had no other treatment options. Phage therapy hasshown success in these settings, and in arecent observational studyof 100 patients who received phages alongside antibiotics.\nSo far in clinical trials, though, phage therapy generallyhasn't worked better than standard antibioticsor a placebo. Topline results from two recent trials hint at the treatment's effectiveness inspecific lungand foot infections, but the full results have yet to be released.\nSuccess in future trials will be key to getting phages into the clinic, Turner said. Those trials will have to show the therapy works for multiple types of infections, determine dosage and confirm phage therapies don't hurt helpful bacteria in the body, he added.\nAlthough made famous as a powerful gene-editing tool, CRISPR technology was actually adapted from an immune system found in many bacteria: CRISPR-Cas.\nThe key components of this immune system include molecular scissors, known as Cas proteins, and amemory bank of DNA snippetsthat a bacterium has collected from phages that once infected it. By tapping its memory bank, CRISPR-Cas can guide its lethal scissors to a precise point in an invading phage's DNA and snip it like a piece of ribbon.\nOn occasion, though, rather than attacking phages, CRISPR-Cas can accidentallygo after the bacterial cell's own DNA, triggering a lethal autoimmune reaction. This phenomenon inspired Beisel and his colleagues to explore using CRISPR-Cas to shred bacterial cells' DNA.\n\"The real draw of it is that it is a sequence-specific tool,\" meaning it targets only the DNA you tell it to, and not sequences present in other bacteria, Beisel told Live Science. So, once administered to a patient, \"the CRISPR machinery gets into a set of cells, but only those that have the sequence or sequences you picked will be attacked and killed.\"\nHow do you get CRISPR-Cas into the right bacteria? Various research groups are testing different delivery methods, but at present, the best strategy seems to be loading CRISPR machinery into a phage that infects the target bacterium, Beisel said.\nRelated:Scientists invent 'shape-shifting' antibiotic to fight deadly superbugs\nBeisel is a co-founder and scientific adviser of Locus Biosciences, a biotech company that's currently testinga CRISPR-enhanced phage therapyin a midstage, roughly 800-person trial. This approach couples the bacteria-killing prowess of phages with the ability of CRISPR-Cas to destroy essential bacterial genes. As with CRISPR-less phage therapies, clinical trials are needed to determine the treatment's safety profile and appropriate dosing.\n\"I can see these [treatments] coming about in the five- to 10-year time frame,\" Beisel said.\nBeyond phages and CRISPR, scientists are developing antibiotic alternatives that harness bacteria-slaying peptides — short chains of protein building blocks— and enzymes, specialized proteins that jump-start chemical reactions. These molecules differ from antibiotics because they can kill a very narrow range of bacteria by targeting bacterial proteins that cannot easily gain resistance to their attacks.\nLab-made molecules called peptide nucleic acids (PNAs) are some of the most promising candidates. These engineered molecules can be designed toblock bacterial cells from building essential proteinsthat are crucial to their survival. PNAs do this by latching onto specificmRNA, genetic molecules that carry the instructions for building proteins from the cell's control center to its protein construction sites. PNAs cannot enter bacterial cells on their own, though, so they'retypically attached to other peptidesthat easily pass through the bacterial cell wall.\nBy targeting proteins that cells cannot change without harming themselves, PNAs can avoid triggering drug resistance, Beisel explained. The engineered molecules could also be made totarget proteins that directly contribute to antibiotic resistance, for example, the efflux pumps used to push antibiotics out of cells or the enzymes capable of disabling the drugs. By emptying a germ's drug resistance tool kit, PNAs can then make it vulnerable to standard treatments.\nAntibacterial PNAs are still beingtested in lab dishesand animalsand have not yet moved into human trials. And, scientists need to make sure PNA-based treatments don't inadvertently mess with human cells or helpful bacteria.\nRelated:'Death screams' of swarming bacteria help their comrades survive antibiotic attacks\nIn addition to peptides like PNAs, enzymes called lysins are another promising treatment option. Lysins are used in nature by phages to split bacteria open from the inside. They act like tiny swords that slice through the outer wall of a bacterial cell, spilling its guts. The molecular sabers areunlikely to promote resistancebecause bacteria cannot easily change the essential cell-wall components that lysins target.\nLysins slaughter bacteria quickly upon contact, and they can be very specific, killing some types of bacteria while sparing others. Furthermore,lysins can be tweaked in the labto change which bacteria they target, boost their potency and improve their durability in the body.\nSome lysins have entered mid- and late-stage human trials with hundreds of participants, in which they've been tested as supplementary treatments to antibioticsbut garneredmixed results.\nUntil these next-gen bacteria slayers make it to market, immediate measures must be taken to stall the rise of superbugs, by preventing the misuse of antibiotics that pressures bacteria to evolve resistance in the first place.\nFor example, doctors can be more diligent about confirming that bacteria, not viruses, are behind a patient's infection before prescribing antibiotics, saidDr. Shruti Gohil, a lead investigator of fourINSPIRE-ASP Trials, federally funded research aimed at improving hospitals' antibiotic use. Other safeguards can include auditing doctors' prescriptions to see if narrower-spectrum drugs could be used instead of broad ones, or requiring special clearance for the broadest-spectrum drugs. These steps are essential not only in hospitals but everywhere antibiotics are prescribed, from primary care to dentistry, Gohil said.\nEach interaction between a doctor and their patient matters.\nGohil stressed that \"by reducing individual risk, you anticipate that you will drop the overall population-level risk,\" and eventually slash the prevalence of multidrug-resistant bugs.\nCopyright 2023Live Science, a Future company. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.\nNicoletta Lanese is a staff writer for Live Science covering health and medicine, along with an assortment of biology, animal, environment and climate stories.\nJaimie Seaton\nAllison Parshall\nTanya Lewis\nJohn Horgan\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "FEMA Offers Every State $2 Million to Adopt Safer Building Codes", "date": "2023-10-13 17:15:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nFirst-of-its-kind FEMA funding aims to update archaic building codes that leave millions of people exposed to climate-fueled hurricanes, floods and other extreme weather\nCLIMATEWIRE |Two houses are side by side. One is a crumpled mess of splintered wood and ripped insulation. The other stands perfectly intact.\nThis image is one that increasingly pops up on news sites and social media after hurricanes, floods and climate-fueled disasters. An accompanying caption often emphasizes that the intact home was built with a hurricane-resistant roof and flood-resistant materials.\nSuch images are enmeshed in a growing push to make buildings more resilient to climate impacts — an effort that a federal agency catapulted forward Thursday when it vowed to give every state up to $2 million next year to improve building codes.\nThe unprecedented funding — from the Federal Emergency Management Agency — follows a series of reports showing that most local building codes are archaic and leave millions of people highly exposed to climate impacts. It also comes after President Joe Biden launchedan initiative in June 2022to help states and localities adopt the latest building codes.\n“This is the single largest investment ever at the federal level in support of hazard-resistant building codes,” said Gabe Maser, senior vice president for government relations at the International Code Council, which publishes model building codes that local officials can adopt.\n“It sends an incredibly powerful message,” Maser added.\nThe new FEMA moneycomes as some state legislatures, under pressure from builders,block plans by state agenciesto adopt new building codes. New codes — often criticized as costly — typically have stronger construction standards and account for the latest effects of climate change.\n“The goal here is simple: Building codes save lives,” said Victoria Salinas, FEMA's associate administrator for resilience. Salinas cited reports that partly blamed weak building codes and lax enforcement for the death of 56,000 people during an earthquake in Syria and Turkey in February.\n“There are plenty of places in the U.S. where we still have a long way to go,” Salinas said. “Less than 25 percent of municipalities have adopted the latest building code.”\nFEMA is offering $2 million to every state and U.S. territory — if they apply for the money and have their applications approved. The agency also is offering a total of $25 million to tribal nations.\nWhen FEMA previously offered states annual grants for climate resilience, a few states never applied. Many others received only a portion of the available money.\n“A lot of states are grudgingly accepting building codes,” said Leslie Chapman-Henderson, president of the Federal Alliance for Safe Homes. “This is going to help facilitate those states or local governments that are maybe on the fence.”\n“There was a lot of denial about this years ago,” Chapman-Henderson added. “There’s no rational argument against building codes.”\nReports in recent years have outlined the value of new building codes and the failure of states and localities to adopt them.\nA 2019 study by theNational Institute of Building Sciencesshowed that the adoption of new building codes is far more cost-effective at reducing disaster damage than other strategies, such as elevating flood-prone homes or providing federal grants.\nAscathing FEMA report in 2020found that 65 percent of U.S. counties and municipalities had outdated building codes that exposed residents to “a dangerous, costly and unnecessarily high level of risk.” In March, the agency releasedan analysisthat gave 40 states and territories the lowest possible rating for the quality of their statewide building codes.\n“These reports keep coming out and are consistently finding that structures that are built to current codes or even codes that have been adopted in the last decade perform so much better than the structures around them,” said the code council's Maser.\nMaser’s nonprofit organization publishes model codes every three years for homes and commercial buildings through a collaborative process involving experts. The latest versions of the codes were released in 2021.\nStates can spend the FEMA money on enhancing their existing codes, studying new codes or training employees in using codes. States can distribute their $2 million share to local agencies.\nFEMA is allocating the money as part of a larger grant program that will distribute $1 billion next year to states for projects that build resilience to disasters and climate impacts.\nUnder the grant program, known as Building Resilient Infrastructure and Communities, states are allowed to seek money to improve building codes. But very few of the applications to FEMA sought money for that purpose, according to Salinas, the agency associate administrator.\nThe lack of interest prompted FEMA to set aside $137 million of the grant funding for building codes.\n“Given the gap we have to close in the nation, that’s why we’re trying this approach,” Salinas said. “We’re trying different approaches to incentivize behavior and adoption.”\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nThomas Frank covers the federal response to climate change for E&E News.\nThe Editors | Opinion\nThomas Frank and E&E News\nThomas Frank and E&E News\nThomas Frank and E&E News\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "This Is The Largest Map of The Human Brain Ever Made", "date": "2023-10-13 19:30:00", "text": "Digital offer!\nDigital offer!\nDigital offer!\nDigital offer!\nResearchers catalogue more than 3,000 different types of cell in our most complex organ\nResearchers have created the largest atlas of human brain cells so far, revealing more than 3,000 cell types — many of which are new to science. The work, published in apackageof 21 papers today inScience,Science AdvancesandScience Translational Medicine, will aid the study of diseases, cognition and what makes us human, among other things, say the authors.\nThe enormous cell atlas offers a detailed snapshot of the most complex known organ. “It’s highly significant,” says Anthony Hannan, a neuroscientist at the Florey Institute of Neuroscience and Mental Health in Melbourne, Australia. Researchers have previously mapped the human brain using techniques such as magnetic resonance imaging, but this is the first atlas of the whole human brain at the single-cell level, showing its intricate molecular interactions, adds Hannan. “These types of atlases really are laying the groundwork for a much better understanding of the human brain.”\nThe research is part of the US National Institutes of Health’s Brain Research through Advancing Innovative Neurotechnologies Initiative — Cell Census Network (BICCN), a collaboration between hundreds of scientists. The programme’s goals include cataloguing brain cell types across humans, non-human primates and mice to improve understanding of the cellular mechanisms behind poorly understood brain disorders. The data from the 21 studies have been made publicly available on theNeuroscience Multi-omic Archiveonline repository.\nKimberly Siletti, a neuroscientist now at the University Medical Center Utrecht in the Netherlands, and her team laid the cornerstone for the atlas by sequencing the RNA of more than 3 million individual cells from 106 locations covering the entire human brain, using tissue samples from three deceased male donors. They also included one motor cortex dissection from a female donor that had been used in previous studies. Their analysis documented 461 broad categories of brain cell that included more than 3,000 subtypes. “I was surprised at how many different cell types there were,” says Siletti.\nNeurons — cells in the brain and nervous system that send and receive signals — varied widely in different parts of the brain, suggesting different functions and developmental histories. The mix of neurons and other cell types also differed across each region; some cells were only found in specific locations. The brainstem — a relatively under-studied structure connecting the brain to the spinal cord — harboured a particularly high number of neuron types, says study co-author Sten Linnarsson, a molecular systems biologist at the Karolinska Institute in Stockholm, Sweden. “One of the big surprises here is how incredibly complex the brainstem is.”\nOther studies drilled into the mechanisms of gene regulation and expression in different cells. Joseph Ecker, a molecular biologist at the Salk Institute for Biological Studies in La Jolla, California, and his colleagues investigated the brain through an epigenetic lens using tissue samples from the same three donors. They analysed chemical markers that switch genes on or off in more than 500,000 individual cells. The various molecules that acted as switches enabled the team to identify nearly 200 brain cell types. Even the same gene in the same type of cell could have different characteristics across the brain. One gene was turned on with one switch at the front of the brain and with another at the back. “There are remarkable regional differences,” says study co-author Wei Tian, a computational biologist at the Salk Institute.\nPinpointing the switches that activate or block gene expression in brain cells could be useful for diagnosing brain disorders and developing tailored treatments, says Ecker. “That’s another tool that comes out of the toolbox we’re building,” he says.\nImproving understanding of how genetic switches might contribute to disease risk was also a focus for Bing Ren, a molecular biologist at the University of California, San Diego, and his team. They analysed how more than one million brain cells from the three donors access and use genetic information. The researchers uncovered links between certain brain cell types and neuropsychiatric disorders, including bipolar disorder, depression and schizophrenia.\nRen and his colleagues used the cell-type data to predict how the genetic switches influence gene regulation and increase the risk of neurological diseases. For instance, in cells called microglia , which clear away dead or damaged cells, the presence of some genetic switches was strongly linked to risks of Alzheimer's disease. Such findings can be used to test whether particular genes or faulty switches contribute directly to the onset of disease. “This is made possible because we have — for the first time — delineated the genetic switches for hundreds of different cell types,” says Ren.\nThe next step for the BICCN team is to sequence more cells from all parts of the brain, says Ren. The researchers will also work with more tissue samples to build a picture of how the human brain can vary across populations and age groups. “This is only the beginning,” says Ren.\nThis article is reproduced with permission and was first published on October 12,2023.\nGemma Conroy is a freelance science journalist based in Sydney, Australia.\nGemma Conroy and Nature magazine\nThomas Frank and E&E News\nNicoletta Lanese and LiveScience\nKatie Worth\nMeghan Bartels\nChristopher Intagliata\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "We Need to Think about Conservation on a Different Timescale", "date": "2023-10-15 12:00:00", "text": "Digital offer!\nDigital offer!\nRestoring habitats to how they were centuries ago, not years ago, could mean more successful conservation efforts\nTime is one of humanity’s greatest blind spots. We experience it as days, months, or years. But nature functions on much grander scales, measured in centuries, millennia and even longer intervals often lumped together as “deep time.” As paleontologists, we were trained to think in deep time. Yet, as conservationists, we’ve come to realize that time can be confounding.\nHumanity’s shortsightedness around time creates major constraints on modern conservation. As the climate and biodiversity crises accelerate, we are urgently working to protect and regenerate ecosystems without understanding how they functioned when they were truly thriving. Indeed, most conservation efforts today, whether reintroducing extirpated species or setting protection priorities, generally consider timescales of a century or less, almost as if species somehow did not exist before Western scientists “discovered” them, and with no good idea if, at that moment, the ecosystem was at its peak.\nEvaluating ecosystems based solely on their recent past is part of a larger trend known as shifting baseline syndrome—the tendency for accepted norms in a given place to shift almost imperceptibly over time. Usually for the worse.\nA deep time perspective can improve conservation efforts, and our work could make those perspectives easier to visualize.\nIn recent years, shifting baselines in California and elsewhere have had dire repercussions. For decades, forest management practices throughout the Sierra Nevada called for all-out suppression of even the mildest forest fires, based on the persistent belief—supported by economic interests and aesthetics—that fire was bad for both people and nonhuman nature. These practices resulted in the build up of dense trees, brambles, and other woody kindling that have fueled devastating wildfires.\nUntil recently we ignored the forest management strategies Indigenous communities had successfully deployed for millennia, in particular the application of small-scale controlled burns. Fire, it turns out, has always been an integral ingredient in healthy forest ecosystems, spurring new growth by thinning the understory, enriching the soil and, for many tree species, aiding their reproduction. Today, we’re beginning to see widespread application of Indigenous knowledge to forest management, tapping into this ancient wisdom.\nBut how can we know what an ecosystem looked like 100 years ago? 1,000 years ago? One pathway is through modern mathematical modeling. Along with another paleontologist, Roxanne Banker, we have married this kind of modeling with streams of long-term data—for example, natural history museum collections, Indigenous ecological knowledge and the fossil record—and discovered a possible way to preserve the ecosystem of California’s kelp forest, now nearly destroyed. The key factor turns out to be an extinct sea mammal.\nOver the past decade, kelp forests, which provide habitat for countless species and prevent coastal erosion by buffering waves, have lost more than 90 percent of their historical range. The cause for this precipitous decline, like the ecosystem itself, is complex. One dominant factor has been the unchecked proliferation of kelp-consuming purple sea urchins. After two of their major predators, sea otters and sunflower sea stars, were pushed to the brink of extinction by 19th-century fur trading and a 2014 ocean warming event, these spiny invertebrates flourished unchecked. The end result has been transformation of complex, three-dimensional kelp forests into large-two dimensional expanses of so-called “urchin barrens.”\nYet, by examining how North Pacific kelp forests existed long before the 19th century, we found that there is a deeper, untold story that could impact kelp forest regeneration. It turns out that we’ve largely ignored the presence of a keystone species and its role in maintaining the harmony of this ecosystem. This oversight is somewhat surprising, given that this creature weighed four tons.\nOur model described the interactions between giant kelp and understory algae competing for light and space on the seafloor, sea urchins that consume both kelp and algae, and sunflower sea stars and sea otters that prey on the urchins. We then used the model to predict how the system responds to marine heat waves and outbreaks of sea star wasting disease, recreating the events of the past 10 years. Then we ran the model again, but this time with the four-ton sea creature—the Steller’s sea cow—added in.\nThis massive herbivore, closely related to the modern-day manatee, lived in near-shore marine settings throughout much of the Pacific Rim. These megamammals inhabited coastal kelp forests, filling their massive bellies with fronds from the upper kelp canopy. All this pruning allowed light to penetrate to the sea bottom, which in turn stimulated growth not only of kelp, but of other kinds of organisms as well, generating a more diverse, resilient understory. In re-creating that vanished historical system that included the Steller’s sea cow, we could see a more diverse forest where the understory competed better with kelp. This forest would have been more resilient against modern stressors.\nSo, rather than focusing solely on removing urchins or reintroducing sea otters, we might consider deploying teams of humans to selectively harvest kelp fronds, as the Steller’s sea cow once did, to allow light to encourage fresh growth in these underwater forests. Kelp is a culinary delicacy, after all, and the harvest could be sold to grocery outlets and restaurants.\nIn short, what we assume we know about an ecosystem based on the recent past may impede our ability to fully understand and protect it. Instead of suppressing fires, it is often preferable to employ prescribed burns to bring “good fire” safely back to California’s forests. We advocate for applying similar modeling studies to other ecosystems and conservation efforts. Deep time and an understanding of past ecosystems could significantly change how we carry out conservation work.\nNo matter where you live, chances are that when you gaze out the window, you’re looking at an ecosystem that is severely degraded compared to 50 years ago, let alone a century or millennium. To ensure that our boldest conservation efforts are successful, we must begin looking at time as an essential tool. We are all characters in an epic story that has been unfolding for millions upon millions of years. The decisions we make today will shape how the future unfolds. It’s high time we embraced our role in this ever-evolving drama and established vital through lines from past to future.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those ofScientific American.\nScott D. Sampson, trained as a dinosaur paleontologist and paleobiologist, serves as executive director at the California Academy of Sciences in San Francisco.\nPeter D. Roopnarine, an evolutionary biologist whose work focuses on eco-evolutionary dynamics, serves as curator of geology at the California Academy of Sciences in San Francisco.\nScott D. Sampson and Peter D. Roopnarine | Opinion\nGemma Conroy and Nature magazine\nThomas Frank and E&E News\nNicoletta Lanese and LiveScience\nKatie Worth\nMeghan Bartels\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Should Insurance Cover Wegovy, Ozempic and Other New Weight-Loss Drugs?", "date": "2023-10-16 10:45:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nInsurance plans could cover blockbuster weight-loss medications such as Wegovy and Ozempic, but the benefits may not be accessible to everyone\nPamela Torres used to run a seven-minute mile. But when the former track star suffered a severe knee injury in college, she began to rapidly gain weight. She was diagnosed with type 2 diabetes in her 30s and obesity in her early 50s. Torres, now age 68, was prescribed Ozempic, a medication approved to treat type 2 diabetes, in January. She lost nearly 20 percent of her body weight. Her joints didn’t ache as much, and her blood sugar returned to healthy levels. “I bought three new pairs of jeans. I wore a sundress for the first time in a decade,” she says. But these gains have been short-lived because Torres no longer qualifies for health insurance coverage of the drug.\nOzempic has become popular for off-label use for weight loss. Its counterpart Wegovy—which contains the same active ingredient, semaglutide, but is specifically approved for chronic weight management—has also gained popularity, as has the off-label use of the diabetes medication Mounjaro for this purpose. Semaglutide has been shown to help people lose an average of about 15 percent of their weight. These popular weight-loss drugs have provided new opportunities for treating obesity, a condition that affects more than 40 percent of adults in the U.S. New findings suggest they also have the potential to lower the risk of heart disease and stroke.\nBut the availability and price of these drugs are raising important questions about equity and affordability. Most private insurance companies and federal health programs don’t cover weight-loss drugs, and Ozempic, Wegovy and Mounjaro each cost $1,000 or more per month out of pocket. Medicare, the federal health insurance program primarily for people aged 65 and older, has been explicitly forbidden by law from providing coverage for weight-loss treatments since 2003. The ban was implemented in part because of concerns over the safety of weight-loss drugs at the time, such as the combination of fenfluramine and phentermine, or fen-phen, which was associated with life-threatening hypertension and heart valve issues.\nThose restrictions could soon be loosened. In August drug manufacturer Novo Nordisk, which makes Ozempic and Wegovy, announced clinical trial findings that indicate semaglutide does more than help people lose weight. In a trial of more than 17,000 people, the drug cut the risk of cardiac complications, such as heart attacks and strokes, by 20 percent. While Novo Nordisk won’t release the trial’s full results until November, the findings have already put pressure on insurance providers to offer coverage for these blockbuster drugs. In July a bipartisan group of congressional lawmakers reintroduced a bill to reauthorize Medicare coverage of weight-loss medications. As of mid-October, progress on that legislation has stalled, but the release of Novo Nordisk’s results could revive it.\nMedicare coverage would put antiobesity drugs within reach of many people, including older adults, who can’t otherwise afford them. It could have a multiplier effect because private insurers often follow Medicare’s lead. Even if insurance providers shift their policies, however, there are lingering concerns about whether and how they will restrict coverage for weight-loss medications—and who might be left behind.\nExperts are eagerly watching to see if Congress will allow Medicare to cover these highly sought-after medications. “This lines up as a once-in-a-generation event,” says Ethan Weiss, a cardiologist and entrepreneur at the biotechnology company Third Rock Ventures, who studies metabolic disorders such as obesity and diabetes. “What happens next will shape who can access these weight-loss drugs for decades.”\nDemand for these weight-loss drugs has surged since their debut in the past few years. The medications, designed to be injected once a week, suppress appetite by slowing down the process by which the stomach empties and thus signaling to the body that it feels full. Semaglutide imitates a hormone called glucagon-like peptide-1 (GLP-1), which prompts the body to produce more insulin and makes a person feel satiated.\nTorres and others who have taken these drugs report losing constant cravings for food. “I don’t daydream or obsess over eating as much. I’m grabbing smaller plates, and I’m very satisfied with those portions in a way I wasn’t before,” she says.\nThese drugs are also reshaping the way doctors and the public perceive obesity, a condition historically seen as a problem of willpower. “Now we have the option to treat obesity like we treat any other disease—with medication,” says Shauna Levy, medical director of Tulane University’s Bariatric and Weight Loss Center. She hopes that recent research highlighting the overall health benefits of weight-loss drugs will prompt Medicare and private insurance companies to categorize obesity treatment as necessary rather than cosmetic.\nA once-a-week weight-loss drug could be an especially attractive choice for seniors who haven’t had success with lifestyle interventions such as dieting and exercise. More invasive measures such as bariatric surgery often carry higher risks, Levy says.\nBut more research may be necessary to understand how seniors fare with the semaglutide medications’ potential side effects. These include nausea, fatigue, lightheadedness, decreased muscle mass and, in rare cases, chronic paralysis of the digestive system. Studies show the side effects of such weight-loss drugs tend to be more common and more severe in older adults, and people age 65 and older are more likely to discontinue weight-loss medications because of those effects.\nLast October a doctor prescribed Ozempic to Shawna Weber, a 71-year-old resident of Oregon, after diagnosing her with severe obesity. “I didn’t even make it to Christmas,” Weber says of taking the drug. She shed 20 pounds in three months, but severe cramping, nausea and vomiting spells ultimately caused her to stop using the medication.\nStill, related GLP-1 medications have been used to treat diabetes for nearly two decades, which has assuaged some physicians’ fears of large-scale safety issues. “You make a risk-benefit calculation when you prescribe any medication,” Weiss says. “But these are not an entirely new type of drug, and there doesn’t appear to be significant lingering safety concerns with them.”\nTorres discontinued Ozempic after just a few months of use. But her decision was driven by insurance barriers, not side effects or safety concerns. In June Torres’s pharmacy notified her that she wasn’t eligible for Medicare coverage of the medication because she no longer qualified as diabetic. She has since regained most of the weight she initially lost. “I’m just so, so hungry all the time—like it’s mentally and physically gnawing away at me,” she says. “Paying out of pocket isn’t an option. It feels like there’s nowhere else to go from here.”\nA national survey by the nonprofit organization KFF found that nearly half of adults expressed interest in taking a safe and effective drug for losing weight, including 59 percent of those who were currently trying to do so. However, that interest dropped to only 16 percent if the drug was not covered by insurance.\nThe list prices of Ozempic and Wegovy are about $900 and $1,300 per month, respectively. Adding to the cost, people typically need to take the drugs indefinitely to keep weight off. It’s not surprising that federal health programs and private insurers don’t want to cover these drugs, says Alison Sexton Ward, an economist at the University of Southern California, who specializes in drug pricing policies. Yet the initial cost of weight-loss drugs would be partially offset by the long-term health benefits they may provide, such as the decrease in cardiovascular events shown in the new Novo Nordisk trial, Ward says. “When it comes to the math of what Medicare considers in calculating expenditures, you have to subtract the savings that occur with these drugs.”\nBut these savings may be less likely to persuade insurers, according to David Rind, chief medical officer at the Institute for Clinical and Economic Review, a nonprofit organization that estimates fair prices for the U.S. health system. “Will this create more pressure on insurers to cover these drugs? Maybe,” he says. “But I think the exchange is insurers saying, ‘You’re going to have to pay more for premiums,’ which will turn some people away.” To reduce prices over the long term, Rind says, companies should develop more weight-loss drugs, thereby fostering competition among drug manufacturers.\nOther experts worry that paying for expensive weight-loss medications will divert funding away from coverage for other medical treatments. “There are so many spillover effects. If you pay too much for something, other things get displaced,” says Khrysta Baig, a doctoral candidate in the department of health policy at Vanderbilt University. “That’s where there are equity issues we don’t talk about enough.”\nIn a study published in March in the New England Journal of Medicine, Baig and her colleagues estimated that, even with modest uptake of the medications, the annual cost of brand-name semaglutide weight-loss drugs to Medicare could be $13.6 billion to $26.8 billion. (For reference, total annual spending for Medicare Part D, the program that helps beneficiaries pay for self-administered prescription drugs, is about $98 billion.)\n“If drug manufacturers really wanted to make the medication more accessible, they would lower prices. That could also encourage policymakers to come to the table to provide federal health coverage,” Baig says. “If you want to promote equity, put your money where your mouth is.”\nNovo Nordisk did not respond to requests for comment about its drug pricing.\nIf Medicare and private insurers decide to cover weight-loss drugs, they could control rising costs by imposing strict eligibility criteria for treatment reimbursement. Aside from requiring a medical diagnosis of obesity, they might insist on people having other weight-related health issues or restrict the duration of coverage, Rind says. While this approach may prevent those who are healthy but simply feel pressured to lose weight from taking the drugs, it could also bar coverage for people who genuinely need them.\nObesity is most prevalent among Black and Hispanic adults, who are also the least likely to receive treatment for the condition. Medicare coverage of weight-loss drugs could potentially reduce these disparities. In April Ward and a team of U.S.C. health economists released a white paper demonstrating that broadening coverage for these medications would generate more social and health benefits for Black and Hispanic adults, compared with white adults, across almost all age categories.\nExperts are skeptical. They say that even if Medicare shifts its policies to cover such drugs, access to them may follow the familiar pattern of obesity medicine in the U.S. health care system: “We don’t want a situation where only wealthy, white patients can easily access these drugs, and everyone else is left in the dust,” Levy says. Even in Novo Nordisk’s recent clinical trial of more than 17,000 participants, 84 percent were white, and only 3.8 percent were Black.\nCompounding the equity issue, Novo Nordisk has faced repeated shortages of Ozempic and Wegovy. The company announced earlier this year that it would cut back on supplying doses of Wegovy for new patients to preserve the medication for those already taking it. These global supply constraints have already left many people with diabetes, who rely on semaglutide, unable to procure their medication. The shortages have also stoked worries about the company’s ability to meet the skyrocketing demand expected if insurers begin to cover these medications.\n“If these drugs are in short supply, we need to think proactively about which patients will be able to obtain them at the end of the day,” Baig says. “We need to think about equity at every step—with diagnosis, treatment and prevention—not just with insurance coverage.”\nLucy Tu was a 2023 AAAS Mass Media Fellow at Scientific American. Follow her on X (formerly Twitter) @LucyTTu\nSara Reardon\nNial Wheate, Jessica Pace and The Conversation US\nJudith Graham and Kaiser Health News\nClaudia Wallis\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "A Married Bachelor Proves That Unicorns Exist", "date": "2023-10-16 11:00:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nThe “principle of explosion” explains why a single contradiction would destroy math\nUnicorns roam free in fantasy novels and children’s stories, not so much in the real world, much less the cold, analytical ones of math and philosophy. But it turns out that these logical disciplines are only one misstep away from proving the existence of the long-adored mythic creatures—or proving any absurdity.\nTo understand how unicorns could migrate into our most objective fields of study, we must first look to tenets laid down by Aristotle more than 2,300 years ago. Among his many impressive contributions, he is often credited with articulating the “three laws of thought”—self-evident statements that we must assume for any theory of logic to take flight. The one that matters for unicorn hunters is the law forbidding contradiction. That law says propositions cannot be both true and false. You can’t have A and not A. Square circles and married bachelors are simply unwelcome in a civilized logic.\nContradictions keep math and philosophy on course through negative feedback. Like dead ends in a maze, they signal “this is not the way forward” and demand that you retrace your steps and choose a different path. Contradictions also underpin all paradoxes. Consider the infamous liar paradox: “This sentence is false.” If it’s true, then we should take it at face value: the sentence is false. If it’s false then it is not the case that the sentence is false, i.e., it’s true. So if the statement is true, then we deduce that the statement is false and vice versa, a contradiction. Because of Aristotle’s law, the contradiction cannot stand, so the liar paradox and hundreds of other known paradoxes beg for resolutions. Reams of philosophical papers have been devoted to the impressively resilient liar paradox, all in an effort to purge the world of one contradiction.\nBut why are contradictions so unacceptable? Need we accept the law of noncontradiction? Maybe contradictions are akin to black holes. They’re weird, counterintuitive boundary objects that violate some accustomed rules, but we must make room for them in our description of reality. What would happen if we threw up our hands and accepted the liar paradox as a genuine contradiction? Aside from them being aesthetically unpalatable, inviting a contradiction into logic poses a major problem known as the principle of explosion. Once we admit even a single contradiction, we can prove anything, whether it’s true or not.\nThe argument that proves anything from a contradiction is remarkably straightforward. As a warm-up, suppose you know that the following statement is true.\nTrue statement: Omar is married or Maria is five feet tall.\nYou know the above to be true. It doesn’t necessarily imply that Omar is married, nor does it imply that Maria is five feet tall. It only implies that at least one of those must be the case. Then you import an additional piece of knowledge.\nTrue statement: Omar is not married.\nWhat can you conclude from this pair of assertions? We conclude that Maria must be five feet tall. Because if she isn’t and Omar isn’t married either, then our original or-statement couldn’t have been true after all. With this example in mind, let’s assume a contradiction to be true and then derive something ridiculous from it. Philosophers love a married bachelor as a succinct example of a contradiction; so to honor that tradition, let’s assume the following:\nTrue statement: Omar is married.\nTrue statement: Omar is not married.\nUsing these as true statements, we’ll now prove that unicorns exist.\nTrue statement: Omar is married or unicorns exist.\nThis is true because we know from our assumption that Omar is married and an or-statement as a whole is true whenever one of the claims on either side of the “or” is true.\nTrue statement: Omar is not married.\nRemember, we assumed this to be true.\nConclusion: Unicorns exist.\nJust like we concluded that Maria must be five feet tall, once we accept that either Omar is married or unicorns exist and then add in that Omar is not married, we’re forced to admit the absurd. The simplicity of this argument can make it seem like sleight of hand, but the principle of explosion is fully sound and a key reason why contradictions cause intolerable destruction. If a single contradiction is true, then everything is true.\nSome logicians find the principle of explosion so disturbing that they propose altering the rules of logic into a so-called paraconsistent logic, specifically designed to invalidate the arguments we’ve seen above. Proponents of this project argue that since unicorns have nothing to do with Omar’s marital status, we should not be able to learn anything about one from the other. Still, those in favor of paraconsistent logic have to bite some hearty bullets by rejecting seemingly obvious arguments as invalid, like the argument we used to conclude that Maria is five feet tall. Most philosophers decline to make that move.\nSome advocates of paraconsistent logic take an even more radical stance called dialetheism, which asserts that some contradictions are actually true. Dialetheists reject the law of noncontradiction and claim that rather than expelling contradictions from every corner of rationality, we should embrace them as peculiar types of statements that are occasionally true and false simultaneously. Dialetheists boast that under their view, head-banging conundra like the liar paradox resolve themselves. They simply say that “this sentence is false” is both true and false, with no need for further debate. Although dialetheism has relatively few adherents, it has gained recognition as a respectable philosophical position, largely thanks to the extensive work of British philosopher Graham Priest.\nLogic is also the foundation of mathematics, meaning that math is just as vulnerable to catastrophe if a contradiction arises. Spanning different eras and languages, mathematicians have erected a towering edifice of intricately tangled arguments that govern everything from the stuff you use to balance your checkbook to the calculations that make planes fly and nuclear reactors cook.\nThe principle of explosion ensures that unless we want to rewrite logic itself, a single contradiction would bring the whole field tumbling to the ground. It is remarkable to consider that among countless complicated arguments in logic and math, we’ve avoided collapse and not let one contradiction slip through the cracks—at least that we know of.\nJack Murtagh writes about math and puzzles, including a series on mathematical curiosities at Scientific American and a weekly puzzle column at Gizmodo. His original puzzles have appeared in the New York Times, the Wall Street Journal and the Los Angeles Times, among other outlets. He holds a Ph.D. in theoretical computer science from Harvard University. Follow Murtagh on Twitter @JackPMurtagh\nMeghan Bartels\nManon Bischoff and Allison Parshall\nManon Bischoff\nRachel Crowell\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "As Arctic Sea Ice Breaks Up, AI Is Starting to Predict Where the Ice Will Go", "date": "2023-10-16 13:00:00", "text": "Sea ice is changing fast. Areforecasts, created by artificial intelligence,the best way to keep up with the pace of a warming climate in the far north?\nEmily Schwing: In October 2019 an international team of scientists onboard an icebreaker intentionally let Arctic Sea ice freeze up around the ship. They wante d to learn more about the ice itself. But in April 2020, just halfway through the year-long experiment, it was unclear if that ice would stay frozen for the remaining six months of the project.\n[CLIP: Show music; Sea ice sounds]\nSchwing: You’re listening to Scientific American’s Science, Quickly. I’m Emily Schwing.\nSea ice, according to scientists, is melting at an alarming rate—so quickly that some researchers believe traditional methods for forecasting its extent may not keep up with the pace of a changing climate.\nBy the year 2050, the Arctic could be ice-free in the summer months. And shipping traffic in the region is on the rise, but predicting sea ice extent is complicated.\nToday we’re looking at how machine learning—artificial intelligence—could become the tool of the future for sea ice forecasting.\nLeslie Canavera: We build artificial intelligence and machine learning models for the Arctic, based on the science of oceanography.\nSchwing: That’s Leslie Canavera. She is CEO of a company called PolArctic, and she is trying to forecast ice in a different way than science ever has.\nSince the late 1970s, scientists have relied on physics and statistical modeling to create sea ice forecasts.\nCanavera: When you take two water molecules, and you freeze them together, you know, like, right, this is how they freeze together. But there’s a lot of assumptions in that. And when you extrapolate to the ocean, there’s a lot of error.... And statistical modeling is based on, like, historical things of what’s happened. But with climate change, it’s not acting like the history anymore. And so artificial intelligence really takes the best of both of those and is able to learn the system and trends to be able to forecast that more accurately.\nSchwing: Of course, that foundation of statistics and historical data is still important, even with its errors and caveats.\nHolland: We can't model every centimeter of the globe.\nSchwing: Marika Holland is a scientist at the National Center for Atmospheric Research in Boulder, Colorado. The center has been using physics and statistical modeling to predict sea ice extent for the past five decades. Holland says that she is confident in the methodology but that these forecasts aren’t perfect.\nHolland: You know, we have to kind of coarsen things, and so we get a little bit of a muddy picture of how the sea ice cover is changing or how aspects of the climate or the Earth’s system are evolving over time.\nSchwing: Marika says there are also a lot of smaller-scale processes that can create problems for accurate forecasting.\nHolland: Something like the snow cover on the sea ice, which can be really heterogeneous, and that snow is really insulating, it can affect how much heat gets through the ice.... We have to approximate those things because we aren’t going to resolve every centimeter of snow on the sea ice, for example.... So there’s always room for improvement in these systems.\nSchwing: It’s that space—the room for improvement—where Leslie says artificial intelligence can be most helpful. And that help is especially important right now because of what is happening in the Arctic.\nAccording to the Arctic Council, marine traffic increased by 44 percent through the Northwest Passage between 2013 and 2019. Search-and-rescue capabilities in the region are limited, and there has been increased attention on the region for its vast natural resource development potential. Leslie says AI can create a forecast on a smaller scale, homing in on specific locations and timing to benefit those user groups.\nCanavera : We did a seasonal forecast and then an operational forecast where the seasonal forecast was 13 weeks in advance. We were able to forecast when their route would be open..., and we were actually to the day on when the route would be able to be open and they would be able to go. And then we did operational forecasts where it was like,“All right, you’re in the route, what [are] the weather conditions kind of looking like?”\nSchwing: Using AI to forecast sea ice extent isn’t a novel approach, but it is gaining traction. A team led by the British Antarctic Survey’s Tom Anderson published a study two years ago in the journal Nature Communications. In a YouTube video that year, Tom touted the benefits of his team’s model, called IceNet.\n[CLIP: Anderson speaks in YouTube video: “What we found is super surprising. IceNet actually outperformed one of the leading physics-based models in these long-range sea ice forecasts of two months and beyond while also running thousands of times faster. So IceNet could run on a laptop while previous physics-based methods would have to run for hours on a supercomputer to produce the same forecasts.”]\nSchwing: One of the biggest limitations when it comes to AI-generated sea ice forecasts is what Leslie calls “the black box.”\nCanavera: And you have all of this data. You put it into the artificial intelligence black box, and then you get the answer. And the answer is right. And scientists get very frustrated because they’re like, “Well, tell me what the black box did,” right? And you’re like, “Well, it gave you the right answer.” And so there's a big trend in artificial intelligence that is called XAI, and explainable AI si hwat that kind of relates to and “Why did your artificial intelligence give you the right answer?”\nSometimes, she says, AI happens upon the right answer but for the wrong reasons. That’s why Marika at the National Center for Atmospheric Research says the most effective sea ice forecasts are likely to come from combining both machine learning and five decades’ worth of physics and statistical modeling.\nHolland: If machine learning can help to improve those physics-based models, that’s wonderful. And that is kind of the avenues that we’re exploring—is how to use machine learning to improve these physics-based models that then allow us to kind of predict how the climate and the sea ice system are going to change on decadal, multidecadal [kinds] of timescales.\nSchwing: And there’s one piece of the sea ice forecasting puzzle Leslie, who is Alaska Native, believes is irreplaceable: traditional Indigenous knowledge.\nCanavera: What's great about traditional Indigenous knowledge and artificial intelligence is that a lot of traditional Indigenous knowledge is data, and artificial intelligence builds models on data. And that’s why it works better than these like dynamical models in being able to incorporate the traditional Indigenous knowledge.\nFor Science, Quickly, I’m Emily Schwing.\nScientific American’s Science, Quickly is produced and edited by Tulika Bose, Jeff DelViscio and Kelso Harper. Our theme music was composed by Dominic Smith.\nYou can listen to Science, Quickly wherever you get your podcasts. For more up-to-date and in-depth science news, head to ScientificAmerican.com. Thanks, and see you next time.\nFollow Emily Schwing on Twitter\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Is the Novavax COVID Vaccine Better than mRNA Vaccines? What We Know So Far", "date": "2023-10-16 16:00:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nNovavax’s protein-based vaccine is the latest FDA-authorized COVID booster available this fall. Here’s what you should know\nAs the updated COVID vaccines roll out around the country, one more competitor has joined the mix. In early October the U.S. Food and Drug Administration authorized a new booster shot made by the company Novavax. Like the mRNA-based Pfizer and Moderna shots, it targets a SARS-CoV-2 variant, XBB.1.5, which is a descendant of Omicron. It is the first protein vaccine to appear in more than a year, which some public health experts say is encouraging news for people who are hesitant the mRNA vaccines that have been widely used throughout the pandemic.\nScientific American consulted experts on the latest science behind the new shot.\nWhat’s different about Novavax’s vaccine?\nUnlike Moderna’s and Pfizer’s mRNA vaccines, which contain modified viral genetic material that the body’s own cellular machinery uses to make viral proteins that elicit an immune response, Novavax relies on a more traditional approach in which proteins resembling those in SARS-CoV-2 are injected directly into the body. This protein-based method has been used for more than 30 years in other vaccines, such as the hepatitis Bvaccine. The company Novavax produces the protein in moth cells, which grow more quickly than mammalian cells.\nThe Novavax jab also includes a proprietary compound called Matrix-M, which was developed from the bark of Chilean soapbark trees and further stimulates the immune system. Matrix-M is now being integrated into other vaccines, including one for malaria that the World Health Organization approved earlier this month.\nWhat variants does it target?\nThe new Novavax vaccine was developed for the XBB.1.5 viral variant—the same one targeted by Moderna’s and Pfizer’s updated shots. None of these are optimized for newer versions of the virus, including the Eris and Pirola variants that became prominent in August and appear better able to escape the immune system than previous mutants. (The FDA selected the XBB.1.5 variant for this fall’s boosters in June). That’s nothing new, says vaccinologist Gregory Poland of the Mayo Clinic—vaccine companies have been “chasing the tail” of emerging variants throughout the pandemic, he says.\nAll three vaccine boosters seem to confer at least some protection against the new variants. But one disadvantage of protein vaccines is that it takes much longer for researchers to develop new formulas to protect against new variants, whereas mRNA vaccines can be adapted far more easily.\nHow effective is it?\nNovavax has about the same efficacy as other COVID vaccines, says infectious disease researcher Kirsten Lyke of the University of Maryland. A study published this month found that the Novavax booster was about 55 percent effective at preventing COVID symptoms and 31 percent effective at preventing infection, which is similar to the mRNA vaccines.\nLyke’s own July study in the journal npj Vaccines tested whether “mixing and matching” the different COVID vaccine and booster types produced stronger or more durable immunity against the virus. It found that all the boosters led to similar antibody responses regardless of whether a person had initially received an mRNA or protein vaccine. Other evidence published in 2022 suggested that receiving an mRNA booster after a protein vaccine, such as Novavax’s original shot or the now-discontinued Johnson and Johnson protein subunit vaccine, might produce the best immunity of all.\nAccording to Lyke’s most recent study, the antibodies elicited by the new Novavax booster may have lasted a little longer than those produced after an mRNA vaccine. But Lyke says that’s not conclusive: by the time the study began early in 2022, many vaccinated people had recently been infected with Omicron or another dominant variant that’s good at avoiding the immune system. The infection gave their body a level of natural immunity that was difficult to distinguish from the vaccine’s effects.\nLyke says it is nearly impossible to directly compare different vaccines’ efficacy, given that people have had different exposures, infections and combinations of vaccinations. “I just don’t think we can run those trials anymore,” she says.\nWhat are the side effects?\nCompared with mRNA vaccines, the Novavax booster seems to have a lower risk of causing myocarditis or pericarditis—heart conditions that occasionally occur, especially in young men—although it does not have zero risk. It also has fewer side effects, including muscle fatigue and nausea, in the first 48 hours after vaccination. “If people have had a side effect with an mRNA vaccine, I’d say try a protein subunit [vaccine],” Poland says. “The goal is to get you protected.”\nBut it is difficult to draw firm conclusions on the vaccines’ comparative safety. “We’ve got millions of data points for the mRNA vaccine, and we don’t have that for Novavax,” Poland says. Manufacturing issues prevented the company’s immunization against the original COVID variant from being approved until 2022—long after most people who wanted a vaccine had gotten one. The CDC estimates that fewer than 90,000 doses of the original Novavax vaccine were administered, and only a few hundred people have received the booster in clinical trials.\nWhen will Novavax be available for the fall and winter season?\nNovavax says the booster is now available in pharmacies and that it has shipped millions of doses to thousands of locations around the country. Like the mRNA vaccines, the Novavax booster is one dose, but the CDC recommends that unvaccinated people receive two doses eight weeks apart.\nThe rollout of the latest round of boosters—both the mRNA and protein varieties—has lagged despite rising numbers of COVID infections in recent weeks. This has largely been because of confusion around how the vaccines would be paid for after the U.S. government announced it would no longer pay for all COVID vaccines and instead mandated all insurance companies to cover them for free. Some areas won’t have boosters available right away as states continue to navigate insurance and delivery complications. But no matter which vaccine booster becomes available first, Lyke says, the most important thing is to “pick one and get it.”\nSara Reardon is a freelance journalist based in Bozeman, Mont. She is a former staff reporter at Nature, New Scientist and Science and has a master's degree in molecular biology.\nTanya Lewis\nLauren J. Young\nZoe Cormier\nAchal Prabhala | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "American Catholics Call for Climate Action after Pope Francis Encourages Change", "date": "2023-10-16 18:30:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nPope Francis’s new encyclical says irresponsible lifestyles are the biggest impediment to reducing carbon emissions\nCLIMATEWIRE |Some American Catholics are calling for climate action after Pope Francis’ latest encyclical, which singled out the United States as the world’s biggest emitter of planet-warming emissions.\nThe pope's Oct. 4 message — called \"Laudate Deum,\" or \"Praise God\" — is an update to his landmark 2015 encyclical on the environment. It asserts that emissions per person in the U.S. are “about two times greater than those of individuals living in China, and about seven times greater than the average of the poorest countries.”\n“We can state that a broad change in the irresponsible lifestyle connected with the Western model would have a significant long-term impact,\" the pope wrote in the 17-page document. He called for political decisions on climate change that would make progress “to genuine care for one another.”\nLast Thursday, Catholics, environmental leaders and academics met at Georgetown University in Washington to discuss the pope's message — and call for stricter laws to cut carbon dioxide and methane emissions. About 1,200 people attended the \"public dialogue,\" either in person or online.\nSharon Lavigne, who leads the faith-based advocacy group RISE St. James, was among five panelists at the discussion. She spoke about Louisiana's \"Cancer Alley,\" an 80-mile stretch along the Mississippi River that is home to a cluster of oil refineries and other petrochemical producers.\nHer home in St. James Parish, La. — a predominantly Black community — is surrounded by industrial facilities, said Lavigne, a retired Catholic teacher.\n“We are fighting for our lives,” she asserted, pointing to the deaths in her area from cancer. \"Every week we have a funeral.\"\n“Someone needs to do something, and I feel if Pope Francis brings it down to us, to the bishops to priests, we can stand together in solidarity,\" Lavigne added. \"We can stop this.\"\nLavigne started RISE St. James in 2018, protesting the construction of a $1.25 billion Chinese-owned plastics plant. Her efforts led to the owners canceling the project in 2019 — and to herwinning the Goldman Environmental Prize.\nSeveral other speakers at the Georgetown event held up Lavigne's work as an example. Combatting industrial emissions is one way to preserve the “sacredness” of human lives, as is “building bridges” to gain support from other community groups, said Jose Aguto, executive director of Catholic Climate Covenant.\n“We as Catholics need to be stepping into that kind of advocacy because it is an integral part of our faith,” he said.\nChristiana Zenner, who teaches theology at Fordham University in New York, is writing a book about Pope Francis encouraging Catholics to become more active in the global fight against climate change.\nPope Francis, she said, appears “heartbroken” over the continuing escalation of climate change and the emissions that cause it. Her book will focus on the Pope's original 2015 encyclical, called \"Laudato Si',\" and the recent update.\n“What should we do in the face of this?” she asked. “Sometimes that requires saying no.”\nJohn Mundell, director of the Vatican's Laudato Si’ Action Platform, echoed the calls for action.\n\"I think he is calling us to act, to walk the walk, not just talk the talk,\" said Mundell, who also runs an environmental consulting firm. \"We have a greater moral voice than what we are doing and saying.”\nAbout 51 million adult Catholics live in the U.S., making the Catholic Church the largest single religious institution in the country, according to the Pew Research Center. In 2021, Pew found that most Americans had a favorable view of Pope Francis, including 82 percent of Catholics.\nThis month, the Vatican began what it calls the “Synod of Synodality,” a long-planned series of discussions and studies in which Catholic bishops and some Catholic laypeople discuss how the church handles sensitive issues.\nThe issues discussed range from whether priests can marry to the morality of death penalties. But whether the church will delve into its growing support for climate action is among many of the unknowns: the discussions, so far, have not been made public.\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nJohn Fialka is a reporter with E&E News.\nScott Detrow and ClimateWire\nLawrence M. Krauss\nMalavika Vyawahare and ClimateWire\nNuno Castel-Branco | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Police Blame 'Excited Delirium' for Deaths in Custody, but It's Not a Real Medical Condition, Experts Say", "date": "2023-10-16 20:15:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nDoctors want to ban the term“excited delirium,” which has been cited as a possible factor in high-profile police killings of George Floyd and others but is not a recognized medical diagnosis\nBrooks Walsh hadn’t questioned whether “excited delirium syndrome” was a legitimate medical diagnosis before the high-profile police killings of Elijah McClain in Colorado in 2019 and George Floyd in Minnesota in 2020.\nTheemergency physicianin Bridgeport, Connecticut, was familiar with the term from treating patients who were so severely agitated and combative that they needed medication just to be evaluated.\nBut it gave him pause when excited delirium — and not the restraint tactics used by arresting police officers — was mentioned as a possible factor in the deaths of those two Black men. That’s when Walsh took a closer look at the American College of Emergency Physicians’2009 position paper on excited delirium, which he and other physicians had relied on to treat such patients, then decided something needed to be done.\n“I was disappointed by a lot of stuff in that paper: the quality of the evidence that they cite and just, frankly, odd language,” Walsh said.\nExcited delirium is not listed in the standard reference book of mental health conditions, nor does it have its own diagnostic code under a system used by health professionals to identify diseases and disorders. No blood test or other diagnostic test can confirm the syndrome. Most major medical societies, including theAmerican Medical Associationand theAmerican Psychiatric Association, no longer recognize excited delirium as a legitimate medical condition. One of the last medical holdouts, the National Association of Medical Examiners,rejected excited deliriumas a cause of death this year.\nBut the American College of Emergency Physicians, the medical society representing Walsh and more than 36,000 other doctors, still hadn’t disavowed its report that gave excited delirium much of its legitimacy — until this month. On Oct. 12, the group approved a resolution that Walsh co-authored towithdraw the 2009 white paper on excited delirium, removing the only remaining official medical pillar of support for a theory, which despite being based primarily ondiscredited researchand racial biases, has played a key role in absolving police of culpability for in-custody deaths.\n“This is the membership of ACEP saying we recognize that this was wrong,” saidSophia Spadafore, an emergency physician at Mount Sinai Hospital in New York City. “And now, as an organization, we need to reckon with our history and try to make up for some of the mistakes that were made and repair some of the damage that we did.”\nThe vote brought somevindication to Verdell and William Haleck, whose son Sheldon died in 2015 after being pepper-sprayed, shocked with a Taser, and restrained. The Utah family lost its civil case against Honolulu police officers, whose lawyers argued the 38-year-old former Hawaii Air National Guardsman had experienced excited delirium. Watching defense experts paint their son as responsible for his own death was excruciating, his parents said.\n“We were right all along,” Verdell Haleck said in response to the ACEP vote. “Now our hopes are that the term can never be used again to cause pain and suffering for another family in their pursuit of justice.”\nAnd momentum is building. Just before the vote, California became thefirst state to ban excited deliriumas a diagnosis and cause of death on death certificates, autopsy reports, and police reports, as well as in civil court proceedings.\nBackers of the emergency physicians’ resolution hope such disavowals of the term will lead to better training and greater accountability of paramedics and police when they interact with people in mental health crises.\nBut it is unlikely the doctors’ vote can affect past wrongful death and criminal cases against police. And it remains unclear whether renouncing the 2009 document will prevent defense lawyers in future cases from using similar victim-blaming concepts — just with alternative terminology.\nNearly 14 years ago, Patrick Burns, 50, died after sheriff’s deputies hogtied him and shocked him multiple times with Tasers in Sangamon County, Illinois, according to court documents. A medical examiner concluded the official cause of death was excited delirium.\nThat diagnosis in Burns’ death stymied the family’s lawsuit against the county officers, which ended in a $40,000 settlement in 2015, said Richard Burns, one of Patrick’s brothers. The label also helped law enforcement create a picture of him as someone who was “out of control,” which ruined his brother’s reputation, Richard said. “That picture is implanted on who my brother was, and that’s not the truth.”\nThe term “excited delirium” dates back decades but has never been supported by rigorous scientific studies. Still, the term persisted as some of its early researchers earned money for testifying as expert witnesses in cases involving law enforcement and the company now called Axon Enterprises, which makes the Taser stun gun.\nThe theory suggested that agitated, delirious individuals were dying not because they had been shocked by stun guns, restrained with chokeholds, or held facedown so they couldn’t breathe, but because of this unexplained medical condition that could lead to sudden death.\nFunding from Taser International, Axon’s former company name, sponsored some of the research forming the basis of ACEP’s white paper supporting the excited delirium theory, according to a2017 Reuters investigation. The 19-person task force that drafted the 2009 paper included three people who provided paid testimony or performed consulting work for Taser, that report found. KFF Health News called eight of the task force members but none agreed to interviews. Axon executives did not respond to calls or emails seeking comment on the white paper.\nThat ACEP paper described patients with excessive delirium as having superhuman strength, being impervious to pain, exhibiting aggressive behavior, and making guttural sounds. To Walsh and other doctors behind the push to reject the diagnosis, those descriptions reflected age-old racist tropes of Black men as being stronger than white men or being animalistic. Theincorrect notion that Black people feel less painpersists in modern medicine and has led to disparities in pain treatment.\nIndeed, excited delirium has been cited more often in cases involving people of color. According toa Virginia Law Review article, at least 56% of police custody deaths from 2010 to 2020 attributed to excited delirium involved Black and Latino victims.Reviews of deathsattributed to excited delirium also found they overwhelmingly occurred when people were being restrained.\nYet the authority of the esteemed doctors group and its position paper helped cement an alternative cause of death that defense attorneys for police argued in court. And now, it’s likely too late for families who lost cases based on an excited delirium defense. Even with ACEP’s disavowal, courts may be reluctant to reopen resolved cases, said Jim Davy, a civil rights lawyer in Philadelphia.\nIn June, just months after the National Association of Medical Examiners decided excited delirium should no longer be listed as a cause of death, the county coroner changed Patrick Burns’ official manner of death to homicide. The coroner concluded he had suffered brain damage due to a lack of oxygen after being restrained on his stomach, not from excited delirium.\nBut the Illinois state attorney declined to pursue new charges against the deputies in Burns’ death.\n“It’s more than just an unfortunate story,” Richard Burns said. “This drastically affected our lives.”\nAt a 2020 American Medical Association policy conference, medical students spurred by the racial reckoning in the wake of the police-involved deaths of Floyd and many others introduced a series of resolutions around combating racism in medicine, including one against excited delirium. But emergency physicians, who also belong to that broader physician group, objected.\n“They’re regarded as the content experts on the issue, and so I think it was hard for us to combat some of those counterarguments at that time,” saidRohan Khazanchi, a medical resident and a researcher with theFXB Center for Health and Human Rightsat Harvard University.\nEmergency physicians see patients with agitation and delirium more often than clinicians in other specialties do and oversee emergency medical technicians and paramedics who encounter such individuals outside of a hospital.\nThe AMA decided to study the issue. Its subsequent report firmly sided with the medical students and, in 2021, the AMA delegates issued a strong condemnation of excited delirium as a clinical diagnosis.\nBut ACEP, which represents apredominantly white specialty, dragged its feet in addressing its problematic paper. Instead, the group released a new policy statement in 2021 using the term “hyperactive delirium,” saying the guidance was not meant as an update or refutation of the paper.\nJeffrey Goodloe, an emergency physician in Tulsa, Oklahoma, and one of the authors of the 2021 policy statement, said ACEP didn’t want to issue a statement without providing a clinical document to help guide physicians. And since the task force wanted to focus on clinical considerations, he said, it avoided addressing “excited delirium,” which had been under fire.\n“It was being used in nonclinical ways, which no one ever really thought that it would be,” he said. “It was becoming at times a flashpoint between law enforcement and the community at large.”\nThis spring, the group issued a statement saying it no longer recognized excited delirium as a diagnosis but stopped short of retracting the 2009 white paper. And until this month’s vote, it hadn’t taken any steps to prevent its name and policy statement from being used by defense attorneys defending police in court cases involving in-custody deaths.\nGoodloe, who now chairs the ACEP board, said it was hard for ACEP to track individual court cases and what expert witnesses were saying, especially if they were not ACEP members.\n“We can’t ensure how nonmedical professionals use a document that is designed to inform and guide medical care,” he said. “I would hope that they would continue to recognize the primary intent of the paper and be very meticulous about avoiding misquoting or mischaracterizing what that paper is for.”\nThe remaining defenders of the term insist that excited delirium is a real condition that puts patients, physicians, and first responders at risk.\nOne of the 2009 white paper’s co-authors, Deborah Mash, a retired professor of neurology at the University of Miami, declined an interview but wrote in an email that the task force that penned the white paper included some of the most respected thought leaders in emergency medicine at the time, who sought to suggest best practices for treating patients with such symptoms.\nSince then, she said, “banning the use of the ‘term’ has caught on with the anti-police movement.”\nMash hastestified about excited delirium as an expert witnessfor the defense in wrongful death claims filed against Axon over the use of its Tasers.\nSome lawyers who bring in-custody death cases on behalf of families believe the ACEP reversal will help wipe out a major police defense tactic.\n“It has a huge impact on cases going forward, because the white paper was the main vehicle for trying to legitimize excited delirium,” said Julia Sherwin, a civil rights attorney who is representing the family of Mario Gonzalez, who died in police custody in California in 2021.\nBut eradicating the term “excited delirium” may not stop police from trying to use the theory behind it to justify the deaths of suspects in custody: The Minneapolis Star-Tribunereported last yearthat a training for the Minneapolis Police Department, which was involved in Floyd’s death, used PowerPoint slides with the words “excited delirium” crossed out and replaced with the term “severe agitation with confusion (delirium).”\nClinical documents from ACEP and other organizations have described the same cluster of symptoms at various times as hyperactive delirium, agitated delirium, or restraint-related cardiac arrest. Defense lawyers might argue the same concept using those terms or rely on other medical conditions to explain a death rather than law enforcement officials’ use of force.\n“It’s so easy for them, once the excited delirium argument is dismissed, to use another kind of medical argument that’s quite similar,” saidJustin Feldman, a social epidemiologist at Harvard University who studies patterns of in-custody deaths.\nIn April 2021, Gonzalez died after police officers in Alameda, California, restrained him on his stomach, handcuffed him, and placed their weight on him. The county coroner listed his death as a homicide. But ACEP memberGary Vilke, one of the co-authors of the 2009 white paper, said in a September 2023 deposition he believed that Gonzalez died of cardiac dysrhythmia, an irregular heartbeat.\nVilke testified in the deposition that he could make up to $50,000 as a defense expert in the case, which is set to go to trial later this year, and that he has testified in restraint or law enforcement-related cases 58 times over the past four years. Vilke declined to comment to KFF Health News on the white paper.\nCalifornia’snew lawlists alternative terms — hyperactive delirium, agitated delirium, and exhaustive mania — that will be restricted along with excited delirium starting in January. Nothing in the law prevents defense experts from using other medical explanations, such as cardiac dysrhythmia, for the deaths.\n“People in agitated states due to cocaine, methamphetamine or untreated psychiatric illness still require help which is provided by police and first responders,” Mash, who helped create the 2009 paper, wrote in an email. “These individuals are at increased risk of sudden death regardless of what you call it.”\nStill, Richard Burns, the Halecks, and others whose loved ones died during police encounters hope the ACEP vote prevents future abuses, pushes more states to follow California’s lead, and boosts police accountability.\n“What needs to happen is to focus on the why, the reason, the cause,” said Burns. “The cause is the police brutality, which gets minimized when it’s being able to be hidden behind these terms.”\nChris Vanderveen, KUSA-TV’s director of special projects, contributed to this report.\nKHN (Kaiser Health News) is a national newsroom that produces in-depth journalism about health issues. Together with Policy Analysis and Polling, KHN is one of the three major operating programs at KFF (Kaiser Family Foundation). KFF is an endowed nonprofit organization providing information on health issues to the nation.\nMarkian Hawryluk is a senior Colorado correspondent for KFF Health News.\nRenuka Rayasam is a senior correspondent at KFF Health News.\nLydia Denworth\nAmitha Kalaichandran | Opinion\nAnn Crawford-Roberts, Sonya Shadravan, Jennifer Tsai, Nicolás E. Barceló, Allie Gips, Michael Mensah, Nichole Roxas, Alina Kung, Anna Darby, Naya Misa, Isabella Morton and Alice Shen | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Will the Next Supercontinent Really Drive Mammals to Extinction?", "date": "2023-10-17 10:45:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nThe formation of Pangaea Ultima some 250 million years from now would be bad news for mammalian life. But whether it would mean the end for mammals—or whether the supercontinent will form at all—is far from certain\nThere are dunes as far as the eye can see, parched and shimmering in the unforgiving sun. This gold and ochre sea of sand would seem infinite to any living creature wandering its vastness. But no one wanders this wasteland, and there is no water to drink. In this bereft, forsaken place—a place in which all landmasses have merged to form a single “supercontinent”—moisture and most animal life are merely a faded memory.\nThis isn’t Tatooine or Arrakis. This is Earth, a quarter-billion years from now.\nWell, maybe.\nThere have been several supercontinental eras in the past; each were forged when tectonic plates—giant slabs of solid rock floating atop Earth’s mantle—thrust landmasses together like pieces of a jigsaw puzzle. A supercontinent’s assembly is a leisurely thing because tectonic plates annually shift their positions at roughly the same rate at which toenails grow. The most recent supercontinent, known as Pangaea, formed more than 300 million years ago and gradually disintegrated across the next hundred million years. And should researchers’ projection of the future be correct, the next one, dubbed Pangaea Ultima, will form around Earth’s equator 250 million years from now, with potentially ruinous effects. According to a recent study published in Nature Geoscience, Pangaea Ultima’s rise will likely lead to a precipitous fall in biodiversity caused by scorching surface temperatures that could render more than 90 percent of that future supercontinent uninhabitable for mammalian life.\nThe study sparked extensive press coverage when it appeared in late September. Most outlets astutely noted that humans, also being mammals, would have a hard time living on Pangaea Ultima, too.\nBut whether this would really be “the end” depends, of course, on who you ask.\nSome scientists simply scoff at the idea of making forecasts 250 million years into the future. “This is completely unfalsifiable,” says Robert Stern, a plate tectonics expert at the University of Texas at Dallas. But others appreciate the study, seeing it as a helpful thought experiment and a provocative reminder that no world—Earth included—can traverse geological timescales unscathed. “There is nothing sacred about that time,” says Elena Shevliakova, a climate modeler at the National Oceanic and Atmospheric Administration, who did not participate in the new research. “Physics-wise, [Pangaea Ultima’s climate] is plausible. It’s nothing crazy.”\nThe study’s doomsday framing is certainly attention-grabbing. Several scientists, however, perceive this paper as a story less about the fate of mammals but rather of habitable worlds. “This is the kind of imaginative science people should be doing,” says John Damuth, an ecologist and evolutionary biologist at the University of California, Santa Barbara, who was not involved in the paper. “This tells you how planets work.”\nDespite its dire conclusions, this study was born from whimsy. Alexander Farnsworth, a climate scientist at the University of Bristol and the paper’s lead author, has done plenty of serious climate modeling before, including the sort that investigates Earth’s deep past. But when he felt stir-crazy while quarantining during the early stage of the COVID pandemic, he decided “to do something a little bit different—a little bit fun.”\nHe had already applied climate models to Westeros (one of the continents from Game of Thrones) and Arrakis (the planet from Dune). Why not turn those same forecasting techniques to Earth’s notional next supercontinent—essentially a fictional world, from our ephemeral point of view—and see what happens? When his initial modeling revealed “a quite toasty time period,” Farnsworth decided to team up with colleagues to turn his “fun” into a proper paper.\nThis is what they found: The suturing together of Pangaea Ultima’s constituent parts would increase volcanic activity, powering a massive pulse of explosive, greenhouse gas–belching eruptions that raise global temperatures. An immense desert would occupy the supercontinent’s interior, while conditions at the coasts would resemble a lethally sweltering sauna. And the sun, having burned through more of its hydrogen fuel, would shine slightly brighter in the sky, exacerbating the planet’s thermal troubles.\nBut as the paper itself notes, such projections are riddled with uncertainties. Let’s go through them step-by-step as the hellscape of Pangaea Ultima emerges.\nEarth’s plate tectonics ensure that the planet’s face is forever changing. Alas, this comes with a geological downside: most rocks that would otherwise serve as helpful tracers of ancient events are instead churned to molten oblivion beneath Earth’s ever-shifting crust. Consequently, no one can say with confidence how many supercontinents have come and gone in the planet’s history, and the gaps in our knowledge grow the further we look back in time.\nWorking out the past motions of tectonic plates is tricky enough. But ascertaining future arrangements is even harder. The debate over the timing, assembly and final form of primeval supercontinents means that “it is not clear how long it may take to form the next one,” says Dietmar Müller, a geophysicist and plate tectonics expert at the University of Sydney, who did not participate in the new study. And not all supercontinents necessarily include all continental landmasses—sizable stragglers can exist in isolation.\nPangaea Ultima is one all-continent possibility. It was first proposed (and alternately called Pangaea Proxima) in 1982 by geologist Christopher Scotese, who is also a co-author of the new study. A handful of competing tectonics models culminate in equatorial supercontinents such as Ultima, too. But one of the proposed supercontinents, Amasia, would sit at a far higher—and thereby cooler—latitude. “If the supercontinent that straddles the north pole happens, then mammals probably end up continuing to dominate,” says Jessica Whiteside, a geochemist and paleoclimatologist at the University of Southampton in England, who was not a part of the new research.\nLet’s say that Pangaea Ultima is the chosen supercontinent that materializes a quarter-billion years from now. By that time, the sun will be shining 2.5 percent brighter than today—a near certainty of astrophysics. But our local star won’t be the biggest thumb on the climate’s scales.\nThe supercontinent’s assembly would involve the collision of various tectonic plates—and some of those plates will tumble (or subduct) below others, sloughing off molten material that bubbles back up as a globe-warming surge of volcanism. “All this smashing around and reconfiguration would result in the release of greenhouse gases,” such as water vapor, carbon dioxide and methane, Whiteside says. Volcanic eruptions can induce cooling, too, by venting out sulfur dioxide that combines with water vapor to form sunlight-reflecting aerosols. But that cooling would be brief because aerosols are quickly washed out of the sky, leaving greenhouse warming to dominate the world.\nThe heat would be especially withering deep within Pangaea Ultima’s borders. Far removed from the global ocean’s moisture-carrying winds, the parched landscapes there would be on par with today’s driest and most desolate deserts, denuded of plants and precipitation alike. At the coasts, however, an abundance of atmospheric water would be a bigger problem. “You get more water vapor and more evaporation from the oceans nearby, and so you’re increasing that relative humidity,” Farnsworth says. And as anyone knows who has experienced a sticky summer afternoon, it’s not the heat that gets you—it’s the humidity.\nThe killer combination of a topographically flat and bone-dry interior could also stifle any river-borne transport of carbon-rich sediments otherwise destined to be sequestered in the ocean. This could in turn short-circuit the global process of rock weathering that subtly but powerfully sways Earth’s thermostat. But such effects depend in part on the specifics of mountain ranges and other topographic features that are essentially impossible to predict. “That’s actually quite hard to know or, I would say, very hard to know,” says Alex Whittaker, a landscape dynamics researcher at Imperial College London, who was not involved in the new study. “And we’re not very good at understanding the relationship between [rock] weathering and climate today, let alone 250 million years from now.”\nLet’s pessimistically assume that we are still in the worst timeline, and Pangaea Ultima is a truly infernal place. How would land mammals fare? Keep in mind that Earth’s mammalian forebears were already put through the planetary wringer at least once, somehow enduring the Chicxulub impactor that slammed into the planet 66 million years ago and sent the dinosaurs out with a bang.\nThat our ancient ancestors survived at all is partly thanks to their ability to regulate their internal body temperature, which mammals can do in multiple ways. “If you think about desert foxes or desert hares, they have huge ears, and they’re maximizing surface area to exchange heat with the environment. Hot blood is going up to these thinly insulated parts of the body,” where it escapes into the environment, says Andrea Rummel, a comparative physiologist at Rice University, who was not involved in the research.\n“Sweating is also huge—probably the most important thing,” Rummel adds. “The animal doesn’t really have to work to do anything once it pushes the water out. But water is expensive, and you have to go get more of it when you run out of it,” which would be an issue in future hyper-arid deserts. Even worse, above certain thresholds for temperature and humidity, no method of thermoregulation can help animals cool down; the ambient environment simply won’t accept additional waste heat, and organisms will be poached to death.\nThere are, however, other ways to evade the surface furnace. “Today a lot of desert species are nocturnal to escape the intense heat of the day,” says Gemma Benevento, a macroevolutionary paleobiologist at the Senckenberg Biodiversity and Climate Research Center in Germany, who was not a part of the study. “Burrowing, or even moving entirely underground, could also help to shield organisms from rising temperatures.”\nWith all this in mind, if we could imagine a mammal wandering about the deserts of Pangaea Ultima, what would it be like? It would have to be “something with huge surface area to dump heat, something that could go underground to avoid heat, and [it would have] some kind of water capture method,” Rummel says. It would be like the big-eared desert mouse in Dune, then.\nWould evolutionary biology across the span of 250 million years grant mammals brand-new thermoregulatory adaptations? Don’t hold your breath. “What if you raised the typical body temperature of a mammal?” Rummel asks. Could that push the top limit of temperature survivability even higher? “That’s the big question. And all the available research to date in mammals seems to indicate that higher thermal limits are slow to evolve, if they evolve at all,” she says. “It’s easier to move your cold tolerance, and it’s harder to move your heat tolerance.”\nOverall, if Pangaea Ultima comes to pass, “it’s very hard to make a mammal that can withstand the kinds of environments they’re proposing would occur,” Damuth says. Even if far-future mammals did find ways to manage the heat, the house-of-cards-style collapse of food chains could still starve them to extinction.\nBut all this hinges on what the term “mammal” even means. “If we go back 250 million years, the lineage that gave rise to mammals was quite different anatomically and physiologically,” Benevento says. “It’s absolutely inevitable that over timescales of hundreds of millions of years—and even less—the mammals we know today will have long since gone extinct or evolved.”\nEvolution can seem slow to us, but across geologic timescales, it’s lightning fast. This makes a quarter of a billion years simply too far into the future to forecast fates for mammals—or most any other kind of multicellular life, for that matter. “Who knows what we’ve got to look forward to over that period of time? In 250 million years, the entirety of dinosaurs evolved [and] then went extinct, more or less,” says Tori Herridge, a mammal paleontologist at the University of Sheffield in England, who did not take part in the research.\nThe formation of a supercontinent is not a fast and furious horror show like a cometary impact or, say, humanity’s rapid-fire gaming of the climate and annihilation of natural habitats. It gives animals time to adapt. “It’s completely different to the scenario that we’re talking about with climate change right now,” Herridge says. “I don’t think Pangaea Ultima is the biggest problem mammals have to face right now. Let’s see first if they make it through the next 100 years.”\nThe mammalian aspect of this study is so uncertain that it is essentially unknowable. But its inclusion makes the terrible potential of Pangaea Ultima all the more tangible to us luxuriously well-hydrated, thermoregulated, surface-dwelling primates—likely a key factor in the study’s widespread press coverage.\nThis supercontinental tragedy may never come to pass. But if it does, and even if the land is scorched, one may wonder: What about the oceans? This study only assessed the survivability of land mammals, so “the whales may be safe,” Damuth says. Perhaps the denizens of the seas shall inherit the Earth—if, that is, they survive humanity’s heavy hand.\nBut don’t be so sure: Farnsworth’s team isn’t done dreaming up ways to destroy the future Earth. “We want to do the marine side of it next,” he says, with a grin.\nRobin George Andrews is a volcanologist, author and science writer based in London. His first book,Super Volcanoes: What They Reveal about Earth and the Worlds Beyond,was published in November 2021.Follow Robin George Andrews on Twitter.Credit: Nick Higgins\nJonathan O'Callaghan and Nature magazine\nJack Tamisiea\nJudith B. Moody, R. Damian Nance and Thomas R. Worsley\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Treating Mental Health as Part of Climate Disaster Recovery", "date": "2023-10-17 11:00:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nMental health specialists discuss strategies for residents reexperiencing trauma in the aftermath of hurricanes, wildfires and floods\nThe U.S. has had an unprecedented year of climate disasters—a relentless whirlwind of droughts, floods, cyclones and wildfires costing billions of dollars. Catastrophic events such as the firestorm in Hawaii and Hurricane Idalia in Florida have been battering down the homes and livelihoods of countless people, leaving trails of long-lasting destruction across the country.\nMarty Dwyer, a disaster mental health supervisor with the American Red Cross, says the psychological impact of such sudden and massive losses can make it especially difficult to make big decisions in the aftermath, when they are often most urgently needed. And a hugely consequential choice immediately faces most survivors when they return to their destroyed homes: Should they stay and rebuild or migrate to someplace that seems safer?\n“Whether you are a person experiencing homelessness or transiently unhoused because of disaster, that is a risk [to mental health],” says Joshua Morganstein, chair of the American Psychiatric Association’s Committee on the Psychiatric Dimensions of Disaster. Morganstein has worked with survivors of mass shootings, Hurricane Katrina and various wildfires and has witnessed firsthand how disaster trauma impacts mental wellbeing.\nA growing body of research is revealing how crises of climate change—including wildfire smoke, pollution, flooding and extreme heat—are worsening conditions such as anxiety, depression and post-traumatic stress disorder (PTSD). While experts emphasize the importance of quickly getting people rehoused, rebuilding in a disaster-prone area could subject people to the trauma of losing their home yet again.\nScientific American spoke with Morganstein and Dwyer about the correlation between housing and mental health post-disaster and about measures to prevent repeated traumatization as these disasters persist.\n[An edited transcript of the interview follows.]\nHow does climate disaster trauma differ from other kinds and symptoms of trauma?\nDWYER: A climate disaster raises the level of trauma significantly when people don’t have a chance to prepare and wait. For example, with the wildfire in Maui, they basically had no notice. But in all disasters, you see some pretty similar responses: people might be feeling just absolutely overwhelmed or numb or experiencing high levels of anxiety. It’s not uncommon for people to be very angry.\nThe first things I see are more physical complaints. People describe having insomnia, diminished appetite, headaches or stomachaches. On top of that, many people have preexisting mental health conditions or they have had prior trauma that makes them more likely to need additional assistance.\nMORGANSTEIN: People who are exposed to any given disaster have different types of exposure. Many people experience distress, annoyances and general stressors. And there can be many of those that pile up on top of one another. Of course, the stresses that people experience change over time. The stresses of the moment of a hurricane are very different from the stress of two weeks, six weeks, six months and 12 months after the event.\nImmediate stress reactions include feeling unsafe, which causes significant negative health effects. People who feel unsafe, for instance, are more likely to have difficulty with sleep, and they’re more likely to increase their use of alcohol and tobacco. They’re also more likely to indicate symptoms of general distress.\nSome people may ultimately develop psychiatric disorders. Most often we think about PTSD in the event of a disaster. PTSD is not the most frequent disorder, however. Depression is more common.\nIt’s hard enough to move to a new place when you want to, and you’ve planned for it, and all of your possessions are with you. But people who have been forcefully displaced are dealing with issues of grief, which is a very overlooked but universal response to disasters. It’s often the thing that hangs on for people long after scars are healed. Mental health professionals will diagnose depression, anxiety or PTSD. But we as a society do not do a very good job, I think, at anticipating and addressing the almost universal issue of grief that happens in the wake of all disaster events.\nWhy is housing important to mental health in post-disaster relief?\nMORGANSTEIN: There are negative physical health and mental health effects that become enhanced when people are unhoused.\nMany people who are displaced find themselves in shelters, makeshift or otherwise, with a bunch of strangers. They are without comfort or things that make them feel safe—such as a locked door or just some place to go where they don’t feel exposed to other people. People have difficulty sleeping in loud, noisy places, and they’re limited in their ability to protect whatever property they’re able to take. When someone has chronically underslept, almost everything in their life gets worse: their ability to make decisions, to exercise good judgment, to take protective actions, to assess threats properly in ways that protect themselves and their family.\nIn an attempt to address that, hotels have offered support and have tried to be good stewards in their community after disasters. They move people into their facilities. Being in a place where your family can go and be together and lock a door will help some people to feel safer. People find they can connect with, learn from or share adversity with others who are going through this difficult situation. But one of the things that this might also do is lead some people to feel isolated. Different people have different needs.\nDWYER: Housing is very, very important. One of the things we have seen, especially during the COVID pandemic, is that organizations in the U.S. seem to be getting people out of congregate group shelters and moving towards what we refer to as “noncongregate shelters” [such as hotels]. It might not be home, but it’s not a large building where you’re sleeping right next to strangers.\nWhat are some pros and cons of staying and rebuilding?\nMORGANSTEIN: Some people leave because they feel a sense of threat and feel unsafe. Disasters often do not just take people out of their home but also scatter the community. Everyone disperses because their communities were wiped out by a tornado, hurricane or wildfire. Everyone had to move. Now all of that support is sort of gone. It’s probably important to think about the extent to which people choose to stay versus people who simply do not have the means or resources to go [who say] “I’m here because I have no other choice.”\nFor others, staying can be a way to build a sense of resilience. It can be a path to recovery to go back to and to be present in a place where something difficult happened. We have to remember that most people, even people who have difficulties along the way, will ultimately be okay—and this is very important. Eventually people are able to make meaning of those events. And at some point, people can look hopefully to the future.\nHow can people rebuilding in disaster-sensitive areas prevent retraumatization?\nMORGANSTEIN: The fundamental framework for interventions that we know protect mental health, foster resilience and improve people’s ability to function after disasters involves five essential elements: enhancing a sense of safety, calming, social connectedness, self- or community efficacy and hope. Before it gets to the point where we’re talking about medications and therapies, fostering those five essential elements really is the framework for protecting people who are experiencing extreme stress.\nWe also want to remind people of their innate strengths and capabilities. When we see someone doing something, our goal is not to take over and do everything for a person. We might feel, “Oh, my gosh, this person has been through so much. I’m just going to help them.” Unfortunately, when we do everything for someone, the feeling of helplessness can almost be exacerbated. Helping someone to know where to go encourages them to take those steps. Lower those barriers for people who are having a lot of difficulties.\nIs it going to be worse or better? I’d like to be able to give you a simple answer to whether people should come back. The reality is that there are many factors for individuals that will likely come into play. I do think it’s important to think about—because these events are happening more frequently.\nIf you simply search the literature for “repeat disasters,” there isn’t a lot out there to show what happens over time for people who are exposed to events over and over again. Certainly we have some evidence to show that after difficult situations, people learn from them and feel better equipped to handle them in the future.\nDWYER: Our goal is not to replace the community resources. We are there to supplement and strengthen what the local community has in place, especially in places such as Hawaii or Puerto Rico, where the culture is so important. We want people to get support in a culturally sensitive way. We come from all over; we don’t necessarily know what it’s like to live in that community.\nIf you can alleviate immediate emotional distress, it really does make a difference. Most individuals and families are able to function adequately after a disaster. They may not be as effective in their daily activities. They may have difficulty processing and problem solving, for example. But most people, as devastating as [the disaster] seems, are able to move forward. We help them to discover their resilience and take those first steps.\nAnna Mattson is a freelance science journalist based in South Dakota. You can find more of her work at annamattson.com or follow her on Twitter @AnnaMattson9.\nStephanie Pappas\nIsobel Whitcomb and Gizmodo\nChelsea Harvey and E&E News\nEmily Willingham\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "AI Reads Ancient Scroll Charred by Mount Vesuvius in Tech First", "date": "2023-10-17 11:30:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nFor the first time, a machine learning technique has revealed Greek words in CT scans of fragile rolled-up papyrus\nA 21-year-old computer-science student has won a global contest to read the first text inside a carbonized scroll from the ancient Roman city of Herculaneum, which had been unreadable since a volcanic eruption inAD79 — the same one that buried nearby Pompeii. The breakthrough could open up hundreds of texts from the only intact library to survive from Greco-Roman antiquity.\nLuke Farritor, who is at the University of Nebraska–Lincoln, developed a machine-learning algorithm that has detected Greek letters on several lines of the rolled-up papyrus, including πορϕυρας (porphyras), meaning ‘purple.’Farritor used subtle, small-scale differences in surface texture to train his neural network and highlight the ink.\n“When I saw the first image, I was shocked,” says Federica Nicolardi, a papyrologist at the University of Naples in Italy and a member of the academic committee that reviewed Farritor’s findings. “It was such a dream,” she says. Now, “I can actually see something from the inside of a scroll.”\nHundreds of scrolls were buried by Mount Vesuvius in OctoberAD79, when the eruption left Herculaneum under 20 metres of volcanic ash. Early attempts to open the papyri created a mess of fragments, and scholars feared the remainder could never be unrolled or read. “These are such crazy objects. They’re all crumpled and crushed,” says Nicolardi.\nThe Vesuvius Challenge offers a series of awards, leading to a main prize of US$700,000 for reading four or more passages from a rolled-up scroll. On 12 October, the organizers announced that Farritor has won the ‘first letters’ prize of $40,000 for reading more than 10 characters in a 4-square-centimetre area of papyrus. Youssef Nader, a graduate student at the Free University of Berlin, is awarded $10,000 for coming second.\nTo finally see letters and words inside a scroll is “extremely exciting,”says Thea Sommerschield, a historian of ancient Greece and Rome at Ca’ Foscari University of Venice, Italy. The scrolls were discovered in the eighteenth century, when workmen came across the remains of a luxury villa that might have belonged to the family of Julius Caesar’s father-in-law. Deciphering the papyri, Sommerschield says, could “revolutionize our knowledge of ancient history and literature.”Most classical texts known today are the result of repeated copying by scribes over centuries. By contrast, the Herculaneum library contains works not known from any other sources, direct from the authors.\nUntil now, researchers were able to study only opened fragments. A few Latin works have been identified, but most of these contain Greek texts relating to the Epicurean school of philosophy. There are parts ofOn Nature, written by Epicurus himself, and works by a little-known philosopher named Philodemus on topics such as vices, music, rhetoric and death. It has been suggested that the library might once have been his working collection. But more than 600 scrolls — most held in the National Library in Naples, with a handful in the United Kingdom and France — remain intact and unopened. And more papyri could still be found on lower floors of the villa, which have yet to be excavated.\nBrent Seales, a computer scientist who has helped set up the Vesuvius Challenge, and his team spent years developing methods to “virtually unwrap” the vanishingly thin layers using X-ray computed tomography (CT) scans, and to visualize them as a series of flat images. In 2016 Seales, who is at the University of Kentucky in Lexington, he reportedusing the technique to read a charred scroll from En-Gedi in Israel, revealing sections of the Book of Leviticus — part of the Jewish Torah and the Christian Old Testament — written in the third or fourth centuryAD. But the ink on the En-Gedi scroll contains metal, so it glows brightly on the CT scans. The ink on the older Herculaneum scrolls is carbon-based, essentially charcoal and water, with the same density in scans as the papyrus it sits on, so it doesn’t show up at all.\nSeales realized that even with no difference in brightness, CT scans might capture tiny differences in texture that can distinguish areas of papyrus coated with ink. To prove it, he trained an artificial neural network to read letters in X-ray images of opened Herculaneum fragments. Then, in 2019, he carried two intact scrolls from the Institut de France in Paris to the Diamond Light Source, a synchrotron X-ray facility near Oxford, UK, to scan them at the highest resolution yet (4–8 micrometres per 3D image element, or voxel).\nReading intact scrolls was still a huge task, however, so the team released all of its scans and code to the public and launched the Vesuvius Challenge. “We all agreed we would rather get to the reading of what’s inside sooner, than try to hoard everything,” says Seales.\nAround 1,500 teams were soon discussing and collaborating through the gamer chat platform Discord. The prizes were designed in phases, and as each milestone is reached, the winning code is released for everyone to build on. Farritor, who had always been interested in history and taught himself Latin as a child, got involved early on.\nIn parallel, Seales’ team worked on the virtual unwrapping, releasing images of the flattened pieces for the contestants to analyse. A key moment came in late June, when one competitor pointed out that on some images, ink was occasionally visible to the naked eye, as a subtle texture that was soon dubbed ‘crackle.’Farritor immediately focused on the crackle, looking for further hints of letters.\nOne evening in August, he was at a party when he received an alert that a fresh segment had been released, with particularly prominent crackle. Connecting through his phone, he ran his algorithm on the new image. Walking home an hour later, he pulled out his phone and saw five letters on the screen. “I was jumping up and down,” he says. “Oh my goodness, this is actually going to work.” From there, it took just days to refine the model and identify the ten letters required for the prize.\nPapyrologists are excited, too. The word “purple” has not yet been read in the opened Herculaneum scrolls. Purple dye was highly sought-after in ancient Rome and was made from the glands of sea snails, so the term could refer to purple colour, robes, the rank of people who could afford the dye or even the molluscs. But more important than the individual word is reading anything at all, says Nicolardi. The advance “gives us potentially the possibility to recover the text of a whole scroll,”including the title and author, so that works can be identified and dated.\nYannis Assael, a staff research scientist at Google DeepMind in London, describes the Vesuvius Challenge as “unique and inspirational.”But it is part of a broader shift, he notes, in which artificial intelligence (AI) is increasingly aiding the study of ancient texts. Last year, for example, Assael and Sommerschieldreleased an AI tool called Ithaca, designed to help scholars glean the date and origins of unidentified ancient Greek inscriptions, and make suggestions for text to fill any gaps. It now receives hundreds of queries per week, and similar efforts are being applied to languages from Korean to Akkadian, which was used in ancient Mesopotamia.\nSeales hopes machine learning will open up what he calls the “invisible library.”This refers to texts that are physically present, but no one can see, including parchment used in medieval book bindings; palimpsests, in which later writing obscures a layer beneath; and cartonnage, in which scraps of old papyrus were used to make ancient Egyptian mummy cases and masks.\nFor now, however, all eyes are on the Vesuvius Challenge. The deadline for the grand prize is 31 December, and Seales describes the mood as “unbridled optimism.”Farritor, for one, has already run his models on other segments of the scroll and is seeing many more characters appear.\nThis article is reproduced with permission and was first published on October 12,2023.\nJo Marchant is a freelance science writer based in London.\nShawn O'Bryhim and Ken Krebs\nJosie Glausiusz\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "The Heroic Black Nurses Who Helped Cure Tuberculosis", "date": "2023-10-17 12:00:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nMaria Smilios’new bookThe Black Angelschronicles the history of the nurses ofSea ViewHospital and the curefortuberculosis\nTuberculosis (TB) is one of the oldest and deadliest diseases that can now be prevented and cured. Many researchers worked to develop effective TB treatments, but they didn’t do it alone. In The Black Angels: The Untold Story of the Nurses Who Helped Cure Tuberculosis, author Maria Smilios chronicles the lives and lifesaving work of the Black nurses of Sea View Hospital on Staten Island, N.Y., who worked alongside them and were largely unknown to history until now.\nCaused by the bacterium Mycobacterium tuberculosis, TB is a terrifying illness that is currently the second-deadliest infection globally, behind COVID. It easily infects a host as an airborne germ and lies dormant until it jumps to attention, when it can quickly liquify the lungs, wilt the skin or even swell one’s tongue beyond their mouth. For generations, tuberculosis was a death sentence, and in some developing countries, it still is. Recently TB medication became more widely available when Johnson & Johnson lowered the drug price after John Green, a young adult novelist and YouTube star, called the company out online as part of a long public campaign.\nScientific American spoke with Smilios about her new book and the Black nurses who saved so many lives in their wards and across the world while risking their own lives along the way.\nYou follow so many interesting characters in this book. Initially we see the world through the eyes of Edna Sutton, the aunt of Virginia Allen. (Both women were nurses at Sea View.)But there are many other characters that have stories—doctors, patients and even some of the living relatives of the Sea View nurses. How did you decide which characters to unfold this kind of complicated story around?\nIt was hard. I knew I had to make Edward Robitzek[who helped lead the development of isoniazid, an antibiotic to treat TB] a main character in the sense that he’s the one who initiates these [drug] trials. None of this would have happened if it wasn’t for him, and he saidthat none of it would have happened if it wasn’t for the nurses. I also knew that I had to have the patients in there; I was able to locate two of them who were still alive. I needed to focus on some of the more prominent trial patients that were featured in newspapers, such asHilda [Ali]. Then I was really drawn to the Black nurse Missouria [Meadows-Walker]’s story. She had to be a prominent figure because she stood her ground. So much change happened because of her. The same thing happened with Edna. She was one of the first Black people to own a home in that part of Staten Island, and she was basically the cornerstone for an entire new Black community in Staten Island that’s still there and still thriving.\nYou mention Virginia Allen and Bernice Alleyne [a relative of Missouria Meadows-Walker] in your acknowledgements. Could you tell me about your relationship to them and how it informed your research?\nWhen I was a science editor for Springer Nature, I was reading a book on orphan [rare] lung diseases. It was this book of maybe 10 case studies. One of them mentioned this very rare lung disease, and the doctor who was writing it made a sort of cursory comment, like, “Well, I hope this medication becomes like the cure for tuberculosis at Sea View Hospital.” I was thinking, “What is he talking about?” I’m a New Yorker; I’m kind of a history buff for abandoned hospitals and anything that has to do with disease, so I started Googling it. And then up came the article about Sea View and the cure. Then next to it was this article about Virginia Allen. I found her through the Staten Island Museum, where she was speaking that weekend. So I went and I met her, and then for about six weeks, we met at a little cafe near Harlem Hospital Center[in New York City]. After that, she invited me to her home, which was in the restored nurses’ residence on the grounds of Sea View. We walked and talked, and she pointed at the buildings, and then she said to me, “Would you want to tell the story?” And I asked her, “Are there any archives?” She said, “No, there’s oral history, and I can tell you it.”\nWhat were the nurses’ political lives like during this time period? Their work life and home life were very closely intertwined when they were living in the hospital that they were also working in and testing positive for TB themselves while treating ill patients.\nSo I can’t speak to exactly what political affiliation they belonged to, but they were very political in the sense that they were activists. They all were part of the NAACP [National Association for the Advancement of Colored People] and the National Association of Colored Graduate Nurses. Missouria would often take in the sick; if a nurse didn’t have a family, she took them in. When I researched this book, one of the things that I came to realize was that Black nurses were activists from the outset. They were barred from the American Nurses Association [at the time], so they had to make their own way. They were very, very, very smart. Edna was, Virginia told me, a more quiet activist. She used her home in the later years to hold meetings, and she would raise money—she had a scholarship for young Black women to go to college.\nYour book puts readers on the front line of the tuberculosis epidemic and showcases the graphic nature of TB—it is a violent disease. There are explicit descriptions of some difficult medical procedures or experimental surgeries that were used at the time. How did you approach this part of the research, and why did you want readers to understand, and even experience, the graphic nature of the disease?\nI wanted to banish the myth that tuberculosis is just a disease of the lungs and that all you do is cough. As you said, it is a violent disease; it ruins the body in unthinkable and fantastic ways. The microbe, as I say, is beautifully rendered to torture and to kill at a very slow rate. People don’t even know that they’re sick for weeks or months. I needed readers to know that it affected the tongue, brain and kidneys—it shrinks the kidneys until they’re just these two little useless nodules inside your body. I struggled with not wanting to gross people out, but I thought it was really important to describe the symptoms and procedures. This was a heavy mental toll on these women. Virginia said that Edna never talked about it, but Ednawas a surgical nurse when ribs were taken out in bushels of six to 10 at a time. I also wanted it to go up against the pseudoscience because tuberculosis [had a lot of pseudoscience surrounding it at the time]. It would loom so large in people’s mind. They were so afraid of it, and it was also stigmatizing.\nThis book showed some eerie similarities between our experience in the initial height of the COVID pandemic and that of the average citizen during a tuberculosis epidemic. Could you tell me how your research and the writing of this book affected your perspective on COVID?\nOne of the things writers hope for is to be able to experience as much of our book as possible. So I went to Savannah, Ga., and to Clinton, S.C., and I also walked around Sea View. I never wanted to experience what it was like to live through a time when we had an airborne virus that had no cure. But I found myself in that position on March 13, 2020, with the rest of the world. Virginia called me early on, and she said to me, “Always have your windows open, and have fans and air moving because that’s what we did for tuberculosis.” In terms of the book, I had to rewrite it when COVID happened. I want people to be able to read this book and know that we really need to look at history because we’re in the midst of another COVID outbreak. And I thought it was really important for people to see how ridiculous it is that we’re in the same position now. It was terrifying to me because I knew it took almost nine more years for researchers to really tweak the drug for it to begin to work for tuberculosis. And I was like, “Oh, my God, do we have to go through this for nine more years?”\nCan you tell me how you think the history of TB will help us in our fight against COVID?\nUnfortunately, last week I read that there are about 500 active cases of TB in New York City, which is a rise of about 20 percent, compared with last year. These numbers make it the worst year for TB infection in more than a decade.\nI think one thing we can take away here is that fighting tuberculosis was a global, democratic, long-sustained effort. There was no overnight fix. But most importantly, when an effective treatment became available, it was disseminated worldwide, and part of that happened because isoniazidwas unpatentable, so costs for producing it and treating people with it remained low. And lastly, while there was still pseudoscience, the majority of people didn’t mount a collective effort to say it was “a fake disease.” They wanted it gone. When we reach that point, if we do, then I think we can really begin to end COVID.\nBrianne Kane is senior editorial coordinator at Scientific American.\nLucy Tu\nSofia Moutinho\nAmy Maxmen and Nature magazine\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "AI Is Becoming a Band-Aid over Bad, Broken Tech Industry Design Choices", "date": "2023-10-17 12:30:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nAfter decades of messy, thoughtless design choices, corporations are using artificial intelligence to sell basic usability back to consumers\nThe iPhone, one of the most popular consumer products of all time, has become a usability nightmare. A new one comes with 38 preinstalled apps, of which you can delete 27. Once you’ve downloaded your favorite personal finance, social media and productivity apps, you’re now sitting at 46 or more.\nBut finding the one you’re looking for is a slog: Apple has decided, over time, that there is simply no reason to build a clean user interface for the iPhone anymore, so users cannot rely on their home screen unless they sit and carefully craft separate folders and labels for everything. The “settings” app is a labyrinth of different options for various apps and features, one that isn’t even organized alphabetically, with each option leading to more options that lead to even more options.\nApple isn’t alone. Like many companies, it has decided that there’s no need to build an easy-to-use product when it can just patch over its messy design choices with layers of artificial intelligence. If you want to find something in their garbage dump of apps and options, you must use Spotlight, Apple’s AI-powered search engine that can find everything from text messages to that one setting that they’ve buried deep in a Matryoshka of bolted-on features.\nThis “innovation” of artificial intelligence in your iPhone and throughout the world is not the creation of something new, or revolutionary, but simply corporations selling you back basic usability after decades of messy, thoughtless and bloated design choices. We need to call out what is going on here: tech firms are charging us more to fix their mistakes and slapping an AI label on the shakedown.\nTake Google. Since 2007 the search market leader has slowly eroded the signifiers of advertisements, all while allowing results to turn into a mess of search engine–optimized content that seeks to interrupt your quest for answers with something that will make somebody else money. Users must now trick Google into giving them usable results by putting “+Reddit” or other Boolean strings into search prompts. No worries, Google has an answer: it will use generative AI to summarize search results, solving the search problem not by producing more relevant sources, but by reading them for you. One might think that the solution here would be to build a better search engine, or to reject content that was specifically built to game searches, but Google has (willingly or otherwise) fallen so far behind that it must now innovate simply to provide its original service.\nThis is the ultimate result of the tech ecosystem’s obsession with growth—something I call the Rot Economy. Modern tech companies (especially public ones) are incentivized not to provide better or more usable products, but instead for endless expansion of both revenue and customers. The bloated user experience of an iPhone or Mac computer results from Apple’s constant attempts to bolt on more features and services to your devices. That’s how we ended up with Apple News and Apple Music and Apple Fitness and Apple TV+, each with its own unique set of notifications and popups. This is all in service of increasing the revenue of its multibillion dollar services business, even if these apps (and their various settings) continue to erode user experiences. And the cash that Apple generates from the app store (over $100 billion per year in 2022) means that the company has little interest in trimming the number of apps that users put on their phones. This makes things more bloated, harder to find, and ultimately dependent on Apple’s artificial intelligence.\nAlexa and Siri have become replacements for conscious and intentional computing. They aggregate commands into voice interfaces that, while convenient, utterly sacrifice “what we can do” to “what Amazon or Apple allows us to do.” We have been trained to hoard apps and files, while tech companies have failed to provide any intuitive or easy way to organize them. And their solution isn’t to make things more organized or usable. No, our technological overlords have decided that disorganized chaos is fine as long as they can provide an automated search product to sift through the mess.\nMuch like how having a hammer makes everything look like a nail, tech’s solution to problems is almost always more tech—even if tech created the problem in the first place. While one might argue that artificial intelligence allows for quicker, slicker user experiences, creating user experiences dependent on AI guarantees that any error or poor design choice becomes a single point of failure. It leaves users to sift like a raccoon through hundreds of apps and settings to find the thing they actually want to do.\nAs I’ve already suggested, artificial intelligence–based user interfaces also deprive the user of choice and empower tech giants to control their decision-making. When one searches for something in Siri or Alexa, Apple and Amazon control the results. They provide potentially what the user wants to see, but also a slew of other options benefiting the firms, such as their own services or preferred search results. Google already provides vastly different search results based on your location, and has redesigned search itself multiple times to trick users into clicking links that benefit Google in some way. \nArtificial intelligence that is built to “guide” a user will almost always prioritize the experience that the company wants you to have over the one that you’d actually like. And while the deterioration of the user experience may not be a deliberate choice, Big Tech’s failure to continually improve the ease of use of their devices has given them an opportunity to further funnel and control what a user can do—and manipulate it to their advantage.\nDepressingly, our future is becoming one where we must choose between asking an artificial intelligence for help, or fighting through an ever-increasing amount of poorly designed menus in the hope we might be able to help ourselves. We, as consumers, should demand more from the companies that have turned our digital lives into trillion-dollar enterprises.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those ofScientific American.\nEd Zitronis the CEO ofEZPR, a national tech and business public-relations agency. He is also the author of the tech and culture newsletterWhere's Your Ed Atand the host ofthe 15 Minutes in Hell podcast.\nAlexandra Witze and Nature magazine\nChristine Kenneally\nJosh Fischman, Tanya Lewis, Jeffery DelViscio and Elah Feder\nErika Engelhaupt\nDaniel Lingenhöhl\nGeoffrey H. Fettus | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "The Theory That Men Evolved to Hunt and Women Evolved to Gather Is Wrong", "date": "2023-10-17 13:00:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nThe influential idea that in the past men were hunters and women were not isn’t supported by the available evidence\nEven if you're not an anthropologist, you've probably encountered one of this field's most influential notions, known as Man the Hunter. The theory proposes that hunting was a major driver of human evolution and that men carried this activity out to the exclusion of women. It holds that human ancestors had a division of labor, rooted in biological differences between males and females, in which males evolved to hunt and provide, and females tended to children and domestic duties. It assumes that males are physically superior to females and that pregnancy and child-rearing reduce or eliminate a female's ability to hunt.\nMan the Hunter has dominated the study of human evolution for nearly half a century and pervaded popular culture. It is represented in museum dioramas and textbook figures, Saturday morning cartoons and feature films. The thing is, it's wrong.\nMounting evidence from exercise science indicates that women are physiologically better suited than men to endurance efforts such as running marathons. This advantage bears on questions about hunting because a prominent hypothesis contends that early humans are thought to have pursued prey on foot over long distances until the animals were exhausted. Furthermore, the fossil and archaeological records, as well as ethnographic studies of modern-day hunter-gatherers, indicate that women have a long history of hunting game. We still have much to learn about female athletic performance and the lives of prehistoric women. Nevertheless, the data we do have signal that it is time to bury Man the Hunter for good.\nThe theory rose to prominence in 1968, when anthropologists Richard B. Lee and Irven DeVore published Man the Hunter, an edited collection of scholarly papers presented at a 1966 symposium on contemporary hunter-gatherer societies. The volume drew on ethnographic, archaeological and paleoanthropological evidence to argue that hunting is what drove human evolution and resulted in our suite of unique features. “Man's life as a hunter supplied all the other ingredients for achieving civilization: the genetic variability, the inventiveness, the systems of vocal communication, the coordination of social life,” anthropologist William S. Laughlin writes in chapter 33 of the book. Because men were supposedly the ones hunting, proponents of the Man the Hunter theory assumed evolution was acting primarily on men, and women were merely passive beneficiaries of both the meat supply and evolutionary progress.\nBut Man the Hunter's contributors often ignored evidence, sometimes in their own data, that countered their suppositions. For example, Hitoshi Watanabe focused on ethnographic data about the Ainu, an Indigenous population in northern Japan and its surrounding areas. Although Watanabe documented Ainu women hunting, often with the aid of dogs, he dismissed this finding in his interpretations and placed the focus squarely on men as the primary meat winners. He was superimposing the idea of male superiority through hunting onto the Ainu and into the past.\nThis fixation on male superiority was a sign of the times not just in academia but in society at large. In 1967, the year between the Man the Hunter conference and the publication of the edited volume, 20-year-old Kathrine Switzer entered the Boston Marathon under the name “K. V. Switzer,” which obscured her gender. There were no official rules against women entering the race; it just was not done. When officials discovered that Switzer was a woman, race manager Jock Semple attempted to push her physically off the course.\nAt that time, the conventional wisdom was that women were incapable of completing such a physically demanding task and that attempting to do so could harm their precious reproductive capacities. Scholars following Man the Hunter dogma relied on this belief in women's limited physical capacities and the assumed burden of pregnancy and lactation to argue that only men hunted. Women had children to rear instead.\nToday these biased assumptions persist in both the scientific literature and the public consciousness. Granted, women have recently been shown hunting in movies such as Prey, the most recent installment of the popular Predator franchise, and on cable programs such as Naked and Afraid and Women Who Hunt. But social media trolls have viciously critiqued and labeled these depictions as part of a politically correct feminist agenda. They insist the creators of such works are trying to rewrite gender roles and evolutionary history in an attempt to co-opt “traditionally masculine” social spheres. Bystanders might be left wondering whether portrayals of women hunters are trying to make the past more inclusive than it really was—or whether Man the Hunter–style assumptions about the past are attempts to project sexism backward in time. Our recent surveys of the physiological and archaeological evidence for hunting capability and sexual division of labor in human evolution answer this question.\nBefore getting into the evidence, we need to first talk about sex and gender. “Sex” typically refers to biological sex, which can be defined by myriad characteristics such as chromosomes, hormone levels, gonads, external genitalia and secondary sex characteristics. The terms “female” and “male” are often used in relation to biological sex. “Gender” refers to how an individual identifies—woman, man, nonbinary, and so forth. Much of the scientific literature confuses and conflates female/male and woman/man terminology without providing definitions to clarify what it is referring to and why those terms were chosen. For the purpose of describing anatomical and physiological evidence, most of the literature uses “female” and “male,” so we use those words here when discussing the results of such studies. For ethnographic and archaeological evidence, we are attempting to reconstruct social roles, for which the terms “woman” and “man” are usually used. Unfortunately, both these word sets assume a binary, which does not exist biologically, psychologically or socially. Sex and gender both exist as a spectrum, but when citing the work of others, it is difficult to add that nuance.\nIt also bears mentioning that much of the research into exercise physiology, paleoanthropology, archaeology and ethnography has historically been conducted by men and focused on males. For example, Ella Smith of the Australian Catholic University and her colleagues found that in studies of nutrition and supplements, only 23 percent of participants were female. In studies focusing on athletic performance, Emma Cowley of the University of North Carolina at Chapel Hill and her colleagues found, only 3 percent of publications had female-only participants; 63 percent of publications looked exclusively at males. This massive disparity means we still know very little about female athletic performance, training and nutrition, leaving athletic trainers and coaches to mostly treat females as small males. It also means that much of the work we have to rely on to make our physiological arguments about female hunters in prehistory is based on research with small human sample sizes or rodent studies. We hope this state of affairs will inspire the next generation of scientists to ensure that females are represented in such studies. But even with the limited data available to us, we can show that Man the Hunter is a flawed theory and make the case that females in early human communities hunted, too.\nFrom a biological standpoint, there are undeniable differences between females and males. When we discuss these differences, we are typically referring to means, averages of one group compared with another. Means obscure the vast range of variation in humans. For instance, although males tend to be larger and to have bigger hearts and lungs and more muscle mass, there are plenty of females who fall within the typical male range; the inverse is also true.\nOverall, females are metabolically better suited for endurance activities, whereas males excel at short, powerful burst-type activities. You can think of it as marathoners (females) versus powerlifters (males). Much of this difference seems to be driven by the powers of the hormone estrogen.\nGiven the fitness world's persistent touting of the hormone testosterone for athletic success, you'd be forgiven for not knowing that estrogen, which females typically produce more of than males, plays an incredibly important role in athletic performance. It makes sense from an evolutionary standpoint, however. The estrogen receptor—the protein that estrogen binds to in order to do its work—is deeply ancient. Joseph Thornton of the University of Chicago and his colleagues have estimated that it is around 1.2 billion to 600 million years old—roughly twice as old as the testosterone receptor. In addition to helping regulate the reproductive system, estrogen influences fine-motor control and memory, enhances the growth and development of neurons, and helps to prevent hardening of the arteries.\nImportant for the purposes of this discussion, estrogen also improves fat metabolism. During exercise, estrogen seems to encourage the body to use stored fat for energy before stored carbohydrates. Fat contains more calories per gram than carbohydrates do, so it burns more slowly, which can delay fatigue during endurance activity. Not only does estrogen encourage fat burning, but it also promotes greater fat storage within muscles—marbling if you will—which makes that fat's energy more readily available. Adiponectin, another hormone that is typically present in higher amounts in females than in males, further enhances fat metabolism while sparing carbohydrates for future use, and it protects muscle from breakdown. Anne Friedlander of Stanford University and her colleagues found that females use as much as 70 percent more fat for energy during exercise than males.\nCorrespondingly, the muscle fibers of females differ from those of males. Females have more type I, or “slow-twitch,” muscle fibers than males do. These fibers generate energy slowly by using fat. They are not all that powerful, but they take a long time to become fatigued. They are the endurance muscle fibers. Males, in contrast, typically have more type II (“fast-twitch”) fibers, which use carbohydrates to provide quick energy and a great deal of power but tire rapidly.\nFemales also tend to have a greater number of estrogen receptors on their skeletal muscles compared with males. This arrangement makes these muscles more sensitive to estrogen, including to its protective effect after physical activity. Estrogen's ability to increase fat metabolism and regulate the body's response to the hormone insulin can help prevent muscle breakdown during intense exercise. Furthermore, estrogen appears to have a stabilizing effect on cell membranes that might otherwise rupture from acute stress brought on by heat and exercise. Ruptured cells release enzymes called creatine kinases, which can damage tissues.\nStudies of females and males during and after exercise bolster these claims. Linda Lamont of the University of Rhode Island and her colleagues, as well as Michael Riddell of York University in Canada and his colleagues, found that females experienced less muscle breakdown than males after the same bouts of exercise. Tellingly, in a separate study Mazen J. Hamadeh of York University and his colleagues found that males supplemented with estrogen suffered less muscle breakdown during cycling than those who didn't receive estrogen supplements. In a similar vein, research led by Ron Maughan of the University of St Andrews in Scotland found that females were able to perform significantly more weight-lifting repetitions than males at the same percentages of their maximal strength.\nIf females are better able to use fat for sustained energy and keep their muscles in better condition during exercise, then they should be able to run greater distances with less fatigue relative to males. In fact, an analysis of marathons carried out by Robert Deaner of Grand Valley State University demonstrated that females tend to slow down less as the race progresses compared with males.\nIf you follow long-distance races, you might be thinking, wait—males are outperforming females in endurance events! But this is only sometimes the case. Females are more regularly dominating ultraendurance events such as the more than 260-mile Montane Spine foot race through England and Scotland, the 21-mile swim across the English Channel and the 4,300-mile Trans Am cycling race across the U.S. Sometimes female athletes compete in these races while attending to the needs of their children. In 2018 English runner Sophie Power ran the 105-mile Ultra-Trail du Mont-Blanc race in the Alps while still breastfeeding her three-month-old at rest stations.\nThe inequity between male and female athletes is a result not of inherent biological differences between the sexes but of biases in how they are treated in sports. As an example, some endurance-running events allow the use of professional runners called pacesetters to help competitors perform their best. Men are not permitted to act as pacesetters in many women's events because of the belief that they will make the women “artificially faster,” as though women were not actually doing the running themselves.\nThe modern physiological evidence, along with historical examples, exposes deep flaws in the idea that physical inferiority prevented females from partaking in hunting during our evolutionary past. The evidence from prehistory further undermines this notion.\nConsider the skeletal remains of ancient people. Differences in body size between females and males of a species, a phenomenon called sexual size dimorphism, correlate with social structure. In species with pronounced size dimorphism, larger males compete with one another for access to females, and among the great apes larger males socially dominate females. Low sexual size dimorphism is characteristic of egalitarian and monogamous species. Modern humans have low sexual size dimorphism compared with the other great apes. The same goes for human ancestors spanning the past two million years, suggesting that the social structure of humans changed from that of our chimpanzeelike ancestors.\nAnthropologists also look at damage on our ancestors' skeletons for clues to their behavior. Neandertals are the best-studied extinct members of the human family because we have a rich fossil record of their remains. Neandertal females and males do not differ in their trauma patterns, nor do they exhibit sex differences in pathology from repetitive actions. Their skeletons show the same patterns of wear and tear. This finding suggests that they were doing the same things, from ambush-hunting large game animals to processing hides for leather. Yes, Neandertal women were spearing woolly rhinoceroses, and Neandertal men were making clothing.\nMales living in the Upper Paleolithic—the cultural period between roughly 45,000 and 10,000 years ago, when early modern humans entered Europe—do show higher rates of a set of injuries to the right elbow region known as thrower's elbow, which could mean they were more likely than females to throw spears. But it does not mean women were not hunting, because this period is also when people invented the bow and arrow, hunting nets and fishing hooks. These more sophisticated tools enabled humans to catch a wider variety of animals; they were also easier on hunters' bodies. Women may have favored hunting tactics that took advantage of these new technologies.\nWhat is more, females and males were buried in the same way in the Upper Paleolithic. Their bodies were interred with the same kinds of artifacts, or grave goods, suggesting that the groups they lived in did not have social hierarchies based on sex.\nAncient DNA provides additional clues about social structure and potential gender roles in ancestral human communities. Patterns of variation in the Y chromosome, which is paternally inherited, and in mitochondrial DNA, which is maternally inherited, can reveal differences in how males and females dispersed after reaching maturity. Thanks to analyses of DNA extracted from fossils, we now know of three Neandertal groups that engaged in patrilocality—wherein males were more likely to stay in the group they were born into and females moved to other groups—although we do not know how widespread this practice was.\nPatrilocality is believed to have been an attempt to avoid incest by trading potential mates with other groups. Nevertheless, many Neandertals show both genetic and anatomical evidence of repeated inbreeding in their ancestry. They lived in small, nomadic groups with low population densities and endured frequent local extinctions, which produced much lower levels of genetic diversity than we see in living humans. This is probably why we don't see any evidence in their skeletons of sex-based differences in behavior. For those practicing a foraging subsistence strategy in small family groups, flexibility and adaptability are much more important than rigid roles, gendered or otherwise. Individuals get injured or die, and the availability of animal and plant foods changes with the seasons. All group members need to be able to step into any role depending on the situation, whether that role is hunter or breeding partner.\nObservations of recent and contemporary foraging societies provide direct evidence of women participating in hunting. The most cited examples come from the Agta people of the Philippines. Agta women hunt while menstruating, pregnant and breastfeeding, and they have the same hunting success as Agta men.\nThey are hardly alone. A recent study of ethnographic data spanning the past 100 years—much of which was ignored by Man the Hunter contributors—found that women from a wide range of cultures hunt animals for food. Abigail Anderson and Cara Wall-Scheffler of Seattle Pacific University and their colleagues report that 79 percent of the 63 foraging societies with clear descriptions of their hunting strategies feature women hunters. The women participate in hunting regardless of their childbearing status. These findings directly challenge the Man the Hunter assumption that women's bodies and childcare responsibilities limit their efforts to gathering foods that cannot run away.\nSo much about female exercise physiology and the lives of prehistoric women remains to be discovered. But the idea that in the past men were hunters and women were not is absolutely unsupported by the limited evidence we have. Female physiology is optimized for exactly the kinds of endurance activities involved in procuring game animals for food. And ancient women and men appear to have engaged in the same foraging activities rather than upholding a sex-based division of labor. It was the arrival some 10,000 years ago of agriculture, with its intensive investment in land, population growth and resultant clumped resources, that led to rigid gendered roles and economic inequality.\nNow when you think of “cave people,” we hope, you will imagine a mixed-sex group of hunters encircling an errant reindeer or knapping stone tools together rather than a heavy-browed man with a club over one shoulder and a trailing bride. Hunting may have been remade as a masculine activity in recent times, but for most of human history, it belonged to everyone.\nThis article was originally published with the title \"Woman the Hunter\" in Scientific American  329, 4, 22-29 (November 2023)\ndoi:10.1038/scientificamerican1123-22\nThe Evolution of Human Birth. Karen R. Rosenberg and Wenda R. Trevathan; November 2001.\nAlexandra Witze and Nature magazine\nChristine Kenneally\nJosh Fischman, Tanya Lewis, Jeffery DelViscio and Elah Feder\nErika Engelhaupt\nDaniel Lingenhöhl\nGeoffrey H. Fettus | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "'Monster Quake' Hints at Mysterious Source within Mars", "date": "2023-10-17 13:01:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nImages from each and every spacecraft now orbiting Mars have ruled out a meteorite strike as the cause of a 4.7-magnitude marsquake, the strongest temblor ever detected beyond Earth\nBone-dry, bitterly cold and bathed in cosmic radiation, the surface of Mars may well be dead, with not so much as a single microbe breaking its state of barrenness. But just below its frozen exterior, the planet itself is alive with the sound of thunder. There is still warmth deep within, leftover from the world’s formation eons ago, and as that heat slowly escapes to space, the planet’s crust cools, contracts and quivers. Last year a NASA mission sent to listen to such seismic rumbles heard its loudest one. This “marsquake” was far mightier than any other extraterrestrial tremor ever detected. Researchers have now ruled out a meteorite impact as the cause of this huge event, boosting the case that—seismically speaking—reports of the Red Planet’s death have been greatly exaggerated.\nNASA’s stationary InSight lander launched to Mars in May 2018, touching down six months later in November in a plain called Elysium Planitia just north of the Martian equator. Of its handful of instruments, particularly notable was the seismometer it placed delicately on the ground. NASA’s hope was to pick up marsquakes, whether they were caused by crustal cooling, space-rock strikes or even volcanic activity. The instrument was wildly successful: it detected more than 1,300 temblors before InSight ran out of power in December 2022.\nAlmost as a swan song, the lander had recorded its biggest catch earlier that year—a 4.7-magnitude whopper dubbed S1222a, which was detected on May 4, 2022. This monster marsquake was as large as all the others that InSight detected combined—so strong, in fact, that scientists struggled to explain its origin. “When we first saw it, we were very uncertain,” says Mark Panning of NASA’s Jet Propulsion Laboratory (JPL), project scientist on InSight. The quake didn’t appear to be coming from a nearby region of suspected volcanic activity called Cerberus Fossae, which had been pinpointed by InSight as the source for most of its recorded seismic events—and scientists could find no other surface feature suitable for sparking a spasm of this size. The leading idea was that a meteorite had struck the surface of Mars—something that InSight had detected twice before, albeit on smaller scales. “One member of the team made a bet that if it were not an impact, he would do karaoke at a team meeting,” Panning says.\nIt might be time to warm up the karaoke machine. Fresh analysis led by Benjamin Fernando of the University of Oxford, published today in Geophysical Research Letters, has scoured the Martian surface for a new impact crater linked to this quake. In an ambitious international effort combining imagery from every spacecraft circling Mars—involving orbiters from the U.S., Europe, India, the United Arab Emirates and even China—Fernando and his team examined an area of tens of thousands of square kilometers around InSight and looked at imagery both before and after the monster marsquake. The result? “We didn’t find a crater,” Fernando says, “which strongly suggests this event was tectonic.”\nThe quake’s mysterious source, Fernando and his co-authors posit, lies perhaps 20 kilometers below the surface, stemming from faults and folds that form in the planet’s slowly shrinking crust. “The [Martian] ground has cracks everywhere,” says Bruce Banerdt of JPL, principal investigator of InSight. “If they slide past each other, that’s called a fault, and the motion on a fault causes a quake.” This activity can form wrinkle ridges on the surface—protruding ridges hundreds of kilometers long that are associated with fairly shallow crustal activity. No wrinkle ridge on Mars has been linked to one of InSight’s quakes before, however, and it’s unclear why this biggest quake of all would be the only one to be caused by such a feature. “We just don’t know at the moment,” says Simon Stähler, a seismologist at the Swiss Federal Institute of Technology in Zurich (ETH Zurich). Other than its sheer magnitude, “this quake has no features that are remarkable in any way.”\nIf tectonic activity is the cause, that would mean Mars is releasing “closer to the amount of seismic energy that we expected before the mission,” Panning says. Scientists had predicted Mars would exhibit quakes up to a magnitude of about 5, but this forecast was only borne out by the single monster quake in InSight’s final months of operations. “This is a nice confirmation that the estimates weren’t wildly wrong,” Fernando says. “Mars really does support these pretty hefty marsquakes. 4.7 on Earth wouldn’t bring your house down, but you’d certainly notice it.”\nHad the quake been caused by an impact, the incoming meteorite would likely have formed a crater hundreds of meters wide, with debris strewn for kilometers across the surrounding landscape. InSight detected meteorite impacts on at least two other occasions: one in September 2021 and another later that year on December 24. Scientists know these were impact events because they were eventually traced back to specific new-formed surface craters, which appeared as bluish-black, smudges in satellite images. A similar feature from the May 2022 marsquake “would have been easily recognized,” says co-author Daniela Tirsch of the German Aerospace Center (DLR). “We’re very confident” that it was not an impact, Tirsch says. Alternatively, a landslide could have conceivably spawned the supersized tremor, but none were found to have occurred sufficiently close enough to InSight.\nThat leaves tectonic activity as the most plausible explanation. “I’m satisfied beyond reasonable doubt that this was not an impact,” Banerdt says. Mars’s crust today comprises just one tectonic plate, unlike Earth’s crust with its multiple jostling plates. Yet this single global plate is still thought to experience flexing and accumulate stresses from the remnant heat bubbling up from the planet’s slowly cooling, partially molten core. “Mars still has heat, and that heat is still trying to get out,” Panning says. “That’s going to cause stresses to build up that lead to marsquakes.”\nResearchers have linked most of InSight’s marsquakes to Cerberus Fossae, some 1,700 kilometers eastward of the lander, a site striped with parallel fissures thought to have formed from volcanic activity several tens of thousands of years ago. The region’s quakes may be due to deformation from magma intruding tens of kilometers underground. The arrival times of different waves from S1222a, however—pressure waves propagating through the planet’s interior arrived first, followed by slower “surface” waves—allowed for a crude localization of its origin to the southeast, far away from Cerberus Fossae. That makes the quake’s source particularly confusing because there are no obvious surface features indicating active tectonic processes to account for it. One possibility might be that the southern part of Mars has a more fractured and less dense crust than the north, and seismic waves “cannot propagate as cleanly,” Stähler says. “It could be that quakes from the south just always look weird. But because S1222a was the sole southern marsquake InSight detected, we just cannot say.” This strongly fractured crust might also harbor tectonic faults that are just not visible on the surface.\nEven so, future analysis of this lone event could still yield important revelations, Fernando says. “Clearly there’s a massive piece of the tectonic and seismic puzzle that we haven’t yet unraveled,” he says. For example, any future human explorers on Mars “would want to know where this sort of thing was localizing” to beef up any vulnerable infrastructure to withstand strong ground shaking. More fundamentally, discerning the monster marsquake’s true origins could greatly improve both our understanding of Martian history and the broader possibility of life on other rocky worlds. “If Mars was ever habitable, did that change when the large-scale geological activity stopped on the planet as well?” Fernando asks. “The extinction of life on Mars and the extinction of its plate tectonics are very open-ended questions.”\nJonathan O'Callaghan is an award-winning freelance journalist covering astronomy, astrophysics, commercial spaceflight and space exploration. Follow him on Twitter @Astro_JonnyCredit: Nick Higgins\nIan O'Neill\nJonathan O'Callaghan\nRobin George Andrews\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Women Who Hunt, Organ Transplants and 50 Years of the Endangered Species Act", "date": "2023-10-17 13:15:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWhy scary things can be fun, how to grow materials in space, and language’s influence on the mind\nDon't you love it when a paradigm shifts? When people realize that they've been looking at something all wrong and that there's a better way? My favorite example is plate tectonics. The notion that continents (continents!) could move across the surface of the planet was simply unthinkable for most of human history. It took a lot of research and, even more important, a lot of rethinking for people to accept that plate tectonics was real and could explain earthquakes and volcanoes and why South America and Africa look like they could snuggle together. We're proud that Scientific American published some of the first popular articles about plate tectonics and helped us look at the world in a new way.\nIn our cover story, human biologist Cara Ocobock and biological anthropologist Sarah Lacy upend a long-dominant theory of human evolution: that men alone evolved to hunt. Drawing on research from physiology, paleoanthropology, archaeology, and more, they show that women have always hunted and are better adapted to some endurance tests than men.\nApologies in advance, but our article on organ transplantsmay well bring tears to your eyes (it did mine). Tanya Lewis, a Scientific American senior health editor, shares the technological and medical advances that are saving more lives—potentially many more. The generosity of donors and their families, the personal history of the surgeon at the center of the story, and Tanya's own family experiences make this one of our most touching articles of the year.\nThe Endangered Species Act is 50 years old. Have you seen any Bald Eagles lately? That used to be almost impossible throughout most of the U.S., but now they're thriving, and many species that could have gone extinct are still with us. Robert Kunzig, a former Scientific American editor, evaluates the impact of the ESA and what wildlife needs from the next conservation laws.\nMaterials scientist and aeronautics expert Debbie G. Senesky designs electronics resilient enough to work on Venus—where the surface is hot enough to melt lead, and the skies rain sulfuric acid. As she describes, she's been running experiments on the International Space Station to grow materials that could serve as sensors, batteries, or other devices on future missions.\nThe Murrinhpatha language, spoken by some Aboriginal people in Australia, has a very different structure than English does. Words can occur in any order in a sentence, and a single word can have many pieces added on to express actions and intentions. As author Christine Kenneally writes, linguists have recently found that Murrinhpatha speakers prepare to speak in a previously unknown way, which adds to evidence that language influences our perceptions.\nWhy do so many people enjoy haunted houses, monster movies, horror books and true crime podcasts? In a spookily pictorialized story, behavioral scientists Athena Aktipis and Coltan Scrivner present some delightful research about morbid curiosity and scary play. Happy Halloween!\nJune Minju Kim\nCan We Protect Every Species?\nDuring the height of the COVID-19 pandemic, graphs of hospitalization and infection rates dominated the news, catching the eye of June Minju Kim, then a producer for a South Korean broadcast news network. Now a recent graduate of Columbia University's master's program in data journalism, Kim spent the summer as an intern with Scientific American's graphics team and designed this issue's spread on the 50-year history of the Endangered Species Act. She wanted to avoid collapsing the individuality of the species—from flowers to birds to lichen—while capturing the immense scope of the policy. “These are living things, and every species really deserves your attention,” she says. Kim's work often focuses on the technology being used to quell climate change. She has reported on the tension between lithium mining in Nevada (which proponents say will power electric vehicles) and the preservation of an endangered flower. These complex stories “encourage more thinking,” she says. “There's so much room for exploration.”\nDavid Maurice Smith\nHow Grammar Changes Perception\nPhotojournalist David Maurice Smith (above), who is based in Australia's Gold Coast, traveled to the other end of that continent this past July to photograph speakers of an Aboriginal language called Murrinhpatha. He describes it as “incredibly sophisticated—really, really next level.” Smith, originally from Vancouver, Canada, says he doesn't have an ear for learning languages but has always been drawn to learning from people from different cultural backgrounds. He previously worked in social services, often with First Nations communities, and pursued photography as a more creative outlet with a similar purpose. At 6′7″ tall, Smith knows he's rarely a fly on the wall when he arrives in a community with a camera. Instead, he says, the most genuine photos come from listening to and engaging with the folks he's there to photograph. “You're always going to influence what's happening around you,” he says, “but you can minimize that by just taking the time to connect with people.”\nTanya Lewis\nGift of Life\nIn 2021 Tanya Lewis's mother, Gail (above left), moved from Hawaii to California in the hopes of receiving a lung transplant. Her condition worsened as nearly four months on the waiting list passed. Then she got the call. Lewis, Scientific American's senior health and medicine news editor, moved from her home in Brooklyn to care for her mother as she recovered. The surgery was successful, and the recovery was grueling. For months afterward, Lewis didn't want to even think about transplants. “I've just lived this whole experience,” she recalls. But suddenly, transplant medicine was in the news. Doctors had performed the first pig heart and pig kidney transplants into humans, or “xenotransplants,” and Lewis felt compelled to understand how we got to this point. These pioneering techniques might change the grim calculus of organ transplants in a way that no previous advances could, she writes in her feature story this month. “The fact that we have the technology and the know-how to do this is what's so compelling about it to me.”\nDebbie G. Senesky\nThe Right Stuff\nVenus is one of our closest planetary neighbors, but probes visited its surface only briefly in the 1970s and 1980s and haven't gone back since. “It's hard! It's too hard,” says Debbie G. Senesky, an aerospace engineer at Stanford University, who is developing technology for a return trip to the inhospitable planet. “Think of your cell phone working at 600 degrees Celsius. That's a challenge.” In this issue, Senesky shares an unconventional approach she's exploring: creating materials with unique properties that can be manufactured in space. Making things that work in impossible conditions is her favorite kind of puzzle. She traces this passion to a formative moment in her childhood when she fixed her broken cassette player by fiddling with the gear train. Some of Senesky's latest materials—so light they can sit on a flower petal without bending it—recently returned from the International Space Station.\nThis article was originally published with the title \"New Views\" in Scientific American  329, 4, 4-6 (November 2023)\ndoi:10.1038/scientificamerican1123-4\nLaura Helmuth is the editor in chief of Scientific American. She previously worked as an editor for The Washington Post, National Geographic, Slate, Smithsonian and Science magazines. She is a former president of the National Association of Science Writers. She is currently a member of the National Academies of Sciences, Engineering and Medicine's standing committee on advancing science communication, and an advisory board member for SciLine, Spectrum, and 500 Women Scientists. She has a Ph.D. from the University of California at Berkeley in cognitive neuroscience. She recently won a Friend of Darwin Award from the National Center for Science Education.Credit: Nick Higgins\nAlexandra Witze and Nature magazine\nChristine Kenneally\nJosh Fischman, Tanya Lewis, Jeffery DelViscio and Elah Feder\nErika Engelhaupt\nDaniel Lingenhöhl\nGeoffrey H. Fettus | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Ways to Extend Your Healthy Years, Not Just Your Life", "date": "2023-10-17 19:00:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nThe biology of aging shows ways to lengthen your healthspan, years free of serious disease\nOver the past century the average life expectancy in developed countries has increased by 30 years, from roughly age 50 to 80. Vaccines, sanitation, antibiotics, and other advances allow many more people to survive infectious diseases that used to kill them during childhood. (In the U.S., though, the span dropped by nearly three years during the COVID pandemic, a testament to the power of infections to shorten lives.)\nLonger life spans overall have been a public health success. But they have also created a new and important gap: healthspans, usually defined as the period of life free of chronic disease or disability, do not always match longevity. In this, my 12th year of caring for a relative with Alzheimer's disease, I know this fact well.\nBy one calculation, based on the World Health Organization's healthy life expectancy indicator, an American who expects to live to 79 might first face serious disease at 63. That could mean 15 years (20 percent of life) lived in sickness. Indeed, aging is the biggest risk factor for cancer, heart disease and dementia.\nOne reason for this gap is that, for decades, biomedical research and clinical practice have focused on treating individual diseases, which can extend lives but not necessarily healthspan.\nDuring the past 10 years medicine has started to take a different approach based on the biology of aging (a field called geroscience). “We're now saying our focus should be on extending healthy life rather than just length of life, and slowing aging is the tool to do it,” says Jay Olshansky, a longevity expert at the University of Illinois at Chicago. There are molecular and cellular processes in all our tissues and organs that determine both life span and healthspan. These “pillars of aging” include DNA damage, the aging or senescence of individual cells, inflammation, and stress responses.\nNatural variations in these factors are mostly the result of environmental differences. Genes also play a role, accounting for about 25 percent of the variability, more in extreme cases. (Very long-lived smokers probably won the genetic lottery.) The upshot is that some people age faster than others, and with biological aging comes susceptibility to disease and disability.\nHow do you assess biological age? Molecular markers such as chemical modifications to DNA are one way, says computational biologist Morgan Levine of Altos Labs in San Diego. “Do your cells have a pattern of chemical tags like someone who is 20 or 30 or 40?” she asks.\nGeroscientists have yet to deliver a pill or treatment that can slow or reverse what the pillars of aging do. But they are excited about some possibilities. For example, senolytic drugs target senescent cells, which no longer divide but linger in the body instead of being cleared by the immune system. Research has shown that these “zombie cells” secrete proteins that interfere with other cells' health. The zombies have been linked to osteoarthritis, cancer and dementia. For a 2015 study, researchers used senolytics to remove senescent cells in mice and delayed, prevented or alleviated multiple disorders. Clinical trials are underway in people but are years from completion, so researchers are cautious. They also note that few popular wellness claims about “prolonging your youth” are grounded in evidence.\nFor now, one way to extend healthspan is through unsurprising preventive maintenance. Experts recommend checkups, staying on top of cholesterol levels and blood pressure, and following guidelines such as those from the American Journal of Clinical Nutrition for body fat percentage, lean body mass and bone density. “Know where you are so if something needs to be tweaked you can take steps to do that,” says Matt Kaeberlein, founding director of the University of Washington Healthy Aging and Longevity Research Institute and now chief executive officer of Optispan, a health tech company.\nThose steps are also familiar: common-sense nutrition, sleep, exercise and social connection are the four main factors. “The reason those things work is because they modulate the biology of aging,” Kaeberlein says. For example, regular low- or moderate-intensity exercise helps to prevent cardiovascular disease and type 2 diabetes. How much extra health can these steps get us? “Ten years is probably pretty realistic,” Kaeberlein says.\nThis article was originally published with the title \"Healthspan Can Matter More Than Life Span\" in Scientific American  329, 4, 83 (November 2023)\ndoi:10.1038/scientificamerican1123-83\nLydia Denworth is an award-winning science journalist and contributing editor for Scientific American. She is author of Friendship: The Evolution, Biology, and Extraordinary Power of Life's Fundamental Bond (W. W. Norton, 2020).Credit: Nick Higgins\nAlexandra Witze and Nature magazine\nChristine Kenneally\nJosh Fischman, Tanya Lewis, Jeffery DelViscio and Elah Feder\nErika Engelhaupt\nDaniel Lingenhöhl\nGeoffrey H. Fettus | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "'Climate Gentrification' Will Displace One Million People in Miami Alone", "date": "2023-10-17 19:30:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nMore than half of Miami-Dade County residents will face pressure to move as rising seas push residents inland toreachhigher ground, a new study finds\nCLIMATEWIRE |More than half of the 2.6 million residents in the Miami area will experience “climate gentrification” and pressure to relocate if sea levels rise by 40 inches, according to a study published Monday.\nRising oceans will push many coastal residents inland, where they will force an increase in housing costs that could displace as many as 56 percent of households in Miami-Dade County, according tothe study publishedin the journalEnvironmental Research Letters.\n“Markets are aligning with the idea that there is a higher flood risk in these lower lying areas,” Nadia Seeteram, the lead author of the study and a researcher at the Columbia Climate School, said in an interview. “The areas that happened to be gentrifying also happened to be among some of the higher-elevated areas” and that are “homes to historically marginalized communities.”\nIn Miami-Dade, many minority neighborhoods with lower income levels sit higher than rich beachfront areas. Miami’s famous Little Haiti neighborhood, which is 10 feet above sea level and where nearly half the residents live below the poverty line, has experienced a recent surge in development and property values,raising concerns about displacement.\nPotential climate gentrification extends beyond Florida. Sea-level rise will displace as many as13 million people in the United Statesby 2100, according to a 2017 study. Up to 2.2 million New York City residents willface high risk of regular floodingfrom rising oceans by the same year, according to New York nonprofit Rebuild By Design.\nIn 2022, NOAA predicted that large parts of U.S. coastal cities will be submergedfrom 42 to 84 inches of sea-level riseby the end of the century if global warming causes temperatures to rise 2 degrees Celsius above preindustrial levels.\nSeeteram and her team started their analysis by designating each of Miami-Dade’s 700 census tracts as very vulnerable, moderately vulnerable or not vulnerable based on 13 socioeconomic factors relating to income, race, education and elderly population. The researchers then classified the Miami-Dade population into four categories based on their risk from sea-level rise.\nThe categories are “stable” residents who are unlikely to be inundated and have ample resources; “migrating” individuals who will face sea-level rise but have enough money to move; “displaced” households that are less likely to face flooding but will experience climate gentrification; and “trapped” populations that lack resources to relocate and will have their homes inundated from rising seas.\nWith 40 inches of sea-level rise, roughly 19 percent of Miami-Dade County residents will be “stable,” the study predicts. Roughly 7 percent will be “migrating,” with many choosing to move. And approximately 19 percent will be “trapped” in their inundated homes, unable to relocate.\nThe remaining 56 percent will be “displaced” due to rising housing costs as people move in from flood-prone areas.\nWith 80 inches — or 2 meters — of sea-level rise, nearly half of the Miami-Dade population will be “trapped” and 25 percent will be “displaced,” the study found. Only 8 percent will remain “stable” and 18 percent will be “migrating.”\nThe study provides a new model for understanding both property damages caused by sea-level rise and economic impact from land scarcity, Seeteram said.\n“This is a framework that is broadly applicable to coastal communities across the country,” Seeteram said. “It allows you to take a look at who’s flood-exposed, their level of vulnerability and who’s not impacted through time.”\nReprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.\nMinho Kim is an intern at E&E News.\nMallory Richards | Opinion\nJennifer Hijazi and E&E News\nDaniel Cusick and E&E News\nParag Khanna and Susan Joy Hassol | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Scientists Discover Ghost of Ancient Mega-Plate That Disappeared 20 Million Years Ago", "date": "2023-10-17 20:15:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nA long-lost tectonic plate dubbed “Pontus” that was a quarter of the size of the Pacific Ocean was discovered by chance by scientists in Borneo\nA long-lost tectonic plate that once underpinned what is today the South China Sea has been rediscovered 20 million years after disappearing.\nThe plate is known only from a few rock fragments from the mountains of Borneo and the ghostly remnants of its huge slab detected deep in Earth's mantle. It was once a quarter of the size of the Pacific Ocean. Scientists have dubbed it the \"Pontus plate\" because at the time of its existence, it sat under an ocean known as the Pontus Ocean.\n\"It's surprising to find remnants of a plate that we just didn't know about at all,\"Suzanna van de Lagemaat, a doctoral candidate at Utrecht University in the Netherlands, told Live Science.\nVan de Lagemaat and her colleagues were initially studying the Pacific plate under the Pacific Ocean.Tectonic platesconstantly move against one another, and the crust in oceanic plates is more dense than continental plates, so oceanic plates get pushed under continental plates in a process called subduction and disappear. Sometimes, however, rocks from a lost plate get incorporated into mountain-building events. These remnants can point to the location and formation of ancient plates.\nThe researchers were attempting to find remnants of one of these ancient lost plates, known as the Phoenix plate, while doing fieldwork in Borneo. Scientists can look at the magnetic properties of rocks to learn when and where they formed, van de Lagemaat said; themagnetic fieldthat surrounds Earth gets \"locked in\" to rocks when they form, and that magnetic field varies by latitude.\nRelated:Fountains of diamonds erupt from Earth's center as supercontinents break up\nBut the researchers found something strange when they analyzed the rock they'd collected in Borneo.\n\"This latitude didn't fit with the latitude we got from the other plates that we already knew about,\" van de Lagemaat said.\nTo unravel the mystery, she used computer models to investigate the region's geology over the last 160 million years. The plate reconstruction showed a hiccup between what is now SouthChinaand Borneo — an ocean once thought to be underpinned by another ancient plate called the Izanagi plate actually wasn't on that plate. Instead, the Borneo rocks fitted into that mystery gap.\nThe researchers discovered the spot was actually occupied by a never-before-known plate, which van de Lagemaat and her team named the Pontus plate.\nThe reconstruction, published Sept. 29 in the journalGondwana Research, shows that the Pontus plate formed at least 160 million years ago but was probably far older. (The rock samples collected in Borneo date back 135 million years.) It was once enormous but shrank steadily over its lifespan, finally getting pushed under the Australian plate to the south and China to the north, disappearing 20 million years ago.\nDecade-old research from the same lab also showed a hint of the Pontus plate. That research looked at imaging of Earth's middle layer, the mantle, where the subducted crust ends up. It showed a huge slab of crust of unknown origin, but scientists at the time had no way to determine where it came from, van de Lagemaat said. Now, it's clear that this crust is what's left of the Pontus plate.\nCopyright 2023Live Science, a Future company. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.\nStephanie Pappas is a freelance science journalist. She is based in Denver, Colo.\nRobin George Andrews\nChristine Kenneally\nJack Tamisiea\nStephanie Pappas\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Drag Queens Tag Sharks in Annual Florida Science Celebration", "date": "2023-10-18 10:45:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nThe annual “Drag ’n Tag” expedition takes place amid a wave ofantitransgenderlegislation\nIt starts like any other day on the water for the Field School, a marine research and education organization based in Miami. Scientists and volunteers cram into the main cabin of the RV Garvin, a 55-foot converted yacht that bears an unsettling resemblance to the boat in Jaws. A Field School scientist holds a pink plush shark and gestures to its fins and tail, explaining the data that we will be collecting.\nSoon we’re cruising through calm seas off Florida’s Atlantic coast. Volunteers toss big steel hooks baited with bloody chunks of bonito fish overboard, and heavy concrete anchors pull the bait to the sea floor, where it will hopefully attract some of the region’s largest sharks.\nThen the music starts.\nThe cabin door pops open, and Miss Toto—a tall, muscular drag queen with a long red-and-blonde wig and a colorful ruffled costume reminiscent of a tropical fish—emerges and takes the makeshift stage. She dances and lip-synchs to Nicki Minaj’s “Starships” as the boat rolls with the waves. She’s soon joined by Viola Putx, who is dancing energetically to Bad Bunny in heavy black boots, a spiked collar and pointy elf ears, and finally by Opal Am Rah in a tight pink dress, performing (what else?) Céline Dion’s “My Heart Will Go On”—because this is no ordinary shark tagging expedition. This is Drag ’n Tag.\nNine years ago, Toto was a master’s student at the University of Miami. There she met Catherine Macdonald, head of the university’s shark research program and director of the Field School. Though Toto was studying aquaculture, she had always been interested in sharks—so she joined Macdonald’s shark tagging program as an intern.\nAround that time, Miss Toto also began performing in drag shows. “It was an outlet to meet other queer people,” she says. “It was the first time I had a group of friends outside of school or sports.”\nAfter graduating, Toto felt mentally “tapped out” in science and needed a break. She worked as an educator at a science center while doing drag shows on the side before she decided to really focus on her craft. Now Toto is a full-time drag queen and DJ based in Chicago. But she still gets out on the boat with the Field School every time she returns to Miami.\nShe and Macdonald started Drag ’n Tag expeditions in 2021 to showcase queerness in marine science. “It can be hard for queer people in this field,” Macdonald says. “Plenty of them are very quiet about it. We want to create welcoming spaces for visual queerness.” Ticket sales and other donations for the event also raise money to support Pridelines, a charity that offers services and support for LGBTQ+ youth and community in South Florida.\nAfter the Garvin’s onboard drag show, it’s time to go to work. The boat circles back to the string of buoys marking the hooks, and we begin hauling them in, alert for the tug of a shark on the line. The first catch is a two-meter-long, sandy-brown nurse shark. It is pulled up onto a floating platform off the back of the boat and held steady by Miss Toto and the Field School staff so the volunteers can begin collecting data.\nThe amateur taggers must work fast despite their inexperience; the goal is for each fish to spend no more than six minutes out of the water.\n“I was so focused on getting the measurements right, I don’t remember much!” says volunteer Cristhian Rojas, a business development manager for a flooring company. He had the thrilling job of measuring the first shark’s length and girth. The animal’s skin felt softer than it looked, he says—rough in one direction and smooth in the other, like a cat’s tongue. Afterward other volunteers help swab the shark’s skin for bacteria and snip off a tiny piece of its dorsal fin for genetic analysis, while one of the professionals takes a blood sample.\nAs someone more used hands-off whale watching trips, I can hardly believe that I’m getting down into the water next to a shark’s thrashing body. I am tasked with attaching the tag—a numbered piece of plastic that will identify the shark if it is ever captured again. Because nurse sharks have such tough skin, I use a mallet to tap the tag into the cartilage at the base of the dorsal fin. It feels a bit like driving a nail into a watermelon, but because sharks have fewer nerves than humans do and don't seem to feel pain the same way, the animals hardly notice.\nThe data we collect will contribute to shark population monitoring and research projects in Macdonald’s lab, which tracks how these animals respond to changes in their environment. “It’s very difficult to protect a species you don’t understand, so data on sharks can play a role in identifying essential habitats or potential threats,” Macdonald says.\nDrag ’n Tag focuses not just on the sharks but also on the scientists doing the research. “Many in the queer community have had adverse experiences in marine science with people who don’t think we belong,” says Jenny Norcross, a master’s student in Macdonald’s lab who studies Atlantic guitarfish and introduced herself to those on the boat as a “raging lesbian.” “So events like this that bridge the gap between the community and science are immensely important.”\nThere are few data on LGBTQ+ people in marine science, but research shows that the field lacks racial and gender diversity. Nonwhite and nonmale students and researchers have reported that they often do not feel welcome in the field and that they have faced overt discrimination, microaggressions and a lack of recognition for their work. Many people from underrepresented groups who have left marine science say a shortage of support contributed to their decision.\n“Marine science, and especially shark science, is a very white male path,” Toto says. “So showing that there are people of color, there are women [and] there are queer people is important.”\nAmani Webber-Schultz, a Ph.D. student at the New Jersey Institute of Technology, studies how shark scales influence water flow—and has co-founded a nonprofit called Minorities in Shark Sciences. “I always wanted to be a shark scientist but didn’t see anyone who looked like me,” she says. “I hope this helps dissipate stereotypes like ‘Black people don’t like water’ and gets people thinking about what diversity looks like.”\nToday such efforts at inclusion often come with risk. Drag ’n Tag was never intended to be a political statement—but it is taking place in Florida, where simply existing as queer has become an inherently political act. The state has been turning into an increasingly hostile place for queer people; its infamous “Don’t Say Gay” law limits classroom instruction on sexual orientation and gender identity, and the state has also imposed restrictions on gender-affirming treatments for minors, as well as on drag shows, bathroom usage and the pronouns that kids can use in school.\nSuch moves have made Drag ’n Tag fundraising all the more important to Pridelines, which is now barred from much of the work it used to do with schools. “All of the ways we used to reach out to at-risk youth were closed overnight,” says Daniel Molloy, Pridelines’ director of grants and programming. Drag ’n Tag provides “unrestricted funds that allow us to house young people overnight, provide meals for folks who sometimes have not eaten in days and [provide] transportation for people to get somewhere safe,” he says.\nAnd some say the new restrictions have actually emboldened the queer community and its allies. “Because of the time and place, the impact [of Drag ’n Tag] has been bigger than we anticipated,” Toto says. “To have all of these people supporting us, giving the finger to the politicians, is incredible.”\nThe tense atmosphere has, however, made the event more frightening to hold, Macdonald says. The Garvin flies both a rainbow Pride flag and a Black Lives Matter flag, prompting the occasional shouted slur. “We’re still figuring out what protecting our students looks like,” Macdonald adds. “It’s important to make our values clear, but we don’t want people screaming at them.”\nBut the only screaming today (besides from the audience during the drag show) comes from a family on a passing boat, whose children recognize Miss Toto and call out happy greetings. “I never expected that!” Toto says, with a huge grin and a hint of tears in her eyes.\nThroughout the afternoon, we catch, sample and tag two more nurse sharks and a slate-gray bull shark. As we finally return to the marina in the baking late-afternoon heat, everyone aboard, scientists and civilians alike, buzzes with the excitement of the day. Miss Toto is already looking forward to next year. “This day is about joy and celebration,” she says, “and making a statement that love and community will always conquer hate.”\nBrian Owens is a freelance science journalist based in New Brunswick, Canada.\nDavid Shiffman | Opinion\nCatherine Macdonald | Opinion\nJon Freeman\nHeather Boerner\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Nuclear Waste Is Piling Up. Here's How to Fix the Problem", "date": "2023-10-18 11:00:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nCongress must end the exemption of nuclear waste from environmental law if we ever hope to end a 60-year logjam on how to safely store it\nNuclear waste lasts for tens of thousands of years. On some days, it seems, so does litigation over its disposal. In the latest twist, the United States Court of Appeals for the Fifth Circuit ruled in August on behalf of Texas and two oil companies, determining it was unlawful for the Nuclear Regulatory Commission to license a private, “away from reactor” storage facility for spent nuclear fuel in the Lone Star state.\nWelcome to the club, Texas. Storage or disposal sites at Yucca Mountain in Nevada; the Lyons salt mine in Kansas; in Tennessee; and in New England and the Upper Midwest, have all been set adrift via the courts, Congress or in the court of public opinion over the past six decades.\nWhile the decision itself by the Fifth Circuit may be appealed, its immediate effect is crystal clear: There’s no workable path visible on nuclear waste.\nIt’s time for a new way forward.\nAfter 60 years of failure, some may question whether it’s even possible to solve the conundrum of siting nuclear waste disposal. We absolutely can solve the problem, but first we need to start with a clear-eyed dismissal of clichéd explanations for why national efforts have failed for so long. For more than a decade, there have been two competing efforts underway on nuclear waste, both fitful and incomplete—and unsuccessful.\nOn one hand, since 2012’s Blue Ribbon Commission (undertaken after the Yucca Mountain site was deemed unworkable), many policy makers and advocates have said that “consent” is the key to finding a final repository site. But no one has defined how to achieve this consent.\nAgainst this, several of the bills in Congress introduced over the last decade, even if they technically use the word “consent” somewhere in the text, have focused on forcing the waste into the Yucca site in Nevada or establishing consolidated storage sites in New Mexico or Texas. Expedient for the industry, each has been doomed to failure. Bipartisan leaders in the states have loudly expressed no consent, and what just happened in Texas, no matter how it resolves in the courts, will keep happening until we sort this out.\nThe National Academy of Sciences, federal agencies, courts and independent experts have all come to a clear consensus that nuclear waste is strikingly dangerous and isolating it as remotely as possible from the biosphere via geologic repositories is the best choice. I agree. And developing the criteria to site a repository that isolates waste toxic for a million years is an extraordinary scientific challenge. And that’s just the start. Equally important, there’s no way to ignore the spectacularly difficult institutional hurdles of how society manages and disposes of its nuclear waste.\nWho gets to decide? And how do they carry out such a grave responsibility? This is where bedrock environmental law comes into the discussion.\nFederalism underlies our environmental statutes, with the Environmental Protection Agency first setting a baseline standard, and then states implementing those rules in an expressly reserved role if they so choose. This is how the Clean Water Act, Clean Air Act and hazardous waste laws work. States generally then have “delegated” authority to enforce those standards with some leeway to impose stricter requirements or different, but no less protective, regulatory mandates.\nNuclear waste, however, is different. The Atomic Energy Act and its progeny, the Nuclear Waste Policy Act, exempt nuclear waste from these bedrock environmental laws. And that’s the central reason we are stuck where we are.\nThe cooperative federalism of our environmental statutes is the path to state consent and public acceptance of a nuclear waste solution. Specifically, Congress must finally end the exemption of nuclear waste from environmental law. Our hazardous waste and clean water laws must have full authority over radioactivity and nuclear waste facilities so that EPA—and the states—can assert direct regulatory authority.\nGiven current congressional dysfunction, no one could suggest such a nuclear waste bill will pass imminently. But as the Texas situation illustrates, there’s both bipartisan opposition to the current system and no other viable path forward. Neither Yucca Mountain nor an interim site is going to receive waste under the current legal system. Figuring out how to meaningfully get consent would give lawmakers a constructive pause while providing agencies, states, tribes and independent experts room to debate solutions. Having exhausted every other option, Congress can now go about doing the right thing.\nNow, to be clear, this won’t be easy. EPA’s standard setting would be incredibly hard—and hard fought, as the agency would need to define levels of radiation exposure, cleanup standards and protective terms that could apply in a range of proposed geologic settings. States would then have comparably tough decisions to make as they would need to decide whether to site nuclear waste within their borders—and, if so, how much, and on what terms that are protective of their citizens and natural resources. But they would finally have the authority to make those decisions and not be on the hook for the entirety of the nation’s nuclear waste burden. Thus, states could address the nuclear waste in their state or region, and hold all actors accountable, just as they do with other environmental challenges. And having such authority to set scientifically defensible and limited terms can finally allow political actors to not risk careers by simply entertaining the notion. This will take years.\nBut consider the alternative: We are now stuck in the same place we were 60 years ago, with nuclear waste sitting on the surface at reactor sites around the country and no long-term plan in place to ultimately dispose of it deep underground. \nBut there is hope, and there are leaders pushing forward. Last Congress Senator Ed Markey of Massachusetts and Representative Mike Levin of California proposed legislation that would establish a task force to examine placing nuclear waste under bedrock environmental law.\nThe legislation would bring together the stakeholders and necessary expertise to sketch out a broadly acceptable and politically durable solution. And it would analyze the implications of ending nuclear waste’s exemptions from bedrock environmental laws and a time frame for regulations.\nThe key question of how to define consent, with all ideas, voices and approaches evaluated in the public eye, can finally be tackled.\nNo one has a perfect crystal ball, but history has shown one thing to be true: trying to force this dangerous waste on states without giving them any meaningful recourse under environmental law has failed time and time again. This new approach would allow us to distill the differences and clarify the precise river crossings Congress, EPA and the states must make to write, at last, a way forward on nuclear waste that can be both scientifically defensible and publicly accepted.\nThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those ofScientific American.\nGeoffrey H. Fettus is the former director of the nuclear program at the Natural Resources Defense Council. His work focuses primarily on the legal and regulatory issues of the beginning and end of the nuclear fuel cycle.\nAlexandra Witze and Nature magazine\nChristine Kenneally\nJosh Fischman, Tanya Lewis, Jeffery DelViscio and Elah Feder\nErika Engelhaupt\nDaniel Lingenhöhl\nGeoffrey H. Fettus | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Animals of the Safari Are More Afraid of Humans Than Lions", "date": "2023-10-18 11:30:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nThe savanna is a dangerous place: it has lions, buffalo and poachers. What scares animals the most in a South African national park?\nDespite heavy poaching of rhinos, South Africa’s Kruger National Park is still a natural paradise. One of the largest remaining lion populations in Africa lives there. Yet there is something the local animals fear even more than the big cats.\nLiana Zanette of Western University in Ontario and her colleagues were able to show that animals react most strongly to human voices and flee in response, as the researchers report in Current Biology.\n“We compared fear of humans to fear of lions to see if humans are more feared than the big cats,” says conservation biologist Michael Clinchy, a co-author of the study.\nFor their experiment, the team placed camera traps and loudspeakers at water holes in the national park, which allowed the researchers to influence and record the behavior of a total of 19 mammal species. They played the animals sounds of normal conversations of humans in four South African languages, dogs barking, gunshots and lion sounds—their growls and snarls, not loud roars. “We put the camera in a bear box not because there are bears in South Africa but because of the hyenas and leopards that like to chew them up,” Zanette says. “One night, though, the lion recording made an elephant so angry that it attacked and just smashed the whole thing.”\nThe study group found that animals were twice as likely to flee and vacated an area faster when they heard human voices than when they heard lions or gunshots. This was true for 95 percent of the animal species observed, including giraffes, leopards, hyenas, zebras, kudu, warthogs, impalas and rhinos. Only elephants were significantly more likely to run from lions than from humans.\nThe same was true of the time that animals spent at water holes: they usually stayed longer when lion sounds were played to them than when human voices were heard. Wild dogs, leopards and buffalo were the only animals who stayed at water holes longer when they heard humans, and the difference was not statistically significant for these species. “There is a notion that animals get used to humans when they are not being hunted. But we’ve shown that’s not the case,” Clinchy says. “Fear of humans is deeply rooted and pervasive, so we need to seriously address it for conservation reasons.”\nThe team is now investigating whether its customized sound systems can be used to help endangered species, such as the southern white rhino, away from known poaching areas in South Africa. Initial tests of keeping rhinos away from such areas through the use of human voices have been successful.\nThis article originally appeared in Spektrum der Wissenschaft and was reproduced with permission.\nDaniel Lingenhöhl is editor in chief of the magazines Spektrum der Wissenschaft and Gehirn&Geist. Follow him on Twitter @lingenhoehl\nAlexandra Witze and Nature magazine\nChristine Kenneally\nJosh Fischman, Tanya Lewis, Jeffery DelViscio and Elah Feder\nErika Engelhaupt\nDaniel Lingenhöhl\nGeoffrey H. Fettus | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "New DNA Tests Are Identifying Missing Persons and Solving Crimes", "date": "2023-10-18 12:00:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nEvery year about 1,000 human remains go unidentified in the U.S. New genetic technology can give them names and return them to their families\nOn June 5, 2017, Ashley Loring Heavyrunner disappeared from the Blackfeet Reservation in Montana. The then 20-year-old college student stopped by her parents’ house that day and went to a party; then, at some point, she became part of an epidemic of missing Indigenous women. Six years later she’s still missing.\n“When she went missing, it really hit our community hard,” says Haley Omeasoo, a classmate and a distant relative of Heavyrunner. Omeasoo, a descendent of the Blackfeet Tribe and a member of the Hopi Tribe, decided to pursue forensic anthropology so she could help find Heavyrunner and other missing Indigenous people. Today she’s a Ph.D. student at the University of Montana. In September Omeasoo joined other researchers at a workshop of the International Symposium on Human Identification in Denver, Colo., to share new strategies for using DNA to identify missing persons. Of the human remains found in the U.S. each year, about 1,000 still remain unidentified after a year has gone by. It is “a mass disaster over time,” says retired FBI geneticist Bruce Budowle, who organized the symposium.\nRecent advances in rapid DNA sequencing, along with genetic genealogy that traces familial relationships, are beginning to be used to solve missing person cases that had long gone cold, Budowle, Omeasoo and other scientists reported in Denver. New testing kits can extract many thousands of genetic markers from unidentified human remains, and that high number makes it much easier to link those remains to missing persons or their relatives. Older kits could only salvage a few dozen such markers. Traditional testing could at best identify a first- or second-degree relative from an unknown DNA sample. The newer methods, however, can identify even very distant relatives, giving law enforcement a much better chance to connect remains to a family.\nAccording to an estimate from the Bureau of Justice Statistics, each year more than 4,000 sets of human remains are found in the United States, and of those about a quarter stay unidentified after one year. The situation is particularly dire for Native American populations. No single database tracks missing and murdered Indigenous women, but figures from the National Crime Information Center suggest that nearly 5,500 missing persons reports of Indigenous women and girls were filed in 2022 alone.\nWhat’s more, the primary U.S. database of missing persons, the National Missing and Unidentified Persons System, or NamUs, doesn’t include DNA data. So when remains are found, there’s nothing to match them to—unless the missing person or a very close relative (who shares enough genetic markers for a partial match) happens to be in the FBI’s criminal DNA database, the Combined DNA Index System (CODIS).\nThat’s where forensic investigative genetic genealogy, or FIGG, can help. Using FIGG, law enforcement personnel can search the DNA of people who have voluntarily contributed DNA profiles to genealogy databases such as GEDmatch and DNASolves, which allow users to upload data from 23andMe and other commercial testing services. Private laboratories such as Parabon NanoLabs and Othram have worked with law enforcement to solve hundreds of cases in the past few years using genetic genealogy, including decades-old cases such as the Golden State Killer and Long Island Serial Killer murders.\nNow, Budowle says, investigators are using the same approaches to link unidentified remains to missing persons. Parabon, for instance, says that of the 293 cases they have helped to solve to date, 77 have involved unidentified remains. One limitation remains, however: DNA profiles from a broad population are needed for comparison with remains. Because of privacy concerns, the U.S. Department of Justice and some states have dialed back on law enforcement’s access to ancestry databases. Plus, the data that are available come mostly from people with white European ancestry; very little are available for Native American and other minority populations.\nThat’s one reason cases involving Indigenous people remain among the most difficult to solve. Resources are slim, and jurisdiction is complicated on tribal lands, and furthermore, DNA analysis poses thorny cultural issues. Some tribes have ethical prohibitions against destructively sampling human remains, and many are wary of providing genetic information.\nStill, there has been some promising recent news. For instance, in 2008 skeletal remains were found in a remote part of the Yakama Nation Reservation in Washington State. Investigators could not get a useful genetic profile using the technology of the time, but in 2022 the Yakima County Coroner’s Office partnered with Othram to try newer techniques. Othram scientists had improved methods for collecting DNA from bones and used rapid genome sequencing to develop a full genetic profile. They then compared that profile with DNA provided by family members of a woman who was reported missing in the area more than 35 years earlier.\nThis time the work paid off. In January 2023 the remains were identified as belonging to Daisy Mae Tallman, also known as Daisy Mae Heath, a Native American woman who was 29 years old when she disappeared in 1987. Her remains were returned to her family.\nOmeasoo and her graduate advisor, anthropologist Meradeth Snow of the University of Montana, are working with the Blackfeet Tribe to create a DNA database of tribal members that can be compared with unidentified human remains. The tribe will own and maintain its own data. To alleviate concerns about destroying remains, Snow has adapted nondestructive methods to recover DNA. She uses a nontoxic chemical solution that releases DNA from bone so that it can then be essentially soaked up without damaging remains.\nSomeday this work could identify Ashley Heavyrunner’s remains. Omeasoo says she thinks about that possibility often. “Everyone still holds out hope” that somehow Heavyrunner is alive, “but it has been six years, and there’s been no answers,” she says. “So just getting her family closure, I think, is the most important thing right now.”\nSnow has been able to provide that closure for one family. She tested the DNA of an ancient Native American man whose remains had been in storage for years. From the genetic material, she was able to pinpoint the man’s closest living relative and return his bones to his descendants. It was the most rewarding work she’s ever done, she says. “As a scientist, I’m not allowed to say it’s magic,” Snow says, “but, like, it feels like magic sometimes.”\nErika Engelhaupt is a freelance science writer based in Knoxville, Tenn. She is the author of Gory Details: Adventures from the Dark Side of Science (National Geographic).\nAnanda Rose\nSteve Mirsky\nSally Lehrman\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "How to Handle This New COVID Season", "date": "2023-10-18 13:00:00", "text": "The dangerous virus is still here. Here’s how you can stay safe.\nTanya Lewis: Hi, this is Your Health, Quickly, a Scientific American podcast series.\nJosh Fischman: We bring you the latest vital health news: Discoveries that affect your body and your mind.\nLewis: And we break down the medical research to help you stay healthy.\nI’m Tanya Lewis.\nFischman: I’m Josh Fischman.\nLewis: We’re Scientific American’s senior health editors.\nOn today’s show, we’re doing a refresher course on COVID. Fall and winter usually see a peak in virus cases, so we thought it would be a good time to talk about where we’re at. That means knowing where COVID is spreading, how to stay safe, and when you should test yourself.\n[Clip: Show theme music]\nFischman: I really haven’t been worrying much about COVID for months now. It was summer, it was warm and nice outside, and the public health emergency ended last spring. Cases seemed low, so I wasn't thinking about the diseaseall that much.\nLewis: Yeah, me neither. I've had a nice little break from COVID for a few months now, really. But the virus is still there, and it's continuing to spread, so I'm starting to get my mask out again.\nFischman: But a friend of mine just caught COVID for the third time. Another friend has been sick with it for three weeks. And it’s getting to be fall and winter, seasons when the virus has peaked in the past.\nLewis: Yeah, COVID isn’t quite a seasonal virus yet, but it does seem to follow some seasonal patterns. It spreads easily when people are indoors, like we are much of the winter. And then you add in holidays and kids going back to school, and it’s the perfect viral storm.\nFischman: These friends of mine, the ones who got sick, have been texting back and forth, arguing over the best time to use home COVID tests, and a bunch of other stuff that I think we all had a better handle on last year. I think we’ve kind of forgotten some of the basics.\nSo to catch up, we thought we’d talk to someone who’s been tracking the virus and public health for the whole pandemic: Katelyn Jetelina.\nJetelina: I’m an epidemiologist, and publisher of Your Local Epidemiologist.I do a lot of contracting work with the CDC, also adjunct at University of Texas Health Science Center.\nLewis: Your Local Epidemiologist is a newsletter that’s become a go-to source for hundreds of thousands of people, because Katelyn explains COVID research in plain English and turns it into advice for readers trying to figure out how to stay as safe as they can.\nFischman: One of the first things I wanted to know was: how do I know if COVID cases are rising in my community, so I can take extra care.\nAnd, here’s what Katelyn said:\nJetelina: Yeah, this is really challenging to do, especially on a local level. I, [in] particular, know a lot of other epidemiologists are focused on wastewater.\nLewis: Wastewater is sewer water, essentially. If people are infected with the virus, and use the bathroom, that virus gets flushed down the drain. Then scientists can test for it. If levels go up, week after week, it means the virus is spreading in the community.\nJetelina: For example, in San Diego, we have a fantastic wastewater system for viral surveillance. But really, you just need like a regional kind of trend. Because wastewater is good forlooking at trends.\nAnd so if that trend in your region is increasing, then like you said, you're gonna start hearing more and more people getting infected.\nThe wastewater dashboard I use is Biobot. It's super, it's pretty, it's straightforward.\nFischman: Biobot is a company that works with public health agencies to monitor viruses in the water. And they do have a pretty nice trend dashboard on their website, which you can Google.\nBe warned, though. It doesn’t get super local. For instance, I’m pulling it up here on my phone… I live in Maryland, so I’m looking there for the county I live in… And…it’s not listed. It’s just not there.\nWhat about you, Tanya?\nLewis: Let me take a look and see if they have one for Brooklyn … or King’s County, where I live. Um, but, I do not see anything. And I don’t see anything for New York City, so the closest one is Nassau County in Long Island.\nFischman: So wastewater isn’t perfect. There are gaps in Biobot’s coverage, but there are other programs that might fill in. And wastewater is better than some other indicators.\nLewis: Yeah, like the number of people testing positive for the virus, or case rates. Katelyn doesn’t think those numbers are very reliable anymore.\nJetelina: So as we left the pandemic emergency, as fatigue has certainly crawled in, people are stopping to test. So certainly case data is not anything I would pay attention to.\nFischman: She did mention something new, which I hadn’t heard about, which is a way to look at COVID and the flu together.\nJetelina: We're going into the fall, winter season… and there's going to be a lot of crap out there. And so one thing I know the CDC is updating, which should be in the next week or two, is a respiratory map by state.\nLewis: The CDC has long had a tracker for flu-like illnesses, but during the pandemic they had a separate tracker for COVID. And now that’s changing.\nJetelina: That COVID number is going to be folded into this respiratory outlook. And I'll probably be using that to really determine when to wear a mask, for example, because I don't want flu or RSV, or COVID, or norovirus or whatever is out there.\nFischman: Another thing I wanted to know about was what to do if you think you’ve been exposed. I know Katelyn said a lot of people don’t do rapid home antigen tests anymore. But plenty still do.\nSo you get a call from a friend who you just had lunch with. And she says she just tested positive. Should you test yourself?\nLewis: The tests are most accurate at detecting infection once the virus has had a few days to replicate in your body. The advice from the FDA and the CDC is to wait five days after exposure, and then test.\nFischman: But Katelyn pointed out there are lots of times you don’t know the exact time or day of exposure. And also that with new variants, viral loads seem to build more slowly, so it may be more useful to wait until you actually start seeing symptoms, like a runny nose, cough, a fever, the usual stuff. And, then, wait out a few days of those before testing.\nLewis: So…you shouldn’t take a home antigen test during the first two days you feel sick?\nJetelina: Yeah, third day, it may start increasing your viral load. But yeah, those first two days – there's a high likelihood of a false negative on your antigen test.\nLewis: Good to know.\nSo, when COVID is on the rise, what’s the best way to keep yourself safe?\nJetelina: Wear a mask. Like, I have two toddlers I need to take care of. I'm traveling all the time for work. Like I just don't have time to get sick and so I wear a mask. Wearing a mask helpsprotect you, it helps protect those around you. Taking an antigen test a couple of days after symptoms, getting a vaccine. I mean, just go get your vaccines by Halloween. You may get infected, but you're not going to end up at the hospital.\nLewis: So that’s the advice from your local epidemiologist. We’re not in the same place we were in previous years, but COVID is still a risk. We have the tools to protect ourselves. Let’s use them.\n[CLIP: Show music]\nFischman: If you want more info on how science tracks viruses in wastewater, we have a short documentary on that. There’s a link to it in the transcript for this episode.\nLewis: It’s fascinating. Take the plunge!\nFischman: Your Health, Quickly is produced by Tulika Bose, Jeff DelViscio, Kelso Harper, Carin Leong, and by us. It’s edited by Elah Feder and Alexa Lim. Our music is composed by Dominic Smith.\nLewis: Our show is a part of Scientific American’s podcast, Science, Quickly. Subscribe wherever you get your podcasts. If you like the show, give us a rating or a review!\nAnd if you have ideas for topics we should cover, send us an email at Yourhealthquickly@sciam.com. That’s your health quickly at S-C-I-A-M dot com.\nI’m Tanya Lewis.\nFischman: I’m Josh Fischman.\nLewis: See you next time.\nJosh Fischman is a senior editor atScientific Americanwho covers medicine, biology and science policy.He has written and edited about science and health forDiscover, Science,Earth, andU.S. News & World Report. Follow Josh Fischman on Twitter.\nTanya Lewis is a senior editor covering health and medicine at Scientific American. She writes and edits stories for the website and print magazine on topics ranging from COVID to organ transplants. She also co-hosts Your Health, Quickly on Scientific American's podcast Science, Quickly and writes Scientific American's weekly Health & Biology newsletter. She has held a number of positions over her seven years at Scientific American, including health editor, assistant news editor and associate editor at Scientific American Mind. Previously, she has written for outlets that include Insider, Wired, Science News, and others. She has a degree in biomedical engineering from Brown University and one in science communication from the University of California, Santa Cruz.Follow Tanya Lewis on TwitterCredit: Nick Higgins\nJeff DelViscio is currently Chief Multimedia Editor/Executive Producer at Scientific American. He is former director of multimedia at STAT, where he oversaw all visual, audio and interactive journalism. Before that, he spent over eight years at the New York Times, where he worked on five different desks across the paper. He holds dual master's degrees from Columbia in journalism and in earth and environmental sciences. He has worked aboard oceanographic research vessels and tracked money and politics in science from Washington, D.C. He was a Knight Science Journalism Fellow at MIT in 2018. His work has won numerous awards, including two News and Documentary Emmy Awards.Follow Jeffery DelViscio on Twitter\nElah Feder is a journalist, audio producer, and editor. Her work has appeared on Science Friday, Undiscovered, Science Diction, Planet Money, and various CBC shows.Follow Elah Feder on Twitter\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
{"title": "Grammar Changes How We See, an Australian Language Shows", "date": "2023-10-18 13:30:00", "text": "Wonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nWonderfall Savings!\nAn Aboriginal language provides unexpected insight into how language influences perception\nIn the early 20th century linguist Benjamin Lee Whorf thrilled his contemporaries by noting that the Hopi language, spoken by Native American people in what is now Arizona, had no words or grammatical elements to represent time. Whorf argued that this meant Hopi speakers had no concept of time and experienced what an English speaker might call “the passage of time” in a completely different way. This bold idea challenged the prevailing notion that there was a correct way to see the world—a way that lined up with the concepts already embedded in the languages of Western scholarship.\nAs it turns out, Hopi has quite a complex system for describing time, and those who speak it are perfectly capable of thinking about time in all kinds of ways, as indeed are all humans. In light of this realization, modern linguists assumed that even if the fundamental structures of language may differ—and even if languages specify things such as gender, number, direction and relative time in diverse ways—everyone must perceive the world in the same basic way.\nWork on Australian Aboriginal languages has complicated that view, most recently in a groundbreaking study of Murrinhpatha. Spoken by most residents of Wadeye, a town of 2,500 people on Australia's northwestern coast, the language has many fascinating characteristics. Action, participants, ownership and intention may be expressed with a single word. This quality, which linguists describe as “polysynthetic,” means that many affixes may attach to a verb—and with each additional affix another layer of story accrues. The meaning conveyed by such a word contains actors and acting entwined into a complex whole. For example, the single word mengankumayerlurlngimekardi means “he was going through our bags stealing from us.\nMurrinhpatha also has free word order, which means subjects, verbs and objects can and do occur in any position in a sentence. In practice, this means the two-year-olds of Wadeye learn how to wield massively complex words that bear little relation to the content of a typical English-language book of ABCs.\nRecently Rachel Nordlinger, a linguist at the University of Melbourne who has studied Murrinhpatha for 18 years, and her colleagues conducted the first psycholinguistic experiment in the language. Significantly, they found that when people are putting their thoughts into words, their mental processes may be shaped by the structure of their language.\nFrom the late 1950s onward one of the most important observations in modern linguistics was that any child can learn any language. It followed that all children must have the same mental equipment for acquiring language. In 2009 psycholinguist Anne Cutler observed that, in part because of this truism, researchers assumed the systems for adult language processing were also the same and would yield similar results across studies no matter what language they used to test them. Language-processing experiments were written up, replicated and discussed with no consideration of the fact that the different languages used may have had some effect on the findings. It wasn't that language diversity was entirely invisible, Cutler noted, but that the research objective was to unearth a universal system that all humans used.\nOver time that view became less tenable, in part because of Cutler's contributions. One of her findings was that listeners segment a speech stream based on the cadence of their first language. French speakers segment a speech stream into syllables, whereas English speakers segment it by stress placement.\nField linguists, whose work brings them regularly into contact with the stunning diversity of the world's languages, also have long doubted the idea that a person's native language has no impact on their thought processes. And more recently, many researchers have been troubled by the fact that most work on universal properties of language and language processing has been carried out using English and a few other familiar languages—a group that probably represents less than 5 percent of the world's language diversity. “The focus was on finding universals and explaining away the differences,” says psycholinguist Evan Kidd, one of Nordlinger's co-experimenters. “But the search for universals took place in only one corner of the language universe.”\nAustralian languages are among the least explored by psycholinguists—a major gap given the size of the language family. Just 200 years ago at least 300 languages were spoken by people in Australia. Of that enormous group of languages, most belonged to the Pama-Nyungan family, with dozens of branches that descended from a protolanguage probably spoken 6,000 years ago in the northeastern part of the continent. Since colonization began in Australia in 1788, the number of Aboriginal languages still spoken in Indigenous homes in the country has been roughly halved. Of those remaining, only 13 are learned as a first language by children. Murrinhpatha, part of the relatively small group of non-Pama-Nyungan languages, is one of these 13—forming an unbroken thread of dynamic cultural inheritance that extends back many thousands of years. The language's survival is nothing short of astonishing.\nWadeye was first established as a mission in 1935, and many local Indigenous people there experienced forced assimilation. Children were taken from their families and incarcerated in a boarding school, where they were punished, sometimes sadistically, if they spoke their language. In many places where people experienced similar abuse, the local languages did not survive.\nMoreover, the Wadeye mission brought together Indigenous Australians from 10 other language groups, but those languages did not survive in the same way. Now only a few elderly speakers who know them remain. But the children in Wadeye, Nordlinger says, speak Murrinhpatha. She once asked an elder, her friend and language consultant, how it was that despite the cruelty of the missions and the punishment by the nuns, her people still spoke Murrinhpatha. “We just used to whisper,” the woman replied.\nMargaret Perdjert, 61, and Stephen Bunduck, 41, elders and residents of Wadeye, learned Murrinhpatha from their elders and later learned English in school. As speakers of both languages, they find that the two have different uses. English is good for talking to outsiders, and it helps kids in the community find good jobs. But their culture and their worldview are completely embedded inside Murrinhpatha, and, they add, the language is vital for their community. In fact, the number of Murrinhpatha speakers who learn it as a first language is growing. It has become the lingua franca of many local Indigenous groups, all with distinctly different language histories.\nNordlinger, who has been working with Murrinhpatha since 2005 but says she speaks it like a three-year-old, long suspected that understanding the demands the language puts on its learners could open windows on human thought. As director of the University of Melbourne's Research Unit for Indigenous Language, she leads the biggest team of researchers devoted to both studying Australian languages and supporting Indigenous speakers in their language goals. For Nordlinger, each language represents a unique expression of the human experience and contains irreplaceable knowledge about the planet and people, holding within it the traces of thousands of speakers past. Each language also presents an opportunity to explore the dynamic interplay between a speaker's mind and the structures of language.\nIn 2015 Nordlinger and Kidd attended a talk about using eye-tracking technology in language experiments, presented by psycholinguist Stephen C. Levinson, now director emeritus of language and cognition at the Max Planck Institute for Psycholinguistics in the Netherlands. The studies Levinson described demonstrated a clear relation between the grammar of a participant's language—specifically, the way words were ordered in it—and the way the person assessed a picture. For example, with a picture of a woman washing a child, English speakers, who perceived the woman as the subject, tended to look at the woman first. “The thinking,” Nordlinger says, “is that English speakers zoom in on the thing that they will express as their subject.” So English-speaking participants focused on the woman and started speaking. Then they looked at the rest of the picture and finished the sentence. “This all happens in milliseconds,” Nordlinger says.\nTseltal speakers did it differently. The grammar of Tseltal, spoken in Chiapas, Mexico, obliges speakers to produce a verb first. So when a group from Levinson's laboratory used eye tracking to understand sentence planning and production in Tseltal, the researchers found that speakers viewed the woman and the child more evenly, looking back and forth between the two. Psycholinguists call this relational encoding. “It makes sense,” Nordlinger says. “If you have to produce the verb first, you have to look across the picture, work out what's going on and assess it.”\nAt the talk Nordlinger asked Levinson what would happen if participants spoke a language with free word order. “We have no idea,” Levinson said. Kidd, who was sitting next to Nordlinger, whispered, “We should do that!\nThe obvious candidate was Murrinhpatha, which Nordlinger had been studying for a decade. But it took some planning to take a lab-based experimental method that closely tracks participants' utterances and eye movements and apply it to a language that had never been studied in that way before.\nFinding a quiet space in Wadeye was step one. The first time Nordlinger ran the experiment she used a room in what is now a museum, although it was once a morgue. On other trips Nordlinger and Kidd used their rented lodgings in the town's old nurses' quarters—three units made from gray breeze-block, joined together. They used many of the same pictures as Levinson, adapting some to make more contextual sense: replacing deer with kangaroos, giving some people darker skin, and taking out anomalous objects such as a horse and a carriage.\nThe researchers also worried about how the conditions of the experiment might affect the outcomes. Murrinhpatha has free word order, but Nordlinger and Kidd didn't know whether certain situations—such as being asked to sit in a room and look at a series of pictures—might induce people to put the same elements in the same order. They kept their instructions minimal so as not to cue people to use one order over another, and they ran the study with 46 Murrinhpatha speakers.\nThe experimenters showed pictures of an event—a woman washing a child, a crocodile about to bite a man, a kangaroo punching a cow—on a laptop screen and asked the participants to describe what they saw. Before each picture appeared, the speakers were asked to look at a black dot that appeared randomly in the center or to one side of the screen so they wouldn't be inadvertently focused on any character. Then a short tone played, and the picture appeared. As participants assessed the scene and spoke, an infrared tracker that sat below the screen recorded their eye movements.\nThe results were stunning. The Murrinhpatha speakers did something completely new. It was like Tseltal, Nordlinger says, in that the speakers were looking evenly across both characters in a scene, but the Murrinhpatha speakers were doing it much faster and much earlier. It was very rapid relational encoding. “What's amazing,” Nordlinger says, “is that they were doing so much in the first 600 milliseconds.”\nIn that initial window the Murrinhpatha speakers were looking evenly back and forth across both characters in the scene, getting a sense of the entire event. Then, once they had decided which word order they were going to use, they started to look primarily at the character they mentioned first. At that point a person who produced a sentence that started with, say, the woman instead of the child spent more time looking at the woman. If instead they produced a sentence that started with the child, they spent more time looking at the child. Essentially, Nordlinger explains, “what a speaker looked at first in a sustained way after the initial 400-millisecond window was the thing that they mentioned first.”\nThe outcome was not a matter of a speaker simply mentioning the first thing their eye fell on. Sometimes speakers first looked at one of the figures in the picture but then spent sustained time looking at the other figure—and it was the second figure who featured as the first element of their sentence.\nThe researchers also found that every individual Murrinhpatha speaker had, on average, more than five and a half different ways of ordering the subject, verb and object of a sentence. Nordlinger had always argued that many Australian languages had free word order, unlike other languages. German, she says, is often described as having free word order, but when the same experiment was run in German by another researcher, speakers used the same order more than 75 percent of the time. For the Murrinhpatha speakers, word order was truly free. Across the entire set of possible responses, the Murrinhpatha speakers produced 10 possible word orders. There was no preferred order.\nFor example, in response to a picture of a falling man whose outstretched leg projects toward the gaping jaws of a crocodile—a picture where, essentially, a crocodile is about to bite a man—Murrinhpatha speakers offered the following sentences:\nWhy did Murrinhpatha speakers bounce back and forth between subject and object faster than the speakers of any other language? Nordlinger and Kidd suspect that when someone speaks a language that has a truly free word order, they are under pressure to swiftly make decisions about the sentence they will say. “You have to get your head around the whole event much earlier so that you can decide how you want to express it,” Nordlinger says.\nDid Murrinhpatha's polysynthetic verb structure affect the pattern of language processing? To answer this question, Sasha Wilmoth, who was then one of Nordlinger's Ph.D. students, ran the experiment with speakers of Pitjantjatjara. The language is spoken by people in the Anangu Pitjantjatjara Yankunytjatjara lands, where South Australia abuts the Northern Territory. Pitjantjatjara also has free word order, but unlike Murrinhpatha, the language is not polysynthetic. Excitingly, Wilmoth got the same results.\nThe Pitjantjatjara speakers spent the first 600 milliseconds rapidly shifting back and forth between the two characters in the depicted scene and then started to focus primarily on the character that became the first element of their sentence. And like the Murrinhpatha speakers, the Pitjantjatjara speakers used a range of word orders, with each individual speaker using multiple word orders across the collection of pictures and the entire group using all the possibilities.\nAll human brains are of course the same, Nordlinger emphasized. But when people are putting thoughts into words, their mental processes may be different, depending on the language they are using.\nTo be fair to Whorf, even if his claims about Hopi were incorrect, there was significant merit in the questions he posed. Nordlinger and her colleagues focused on the impact of free word order at a critical moment in forming a sentence. Yet sentence structure is only one aspect of the complex, multipart system that is language. The question of how much language may influence thought should in fact be many questions.\nGary Lupyan, a psychology professor at the University of Wisconsin–Madison, says that words can organize the way we think about the world and shape the way we perceive it. In a recent experiment, he and his colleagues measured how hard it was for English speakers to assign circles colored in diverse ways to a random category (such as “A” or “B”) if the colors were easy to name (for instance, “red” or “blue”) or hard to name (“slightly neutral lavender” or “light dusty rose”). All the colors, regardless of how nameable they were in English, were equally easy to discriminate visually from one another. Even so, Lupyan and his colleagues found strong differences in participants' ability to learn which circles went into the different categories based on how easily nameable the colors were.\nThe vocabularies of languages are “systems of categories,” Lupyan explains. “Language entrains us into these systems, one set of categories versus another.” For speakers of different languages, he says, “many of these categories then become entrenched as basic units of thought.” With Lera Boroditsky of the University of California, San Diego, a cognitive scientist who has long pursued these questions, Lupyan and others recently surveyed a large set of studies on the effects of language on visual perception. They found compelling evidence that language influences our ability to discriminate colors.\nFor Murrinhpatha, beyond the window that Nordlinger, Kidd and their colleagues have opened on how the language is produced, we cannot say without rigorous research how individual speakers' perception might be further shaped by their language. Yet we can clearly see, Nordlinger says, that over time the culture has shaped the structure of the language. “Kinship has central importance in Murrinhpatha culture, and we see that encoded in the grammatical structure,” she explains. “When you're talking about a group of people in Murrinhpatha, you have to inflect the verb according to whether the people are related as siblings or not.”\nSimilarly, Murrinhpatha divides all nouns into 10 different classes. Nordlinger asks her students what 10 categories they would use if they were going to divide up all the objects in their language. (English doesn't have categories of nouns that are grammatically differentiated.) The Murrinhpatha noun classes are: familiar humans; all other animate beings; vegetables and other plant-based foods; language and knowledge; water; place and time; spears (used for hunting and ceremonies); weapons; inanimate things; and fire. Things become grammatical, Nordlinger notes, when people talk about them a lot.\nCulture shapes language because what matters to a culture often becomes embedded in its language, sometimes as words and sometimes codified in its grammar. Yet it is also true that in varying ways a language may shape the attention and thoughts of its speakers. Language and culture form a feedback loop, or rather they form many, many feedback loops.\nAt one level, of course, we already understand this reasoning. Over the minutes and days of our lives, we see how perception and judgment and words wind together and influence one another. But as Nordlinger, Lupyan and their colleagues show, some of those loops form tight millisecond whorls that tie together our instantaneous perception of the world and our habitual way of framing it in words. There are much larger interconnected loops, too, that bind speakers throughout history. The things distant generations discussed may shape the structure of a speaker's language today, and that in turn may influence at the micro level how that speaker assesses the world and produces words to describe it.\nTo Perdjert, the language comes first—because that is how she and other elders pass on sacred knowledge to their young people. But language, culture and knowledge are actually forever entwined and integral to one another. Murrinhpatha, she and Bunduck explain to me, is translated as “Murrinh,” meaning “language,” and “patha,” meaning “good”: good language. “Strong language,” Perdjert says.\nWhat's clear now is that the more we ask empirical questions about language and its many loops in all the world's languages, the more we will know about the diverse ways there are to think like a human.\nEven as researchers devise ways to explore all the corners of the language universe, it is shrinking at a frightening rate. The Language Conservancy, a nonprofit organization founded by Indigenous educators and activists in the U.S., estimates that 61 percent of languages around the world that were spoken as a first language in 1795 “are doomed or extinct.” Early in Nordlinger's career, when she worked with a community that spoke Wambaya, another non-Pama-Nyungan language used in the Barkly Tablelands of Australia's Northern Territory, the elders requested that the work be done so younger generations would have a chance to learn the language of their ancestors. At the time there were eight or 10 fluent speakers remaining. All have since died.\nA deeper understanding of Murrinhpatha may help here, too. As with other Australian language communities, there are many Indigenous-guided efforts to maintain the language. Linguists and educators, including Nordlinger, work with the people of Wadeye to support their learning goals and to contribute to a constantly evolving understanding of the language.\nScholars at the Research Unit for Indigenous Language have studied how children first acquire Murrinhpatha, with a view to informing how the language is taught in school. They have worked with Perdjert and other elders to run Murrinhpatha literacy programs in a Darwin prison and have explored how children tell stories in Murrinhpatha. They have tracked how the language has changed over three generations, finding that its grammar has not been influenced by English, although—as all languages do—it has changed in that time. The Literature Production Center at the Wadeye community school works with locals to produce bilingual curriculum materials to support children's Murrinhpatha literacy as much as their English literacy. Being able to read and write Murrinhpatha as well as speak it gives the children confidence, Perdjert says.\nBut even before the children get to school, Perdjert and Bunduck explain, elders take them out to the bush and sit with them around a fire to “teach them in language.” They describe the natural world and tell stories from the dreaming about the beings that created their world. Bunduck also teaches the songlines, stories in ceremonial song that include sacred sites and the routes ancient beings took across the land. When Bunduck learned the songlines from his grandparents, it was a gift they gave him, he says. Now he passes on the songlines to youths in the next generation, giving that gift to them.\nThis article was originally published with the title \"How Grammar Changes Perception\" in Scientific American  329, 4, 48-59 (November 2023)\ndoi:10.1038/scientificamerican1123-48\nHow Language Shapes Thought. Lera Boroditsky; February 2011.\nChristine Kenneally is an award-winning journalist and author. Her most recent book is Ghosts of the Orphanage (PublicAffairs, 2023).Credit: Nick Higgins\nAlexandra Witze and Nature magazine\nChristine Kenneally\nJosh Fischman, Tanya Lewis, Jeffery DelViscio and Elah Feder\nErika Engelhaupt\nDaniel Lingenhöhl\nGeoffrey H. Fettus | Opinion\nDiscover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners.\nFollow us\nScientific american arabic\n© 2023 Scientific American, a Division of Springer Nature America, Inc.\nAll Rights Reserved.\nSupport science journalism.\nThanks for reading Scientific American. Knowledge awaits.\nAlready a subscriber? Sign in.\nThanks for reading Scientific American. Create your free account or Sign in to continue.\nSee Subscription Options\nContinue reading with a Scientific American subscription.\nYou may cancel at any time."}
